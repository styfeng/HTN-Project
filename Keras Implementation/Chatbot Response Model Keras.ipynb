{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# things we need for NLP\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# things we need for Tensorflow\n",
    "import numpy as np\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Activation, Dense, Dropout, Flatten\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: ['a', 'abdom', 'about', 'ach', 'achiev', 'act', 'aft', 'ago', 'al', 'allergenswhy', 'almost', 'alon', 'along', 'alot', 'already', 'also', 'although', 'alway', 'am', 'an', 'and', 'angry', 'ankl', 'annoy', 'antibiot', 'any', 'anyth', 'ap', 'appear', 'appetit', 'appl', 'ar', 'area', 'arm', 'armp', 'around', 'as', 'at', 'away', 'back', 'bad', 'bank', 'bar', 'be', 'becam', 'becaus', 'becom', 'been', 'beg', 'begin', 'believ', 'bend', 'between', 'big', 'bit', 'blee', 'blist', 'blo', 'block', 'blood', 'bloody', 'body', 'bre', 'brea', 'breast', 'bright', 'bump', 'bunch', 'burn', 'but', 'by', 'cafeter', 'cal', 'can', 'catch', 'caught', 'challeng', 'chang', 'chest', 'chlamydia', 'chronic', 'cle', 'cloud', 'coat', 'cold', 'com', 'coma', 'commun', 'complet', 'concern', 'condit', 'conformatbl', 'confus', 'congest', 'conscy', 'const', 'constip', 'cont', 'contact', 'continu', 'coordin', 'cough', 'could', 'couldnt', 'cramp', 'cri', 'cry', 'cyc', 'cystit', 'day', 'daysit', 'decreas', 'depress', 'develop', 'diarrhe', 'did', 'didnt', 'diet', 'difficul', 'difficult', 'dimin', 'din', 'dirty', 'discharg', 'discov', 'diseas', 'dizzy', 'do', 'doct', 'doe', 'doing', 'dont', 'down', 'dread', 'drowsy', 'dry', 'dur', 'eat', 'ejac', 'end', 'enemy', 'entir', 'erect', 'ev', 'every', 'everyth', 'exceiv', 'expery', 'expiery', 'extr', 'extrem', 'ey', 'eyebal', 'fac', 'facesh', 'faimili', 'fal', 'famili', 'fat', 'fatigu', 'feath', 'feel', 'felt', 'fev', 'few', 'fing', 'fish', 'fix', 'flak', 'flow', 'food', 'for', 'forehead', 'found', 'frequ', 'friend', 'from', 'ful', 'funny', 'furtherm', 'gabriel', 'gam', 'gas', 'gav', 'genit', 'get', 'girlfriend', 'gland', 'go', 'going', 'got', 'gre', 'grind', 'groin', 'guess', 'gym', 'hack', 'had', 'hair', 'halfway', 'hamst', 'hand', 'hard', 'hardalmost', 'has', 'hav', 'he', 'head', 'headach', 'heartburn', 'heatburn', 'hell', 'hello', 'help', 'her', 'hey', 'hi', 'high', 'him', 'his', 'hom', 'hous', 'how', 'hurt', 'i', 'ic', 'if', 'il', 'im', 'import', 'in', 'indigest', 'infect', 'inflam', 'init', 'insid', 'instead', 'intercours', 'into', 'invert', 'irrit', 'is', 'it', 'itch', 'itchy', 'iv', 'joint', 'judg', 'jungl', 'just', 'kept', 'know', 'lack', 'last', 'lat', 'leav', 'lif', 'light', 'lik', 'lip', 'liquid', 'littl', 'lookdiff', 'loss', 'lot', 'loud', 'low', 'lump', 'lumpy', 'lymph', 'maintain', 'many', 'mat', 'may', 'me', 'meal', 'meas', 'mem', 'might', 'mild', 'milky', 'min', 'mir', 'misplac', 'miss', 'month', 'monthwh', 'mood', 'mor', 'morn', 'mosquito', 'most', 'moth', 'mou', 'mov', 'movy', 'much', 'musc', 'my', 'myself', 'naus', 'nause', 'near', 'neck', 'nee', 'nev', 'next', 'night', 'nippl', 'nipplesshould', 'no', 'nor', 'nos', 'not', 'numb', 'obsess', 'occas', 'occass', 'occur', 'of', 'off', 'oft', 'on', 'onset', 'ont', 'op', 'or', 'oth', 'out', 'ov', 'pain', 'paralys', 'park', 'part', 'past', 'pay', 'pee', 'peel', 'pen', 'peopl', 'period', 'person', 'pick', 'pink', 'piss', 'plac', 'plan', 'play', 'pool', 'poop', 'prep', 'pretty', 'pric', 'problem', 'project', 'prop', 'puberty', 'puffy', 'puk', 'purg', 'quit', 'random', 'rapid', 'rash', 'raz', 'real', 'rec', 'red', 'refus', 'rel', 'rememb', 'rend', 'rep', 'report', 'requir', 'resta', 'restrict', 'retriev', 'room', 'runny', 'sad', 'sandwich', 'saw', 'say', 'scal', 'school', 'seem', 'sens', 'sensationâ€i', 'sery', 'sev', 'sex', 'shap', 'shiver', 'short', 'should', 'show', 'shredding', 'sid', 'singl', 'sint', 'siz', 'skin', 'slight', 'smal', 'sneez', 'sniff', 'so', 'socc', 'solv', 'som', 'someon', 'someth', 'sometim', 'sor', 'sour', 'spat', 'speak', 'spot', 'standup', 'start', 'stay', 'stiff', 'stomach', 'straight', 'strange', 'street', 'stuffy', 'sunk', 'suppos', 'sur', 'surrend', 'surround', 'swallow', 'swel', 'swim', 'swing', 'swol', 'symptom', 'tak', 'talk', 'task', 'tast', 'tear', 'temp', 'tend', 'tenderswol', 'testic', 'that', 'the', 'them', 'then', 'ther', 'thes', 'they', 'thi', 'thin', 'thing', 'think', 'thos', 'though', 'thought', 'three', 'throat', 'through', 'througout', 'tight', 'tim', 'tir', 'to', 'today', 'toilet', 'too', 'touch', 'transmit', 'trip', 'troubl', 'turn', 'uncomfort', 'uncontrol', 'understand', 'up', 'urg', 'urin', 'useless', 'vagin', 'very', 'vessel', 'vis', 'visit', 'vomit', 'walk', 'want', 'was', 'washroom', 'watery', 'we', 'weak', 'wear', 'week', 'weekend', 'weight', 'weird', 'wel', 'went', 'wer', 'what', 'when', 'wher', 'which', 'whil', 'whit', 'why', 'with', 'withdraw', 'wok', 'wont', 'worry', 'would', 'writ', 'wrong', 'yellowgreen', 'yesterday', 'you', 'zoo']\n",
      "classes: ['Allergies', 'Alzheimer', 'Breast Cancer', 'Chickenpox', 'Chlamydia', 'Common Cold', 'Conjunctivitis', 'Coronary Heart Disease', 'E Coli Infection', 'Eating Disorders including Anorexia & Bulimia Nervosa', 'Hepatitis B', 'Pregnancy', 'Prostate Cancer', 'West Nile Virus']\n",
      "classes details: [{'class': 'Common Cold', 'synonyms': 'Upper Respiratory Tract;Nose and Throat Infection', 'treatments': 'Stay hydrated;rest;sooth a sore throat using saltwater gargle;take over the counter cold and cough medications\\n', 'danger level': '1'}, {'class': 'Allergies', 'synonyms': 'Allergic Reaction', 'treatments': 'Remove the cause of allergy; \\notherwise take Antihistamines to relieve sneezing;Decongestants to relieve congestions in nasal membranes;Anti inflamary agents to reduce;Allergy shots', 'danger level': '1'}, {'class': 'Conjunctivitis', 'synonyms': 'Pink Eye', 'treatments': 'See a doctor;Bacterial cases can be treated with antibiotic eye drops;Allergic reactions can be treated with other eye dro', 'danger level': '1'}, {'class': 'E Coli Infection', 'synonyms': '', 'treatments': 'Visit a hospital immediately', 'danger level': '1'}, {'class': 'Chlamydia', 'synonyms': 'Sexually Transmitted Infection (STI)', 'treatments': 'See a professional doctor;Use Azithromycin or Doxycycline', 'danger level': '4'}, {'class': 'Hepatitis B', 'synonyms': 'Herpes', 'treatments': 'See a doctor immediately;Take antiviral drugs', 'danger level': '6'}, {'class': 'West Nile Virus', 'synonyms': '', 'treatments': 'Please see a healthcare professional;There are no specific treatments for West Nile Virus in humans', 'danger level': '8'}, {'class': 'Chickenpox', 'synonyms': 'Varicella Zoster Virus', 'treatments': 'Drink plenty of fluid;Take Tylenol;Consult with a doctor', 'danger level': '2'}, {'class': 'Alzheimer', 'synonyms': '', 'treatments': 'Cholinesterase inhibitors;Memantine(Namenda);Please consult with a professional doctor', 'danger level': '4'}, {'class': 'Pregnancy', 'synonyms': '', 'treatments': 'You are pregnant! Remember to take your prenatal vitamin;quit smoking;stop drinking alcohol;cut down on caffeine; avoid hazardous foods;eat well and sleep well!', 'danger level': '2'}, {'class': 'Eating Disorders including Anorexia & Bulimia Nervosa', 'synonyms': '', 'treatments': 'Seek help from a therapist, physician, and nutritionist', 'danger level': '3'}, {'class': 'Coronary Heart Disease', 'synonyms': '', 'treatments': 'quit smoking;have a healthy diet;exercise regularly;consult with a doctor', 'danger level': '7'}, {'class': 'Breast Cancer', 'synonyms': '', 'treatments': 'You may have breast cancer, please consult with a doctor and conduct further diagnostics at your local hospital', 'danger level': '10'}, {'class': 'Prostate Cancer', 'synonyms': '', 'treatments': 'You may have prostate cancer, please consult with a doctor and conduct further diagnostics at your local hospital', 'danger level': '10'}]\n"
     ]
    }
   ],
   "source": [
    "# restore all of our data structures\n",
    "import pickle\n",
    "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
    "words = data['words']\n",
    "print(\"words:\",words)\n",
    "classes = data['classes']\n",
    "print(\"classes:\",classes)\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "classes_details = data['classes_details']\n",
    "print(\"classes details:\",classes_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import urllib.request\n",
    "# import urllib.response\n",
    "# import sys\n",
    "# import os, glob\n",
    "# import http.client, urllib\n",
    "# import json\n",
    "# import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "\n",
    "# # Replace the accessKey string value with your valid access key.\n",
    "# accessKey = '82e4612615634c398bfd26e7d6327833'\n",
    "# url = 'westcentralus.api.cognitive.microsoft.com'\n",
    "# path = '/text/analytics/v2.0/keyPhrases'\n",
    "\n",
    "# def extract_keywords(body):\n",
    "#     headers = {'Ocp-Apim-Subscription-Key': accessKey}\n",
    "#     conn = http.client.HTTPSConnection(url)\n",
    "#     body_req = {'documents':[{'language': 'en', 'id': 1, 'text': body}]}\n",
    "#     body_json = json.dumps(body_req)\n",
    "#     conn.request (\"POST\", path, body_json, headers)\n",
    "#     response = conn.getresponse ()\n",
    "#     string = response.read().decode('utf-8')\n",
    "#     json_obj = json.loads(string)\n",
    "#     print(\"json_obj: \", json_obj)\n",
    "#     keyphrases_list = ((json_obj['documents'])[0])['keyPhrases']\n",
    "#     print(\"keyphrases_list: \", keyphrases_list)\n",
    "#     return keyphrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a table structure to hold the different punctuation used\n",
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                    if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "## method to remove punctuations from sentences.\n",
    "def remove_punctuation(text):\n",
    "     return text.translate(tbl)\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    #strip punctuations, numbers, and words containing numbers\n",
    "    no_punct = remove_punctuation(sentence)\n",
    "    no_nums1 = ' '.join(s for s in no_punct.split() if not any(c.isdigit() for c in s))\n",
    "    no_nums2 = re.sub(r'\\d+', '', no_nums1)\n",
    "#     keywords = extract_keywords(no_nums2)\n",
    "#     keyword_str = ' '.join(s for s in keywords)\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(no_nums2)\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    print(\"sentence after stemming: \", sentence_words)\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if w == s: \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence after stemming:  ['i', 'hav', 'rec', 'had', 'a', 'very', 'runny', 'and', 'stuffy', 'nos', 'the', 'last', 'few', 'day', 'my', 'throat', 'has', 'also', 'been', 'very', 'sor', 'and', 'i', 'hav', 'also', 'develop', 'a', 'sev', 'cough', 'with', 'lot', 'of', 'sneez']\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 0]\n",
      "['Allergies', 'Alzheimer', 'Breast Cancer', 'Chickenpox', 'Chlamydia', 'Common Cold', 'Conjunctivitis', 'Coronary Heart Disease', 'E Coli Infection', 'Eating Disorders including Anorexia & Bulimia Nervosa', 'Hepatitis B', 'Pregnancy', 'Prostate Cancer', 'West Nile Virus']\n"
     ]
    }
   ],
   "source": [
    "p = bow(\"I have recently had a very runny and stuffy nose. The last few days, my throat has also been very sore and I have also developed a severe cough with lots of sneezing\", words)\n",
    "print (p)\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our saved model\n",
    "model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i=0\n",
    "# for x_t in x_tokenized:\n",
    "#     prediction = model.predict(np.array([x_t]))\n",
    "#     predicted_label = labels[np.argmax(prediction[0])]\n",
    "#     print(\"File ->\", test_files[i], \"Predicted label: \" + predicted_label)\n",
    "#     i += 1\n",
    "\n",
    "\n",
    "ERROR_THRESHOLD = 0.01\n",
    "def classify(sentence):\n",
    "    # generate probabilities from the model\n",
    "    prediction = model.predict(np.array([bow(sentence, words)]))\n",
    "    #print(results)\n",
    "    # filter out predictions below a threshold\n",
    "    top_values = [classes[i] for i in np.argsort(prediction[0])[-3:]]\n",
    "    top_vals_reversed = top_values[::-1]\n",
    "    predicted_class = classes[np.argmax(prediction[0])]\n",
    "    # sort by strength of probability\n",
    "    print(\"#1 predicted class: \" + predicted_class)\n",
    "    print(\"Top Values: \",top_vals_reversed)\n",
    "\n",
    "def more_response(key):\n",
    "    if key in [\"yes\", \"of course\", \"sure\", \"certainly\", \"absolutely\", \"yeah\", \"yep\", \"yup\", \"ya\", \"yea\", \"aye\"]:\n",
    "        sentence_new = input(\"Okay, please tell me any possible symptoms. The more details, the better!\")\n",
    "        return response(sentence_new,0)\n",
    "    elif key in [\"negative\", \"nope\", \"no\", \"nah\", \"no way\", \"nay\"]:\n",
    "        return print(\"Okay, thanks for visiting iDoctor. Enjoy the rest of your day!\")\n",
    "    else:\n",
    "        more = input(\"Sorry, I couldn't understand that. Would you like more diagnosis?\")\n",
    "        return more_response(more.strip().lower())\n",
    "\n",
    "def response(sentence, counter):\n",
    "    if counter <= 2:\n",
    "        results = classify(sentence)\n",
    "    # if we have a classification then find the matching intent tag\n",
    "        #if results and len(sentence) >= 10:\n",
    "            # loop as long as there are matches to process\n",
    "            #print(\"Here are some likely conditions you may have:\\n\")\n",
    "            #for i in range(0,min(3,len(results))):\n",
    "                #print((results[i])[0] + \": \" + classes_details[(results[i])[0]])\n",
    "           # more = input(\"Is there anything else you would like me to diagnose?\")\n",
    "            #return more_response(more.strip().lower())\n",
    "#         else:\n",
    "#             counter += 1\n",
    "#             sentence_add = input(\"Unfortunately, I do not have enough information. Please tell me more!\")\n",
    "#             sentence = sentence + \" \" + sentence_add\n",
    "#             print(\"SENTENCE UP UNTIL THIS POINT: \" + sentence)\n",
    "#             return response(sentence, counter)\n",
    "    else:\n",
    "        total_responses = \"\"\n",
    "        return print(\"Unfortunately, I cannot help diagnose your medical condition. Please consult a medical professional such as your family doctor. Enjoy the rest of your day!\")\n",
    "\n",
    "def main():\n",
    "    print(\"Hi there, my name is iDoctor. Today I will be helping to diagnose any possible medical conditions you may have. Let's get started!\")\n",
    "    name = input(\"Firstly, what is your name?\")\n",
    "    sentence = input(\"Hi \" + name + \"! Please tell me how you are feeling, and any possible symptoms you may be experiencing. The more details, the better!\")\n",
    "    response(sentence, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence after stemming:  ['a', 'few', 'day', 'ago', 'i', 'went', 'to', 'my', 'friend', 'hous', 'i', 'end', 'up', 'get', 'sweaty', 'and', 'itchy', 'ey', 'and', 'rub', 'them', 'too', 'much', 'caus', 'a', 'lot', 'of', 'red', 'of', 'ey']\n",
      "#1 predicted class: Conjunctivitis\n",
      "Top Values:  ['Conjunctivitis', 'E Coli Infection', 'Allergies']\n"
     ]
    }
   ],
   "source": [
    "classify(\"A few days ago, I went to my friend's house. I ended up getting sweaty and itchy eyes, and rubbing them too much caused a lot of redness of eyes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'abdom', 'about', 'ach', 'achiev', 'act', 'aft', 'ago', 'al', 'allergenswhy', 'almost', 'alon', 'along', 'alot', 'already', 'also', 'although', 'alway', 'am', 'an', 'and', 'angry', 'ankl', 'annoy', 'antibiot', 'any', 'anyth', 'ap', 'appear', 'appetit', 'appl', 'ar', 'area', 'arm', 'armp', 'around', 'as', 'at', 'away', 'back', 'bad', 'bank', 'bar', 'be', 'becam', 'becaus', 'becom', 'been', 'beg', 'begin', 'believ', 'bend', 'between', 'big', 'bit', 'blee', 'blist', 'blo', 'block', 'blood', 'bloody', 'body', 'bre', 'brea', 'breast', 'bright', 'bump', 'bunch', 'burn', 'but', 'by', 'cafeter', 'cal', 'can', 'catch', 'caught', 'challeng', 'chang', 'chest', 'chlamydia', 'chronic', 'cle', 'cloud', 'coat', 'cold', 'com', 'coma', 'commun', 'complet', 'concern', 'condit', 'conformatbl', 'confus', 'congest', 'conscy', 'const', 'constip', 'cont', 'contact', 'continu', 'coordin', 'cough', 'could', 'couldnt', 'cramp', 'cri', 'cry', 'cyc', 'cystit', 'day', 'daysit', 'decreas', 'depress', 'develop', 'diarrhe', 'did', 'didnt', 'diet', 'difficul', 'difficult', 'dimin', 'din', 'dirty', 'discharg', 'discov', 'diseas', 'dizzy', 'do', 'doct', 'doe', 'doing', 'dont', 'down', 'dread', 'drowsy', 'dry', 'dur', 'eat', 'ejac', 'end', 'enemy', 'entir', 'erect', 'ev', 'every', 'everyth', 'exceiv', 'expery', 'expiery', 'extr', 'extrem', 'ey', 'eyebal', 'fac', 'facesh', 'faimili', 'fal', 'famili', 'fat', 'fatigu', 'feath', 'feel', 'felt', 'fev', 'few', 'fing', 'fish', 'fix', 'flak', 'flow', 'food', 'for', 'forehead', 'found', 'frequ', 'friend', 'from', 'ful', 'funny', 'furtherm', 'gabriel', 'gam', 'gas', 'gav', 'genit', 'get', 'girlfriend', 'gland', 'go', 'going', 'got', 'gre', 'grind', 'groin', 'guess', 'gym', 'hack', 'had', 'hair', 'halfway', 'hamst', 'hand', 'hard', 'hardalmost', 'has', 'hav', 'he', 'head', 'headach', 'heartburn', 'heatburn', 'hell', 'hello', 'help', 'her', 'hey', 'hi', 'high', 'him', 'his', 'hom', 'hous', 'how', 'hurt', 'i', 'ic', 'if', 'il', 'im', 'import', 'in', 'indigest', 'infect', 'inflam', 'init', 'insid', 'instead', 'intercours', 'into', 'invert', 'irrit', 'is', 'it', 'itch', 'itchy', 'iv', 'joint', 'judg', 'jungl', 'just', 'kept', 'know', 'lack', 'last', 'lat', 'leav', 'lif', 'light', 'lik', 'lip', 'liquid', 'littl', 'lookdiff', 'loss', 'lot', 'loud', 'low', 'lump', 'lumpy', 'lymph', 'maintain', 'many', 'mat', 'may', 'me', 'meal', 'meas', 'mem', 'might', 'mild', 'milky', 'min', 'mir', 'misplac', 'miss', 'month', 'monthwh', 'mood', 'mor', 'morn', 'mosquito', 'most', 'moth', 'mou', 'mov', 'movy', 'much', 'musc', 'my', 'myself', 'naus', 'nause', 'near', 'neck', 'nee', 'nev', 'next', 'night', 'nippl', 'nipplesshould', 'no', 'nor', 'nos', 'not', 'numb', 'obsess', 'occas', 'occass', 'occur', 'of', 'off', 'oft', 'on', 'onset', 'ont', 'op', 'or', 'oth', 'out', 'ov', 'pain', 'paralys', 'park', 'part', 'past', 'pay', 'pee', 'peel', 'pen', 'peopl', 'period', 'person', 'pick', 'pink', 'piss', 'plac', 'plan', 'play', 'pool', 'poop', 'prep', 'pretty', 'pric', 'problem', 'project', 'prop', 'puberty', 'puffy', 'puk', 'purg', 'quit', 'random', 'rapid', 'rash', 'raz', 'real', 'rec', 'red', 'refus', 'rel', 'rememb', 'rend', 'rep', 'report', 'requir', 'resta', 'restrict', 'retriev', 'room', 'runny', 'sad', 'sandwich', 'saw', 'say', 'scal', 'school', 'seem', 'sens', 'sensationâ€i', 'sery', 'sev', 'sex', 'shap', 'shiver', 'short', 'should', 'show', 'shredding', 'sid', 'singl', 'sint', 'siz', 'skin', 'slight', 'smal', 'sneez', 'sniff', 'so', 'socc', 'solv', 'som', 'someon', 'someth', 'sometim', 'sor', 'sour', 'spat', 'speak', 'spot', 'standup', 'start', 'stay', 'stiff', 'stomach', 'straight', 'strange', 'street', 'stuffy', 'sunk', 'suppos', 'sur', 'surrend', 'surround', 'swallow', 'swel', 'swim', 'swing', 'swol', 'symptom', 'tak', 'talk', 'task', 'tast', 'tear', 'temp', 'tend', 'tenderswol', 'testic', 'that', 'the', 'them', 'then', 'ther', 'thes', 'they', 'thi', 'thin', 'thing', 'think', 'thos', 'though', 'thought', 'three', 'throat', 'through', 'througout', 'tight', 'tim', 'tir', 'to', 'today', 'toilet', 'too', 'touch', 'transmit', 'trip', 'troubl', 'turn', 'uncomfort', 'uncontrol', 'understand', 'up', 'urg', 'urin', 'useless', 'vagin', 'very', 'vessel', 'vis', 'visit', 'vomit', 'walk', 'want', 'was', 'washroom', 'watery', 'we', 'weak', 'wear', 'week', 'weekend', 'weight', 'weird', 'wel', 'went', 'wer', 'what', 'when', 'wher', 'which', 'whil', 'whit', 'why', 'with', 'withdraw', 'wok', 'wont', 'worry', 'would', 'writ', 'wrong', 'yellowgreen', 'yesterday', 'you', 'zoo']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'coremltools'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-42c7c24c3be7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcoremltools\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcoreml_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoremltools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclass_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"successfully loaded keras model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcoremltools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_spec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoreml_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'my_model.mlmodel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'coremltools'"
     ]
    }
   ],
   "source": [
    "import coremltools\n",
    "coreml_model = coremltools.converters.keras.convert('my_model.h5',class_labels=classes)\n",
    "print(\"successfully loaded keras model\")\n",
    "\n",
    "coremltools.utils.save_spec(coreml_model, 'my_model.mlmodel')\n",
    "print(\"successfully saved coreML model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
