{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "# things we need for NLP\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "from nltk.corpus import wordnet\n",
    "syns = wordnet.synsets(\"program\")\n",
    "\n",
    "# things we need for Tensorflow\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.response\n",
    "import sys\n",
    "import os, glob\n",
    "import http.client, urllib\n",
    "import json\n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "\n",
    "# Replace the accessKey string value with your valid access key.\n",
    "accessKey = '82e4612615634c398bfd26e7d6327833'\n",
    "url = 'westcentralus.api.cognitive.microsoft.com'\n",
    "path = '/text/analytics/v2.0/keyPhrases'\n",
    "\n",
    "def extract_keywords(body):\n",
    "    headers = {'Ocp-Apim-Subscription-Key': accessKey}\n",
    "    conn = http.client.HTTPSConnection(url)\n",
    "    body_req = {'documents':[{'language': 'en', 'id': 1, 'text': body}]}\n",
    "    body_json = json.dumps(body_req)\n",
    "    conn.request (\"POST\", path, body_json, headers)\n",
    "    response = conn.getresponse ()\n",
    "    string = response.read().decode('utf-8')\n",
    "    json_obj = json.loads(string)\n",
    "    print(\"json_obj: \", json_obj)\n",
    "    keyphrases_list = ((json_obj['documents'])[0])['keyPhrases']\n",
    "    print(\"keyphrases_list: \", keyphrases_list)\n",
    "    return keyphrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 total classes in training data\n",
      "Common Cold | Upper Respiratory Tract;Nose and Throat Infection | Hi, I have a runny nose all the time and I don't know what to do about it. I was sniffing all the time in the past few days and it was getting very annoying;One of my nausal was blocked and I couldn't breath properly;My throat hurts after a cold shower last night, I am not sure what to do about it;It feels like there was something in my throat and I've been dry coughing for several days already;I recently developed a condition that requires frequent washroom visits througout the day;I am so tired this morning, every single one of my muscle hurts so much;All my joints are sour since last morning;I feel so cold all the time, I sneezed all the time | Stay hydrated;rest;sooth a sore throat using saltwater gargle;take over the counter cold and cough medications\n",
      " | 1\n",
      "Allergies | Allergic Reaction | After the soccer game yesterday, I found small bumps on my skin and extreme itchiness;When I was playing with my friends today, it felt like I had something in my eyes and i was crying uncontrollably;My nose were going off in the park the other day, and I kept sniffing the entire time;Sometimes I could not breath through one of my nose and it feels like it was blocked;When I was walking in the park this morning, I kept sneezing around the flowers even though I am not cold;In the zoo today, it felt like I have a feather or something in my throat the entire day, it was really itchy and I coughed the entire day;I picked a flower today and the part of my hand that touched the flower became swollen, I can barely bend it and it feels numb | Remove the cause of allergy; \n",
      "otherwise take Antihistamines to relieve sneezing;Decongestants to relieve congestions in nasal membranes;Anti inflamary agents to reduce;Allergy shots | 1\n",
      "Conjunctivitis | Pink Eye | I stayed up for a full night grinding Hack the North project and the next morning my eye was bright red. All the blood vessels in my blood were visible;My eyes were really itchy this morning when I woke up and it was pink when I saw it through the mirror;After swimming in the community swimming pool this week, I felt a burning sensation in my eye and i cried uncontrollably. | See a doctor;Bacterial cases can be treated with antibiotic eye drops;Allergic reactions can be treated with other eye dro | 1\n",
      "E Coli Infection |  | I went to a dirty restaurant a few days ago, and I began to feel dizzy this morning initially, later I puked everything out; After eating some street food, I started to feel dizzy, weak and tired all the time, furthermore I began to catch a fever halfway through the week too;I went to the washroom alot more frequently recently and I saw blood in my toilet, I think I might be pooping blood; My stomach hurts after a meal of funny tasting fish in the school cafeteria, it hurts so much that I can barely standup straight. I also vomitted after the meal and constantly tired | Visit a hospital immediately | 1\n",
      "Chlamydia | Sexually Transmitted Infection (STI) | I saw some yellow-green discharge, light bleeding between my periods and an occasional burning sensation while urinating. Are those symptoms of chlamydia or a sexually transmitted infection;Hi, I recently experience  a burning sensation while peeing, frequent urination or a yellow-green discharge, sometimes, even difficulty urinating;I recently have trouble going to the washroom because my genital areas hurt during urination and they sometimes swell up randomly. | See a professional doctor;Use Azithromycin or Doxycycline | 4\n",
      "Hepatitis B | Herpes | Hello, I had this burning sensationâ€”I thought it was cystitis. I went to the doctor and he gave me some antibiotics. But it didn't go away. Then, a few days later, I got some blisters on my vagina, all along my lips, what is that blister;I think I got some skin irritation, razor burn or just some random itch, but they repeat once every a few month,what are those? | See a doctor immediately;Take antiviral drugs | 6\n",
      "West Nile Virus |  | I visited the jungle a few days ago and I got a strange bite because it didn't go away. A few days later, I began to develop a fever and muscle weakness, what should I do?;I discovered a weird mosquito bite on my hand that does not go away, but instead it swell and my hand is numb; My roommate has a weird bite on his forehead, He caught a fever and was confused about his surroundings. He experiences vision loss and fall into occassional comas. What should I do about him?;I have a minor headache, vomiting and I saw red rashes all over my back, chest and stomach | Please see a healthcare professional;There are no specific treatments for West Nile Virus in humans | 8\n",
      "Chickenpox | Varicella Zoster Virus | hey there. i have been feeling extremely bad lately, with a fever developing the past few days;i have been getting lot of blisters and rashes on my body recently. my mouth has also been very sore in a lot of places and there has been itchiness all over my body;i went to my friend's house last night and ended up developing a fever and red spots al over my body. i couldn't even eat anything because i had no appetite, and started getting itchy all over my body;my mouth has been feeling bad lately, and i never feel like eating. my muscles have also been more sore lately even though i have not been to the gym, and my skin has become more itchy recently;blisters and rashes have appeared all over my body recently, and they have all started to itch. my arms and hamstrings are also starting to ache and i believe i may be developing a fever because my temperature is high from the last measurement;red spots are appealing all over my arm, and they are feeling quite uncomfortable. just this morning, i ended up developing a fever and my mouth has felt very sore and uncomfortable;my friend gabrielle and i went to the the movies and i ended up developing rashes all over my body which turned into itchy spots. later that night, i also measured my temperature and had developed a fever. this morning, i cannot even move well because my muscles are aching greatly. | Drink plenty of fluid;Take Tylenol;Consult with a doctor | 2\n",
      "Alzheimer |  | I...can't remember;People say I've gotten angrier, and sometimes I do feel angry, although I don't know why;I couldn't remember her face...she was important to me but I could not, for the life of me, remember her face;Where did I leave my bank notes? It was just yesterday when I retrieved them;What did you say? Can you speak louder?;my muscles are also hurting and ache quite a lot. it's also weird because my mother was home last weekend and we prepared a big dinner, but i had no appetite;completing tasks and doing things has been very difficult lately, as i seem to not remember things i did in the past. doing things i was faimiliar with has been confusing and felt out of place, and it appears my spatial and visual senses are also diminishing | Cholinesterase inhibitors;Memantine(Namenda);Please consult with a professional doctor | 4\n",
      "Pregnancy |  | My back hurts so much just from walking around and my ankles are swollen too;Don't talk to me, just go away and leave me alone;My period is late by three days...it's almost never late;My side was cramping so hard, it felt like someone was shredding me inside out | You are pregnant! Remember to take your prenatal vitamin;quit smoking;stop drinking alcohol;cut down on caffeine; avoid hazardous foods;eat well and sleep well! | 2\n",
      "Eating Disorders including Anorexia & Bulimia Nervosa |  | No matter how little I eat, I get fatter;food is the enemy and I refuse to surrender;How many calories are in that sandwiche? I'll just take an apple instead;I feel so cold, even when I wear an extra coat;I purged myself clean today once more, just like I always have, except there was a burning sensation down my throat. I guess if that's the price I have to pay | Seek help from a therapist, physician, and nutritionist | 3\n",
      "Coronary Heart Disease |  | Recently my chest is feeling pretty tight and even numb at times. I have become light headed and dizzy for most of the day rendering me sad and useless. I also frequently vomit and expierience heartburn which is hella painful. Im really worried that I might have a serious disease and my indigestion is not helping. | quit smoking;have a healthy diet;exercise regularly;consult with a doctor | 7\n",
      "Breast Cancer |  | There are a bunch of red spots on my chest and I don't think I've contacted any allergens...why won't they go away;there are small bits of milky white liquid coming out of my nipples...should I be concerned?;Parts of my breast felt a bit hard...almost lumpy. Would this go away after puberty?;It just occurred to me today that my nipples look...different. Are they supposed to be sunken in? | You may have breast cancer, please consult with a doctor and conduct further diagnostics at your local hospital | 10\n",
      "Prostate Cancer |  | I've been feeling like I needed to go to the washroom more and more often these days;I'm beginning to dread my washroom trips these days because it hurts to urinate;When I went to piss this morning, there was blood and my piss was redish;What's wrong with me? Having sex with my girlfriend yesterday had hurt so much | You may have prostate cancer, please consult with a doctor and conduct further diagnostics at your local hospital | 10\n"
     ]
    }
   ],
   "source": [
    "# medical conditions training data\n",
    "training_data = []\n",
    "\n",
    "import csv\n",
    "\n",
    "# adds every medical condition along with associated info from csv file\n",
    "with open('Disease Database CSV NEW.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count != 0:\n",
    "            training_data.append({\"class\":row[1], \"synonyms\":row[2], \n",
    "                                  \"sentence\":row[3], \"treatments\":row[4], \"danger level\":row[5]})\n",
    "        line_count += 1\n",
    "\n",
    "print (\"%s total classes in training data\" % len(training_data))\n",
    "\n",
    "for term in training_data:\n",
    "    print(term[\"class\"] + \" | \" + term[\"synonyms\"] + \" | \" + term[\"sentence\"] + \n",
    "          \" | \" + term[\"treatments\"] + \" | \" + term[\"danger level\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a table structure to hold the different punctuation used\n",
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                    if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "# method to remove punctuations from sentences.\n",
    "def remove_punctuation(text):\n",
    "     return text.translate(tbl)\n",
    "\n",
    "# method to slice strings\n",
    "def slicer(my_str,sub):\n",
    "    index=my_str.find(sub)\n",
    "    if index !=-1 :\n",
    "         return my_str[index:] \n",
    "    else :\n",
    "         raise Exception('Sub string not found!')\n",
    "\n",
    "# # find synonyms of all the words in a sentence\n",
    "# def find_syns(sentence):\n",
    "#     words = []\n",
    "#     for word in sentence.split():\n",
    "#         if word != '':\n",
    "#             synonyms = []\n",
    "#             for syn in wordnet.synsets(word):\n",
    "#                 for l in syn.lemmas():\n",
    "#                     if l.name() not in synonyms and l.name() != word:\n",
    "#                         synonyms.append(l.name())\n",
    "#             word = (word + ' ' + ' '.join(synonyms)).strip()\n",
    "#             words.append(word)\n",
    "#     print(\"SYNONYMS:\",words)\n",
    "#     return words\n",
    "\n",
    "# # clean all synonyms and words\n",
    "# def clean_syns(arg):\n",
    "#     clean_synonyms = []\n",
    "#     for syn_set in synonyms:\n",
    "#         syn_set = ' '.join(s for s in syn_set.split() if not any(c.isdigit() for c in s))\n",
    "#         syn_set = re.sub(r'\\d+', '', syn_set)\n",
    "#         syn_set = syn_set.replace(\"_\",\" \")\n",
    "#         syn_set = remove_punctuation(syn_set)\n",
    "#         clean_synonyms.append(syn_set)\n",
    "#     print(\"CLEAN SYNONYMS: \",clean_synonyms)\n",
    "#     return clean_synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORD_LIST: [\"Hi, I have a runny nose all the time and I don't know what to do about it. I was sniffing all the time in the past few days and it was getting very annoying\", \"One of my nausal was blocked and I couldn't breath properly\", 'My throat hurts after a cold shower last night, I am not sure what to do about it', \"It feels like there was something in my throat and I've been dry coughing for several days already\", 'I recently developed a condition that requires frequent washroom visits througout the day', 'I am so tired this morning, every single one of my muscle hurts so much', 'All my joints are sour since last morning', 'I feel so cold all the time, I sneezed all the time']\n",
      "WORD_LIST_NEW: ['hi i have a runny nose all the time and i dont know what to do about it i was sniffing all the time in the past few days and it was getting very annoying', 'one of my nausal was blocked and i couldnt breath properly', 'my throat hurts after a cold shower last night i am not sure what to do about it', 'it feels like there was something in my throat and ive been dry coughing for several days already', 'i recently developed a condition that requires frequent washroom visits througout the day', 'i am so tired this morning every single one of my muscle hurts so much', 'all my joints are sour since last morning', 'i feel so cold all the time i sneezed all the time']\n",
      "joined_symps: hi i have a runny nose all the time and i dont know what to do about it i was sniffing all the time in the past few days and it was getting very annoying one of my nausal was blocked and i couldnt breath properly my throat hurts after a cold shower last night i am not sure what to do about it it feels like there was something in my throat and ive been dry coughing for several days already i recently developed a condition that requires frequent washroom visits througout the day i am so tired this morning every single one of my muscle hurts so much all my joints are sour since last morning i feel so cold all the time i sneezed all the time\n",
      "WORD_LIST: ['After the soccer game yesterday, I found small bumps on my skin and extreme itchiness', 'When I was playing with my friends today, it felt like I had something in my eyes and i was crying uncontrollably', 'My nose were going off in the park the other day, and I kept sniffing the entire time', 'Sometimes I could not breath through one of my nose and it feels like it was blocked', 'When I was walking in the park this morning, I kept sneezing around the flowers even though I am not cold', 'In the zoo today, it felt like I have a feather or something in my throat the entire day, it was really itchy and I coughed the entire day', 'I picked a flower today and the part of my hand that touched the flower became swollen, I can barely bend it and it feels numb']\n",
      "WORD_LIST_NEW: ['after the soccer game yesterday i found small bumps on my skin and extreme itchiness', 'when i was playing with my friends today it felt like i had something in my eyes and i was crying uncontrollably', 'my nose were going off in the park the other day and i kept sniffing the entire time', 'sometimes i could not breath through one of my nose and it feels like it was blocked', 'when i was walking in the park this morning i kept sneezing around the flowers even though i am not cold', 'in the zoo today it felt like i have a feather or something in my throat the entire day it was really itchy and i coughed the entire day', 'i picked a flower today and the part of my hand that touched the flower became swollen i can barely bend it and it feels numb']\n",
      "joined_symps: after the soccer game yesterday i found small bumps on my skin and extreme itchiness when i was playing with my friends today it felt like i had something in my eyes and i was crying uncontrollably my nose were going off in the park the other day and i kept sniffing the entire time sometimes i could not breath through one of my nose and it feels like it was blocked when i was walking in the park this morning i kept sneezing around the flowers even though i am not cold in the zoo today it felt like i have a feather or something in my throat the entire day it was really itchy and i coughed the entire day i picked a flower today and the part of my hand that touched the flower became swollen i can barely bend it and it feels numb\n",
      "WORD_LIST: ['I stayed up for a full night grinding Hack the North project and the next morning my eye was bright red. All the blood vessels in my blood were visible', 'My eyes were really itchy this morning when I woke up and it was pink when I saw it through the mirror', 'After swimming in the community swimming pool this week, I felt a burning sensation in my eye and i cried uncontrollably.']\n",
      "WORD_LIST_NEW: ['i stayed up for a full night grinding hack the north project and the next morning my eye was bright red all the blood vessels in my blood were visible', 'my eyes were really itchy this morning when i woke up and it was pink when i saw it through the mirror', 'after swimming in the community swimming pool this week i felt a burning sensation in my eye and i cried uncontrollably']\n",
      "joined_symps: i stayed up for a full night grinding hack the north project and the next morning my eye was bright red all the blood vessels in my blood were visible my eyes were really itchy this morning when i woke up and it was pink when i saw it through the mirror after swimming in the community swimming pool this week i felt a burning sensation in my eye and i cried uncontrollably\n",
      "WORD_LIST: ['I went to a dirty restaurant a few days ago, and I began to feel dizzy this morning initially, later I puked everything out', ' After eating some street food, I started to feel dizzy, weak and tired all the time, furthermore I began to catch a fever halfway through the week too', 'I went to the washroom alot more frequently recently and I saw blood in my toilet, I think I might be pooping blood', ' My stomach hurts after a meal of funny tasting fish in the school cafeteria, it hurts so much that I can barely standup straight. I also vomitted after the meal and constantly tired']\n",
      "WORD_LIST_NEW: ['i went to a dirty restaurant a few days ago and i began to feel dizzy this morning initially later i puked everything out', 'after eating some street food i started to feel dizzy weak and tired all the time furthermore i began to catch a fever halfway through the week too', 'i went to the washroom alot more frequently recently and i saw blood in my toilet i think i might be pooping blood', 'my stomach hurts after a meal of funny tasting fish in the school cafeteria it hurts so much that i can barely standup straight i also vomitted after the meal and constantly tired']\n",
      "joined_symps: i went to a dirty restaurant a few days ago and i began to feel dizzy this morning initially later i puked everything out after eating some street food i started to feel dizzy weak and tired all the time furthermore i began to catch a fever halfway through the week too i went to the washroom alot more frequently recently and i saw blood in my toilet i think i might be pooping blood my stomach hurts after a meal of funny tasting fish in the school cafeteria it hurts so much that i can barely standup straight i also vomitted after the meal and constantly tired\n",
      "WORD_LIST: ['I saw some yellow-green discharge, light bleeding between my periods and an occasional burning sensation while urinating. Are those symptoms of chlamydia or a sexually transmitted infection', 'Hi, I recently experience  a burning sensation while peeing, frequent urination or a yellow-green discharge, sometimes, even difficulty urinating', 'I recently have trouble going to the washroom because my genital areas hurt during urination and they sometimes swell up randomly.']\n",
      "WORD_LIST_NEW: ['i saw some yellowgreen discharge light bleeding between my periods and an occasional burning sensation while urinating are those symptoms of chlamydia or a sexually transmitted infection', 'hi i recently experience  a burning sensation while peeing frequent urination or a yellowgreen discharge sometimes even difficulty urinating', 'i recently have trouble going to the washroom because my genital areas hurt during urination and they sometimes swell up randomly']\n",
      "joined_symps: i saw some yellowgreen discharge light bleeding between my periods and an occasional burning sensation while urinating are those symptoms of chlamydia or a sexually transmitted infection hi i recently experience  a burning sensation while peeing frequent urination or a yellowgreen discharge sometimes even difficulty urinating i recently have trouble going to the washroom because my genital areas hurt during urination and they sometimes swell up randomly\n",
      "WORD_LIST: [\"Hello, I had this burning sensationâ€”I thought it was cystitis. I went to the doctor and he gave me some antibiotics. But it didn't go away. Then, a few days later, I got some blisters on my vagina, all along my lips, what is that blister\", 'I think I got some skin irritation, razor burn or just some random itch, but they repeat once every a few month,what are those?']\n",
      "WORD_LIST_NEW: ['hello i had this burning sensationâ€i thought it was cystitis i went to the doctor and he gave me some antibiotics but it didnt go away then a few days later i got some blisters on my vagina all along my lips what is that blister', 'i think i got some skin irritation razor burn or just some random itch but they repeat once every a few monthwhat are those']\n",
      "joined_symps: hello i had this burning sensationâ€i thought it was cystitis i went to the doctor and he gave me some antibiotics but it didnt go away then a few days later i got some blisters on my vagina all along my lips what is that blister i think i got some skin irritation razor burn or just some random itch but they repeat once every a few monthwhat are those\n",
      "WORD_LIST: [\"I visited the jungle a few days ago and I got a strange bite because it didn't go away. A few days later, I began to develop a fever and muscle weakness, what should I do?\", 'I discovered a weird mosquito bite on my hand that does not go away, but instead it swell and my hand is numb', ' My roommate has a weird bite on his forehead, He caught a fever and was confused about his surroundings. He experiences vision loss and fall into occassional comas. What should I do about him?', 'I have a minor headache, vomiting and I saw red rashes all over my back, chest and stomach']\n",
      "WORD_LIST_NEW: ['i visited the jungle a few days ago and i got a strange bite because it didnt go away a few days later i began to develop a fever and muscle weakness what should i do', 'i discovered a weird mosquito bite on my hand that does not go away but instead it swell and my hand is numb', 'my roommate has a weird bite on his forehead he caught a fever and was confused about his surroundings he experiences vision loss and fall into occassional comas what should i do about him', 'i have a minor headache vomiting and i saw red rashes all over my back chest and stomach']\n",
      "joined_symps: i visited the jungle a few days ago and i got a strange bite because it didnt go away a few days later i began to develop a fever and muscle weakness what should i do i discovered a weird mosquito bite on my hand that does not go away but instead it swell and my hand is numb my roommate has a weird bite on his forehead he caught a fever and was confused about his surroundings he experiences vision loss and fall into occassional comas what should i do about him i have a minor headache vomiting and i saw red rashes all over my back chest and stomach\n",
      "WORD_LIST: ['hey there. i have been feeling extremely bad lately, with a fever developing the past few days', 'i have been getting lot of blisters and rashes on my body recently. my mouth has also been very sore in a lot of places and there has been itchiness all over my body', \"i went to my friend's house last night and ended up developing a fever and red spots al over my body. i couldn't even eat anything because i had no appetite, and started getting itchy all over my body\", 'my mouth has been feeling bad lately, and i never feel like eating. my muscles have also been more sore lately even though i have not been to the gym, and my skin has become more itchy recently', 'blisters and rashes have appeared all over my body recently, and they have all started to itch. my arms and hamstrings are also starting to ache and i believe i may be developing a fever because my temperature is high from the last measurement', 'red spots are appealing all over my arm, and they are feeling quite uncomfortable. just this morning, i ended up developing a fever and my mouth has felt very sore and uncomfortable', 'my friend gabrielle and i went to the the movies and i ended up developing rashes all over my body which turned into itchy spots. later that night, i also measured my temperature and had developed a fever. this morning, i cannot even move well because my muscles are aching greatly.']\n",
      "WORD_LIST_NEW: ['hey there i have been feeling extremely bad lately with a fever developing the past few days', 'i have been getting lot of blisters and rashes on my body recently my mouth has also been very sore in a lot of places and there has been itchiness all over my body', 'i went to my friends house last night and ended up developing a fever and red spots al over my body i couldnt even eat anything because i had no appetite and started getting itchy all over my body', 'my mouth has been feeling bad lately and i never feel like eating my muscles have also been more sore lately even though i have not been to the gym and my skin has become more itchy recently', 'blisters and rashes have appeared all over my body recently and they have all started to itch my arms and hamstrings are also starting to ache and i believe i may be developing a fever because my temperature is high from the last measurement', 'red spots are appealing all over my arm and they are feeling quite uncomfortable just this morning i ended up developing a fever and my mouth has felt very sore and uncomfortable', 'my friend gabrielle and i went to the the movies and i ended up developing rashes all over my body which turned into itchy spots later that night i also measured my temperature and had developed a fever this morning i cannot even move well because my muscles are aching greatly']\n",
      "joined_symps: hey there i have been feeling extremely bad lately with a fever developing the past few days i have been getting lot of blisters and rashes on my body recently my mouth has also been very sore in a lot of places and there has been itchiness all over my body i went to my friends house last night and ended up developing a fever and red spots al over my body i couldnt even eat anything because i had no appetite and started getting itchy all over my body my mouth has been feeling bad lately and i never feel like eating my muscles have also been more sore lately even though i have not been to the gym and my skin has become more itchy recently blisters and rashes have appeared all over my body recently and they have all started to itch my arms and hamstrings are also starting to ache and i believe i may be developing a fever because my temperature is high from the last measurement red spots are appealing all over my arm and they are feeling quite uncomfortable just this morning i ended up developing a fever and my mouth has felt very sore and uncomfortable my friend gabrielle and i went to the the movies and i ended up developing rashes all over my body which turned into itchy spots later that night i also measured my temperature and had developed a fever this morning i cannot even move well because my muscles are aching greatly\n",
      "WORD_LIST: [\"I...can't remember\", \"People say I've gotten angrier, and sometimes I do feel angry, although I don't know why\", \"I couldn't remember her face...she was important to me but I could not, for the life of me, remember her face\", 'Where did I leave my bank notes? It was just yesterday when I retrieved them', 'What did you say? Can you speak louder?', \"my muscles are also hurting and ache quite a lot. it's also weird because my mother was home last weekend and we prepared a big dinner, but i had no appetite\", 'completing tasks and doing things has been very difficult lately, as i seem to not remember things i did in the past. doing things i was faimiliar with has been confusing and felt out of place, and it appears my spatial and visual senses are also diminishing']\n",
      "WORD_LIST_NEW: ['icant remember', 'people say ive gotten angrier and sometimes i do feel angry although i dont know why', 'i couldnt remember her faceshe was important to me but i could not for the life of me remember her face', 'where did i leave my bank notes it was just yesterday when i retrieved them', 'what did you say can you speak louder', 'my muscles are also hurting and ache quite a lot its also weird because my mother was home last weekend and we prepared a big dinner but i had no appetite', 'completing tasks and doing things has been very difficult lately as i seem to not remember things i did in the past doing things i was faimiliar with has been confusing and felt out of place and it appears my spatial and visual senses are also diminishing']\n",
      "joined_symps: icant remember people say ive gotten angrier and sometimes i do feel angry although i dont know why i couldnt remember her faceshe was important to me but i could not for the life of me remember her face where did i leave my bank notes it was just yesterday when i retrieved them what did you say can you speak louder my muscles are also hurting and ache quite a lot its also weird because my mother was home last weekend and we prepared a big dinner but i had no appetite completing tasks and doing things has been very difficult lately as i seem to not remember things i did in the past doing things i was faimiliar with has been confusing and felt out of place and it appears my spatial and visual senses are also diminishing\n",
      "WORD_LIST: ['My back hurts so much just from walking around and my ankles are swollen too', \"Don't talk to me, just go away and leave me alone\", \"My period is late by three days...it's almost never late\", 'My side was cramping so hard, it felt like someone was shredding me inside out']\n",
      "WORD_LIST_NEW: ['my back hurts so much just from walking around and my ankles are swollen too', 'dont talk to me just go away and leave me alone', 'my period is late by three daysits almost never late', 'my side was cramping so hard it felt like someone was shredding me inside out']\n",
      "joined_symps: my back hurts so much just from walking around and my ankles are swollen too dont talk to me just go away and leave me alone my period is late by three daysits almost never late my side was cramping so hard it felt like someone was shredding me inside out\n",
      "WORD_LIST: ['No matter how little I eat, I get fatter', 'food is the enemy and I refuse to surrender', \"How many calories are in that sandwiche? I'll just take an apple instead\", 'I feel so cold, even when I wear an extra coat', \"I purged myself clean today once more, just like I always have, except there was a burning sensation down my throat. I guess if that's the price I have to pay\"]\n",
      "WORD_LIST_NEW: ['no matter how little i eat i get fatter', 'food is the enemy and i refuse to surrender', 'how many calories are in that sandwiche ill just take an apple instead', 'i feel so cold even when i wear an extra coat', 'i purged myself clean today once more just like i always have except there was a burning sensation down my throat i guess if thats the price i have to pay']\n",
      "joined_symps: no matter how little i eat i get fatter food is the enemy and i refuse to surrender how many calories are in that sandwiche ill just take an apple instead i feel so cold even when i wear an extra coat i purged myself clean today once more just like i always have except there was a burning sensation down my throat i guess if thats the price i have to pay\n",
      "WORD_LIST: ['Recently my chest is feeling pretty tight and even numb at times. I have become light headed and dizzy for most of the day rendering me sad and useless. I also frequently vomit and expierience heartburn which is hella painful. Im really worried that I might have a serious disease and my indigestion is not helping.']\n",
      "WORD_LIST_NEW: ['recently my chest is feeling pretty tight and even numb at times i have become light headed and dizzy for most of the day rendering me sad and useless i also frequently vomit and expierience heartburn which is hella painful im really worried that i might have a serious disease and my indigestion is not helping']\n",
      "joined_symps: recently my chest is feeling pretty tight and even numb at times i have become light headed and dizzy for most of the day rendering me sad and useless i also frequently vomit and expierience heartburn which is hella painful im really worried that i might have a serious disease and my indigestion is not helping\n",
      "WORD_LIST: [\"There are a bunch of red spots on my chest and I don't think I've contacted any allergens...why won't they go away\", 'there are small bits of milky white liquid coming out of my nipples...should I be concerned?', 'Parts of my breast felt a bit hard...almost lumpy. Would this go away after puberty?', 'It just occurred to me today that my nipples look...different. Are they supposed to be sunken in?']\n",
      "WORD_LIST_NEW: ['there are a bunch of red spots on my chest and i dont think ive contacted any allergenswhy wont they go away', 'there are small bits of milky white liquid coming out of my nipplesshould i be concerned', 'parts of my breast felt a bit hardalmost lumpy would this go away after puberty', 'it just occurred to me today that my nipples lookdifferent are they supposed to be sunken in']\n",
      "joined_symps: there are a bunch of red spots on my chest and i dont think ive contacted any allergenswhy wont they go away there are small bits of milky white liquid coming out of my nipplesshould i be concerned parts of my breast felt a bit hardalmost lumpy would this go away after puberty it just occurred to me today that my nipples lookdifferent are they supposed to be sunken in\n",
      "WORD_LIST: [\"I've been feeling like I needed to go to the washroom more and more often these days\", \"I'm beginning to dread my washroom trips these days because it hurts to urinate\", 'When I went to piss this morning, there was blood and my piss was redish', \"What's wrong with me? Having sex with my girlfriend yesterday had hurt so much\"]\n",
      "WORD_LIST_NEW: ['ive been feeling like i needed to go to the washroom more and more often these days', 'im beginning to dread my washroom trips these days because it hurts to urinate', 'when i went to piss this morning there was blood and my piss was redish', 'whats wrong with me having sex with my girlfriend yesterday had hurt so much']\n",
      "joined_symps: ive been feeling like i needed to go to the washroom more and more often these days im beginning to dread my washroom trips these days because it hurts to urinate when i went to piss this morning there was blood and my piss was redish whats wrong with me having sex with my girlfriend yesterday had hurt so much\n",
      "14 documents [(['hi', 'i', 'have', 'a', 'runny', 'nose', 'all', 'the', 'time', 'and', 'i', 'dont', 'know', 'what', 'to', 'do', 'about', 'it', 'i', 'was', 'sniffing', 'all', 'the', 'time', 'in', 'the', 'past', 'few', 'days', 'and', 'it', 'was', 'getting', 'very', 'annoying', 'one', 'of', 'my', 'nausal', 'was', 'blocked', 'and', 'i', 'couldnt', 'breath', 'properly', 'my', 'throat', 'hurts', 'after', 'a', 'cold', 'shower', 'last', 'night', 'i', 'am', 'not', 'sure', 'what', 'to', 'do', 'about', 'it', 'it', 'feels', 'like', 'there', 'was', 'something', 'in', 'my', 'throat', 'and', 'ive', 'been', 'dry', 'coughing', 'for', 'several', 'days', 'already', 'i', 'recently', 'developed', 'a', 'condition', 'that', 'requires', 'frequent', 'washroom', 'visits', 'througout', 'the', 'day', 'i', 'am', 'so', 'tired', 'this', 'morning', 'every', 'single', 'one', 'of', 'my', 'muscle', 'hurts', 'so', 'much', 'all', 'my', 'joints', 'are', 'sour', 'since', 'last', 'morning', 'i', 'feel', 'so', 'cold', 'all', 'the', 'time', 'i', 'sneezed', 'all', 'the', 'time'], 'Common Cold'), (['after', 'the', 'soccer', 'game', 'yesterday', 'i', 'found', 'small', 'bumps', 'on', 'my', 'skin', 'and', 'extreme', 'itchiness', 'when', 'i', 'was', 'playing', 'with', 'my', 'friends', 'today', 'it', 'felt', 'like', 'i', 'had', 'something', 'in', 'my', 'eyes', 'and', 'i', 'was', 'crying', 'uncontrollably', 'my', 'nose', 'were', 'going', 'off', 'in', 'the', 'park', 'the', 'other', 'day', 'and', 'i', 'kept', 'sniffing', 'the', 'entire', 'time', 'sometimes', 'i', 'could', 'not', 'breath', 'through', 'one', 'of', 'my', 'nose', 'and', 'it', 'feels', 'like', 'it', 'was', 'blocked', 'when', 'i', 'was', 'walking', 'in', 'the', 'park', 'this', 'morning', 'i', 'kept', 'sneezing', 'around', 'the', 'flowers', 'even', 'though', 'i', 'am', 'not', 'cold', 'in', 'the', 'zoo', 'today', 'it', 'felt', 'like', 'i', 'have', 'a', 'feather', 'or', 'something', 'in', 'my', 'throat', 'the', 'entire', 'day', 'it', 'was', 'really', 'itchy', 'and', 'i', 'coughed', 'the', 'entire', 'day', 'i', 'picked', 'a', 'flower', 'today', 'and', 'the', 'part', 'of', 'my', 'hand', 'that', 'touched', 'the', 'flower', 'became', 'swollen', 'i', 'can', 'barely', 'bend', 'it', 'and', 'it', 'feels', 'numb'], 'Allergies'), (['i', 'stayed', 'up', 'for', 'a', 'full', 'night', 'grinding', 'hack', 'the', 'north', 'project', 'and', 'the', 'next', 'morning', 'my', 'eye', 'was', 'bright', 'red', 'all', 'the', 'blood', 'vessels', 'in', 'my', 'blood', 'were', 'visible', 'my', 'eyes', 'were', 'really', 'itchy', 'this', 'morning', 'when', 'i', 'woke', 'up', 'and', 'it', 'was', 'pink', 'when', 'i', 'saw', 'it', 'through', 'the', 'mirror', 'after', 'swimming', 'in', 'the', 'community', 'swimming', 'pool', 'this', 'week', 'i', 'felt', 'a', 'burning', 'sensation', 'in', 'my', 'eye', 'and', 'i', 'cried', 'uncontrollably'], 'Conjunctivitis'), (['i', 'went', 'to', 'a', 'dirty', 'restaurant', 'a', 'few', 'days', 'ago', 'and', 'i', 'began', 'to', 'feel', 'dizzy', 'this', 'morning', 'initially', 'later', 'i', 'puked', 'everything', 'out', 'after', 'eating', 'some', 'street', 'food', 'i', 'started', 'to', 'feel', 'dizzy', 'weak', 'and', 'tired', 'all', 'the', 'time', 'furthermore', 'i', 'began', 'to', 'catch', 'a', 'fever', 'halfway', 'through', 'the', 'week', 'too', 'i', 'went', 'to', 'the', 'washroom', 'alot', 'more', 'frequently', 'recently', 'and', 'i', 'saw', 'blood', 'in', 'my', 'toilet', 'i', 'think', 'i', 'might', 'be', 'pooping', 'blood', 'my', 'stomach', 'hurts', 'after', 'a', 'meal', 'of', 'funny', 'tasting', 'fish', 'in', 'the', 'school', 'cafeteria', 'it', 'hurts', 'so', 'much', 'that', 'i', 'can', 'barely', 'standup', 'straight', 'i', 'also', 'vomitted', 'after', 'the', 'meal', 'and', 'constantly', 'tired'], 'E Coli Infection'), (['i', 'saw', 'some', 'yellowgreen', 'discharge', 'light', 'bleeding', 'between', 'my', 'periods', 'and', 'an', 'occasional', 'burning', 'sensation', 'while', 'urinating', 'are', 'those', 'symptoms', 'of', 'chlamydia', 'or', 'a', 'sexually', 'transmitted', 'infection', 'hi', 'i', 'recently', 'experience', 'a', 'burning', 'sensation', 'while', 'peeing', 'frequent', 'urination', 'or', 'a', 'yellowgreen', 'discharge', 'sometimes', 'even', 'difficulty', 'urinating', 'i', 'recently', 'have', 'trouble', 'going', 'to', 'the', 'washroom', 'because', 'my', 'genital', 'areas', 'hurt', 'during', 'urination', 'and', 'they', 'sometimes', 'swell', 'up', 'randomly'], 'Chlamydia'), (['hello', 'i', 'had', 'this', 'burning', 'sensationâ€i', 'thought', 'it', 'was', 'cystitis', 'i', 'went', 'to', 'the', 'doctor', 'and', 'he', 'gave', 'me', 'some', 'antibiotics', 'but', 'it', 'didnt', 'go', 'away', 'then', 'a', 'few', 'days', 'later', 'i', 'got', 'some', 'blisters', 'on', 'my', 'vagina', 'all', 'along', 'my', 'lips', 'what', 'is', 'that', 'blister', 'i', 'think', 'i', 'got', 'some', 'skin', 'irritation', 'razor', 'burn', 'or', 'just', 'some', 'random', 'itch', 'but', 'they', 'repeat', 'once', 'every', 'a', 'few', 'monthwhat', 'are', 'those'], 'Hepatitis B'), (['i', 'visited', 'the', 'jungle', 'a', 'few', 'days', 'ago', 'and', 'i', 'got', 'a', 'strange', 'bite', 'because', 'it', 'didnt', 'go', 'away', 'a', 'few', 'days', 'later', 'i', 'began', 'to', 'develop', 'a', 'fever', 'and', 'muscle', 'weakness', 'what', 'should', 'i', 'do', 'i', 'discovered', 'a', 'weird', 'mosquito', 'bite', 'on', 'my', 'hand', 'that', 'does', 'not', 'go', 'away', 'but', 'instead', 'it', 'swell', 'and', 'my', 'hand', 'is', 'numb', 'my', 'roommate', 'has', 'a', 'weird', 'bite', 'on', 'his', 'forehead', 'he', 'caught', 'a', 'fever', 'and', 'was', 'confused', 'about', 'his', 'surroundings', 'he', 'experiences', 'vision', 'loss', 'and', 'fall', 'into', 'occassional', 'comas', 'what', 'should', 'i', 'do', 'about', 'him', 'i', 'have', 'a', 'minor', 'headache', 'vomiting', 'and', 'i', 'saw', 'red', 'rashes', 'all', 'over', 'my', 'back', 'chest', 'and', 'stomach'], 'West Nile Virus'), (['hey', 'there', 'i', 'have', 'been', 'feeling', 'extremely', 'bad', 'lately', 'with', 'a', 'fever', 'developing', 'the', 'past', 'few', 'days', 'i', 'have', 'been', 'getting', 'lot', 'of', 'blisters', 'and', 'rashes', 'on', 'my', 'body', 'recently', 'my', 'mouth', 'has', 'also', 'been', 'very', 'sore', 'in', 'a', 'lot', 'of', 'places', 'and', 'there', 'has', 'been', 'itchiness', 'all', 'over', 'my', 'body', 'i', 'went', 'to', 'my', 'friends', 'house', 'last', 'night', 'and', 'ended', 'up', 'developing', 'a', 'fever', 'and', 'red', 'spots', 'al', 'over', 'my', 'body', 'i', 'couldnt', 'even', 'eat', 'anything', 'because', 'i', 'had', 'no', 'appetite', 'and', 'started', 'getting', 'itchy', 'all', 'over', 'my', 'body', 'my', 'mouth', 'has', 'been', 'feeling', 'bad', 'lately', 'and', 'i', 'never', 'feel', 'like', 'eating', 'my', 'muscles', 'have', 'also', 'been', 'more', 'sore', 'lately', 'even', 'though', 'i', 'have', 'not', 'been', 'to', 'the', 'gym', 'and', 'my', 'skin', 'has', 'become', 'more', 'itchy', 'recently', 'blisters', 'and', 'rashes', 'have', 'appeared', 'all', 'over', 'my', 'body', 'recently', 'and', 'they', 'have', 'all', 'started', 'to', 'itch', 'my', 'arms', 'and', 'hamstrings', 'are', 'also', 'starting', 'to', 'ache', 'and', 'i', 'believe', 'i', 'may', 'be', 'developing', 'a', 'fever', 'because', 'my', 'temperature', 'is', 'high', 'from', 'the', 'last', 'measurement', 'red', 'spots', 'are', 'appealing', 'all', 'over', 'my', 'arm', 'and', 'they', 'are', 'feeling', 'quite', 'uncomfortable', 'just', 'this', 'morning', 'i', 'ended', 'up', 'developing', 'a', 'fever', 'and', 'my', 'mouth', 'has', 'felt', 'very', 'sore', 'and', 'uncomfortable', 'my', 'friend', 'gabrielle', 'and', 'i', 'went', 'to', 'the', 'the', 'movies', 'and', 'i', 'ended', 'up', 'developing', 'rashes', 'all', 'over', 'my', 'body', 'which', 'turned', 'into', 'itchy', 'spots', 'later', 'that', 'night', 'i', 'also', 'measured', 'my', 'temperature', 'and', 'had', 'developed', 'a', 'fever', 'this', 'morning', 'i', 'can', 'not', 'even', 'move', 'well', 'because', 'my', 'muscles', 'are', 'aching', 'greatly'], 'Chickenpox'), (['icant', 'remember', 'people', 'say', 'ive', 'gotten', 'angrier', 'and', 'sometimes', 'i', 'do', 'feel', 'angry', 'although', 'i', 'dont', 'know', 'why', 'i', 'couldnt', 'remember', 'her', 'faceshe', 'was', 'important', 'to', 'me', 'but', 'i', 'could', 'not', 'for', 'the', 'life', 'of', 'me', 'remember', 'her', 'face', 'where', 'did', 'i', 'leave', 'my', 'bank', 'notes', 'it', 'was', 'just', 'yesterday', 'when', 'i', 'retrieved', 'them', 'what', 'did', 'you', 'say', 'can', 'you', 'speak', 'louder', 'my', 'muscles', 'are', 'also', 'hurting', 'and', 'ache', 'quite', 'a', 'lot', 'its', 'also', 'weird', 'because', 'my', 'mother', 'was', 'home', 'last', 'weekend', 'and', 'we', 'prepared', 'a', 'big', 'dinner', 'but', 'i', 'had', 'no', 'appetite', 'completing', 'tasks', 'and', 'doing', 'things', 'has', 'been', 'very', 'difficult', 'lately', 'as', 'i', 'seem', 'to', 'not', 'remember', 'things', 'i', 'did', 'in', 'the', 'past', 'doing', 'things', 'i', 'was', 'faimiliar', 'with', 'has', 'been', 'confusing', 'and', 'felt', 'out', 'of', 'place', 'and', 'it', 'appears', 'my', 'spatial', 'and', 'visual', 'senses', 'are', 'also', 'diminishing'], 'Alzheimer'), (['my', 'back', 'hurts', 'so', 'much', 'just', 'from', 'walking', 'around', 'and', 'my', 'ankles', 'are', 'swollen', 'too', 'dont', 'talk', 'to', 'me', 'just', 'go', 'away', 'and', 'leave', 'me', 'alone', 'my', 'period', 'is', 'late', 'by', 'three', 'daysits', 'almost', 'never', 'late', 'my', 'side', 'was', 'cramping', 'so', 'hard', 'it', 'felt', 'like', 'someone', 'was', 'shredding', 'me', 'inside', 'out'], 'Pregnancy'), (['no', 'matter', 'how', 'little', 'i', 'eat', 'i', 'get', 'fatter', 'food', 'is', 'the', 'enemy', 'and', 'i', 'refuse', 'to', 'surrender', 'how', 'many', 'calories', 'are', 'in', 'that', 'sandwiche', 'ill', 'just', 'take', 'an', 'apple', 'instead', 'i', 'feel', 'so', 'cold', 'even', 'when', 'i', 'wear', 'an', 'extra', 'coat', 'i', 'purged', 'myself', 'clean', 'today', 'once', 'more', 'just', 'like', 'i', 'always', 'have', 'except', 'there', 'was', 'a', 'burning', 'sensation', 'down', 'my', 'throat', 'i', 'guess', 'if', 'thats', 'the', 'price', 'i', 'have', 'to', 'pay'], 'Eating Disorders including Anorexia & Bulimia Nervosa'), (['recently', 'my', 'chest', 'is', 'feeling', 'pretty', 'tight', 'and', 'even', 'numb', 'at', 'times', 'i', 'have', 'become', 'light', 'headed', 'and', 'dizzy', 'for', 'most', 'of', 'the', 'day', 'rendering', 'me', 'sad', 'and', 'useless', 'i', 'also', 'frequently', 'vomit', 'and', 'expierience', 'heartburn', 'which', 'is', 'hella', 'painful', 'im', 'really', 'worried', 'that', 'i', 'might', 'have', 'a', 'serious', 'disease', 'and', 'my', 'indigestion', 'is', 'not', 'helping'], 'Coronary Heart Disease'), (['there', 'are', 'a', 'bunch', 'of', 'red', 'spots', 'on', 'my', 'chest', 'and', 'i', 'dont', 'think', 'ive', 'contacted', 'any', 'allergenswhy', 'wont', 'they', 'go', 'away', 'there', 'are', 'small', 'bits', 'of', 'milky', 'white', 'liquid', 'coming', 'out', 'of', 'my', 'nipplesshould', 'i', 'be', 'concerned', 'parts', 'of', 'my', 'breast', 'felt', 'a', 'bit', 'hardalmost', 'lumpy', 'would', 'this', 'go', 'away', 'after', 'puberty', 'it', 'just', 'occurred', 'to', 'me', 'today', 'that', 'my', 'nipples', 'lookdifferent', 'are', 'they', 'supposed', 'to', 'be', 'sunken', 'in'], 'Breast Cancer'), (['ive', 'been', 'feeling', 'like', 'i', 'needed', 'to', 'go', 'to', 'the', 'washroom', 'more', 'and', 'more', 'often', 'these', 'days', 'im', 'beginning', 'to', 'dread', 'my', 'washroom', 'trips', 'these', 'days', 'because', 'it', 'hurts', 'to', 'urinate', 'when', 'i', 'went', 'to', 'piss', 'this', 'morning', 'there', 'was', 'blood', 'and', 'my', 'piss', 'was', 'redish', 'whats', 'wrong', 'with', 'me', 'having', 'sex', 'with', 'my', 'girlfriend', 'yesterday', 'had', 'hurt', 'so', 'much'], 'Prostate Cancer')]\n",
      "14 classes ['Allergies', 'Alzheimer', 'Breast Cancer', 'Chickenpox', 'Chlamydia', 'Common Cold', 'Conjunctivitis', 'Coronary Heart Disease', 'E Coli Infection', 'Eating Disorders including Anorexia & Bulimia Nervosa', 'Hepatitis B', 'Pregnancy', 'Prostate Cancer', 'West Nile Virus']\n",
      "433 unique stemmed words ['a', 'about', 'ach', 'aft', 'ago', 'al', 'allergenswhy', 'almost', 'alon', 'along', 'alot', 'already', 'also', 'although', 'alway', 'am', 'an', 'and', 'angry', 'ankl', 'annoy', 'antibiot', 'any', 'anyth', 'ap', 'appear', 'appetit', 'appl', 'ar', 'area', 'arm', 'around', 'as', 'at', 'away', 'back', 'bad', 'bank', 'bar', 'be', 'becam', 'becaus', 'becom', 'been', 'beg', 'begin', 'believ', 'bend', 'between', 'big', 'bit', 'blee', 'blist', 'block', 'blood', 'body', 'brea', 'breast', 'bright', 'bump', 'bunch', 'burn', 'but', 'by', 'cafeter', 'cal', 'can', 'catch', 'caught', 'chest', 'chlamydia', 'cle', 'coat', 'cold', 'com', 'coma', 'commun', 'complet', 'concern', 'condit', 'confus', 'const', 'contact', 'cough', 'could', 'couldnt', 'cramp', 'cri', 'cry', 'cystit', 'day', 'daysit', 'develop', 'did', 'didnt', 'difficul', 'difficult', 'dimin', 'din', 'dirty', 'discharg', 'discov', 'diseas', 'dizzy', 'do', 'doct', 'doe', 'doing', 'dont', 'down', 'dread', 'dry', 'dur', 'eat', 'end', 'enemy', 'entir', 'ev', 'every', 'everyth', 'exceiv', 'expery', 'expiery', 'extr', 'extrem', 'ey', 'fac', 'facesh', 'faimili', 'fal', 'fat', 'feath', 'feel', 'felt', 'fev', 'few', 'fish', 'flow', 'food', 'for', 'forehead', 'found', 'frequ', 'friend', 'from', 'ful', 'funny', 'furtherm', 'gabriel', 'gam', 'gav', 'genit', 'get', 'girlfriend', 'go', 'going', 'got', 'gre', 'grind', 'guess', 'gym', 'hack', 'had', 'halfway', 'hamst', 'hand', 'hard', 'hardalmost', 'has', 'hav', 'he', 'head', 'headach', 'heartburn', 'hell', 'hello', 'help', 'her', 'hey', 'hi', 'high', 'him', 'his', 'hom', 'hous', 'how', 'hurt', 'i', 'ic', 'if', 'il', 'im', 'import', 'in', 'indigest', 'infect', 'init', 'insid', 'instead', 'into', 'irrit', 'is', 'it', 'itch', 'itchy', 'iv', 'joint', 'jungl', 'just', 'kept', 'know', 'last', 'lat', 'leav', 'lif', 'light', 'lik', 'lip', 'liquid', 'littl', 'lookdiff', 'loss', 'lot', 'loud', 'lumpy', 'many', 'mat', 'may', 'me', 'meal', 'meas', 'might', 'milky', 'min', 'mir', 'monthwh', 'mor', 'morn', 'mosquito', 'most', 'moth', 'mou', 'mov', 'movy', 'much', 'musc', 'my', 'myself', 'naus', 'nee', 'nev', 'next', 'night', 'nippl', 'nipplesshould', 'no', 'nor', 'nos', 'not', 'numb', 'occas', 'occass', 'occur', 'of', 'off', 'oft', 'on', 'ont', 'or', 'oth', 'out', 'ov', 'pain', 'park', 'part', 'past', 'pay', 'pee', 'peopl', 'period', 'pick', 'pink', 'piss', 'plac', 'play', 'pool', 'poop', 'prep', 'pretty', 'pric', 'project', 'prop', 'puberty', 'puk', 'purg', 'quit', 'random', 'rash', 'raz', 'real', 'rec', 'red', 'refus', 'rememb', 'rend', 'rep', 'requir', 'resta', 'retriev', 'room', 'runny', 'sad', 'sandwich', 'saw', 'say', 'school', 'seem', 'sens', 'sensationâ€i', 'sery', 'sev', 'sex', 'should', 'show', 'shredding', 'sid', 'singl', 'sint', 'skin', 'smal', 'sneez', 'sniff', 'so', 'socc', 'som', 'someon', 'someth', 'sometim', 'sor', 'sour', 'spat', 'speak', 'spot', 'standup', 'start', 'stay', 'stomach', 'straight', 'strange', 'street', 'sunk', 'suppos', 'sur', 'surrend', 'surround', 'swel', 'swim', 'swol', 'symptom', 'tak', 'talk', 'task', 'tast', 'temp', 'that', 'the', 'them', 'then', 'ther', 'thes', 'they', 'thi', 'thing', 'think', 'thos', 'though', 'thought', 'three', 'throat', 'through', 'througout', 'tight', 'tim', 'tir', 'to', 'today', 'toilet', 'too', 'touch', 'transmit', 'trip', 'troubl', 'turn', 'uncomfort', 'uncontrol', 'up', 'urin', 'useless', 'vagin', 'very', 'vessel', 'vis', 'visit', 'vomit', 'walk', 'was', 'washroom', 'we', 'weak', 'wear', 'week', 'weekend', 'weird', 'wel', 'went', 'wer', 'what', 'when', 'wher', 'which', 'whil', 'whit', 'why', 'with', 'wok', 'wont', 'worry', 'would', 'wrong', 'yellowgreen', 'yesterday', 'you', 'zoo']\n",
      "classes_details [{'danger level': '1', 'synonyms': 'Upper Respiratory Tract;Nose and Throat Infection', 'class': 'Common Cold', 'treatments': 'Stay hydrated;rest;sooth a sore throat using saltwater gargle;take over the counter cold and cough medications\\n'}, {'danger level': '1', 'synonyms': 'Allergic Reaction', 'class': 'Allergies', 'treatments': 'Remove the cause of allergy; \\notherwise take Antihistamines to relieve sneezing;Decongestants to relieve congestions in nasal membranes;Anti inflamary agents to reduce;Allergy shots'}, {'danger level': '1', 'synonyms': 'Pink Eye', 'class': 'Conjunctivitis', 'treatments': 'See a doctor;Bacterial cases can be treated with antibiotic eye drops;Allergic reactions can be treated with other eye dro'}, {'danger level': '1', 'synonyms': '', 'class': 'E Coli Infection', 'treatments': 'Visit a hospital immediately'}, {'danger level': '4', 'synonyms': 'Sexually Transmitted Infection (STI)', 'class': 'Chlamydia', 'treatments': 'See a professional doctor;Use Azithromycin or Doxycycline'}, {'danger level': '6', 'synonyms': 'Herpes', 'class': 'Hepatitis B', 'treatments': 'See a doctor immediately;Take antiviral drugs'}, {'danger level': '8', 'synonyms': '', 'class': 'West Nile Virus', 'treatments': 'Please see a healthcare professional;There are no specific treatments for West Nile Virus in humans'}, {'danger level': '2', 'synonyms': 'Varicella Zoster Virus', 'class': 'Chickenpox', 'treatments': 'Drink plenty of fluid;Take Tylenol;Consult with a doctor'}, {'danger level': '4', 'synonyms': '', 'class': 'Alzheimer', 'treatments': 'Cholinesterase inhibitors;Memantine(Namenda);Please consult with a professional doctor'}, {'danger level': '2', 'synonyms': '', 'class': 'Pregnancy', 'treatments': 'You are pregnant! Remember to take your prenatal vitamin;quit smoking;stop drinking alcohol;cut down on caffeine; avoid hazardous foods;eat well and sleep well!'}, {'danger level': '3', 'synonyms': '', 'class': 'Eating Disorders including Anorexia & Bulimia Nervosa', 'treatments': 'Seek help from a therapist, physician, and nutritionist'}, {'danger level': '7', 'synonyms': '', 'class': 'Coronary Heart Disease', 'treatments': 'quit smoking;have a healthy diet;exercise regularly;consult with a doctor'}, {'danger level': '10', 'synonyms': '', 'class': 'Breast Cancer', 'treatments': 'You may have breast cancer, please consult with a doctor and conduct further diagnostics at your local hospital'}, {'danger level': '10', 'synonyms': '', 'class': 'Prostate Cancer', 'treatments': 'You may have prostate cancer, please consult with a doctor and conduct further diagnostics at your local hospital'}]\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "words = []\n",
    "words_total = []\n",
    "classes = []\n",
    "classes_details = []\n",
    "documents = []\n",
    "ignore_words = ['?']\n",
    "\n",
    "# loop through each description per symptom\n",
    "for pattern in training_data:\n",
    "    symptoms = pattern['sentence']\n",
    "    word_list = symptoms.split(';')\n",
    "    print(\"WORD_LIST:\",word_list)\n",
    "    word_list_new = []\n",
    "    for word in word_list:\n",
    "        word = remove_punctuation(word)\n",
    "        word = word.strip().lower()\n",
    "        word_list_new.append(word)\n",
    "    print(\"WORD_LIST_NEW:\",word_list_new)\n",
    "    joined_symps = ' '.join(s for s in word_list_new)\n",
    "    print(\"joined_symps:\",joined_symps)\n",
    "    \n",
    "    # tokenize each word in the description\n",
    "    w = nltk.word_tokenize(joined_symps)\n",
    "    # add to our words list\n",
    "    words.extend(w)\n",
    "    # add to documents in our corpus\n",
    "    documents.append((w, pattern['class']))\n",
    "    # add to our classes list\n",
    "    if pattern['class'] not in classes:\n",
    "        classes.append(pattern['class'])\n",
    "        classes_details.append({\"class\":pattern['class'], \"synonyms\":pattern['synonyms'],\n",
    "                                \"treatments\":pattern['treatments'], \"danger level\":pattern['danger level']})\n",
    "    \n",
    "# stem and lower each word and remove duplicates\n",
    "words = [stemmer.stem(w.lower()) for w in words if w not in ignore_words]\n",
    "words = sorted(list(set(words)))\n",
    "\n",
    "# remove duplicates\n",
    "classes = sorted(list(set(classes)))\n",
    "\n",
    "print (len(documents), \"documents\", documents)\n",
    "print (len(classes), \"classes\", classes)\n",
    "print (len(words), \"unique stemmed words\", words)\n",
    "print (\"classes_details\", classes_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZED WORDS:  ['hi', 'i', 'have', 'a', 'runny', 'nose', 'all', 'the', 'time', 'and', 'i', 'dont', 'know', 'what', 'to', 'do', 'about', 'it', 'i', 'was', 'sniffing', 'all', 'the', 'time', 'in', 'the', 'past', 'few', 'days', 'and', 'it', 'was', 'getting', 'very', 'annoying', 'one', 'of', 'my', 'nausal', 'was', 'blocked', 'and', 'i', 'couldnt', 'breath', 'properly', 'my', 'throat', 'hurts', 'after', 'a', 'cold', 'shower', 'last', 'night', 'i', 'am', 'not', 'sure', 'what', 'to', 'do', 'about', 'it', 'it', 'feels', 'like', 'there', 'was', 'something', 'in', 'my', 'throat', 'and', 'ive', 'been', 'dry', 'coughing', 'for', 'several', 'days', 'already', 'i', 'recently', 'developed', 'a', 'condition', 'that', 'requires', 'frequent', 'washroom', 'visits', 'througout', 'the', 'day', 'i', 'am', 'so', 'tired', 'this', 'morning', 'every', 'single', 'one', 'of', 'my', 'muscle', 'hurts', 'so', 'much', 'all', 'my', 'joints', 'are', 'sour', 'since', 'last', 'morning', 'i', 'feel', 'so', 'cold', 'all', 'the', 'time', 'i', 'sneezed', 'all', 'the', 'time']\n",
      "pattern_words: ['hi', 'i', 'hav', 'a', 'runny', 'nos', 'al', 'the', 'tim', 'and', 'i', 'dont', 'know', 'what', 'to', 'do', 'about', 'it', 'i', 'was', 'sniff', 'al', 'the', 'tim', 'in', 'the', 'past', 'few', 'day', 'and', 'it', 'was', 'get', 'very', 'annoy', 'on', 'of', 'my', 'naus', 'was', 'block', 'and', 'i', 'couldnt', 'brea', 'prop', 'my', 'throat', 'hurt', 'aft', 'a', 'cold', 'show', 'last', 'night', 'i', 'am', 'not', 'sur', 'what', 'to', 'do', 'about', 'it', 'it', 'feel', 'lik', 'ther', 'was', 'someth', 'in', 'my', 'throat', 'and', 'iv', 'been', 'dry', 'cough', 'for', 'sev', 'day', 'already', 'i', 'rec', 'develop', 'a', 'condit', 'that', 'requir', 'frequ', 'washroom', 'visit', 'througout', 'the', 'day', 'i', 'am', 'so', 'tir', 'thi', 'morn', 'every', 'singl', 'on', 'of', 'my', 'musc', 'hurt', 'so', 'much', 'al', 'my', 'joint', 'ar', 'sour', 'sint', 'last', 'morn', 'i', 'feel', 'so', 'cold', 'al', 'the', 'tim', 'i', 'sneez', 'al', 'the', 'tim']\n",
      "BAG:  [1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['after', 'the', 'soccer', 'game', 'yesterday', 'i', 'found', 'small', 'bumps', 'on', 'my', 'skin', 'and', 'extreme', 'itchiness', 'when', 'i', 'was', 'playing', 'with', 'my', 'friends', 'today', 'it', 'felt', 'like', 'i', 'had', 'something', 'in', 'my', 'eyes', 'and', 'i', 'was', 'crying', 'uncontrollably', 'my', 'nose', 'were', 'going', 'off', 'in', 'the', 'park', 'the', 'other', 'day', 'and', 'i', 'kept', 'sniffing', 'the', 'entire', 'time', 'sometimes', 'i', 'could', 'not', 'breath', 'through', 'one', 'of', 'my', 'nose', 'and', 'it', 'feels', 'like', 'it', 'was', 'blocked', 'when', 'i', 'was', 'walking', 'in', 'the', 'park', 'this', 'morning', 'i', 'kept', 'sneezing', 'around', 'the', 'flowers', 'even', 'though', 'i', 'am', 'not', 'cold', 'in', 'the', 'zoo', 'today', 'it', 'felt', 'like', 'i', 'have', 'a', 'feather', 'or', 'something', 'in', 'my', 'throat', 'the', 'entire', 'day', 'it', 'was', 'really', 'itchy', 'and', 'i', 'coughed', 'the', 'entire', 'day', 'i', 'picked', 'a', 'flower', 'today', 'and', 'the', 'part', 'of', 'my', 'hand', 'that', 'touched', 'the', 'flower', 'became', 'swollen', 'i', 'can', 'barely', 'bend', 'it', 'and', 'it', 'feels', 'numb']\n",
      "pattern_words: ['aft', 'the', 'socc', 'gam', 'yesterday', 'i', 'found', 'smal', 'bump', 'on', 'my', 'skin', 'and', 'extrem', 'itchy', 'when', 'i', 'was', 'play', 'with', 'my', 'friend', 'today', 'it', 'felt', 'lik', 'i', 'had', 'someth', 'in', 'my', 'ey', 'and', 'i', 'was', 'cry', 'uncontrol', 'my', 'nos', 'wer', 'going', 'off', 'in', 'the', 'park', 'the', 'oth', 'day', 'and', 'i', 'kept', 'sniff', 'the', 'entir', 'tim', 'sometim', 'i', 'could', 'not', 'brea', 'through', 'on', 'of', 'my', 'nos', 'and', 'it', 'feel', 'lik', 'it', 'was', 'block', 'when', 'i', 'was', 'walk', 'in', 'the', 'park', 'thi', 'morn', 'i', 'kept', 'sneez', 'around', 'the', 'flow', 'ev', 'though', 'i', 'am', 'not', 'cold', 'in', 'the', 'zoo', 'today', 'it', 'felt', 'lik', 'i', 'hav', 'a', 'feath', 'or', 'someth', 'in', 'my', 'throat', 'the', 'entir', 'day', 'it', 'was', 'real', 'itchy', 'and', 'i', 'cough', 'the', 'entir', 'day', 'i', 'pick', 'a', 'flow', 'today', 'and', 'the', 'part', 'of', 'my', 'hand', 'that', 'touch', 'the', 'flow', 'becam', 'swol', 'i', 'can', 'bar', 'bend', 'it', 'and', 'it', 'feel', 'numb']\n",
      "BAG:  [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "TOKENIZED WORDS:  ['i', 'stayed', 'up', 'for', 'a', 'full', 'night', 'grinding', 'hack', 'the', 'north', 'project', 'and', 'the', 'next', 'morning', 'my', 'eye', 'was', 'bright', 'red', 'all', 'the', 'blood', 'vessels', 'in', 'my', 'blood', 'were', 'visible', 'my', 'eyes', 'were', 'really', 'itchy', 'this', 'morning', 'when', 'i', 'woke', 'up', 'and', 'it', 'was', 'pink', 'when', 'i', 'saw', 'it', 'through', 'the', 'mirror', 'after', 'swimming', 'in', 'the', 'community', 'swimming', 'pool', 'this', 'week', 'i', 'felt', 'a', 'burning', 'sensation', 'in', 'my', 'eye', 'and', 'i', 'cried', 'uncontrollably']\n",
      "pattern_words: ['i', 'stay', 'up', 'for', 'a', 'ful', 'night', 'grind', 'hack', 'the', 'nor', 'project', 'and', 'the', 'next', 'morn', 'my', 'ey', 'was', 'bright', 'red', 'al', 'the', 'blood', 'vessel', 'in', 'my', 'blood', 'wer', 'vis', 'my', 'ey', 'wer', 'real', 'itchy', 'thi', 'morn', 'when', 'i', 'wok', 'up', 'and', 'it', 'was', 'pink', 'when', 'i', 'saw', 'it', 'through', 'the', 'mir', 'aft', 'swim', 'in', 'the', 'commun', 'swim', 'pool', 'thi', 'week', 'i', 'felt', 'a', 'burn', 'sens', 'in', 'my', 'ey', 'and', 'i', 'cri', 'uncontrol']\n",
      "BAG:  [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['i', 'went', 'to', 'a', 'dirty', 'restaurant', 'a', 'few', 'days', 'ago', 'and', 'i', 'began', 'to', 'feel', 'dizzy', 'this', 'morning', 'initially', 'later', 'i', 'puked', 'everything', 'out', 'after', 'eating', 'some', 'street', 'food', 'i', 'started', 'to', 'feel', 'dizzy', 'weak', 'and', 'tired', 'all', 'the', 'time', 'furthermore', 'i', 'began', 'to', 'catch', 'a', 'fever', 'halfway', 'through', 'the', 'week', 'too', 'i', 'went', 'to', 'the', 'washroom', 'alot', 'more', 'frequently', 'recently', 'and', 'i', 'saw', 'blood', 'in', 'my', 'toilet', 'i', 'think', 'i', 'might', 'be', 'pooping', 'blood', 'my', 'stomach', 'hurts', 'after', 'a', 'meal', 'of', 'funny', 'tasting', 'fish', 'in', 'the', 'school', 'cafeteria', 'it', 'hurts', 'so', 'much', 'that', 'i', 'can', 'barely', 'standup', 'straight', 'i', 'also', 'vomitted', 'after', 'the', 'meal', 'and', 'constantly', 'tired']\n",
      "pattern_words: ['i', 'went', 'to', 'a', 'dirty', 'resta', 'a', 'few', 'day', 'ago', 'and', 'i', 'beg', 'to', 'feel', 'dizzy', 'thi', 'morn', 'init', 'lat', 'i', 'puk', 'everyth', 'out', 'aft', 'eat', 'som', 'street', 'food', 'i', 'start', 'to', 'feel', 'dizzy', 'weak', 'and', 'tir', 'al', 'the', 'tim', 'furtherm', 'i', 'beg', 'to', 'catch', 'a', 'fev', 'halfway', 'through', 'the', 'week', 'too', 'i', 'went', 'to', 'the', 'washroom', 'alot', 'mor', 'frequ', 'rec', 'and', 'i', 'saw', 'blood', 'in', 'my', 'toilet', 'i', 'think', 'i', 'might', 'be', 'poop', 'blood', 'my', 'stomach', 'hurt', 'aft', 'a', 'meal', 'of', 'funny', 'tast', 'fish', 'in', 'the', 'school', 'cafeter', 'it', 'hurt', 'so', 'much', 'that', 'i', 'can', 'bar', 'standup', 'straight', 'i', 'also', 'vomit', 'aft', 'the', 'meal', 'and', 'const', 'tir']\n",
      "BAG:  [1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['i', 'saw', 'some', 'yellowgreen', 'discharge', 'light', 'bleeding', 'between', 'my', 'periods', 'and', 'an', 'occasional', 'burning', 'sensation', 'while', 'urinating', 'are', 'those', 'symptoms', 'of', 'chlamydia', 'or', 'a', 'sexually', 'transmitted', 'infection', 'hi', 'i', 'recently', 'experience', 'a', 'burning', 'sensation', 'while', 'peeing', 'frequent', 'urination', 'or', 'a', 'yellowgreen', 'discharge', 'sometimes', 'even', 'difficulty', 'urinating', 'i', 'recently', 'have', 'trouble', 'going', 'to', 'the', 'washroom', 'because', 'my', 'genital', 'areas', 'hurt', 'during', 'urination', 'and', 'they', 'sometimes', 'swell', 'up', 'randomly']\n",
      "pattern_words: ['i', 'saw', 'som', 'yellowgreen', 'discharg', 'light', 'blee', 'between', 'my', 'period', 'and', 'an', 'occas', 'burn', 'sens', 'whil', 'urin', 'ar', 'thos', 'symptom', 'of', 'chlamydia', 'or', 'a', 'sex', 'transmit', 'infect', 'hi', 'i', 'rec', 'expery', 'a', 'burn', 'sens', 'whil', 'pee', 'frequ', 'urin', 'or', 'a', 'yellowgreen', 'discharg', 'sometim', 'ev', 'difficul', 'urin', 'i', 'rec', 'hav', 'troubl', 'going', 'to', 'the', 'washroom', 'becaus', 'my', 'genit', 'area', 'hurt', 'dur', 'urin', 'and', 'they', 'sometim', 'swel', 'up', 'random']\n",
      "BAG:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['hello', 'i', 'had', 'this', 'burning', 'sensationâ€i', 'thought', 'it', 'was', 'cystitis', 'i', 'went', 'to', 'the', 'doctor', 'and', 'he', 'gave', 'me', 'some', 'antibiotics', 'but', 'it', 'didnt', 'go', 'away', 'then', 'a', 'few', 'days', 'later', 'i', 'got', 'some', 'blisters', 'on', 'my', 'vagina', 'all', 'along', 'my', 'lips', 'what', 'is', 'that', 'blister', 'i', 'think', 'i', 'got', 'some', 'skin', 'irritation', 'razor', 'burn', 'or', 'just', 'some', 'random', 'itch', 'but', 'they', 'repeat', 'once', 'every', 'a', 'few', 'monthwhat', 'are', 'those']\n",
      "pattern_words: ['hello', 'i', 'had', 'thi', 'burn', 'sensationâ€i', 'thought', 'it', 'was', 'cystit', 'i', 'went', 'to', 'the', 'doct', 'and', 'he', 'gav', 'me', 'som', 'antibiot', 'but', 'it', 'didnt', 'go', 'away', 'then', 'a', 'few', 'day', 'lat', 'i', 'got', 'som', 'blist', 'on', 'my', 'vagin', 'al', 'along', 'my', 'lip', 'what', 'is', 'that', 'blist', 'i', 'think', 'i', 'got', 'som', 'skin', 'irrit', 'raz', 'burn', 'or', 'just', 'som', 'random', 'itch', 'but', 'they', 'rep', 'ont', 'every', 'a', 'few', 'monthwh', 'ar', 'thos']\n",
      "BAG:  [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['i', 'visited', 'the', 'jungle', 'a', 'few', 'days', 'ago', 'and', 'i', 'got', 'a', 'strange', 'bite', 'because', 'it', 'didnt', 'go', 'away', 'a', 'few', 'days', 'later', 'i', 'began', 'to', 'develop', 'a', 'fever', 'and', 'muscle', 'weakness', 'what', 'should', 'i', 'do', 'i', 'discovered', 'a', 'weird', 'mosquito', 'bite', 'on', 'my', 'hand', 'that', 'does', 'not', 'go', 'away', 'but', 'instead', 'it', 'swell', 'and', 'my', 'hand', 'is', 'numb', 'my', 'roommate', 'has', 'a', 'weird', 'bite', 'on', 'his', 'forehead', 'he', 'caught', 'a', 'fever', 'and', 'was', 'confused', 'about', 'his', 'surroundings', 'he', 'experiences', 'vision', 'loss', 'and', 'fall', 'into', 'occassional', 'comas', 'what', 'should', 'i', 'do', 'about', 'him', 'i', 'have', 'a', 'minor', 'headache', 'vomiting', 'and', 'i', 'saw', 'red', 'rashes', 'all', 'over', 'my', 'back', 'chest', 'and', 'stomach']\n",
      "pattern_words: ['i', 'visit', 'the', 'jungl', 'a', 'few', 'day', 'ago', 'and', 'i', 'got', 'a', 'strange', 'bit', 'becaus', 'it', 'didnt', 'go', 'away', 'a', 'few', 'day', 'lat', 'i', 'beg', 'to', 'develop', 'a', 'fev', 'and', 'musc', 'weak', 'what', 'should', 'i', 'do', 'i', 'discov', 'a', 'weird', 'mosquito', 'bit', 'on', 'my', 'hand', 'that', 'doe', 'not', 'go', 'away', 'but', 'instead', 'it', 'swel', 'and', 'my', 'hand', 'is', 'numb', 'my', 'room', 'has', 'a', 'weird', 'bit', 'on', 'his', 'forehead', 'he', 'caught', 'a', 'fev', 'and', 'was', 'confus', 'about', 'his', 'surround', 'he', 'expery', 'vis', 'loss', 'and', 'fal', 'into', 'occass', 'coma', 'what', 'should', 'i', 'do', 'about', 'him', 'i', 'hav', 'a', 'min', 'headach', 'vomit', 'and', 'i', 'saw', 'red', 'rash', 'al', 'ov', 'my', 'back', 'chest', 'and', 'stomach']\n",
      "BAG:  [1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['hey', 'there', 'i', 'have', 'been', 'feeling', 'extremely', 'bad', 'lately', 'with', 'a', 'fever', 'developing', 'the', 'past', 'few', 'days', 'i', 'have', 'been', 'getting', 'lot', 'of', 'blisters', 'and', 'rashes', 'on', 'my', 'body', 'recently', 'my', 'mouth', 'has', 'also', 'been', 'very', 'sore', 'in', 'a', 'lot', 'of', 'places', 'and', 'there', 'has', 'been', 'itchiness', 'all', 'over', 'my', 'body', 'i', 'went', 'to', 'my', 'friends', 'house', 'last', 'night', 'and', 'ended', 'up', 'developing', 'a', 'fever', 'and', 'red', 'spots', 'al', 'over', 'my', 'body', 'i', 'couldnt', 'even', 'eat', 'anything', 'because', 'i', 'had', 'no', 'appetite', 'and', 'started', 'getting', 'itchy', 'all', 'over', 'my', 'body', 'my', 'mouth', 'has', 'been', 'feeling', 'bad', 'lately', 'and', 'i', 'never', 'feel', 'like', 'eating', 'my', 'muscles', 'have', 'also', 'been', 'more', 'sore', 'lately', 'even', 'though', 'i', 'have', 'not', 'been', 'to', 'the', 'gym', 'and', 'my', 'skin', 'has', 'become', 'more', 'itchy', 'recently', 'blisters', 'and', 'rashes', 'have', 'appeared', 'all', 'over', 'my', 'body', 'recently', 'and', 'they', 'have', 'all', 'started', 'to', 'itch', 'my', 'arms', 'and', 'hamstrings', 'are', 'also', 'starting', 'to', 'ache', 'and', 'i', 'believe', 'i', 'may', 'be', 'developing', 'a', 'fever', 'because', 'my', 'temperature', 'is', 'high', 'from', 'the', 'last', 'measurement', 'red', 'spots', 'are', 'appealing', 'all', 'over', 'my', 'arm', 'and', 'they', 'are', 'feeling', 'quite', 'uncomfortable', 'just', 'this', 'morning', 'i', 'ended', 'up', 'developing', 'a', 'fever', 'and', 'my', 'mouth', 'has', 'felt', 'very', 'sore', 'and', 'uncomfortable', 'my', 'friend', 'gabrielle', 'and', 'i', 'went', 'to', 'the', 'the', 'movies', 'and', 'i', 'ended', 'up', 'developing', 'rashes', 'all', 'over', 'my', 'body', 'which', 'turned', 'into', 'itchy', 'spots', 'later', 'that', 'night', 'i', 'also', 'measured', 'my', 'temperature', 'and', 'had', 'developed', 'a', 'fever', 'this', 'morning', 'i', 'can', 'not', 'even', 'move', 'well', 'because', 'my', 'muscles', 'are', 'aching', 'greatly']\n",
      "pattern_words: ['hey', 'ther', 'i', 'hav', 'been', 'feel', 'extrem', 'bad', 'lat', 'with', 'a', 'fev', 'develop', 'the', 'past', 'few', 'day', 'i', 'hav', 'been', 'get', 'lot', 'of', 'blist', 'and', 'rash', 'on', 'my', 'body', 'rec', 'my', 'mou', 'has', 'also', 'been', 'very', 'sor', 'in', 'a', 'lot', 'of', 'plac', 'and', 'ther', 'has', 'been', 'itchy', 'al', 'ov', 'my', 'body', 'i', 'went', 'to', 'my', 'friend', 'hous', 'last', 'night', 'and', 'end', 'up', 'develop', 'a', 'fev', 'and', 'red', 'spot', 'al', 'ov', 'my', 'body', 'i', 'couldnt', 'ev', 'eat', 'anyth', 'becaus', 'i', 'had', 'no', 'appetit', 'and', 'start', 'get', 'itchy', 'al', 'ov', 'my', 'body', 'my', 'mou', 'has', 'been', 'feel', 'bad', 'lat', 'and', 'i', 'nev', 'feel', 'lik', 'eat', 'my', 'musc', 'hav', 'also', 'been', 'mor', 'sor', 'lat', 'ev', 'though', 'i', 'hav', 'not', 'been', 'to', 'the', 'gym', 'and', 'my', 'skin', 'has', 'becom', 'mor', 'itchy', 'rec', 'blist', 'and', 'rash', 'hav', 'appear', 'al', 'ov', 'my', 'body', 'rec', 'and', 'they', 'hav', 'al', 'start', 'to', 'itch', 'my', 'arm', 'and', 'hamst', 'ar', 'also', 'start', 'to', 'ach', 'and', 'i', 'believ', 'i', 'may', 'be', 'develop', 'a', 'fev', 'becaus', 'my', 'temp', 'is', 'high', 'from', 'the', 'last', 'meas', 'red', 'spot', 'ar', 'ap', 'al', 'ov', 'my', 'arm', 'and', 'they', 'ar', 'feel', 'quit', 'uncomfort', 'just', 'thi', 'morn', 'i', 'end', 'up', 'develop', 'a', 'fev', 'and', 'my', 'mou', 'has', 'felt', 'very', 'sor', 'and', 'uncomfort', 'my', 'friend', 'gabriel', 'and', 'i', 'went', 'to', 'the', 'the', 'movy', 'and', 'i', 'end', 'up', 'develop', 'rash', 'al', 'ov', 'my', 'body', 'which', 'turn', 'into', 'itchy', 'spot', 'lat', 'that', 'night', 'i', 'also', 'meas', 'my', 'temp', 'and', 'had', 'develop', 'a', 'fev', 'thi', 'morn', 'i', 'can', 'not', 'ev', 'mov', 'wel', 'becaus', 'my', 'musc', 'ar', 'ach', 'gre']\n",
      "BAG:  [1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['icant', 'remember', 'people', 'say', 'ive', 'gotten', 'angrier', 'and', 'sometimes', 'i', 'do', 'feel', 'angry', 'although', 'i', 'dont', 'know', 'why', 'i', 'couldnt', 'remember', 'her', 'faceshe', 'was', 'important', 'to', 'me', 'but', 'i', 'could', 'not', 'for', 'the', 'life', 'of', 'me', 'remember', 'her', 'face', 'where', 'did', 'i', 'leave', 'my', 'bank', 'notes', 'it', 'was', 'just', 'yesterday', 'when', 'i', 'retrieved', 'them', 'what', 'did', 'you', 'say', 'can', 'you', 'speak', 'louder', 'my', 'muscles', 'are', 'also', 'hurting', 'and', 'ache', 'quite', 'a', 'lot', 'its', 'also', 'weird', 'because', 'my', 'mother', 'was', 'home', 'last', 'weekend', 'and', 'we', 'prepared', 'a', 'big', 'dinner', 'but', 'i', 'had', 'no', 'appetite', 'completing', 'tasks', 'and', 'doing', 'things', 'has', 'been', 'very', 'difficult', 'lately', 'as', 'i', 'seem', 'to', 'not', 'remember', 'things', 'i', 'did', 'in', 'the', 'past', 'doing', 'things', 'i', 'was', 'faimiliar', 'with', 'has', 'been', 'confusing', 'and', 'felt', 'out', 'of', 'place', 'and', 'it', 'appears', 'my', 'spatial', 'and', 'visual', 'senses', 'are', 'also', 'diminishing']\n",
      "pattern_words: ['ic', 'rememb', 'peopl', 'say', 'iv', 'got', 'angry', 'and', 'sometim', 'i', 'do', 'feel', 'angry', 'although', 'i', 'dont', 'know', 'why', 'i', 'couldnt', 'rememb', 'her', 'facesh', 'was', 'import', 'to', 'me', 'but', 'i', 'could', 'not', 'for', 'the', 'lif', 'of', 'me', 'rememb', 'her', 'fac', 'wher', 'did', 'i', 'leav', 'my', 'bank', 'not', 'it', 'was', 'just', 'yesterday', 'when', 'i', 'retriev', 'them', 'what', 'did', 'you', 'say', 'can', 'you', 'speak', 'loud', 'my', 'musc', 'ar', 'also', 'hurt', 'and', 'ach', 'quit', 'a', 'lot', 'it', 'also', 'weird', 'becaus', 'my', 'moth', 'was', 'hom', 'last', 'weekend', 'and', 'we', 'prep', 'a', 'big', 'din', 'but', 'i', 'had', 'no', 'appetit', 'complet', 'task', 'and', 'doing', 'thing', 'has', 'been', 'very', 'difficult', 'lat', 'as', 'i', 'seem', 'to', 'not', 'rememb', 'thing', 'i', 'did', 'in', 'the', 'past', 'doing', 'thing', 'i', 'was', 'faimili', 'with', 'has', 'been', 'confus', 'and', 'felt', 'out', 'of', 'plac', 'and', 'it', 'appear', 'my', 'spat', 'and', 'vis', 'sens', 'ar', 'also', 'dimin']\n",
      "BAG:  [1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
      "TOKENIZED WORDS:  ['my', 'back', 'hurts', 'so', 'much', 'just', 'from', 'walking', 'around', 'and', 'my', 'ankles', 'are', 'swollen', 'too', 'dont', 'talk', 'to', 'me', 'just', 'go', 'away', 'and', 'leave', 'me', 'alone', 'my', 'period', 'is', 'late', 'by', 'three', 'daysits', 'almost', 'never', 'late', 'my', 'side', 'was', 'cramping', 'so', 'hard', 'it', 'felt', 'like', 'someone', 'was', 'shredding', 'me', 'inside', 'out']\n",
      "pattern_words: ['my', 'back', 'hurt', 'so', 'much', 'just', 'from', 'walk', 'around', 'and', 'my', 'ankl', 'ar', 'swol', 'too', 'dont', 'talk', 'to', 'me', 'just', 'go', 'away', 'and', 'leav', 'me', 'alon', 'my', 'period', 'is', 'lat', 'by', 'three', 'daysit', 'almost', 'nev', 'lat', 'my', 'sid', 'was', 'cramp', 'so', 'hard', 'it', 'felt', 'lik', 'someon', 'was', 'shredding', 'me', 'insid', 'out']\n",
      "BAG:  [0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['no', 'matter', 'how', 'little', 'i', 'eat', 'i', 'get', 'fatter', 'food', 'is', 'the', 'enemy', 'and', 'i', 'refuse', 'to', 'surrender', 'how', 'many', 'calories', 'are', 'in', 'that', 'sandwiche', 'ill', 'just', 'take', 'an', 'apple', 'instead', 'i', 'feel', 'so', 'cold', 'even', 'when', 'i', 'wear', 'an', 'extra', 'coat', 'i', 'purged', 'myself', 'clean', 'today', 'once', 'more', 'just', 'like', 'i', 'always', 'have', 'except', 'there', 'was', 'a', 'burning', 'sensation', 'down', 'my', 'throat', 'i', 'guess', 'if', 'thats', 'the', 'price', 'i', 'have', 'to', 'pay']\n",
      "pattern_words: ['no', 'mat', 'how', 'littl', 'i', 'eat', 'i', 'get', 'fat', 'food', 'is', 'the', 'enemy', 'and', 'i', 'refus', 'to', 'surrend', 'how', 'many', 'cal', 'ar', 'in', 'that', 'sandwich', 'il', 'just', 'tak', 'an', 'appl', 'instead', 'i', 'feel', 'so', 'cold', 'ev', 'when', 'i', 'wear', 'an', 'extr', 'coat', 'i', 'purg', 'myself', 'cle', 'today', 'ont', 'mor', 'just', 'lik', 'i', 'alway', 'hav', 'exceiv', 'ther', 'was', 'a', 'burn', 'sens', 'down', 'my', 'throat', 'i', 'guess', 'if', 'that', 'the', 'pric', 'i', 'hav', 'to', 'pay']\n",
      "BAG:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['recently', 'my', 'chest', 'is', 'feeling', 'pretty', 'tight', 'and', 'even', 'numb', 'at', 'times', 'i', 'have', 'become', 'light', 'headed', 'and', 'dizzy', 'for', 'most', 'of', 'the', 'day', 'rendering', 'me', 'sad', 'and', 'useless', 'i', 'also', 'frequently', 'vomit', 'and', 'expierience', 'heartburn', 'which', 'is', 'hella', 'painful', 'im', 'really', 'worried', 'that', 'i', 'might', 'have', 'a', 'serious', 'disease', 'and', 'my', 'indigestion', 'is', 'not', 'helping']\n",
      "pattern_words: ['rec', 'my', 'chest', 'is', 'feel', 'pretty', 'tight', 'and', 'ev', 'numb', 'at', 'tim', 'i', 'hav', 'becom', 'light', 'head', 'and', 'dizzy', 'for', 'most', 'of', 'the', 'day', 'rend', 'me', 'sad', 'and', 'useless', 'i', 'also', 'frequ', 'vomit', 'and', 'expiery', 'heartburn', 'which', 'is', 'hell', 'pain', 'im', 'real', 'worry', 'that', 'i', 'might', 'hav', 'a', 'sery', 'diseas', 'and', 'my', 'indigest', 'is', 'not', 'help']\n",
      "BAG:  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['there', 'are', 'a', 'bunch', 'of', 'red', 'spots', 'on', 'my', 'chest', 'and', 'i', 'dont', 'think', 'ive', 'contacted', 'any', 'allergenswhy', 'wont', 'they', 'go', 'away', 'there', 'are', 'small', 'bits', 'of', 'milky', 'white', 'liquid', 'coming', 'out', 'of', 'my', 'nipplesshould', 'i', 'be', 'concerned', 'parts', 'of', 'my', 'breast', 'felt', 'a', 'bit', 'hardalmost', 'lumpy', 'would', 'this', 'go', 'away', 'after', 'puberty', 'it', 'just', 'occurred', 'to', 'me', 'today', 'that', 'my', 'nipples', 'lookdifferent', 'are', 'they', 'supposed', 'to', 'be', 'sunken', 'in']\n",
      "pattern_words: ['ther', 'ar', 'a', 'bunch', 'of', 'red', 'spot', 'on', 'my', 'chest', 'and', 'i', 'dont', 'think', 'iv', 'contact', 'any', 'allergenswhy', 'wont', 'they', 'go', 'away', 'ther', 'ar', 'smal', 'bit', 'of', 'milky', 'whit', 'liquid', 'com', 'out', 'of', 'my', 'nipplesshould', 'i', 'be', 'concern', 'part', 'of', 'my', 'breast', 'felt', 'a', 'bit', 'hardalmost', 'lumpy', 'would', 'thi', 'go', 'away', 'aft', 'puberty', 'it', 'just', 'occur', 'to', 'me', 'today', 'that', 'my', 'nippl', 'lookdiff', 'ar', 'they', 'suppos', 'to', 'be', 'sunk', 'in']\n",
      "BAG:  [1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "TOKENIZED WORDS:  ['ive', 'been', 'feeling', 'like', 'i', 'needed', 'to', 'go', 'to', 'the', 'washroom', 'more', 'and', 'more', 'often', 'these', 'days', 'im', 'beginning', 'to', 'dread', 'my', 'washroom', 'trips', 'these', 'days', 'because', 'it', 'hurts', 'to', 'urinate', 'when', 'i', 'went', 'to', 'piss', 'this', 'morning', 'there', 'was', 'blood', 'and', 'my', 'piss', 'was', 'redish', 'whats', 'wrong', 'with', 'me', 'having', 'sex', 'with', 'my', 'girlfriend', 'yesterday', 'had', 'hurt', 'so', 'much']\n",
      "pattern_words: ['iv', 'been', 'feel', 'lik', 'i', 'nee', 'to', 'go', 'to', 'the', 'washroom', 'mor', 'and', 'mor', 'oft', 'thes', 'day', 'im', 'begin', 'to', 'dread', 'my', 'washroom', 'trip', 'thes', 'day', 'becaus', 'it', 'hurt', 'to', 'urin', 'when', 'i', 'went', 'to', 'piss', 'thi', 'morn', 'ther', 'was', 'blood', 'and', 'my', 'piss', 'was', 'red', 'what', 'wrong', 'with', 'me', 'hav', 'sex', 'with', 'my', 'girlfriend', 'yesterday', 'had', 'hurt', 'so', 'much']\n",
      "BAG:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# create our training data\n",
    "training = []\n",
    "output = []\n",
    "# create an empty array for our output\n",
    "output_empty = [0] * len(classes)\n",
    "\n",
    "# training set, bag of words for each sentence\n",
    "for doc in documents:\n",
    "    # initialize our bag of words\n",
    "    bag = []\n",
    "    # list of tokenized words for the pattern\n",
    "    pattern_words = doc[0]\n",
    "    print(\"TOKENIZED WORDS: \",pattern_words)\n",
    "    # stem each word\n",
    "    pattern_words = [stemmer.stem(word.lower()) for word in pattern_words]\n",
    "    # create our bag of words array\n",
    "    for w in words:\n",
    "        bag.append(1) if w in pattern_words else bag.append(0)\n",
    "    print(\"pattern_words:\",pattern_words)\n",
    "    print(\"BAG: \",bag)\n",
    "\n",
    "    # output is a '0' for each tag and '1' for current tag\n",
    "    output_row = list(output_empty)\n",
    "    output_row[classes.index(doc[1])] = 1\n",
    "\n",
    "    training.append([bag, output_row])\n",
    "\n",
    "# shuffle our features and turn into np.array\n",
    "random.shuffle(training)\n",
    "training = np.array(training)\n",
    "\n",
    "# create train and test lists\n",
    "train_x = list(training[:,0])\n",
    "train_y = list(training[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\steven\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "---------------------------------\n",
      "Run id: HH81YL\n",
      "Log directory: tflearn_logs/\n",
      "INFO:tensorflow:Summary name Accuracy/ (raw) is illegal; using Accuracy/__raw_ instead.\n",
      "---------------------------------\n",
      "Training samples: 14\n",
      "Validation samples: 0\n",
      "--\n",
      "Training Step: 1  | time: 0.140s\n",
      "| Adam | epoch: 001 | loss: 0.00000 - acc: 0.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2  | total loss: \u001b[1m\u001b[32m2.37620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 002 | loss: 2.37620 - acc: 0.1286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3  | total loss: \u001b[1m\u001b[32m2.58921\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 003 | loss: 2.58921 - acc: 0.1987 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4  | total loss: \u001b[1m\u001b[32m2.61009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 004 | loss: 2.61009 - acc: 0.2104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5  | total loss: \u001b[1m\u001b[32m2.59774\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 005 | loss: 2.59774 - acc: 0.2131 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6  | total loss: \u001b[1m\u001b[32m2.62243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 006 | loss: 2.62243 - acc: 0.1679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7  | total loss: \u001b[1m\u001b[32m2.57255\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 007 | loss: 2.57255 - acc: 0.5386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8  | total loss: \u001b[1m\u001b[32m2.53692\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 008 | loss: 2.53692 - acc: 0.7178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9  | total loss: \u001b[1m\u001b[32m2.50243\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 009 | loss: 2.50243 - acc: 0.8294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 10  | total loss: \u001b[1m\u001b[32m2.46423\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 010 | loss: 2.46423 - acc: 0.8790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m2.42004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 011 | loss: 2.42004 - acc: 0.9363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 12  | total loss: \u001b[1m\u001b[32m2.36852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 012 | loss: 2.36852 - acc: 0.9650 -- iter: 14/14\n",
      "--\n",
      "Training Step: 13  | total loss: \u001b[1m\u001b[32m2.30870\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 013 | loss: 2.30870 - acc: 0.9800 -- iter: 14/14\n",
      "--\n",
      "Training Step: 14  | total loss: \u001b[1m\u001b[32m2.23985\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 014 | loss: 2.23985 - acc: 0.9882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 15  | total loss: \u001b[1m\u001b[32m2.16142\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 015 | loss: 2.16142 - acc: 0.9928 -- iter: 14/14\n",
      "--\n",
      "Training Step: 16  | total loss: \u001b[1m\u001b[32m2.07307\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 016 | loss: 2.07307 - acc: 0.9955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 17  | total loss: \u001b[1m\u001b[32m1.97476\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 017 | loss: 1.97476 - acc: 0.9971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 18  | total loss: \u001b[1m\u001b[32m1.86685\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 018 | loss: 1.86685 - acc: 0.9981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 19  | total loss: \u001b[1m\u001b[32m1.75017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 019 | loss: 1.75017 - acc: 0.9987 -- iter: 14/14\n",
      "--\n",
      "Training Step: 20  | total loss: \u001b[1m\u001b[32m1.62618\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 020 | loss: 1.62618 - acc: 0.9991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 21  | total loss: \u001b[1m\u001b[32m1.49696\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 021 | loss: 1.49696 - acc: 0.9994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 22  | total loss: \u001b[1m\u001b[32m1.36509\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 022 | loss: 1.36509 - acc: 0.9996 -- iter: 14/14\n",
      "--\n",
      "Training Step: 23  | total loss: \u001b[1m\u001b[32m1.23343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 023 | loss: 1.23343 - acc: 0.9997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 24  | total loss: \u001b[1m\u001b[32m1.10477\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 024 | loss: 1.10477 - acc: 0.9998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 25  | total loss: \u001b[1m\u001b[32m0.98154\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 025 | loss: 0.98154 - acc: 0.9998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 26  | total loss: \u001b[1m\u001b[32m0.86562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 026 | loss: 0.86562 - acc: 0.9999 -- iter: 14/14\n",
      "--\n",
      "Training Step: 27  | total loss: \u001b[1m\u001b[32m0.75828\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 027 | loss: 0.75828 - acc: 0.9999 -- iter: 14/14\n",
      "--\n",
      "Training Step: 28  | total loss: \u001b[1m\u001b[32m0.66024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 028 | loss: 0.66024 - acc: 0.9999 -- iter: 14/14\n",
      "--\n",
      "Training Step: 29  | total loss: \u001b[1m\u001b[32m0.57174\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 029 | loss: 0.57174 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 30  | total loss: \u001b[1m\u001b[32m0.49268\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 030 | loss: 0.49268 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 31  | total loss: \u001b[1m\u001b[32m0.42267\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 031 | loss: 0.42267 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 32  | total loss: \u001b[1m\u001b[32m0.36113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 032 | loss: 0.36113 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 33  | total loss: \u001b[1m\u001b[32m0.30744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 033 | loss: 0.30744 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 34  | total loss: \u001b[1m\u001b[32m0.26087\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 034 | loss: 0.26087 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 35  | total loss: \u001b[1m\u001b[32m0.22073\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 035 | loss: 0.22073 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 36  | total loss: \u001b[1m\u001b[32m0.18630\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 036 | loss: 0.18630 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 37  | total loss: \u001b[1m\u001b[32m0.15692\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 037 | loss: 0.15692 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 38  | total loss: \u001b[1m\u001b[32m0.13195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 038 | loss: 0.13195 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 39  | total loss: \u001b[1m\u001b[32m0.11083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 039 | loss: 0.11083 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 40  | total loss: \u001b[1m\u001b[32m0.09305\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 040 | loss: 0.09305 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 41  | total loss: \u001b[1m\u001b[32m0.07813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 041 | loss: 0.07813 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 42  | total loss: \u001b[1m\u001b[32m0.06565\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 042 | loss: 0.06565 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 43  | total loss: \u001b[1m\u001b[32m0.05524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 043 | loss: 0.05524 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 44  | total loss: \u001b[1m\u001b[32m0.04656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 044 | loss: 0.04656 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 45  | total loss: \u001b[1m\u001b[32m0.03933\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 045 | loss: 0.03933 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 46  | total loss: \u001b[1m\u001b[32m0.03330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 046 | loss: 0.03330 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 47  | total loss: \u001b[1m\u001b[32m0.02827\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 047 | loss: 0.02827 - acc: 1.0000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 48  | total loss: \u001b[1m\u001b[32m1.87436\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 048 | loss: 1.87436 - acc: 0.8393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 49  | total loss: \u001b[1m\u001b[32m1.57875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 049 | loss: 1.57875 - acc: 0.8647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 50  | total loss: \u001b[1m\u001b[32m2.98876\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 050 | loss: 2.98876 - acc: 0.7416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 51  | total loss: \u001b[1m\u001b[32m2.53327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 051 | loss: 2.53327 - acc: 0.7810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 52  | total loss: \u001b[1m\u001b[32m3.45958\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 052 | loss: 3.45958 - acc: 0.6853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 53  | total loss: \u001b[1m\u001b[32m2.94987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 053 | loss: 2.94987 - acc: 0.7317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 54  | total loss: \u001b[1m\u001b[32m3.94577\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 054 | loss: 3.94577 - acc: 0.6359 -- iter: 14/14\n",
      "--\n",
      "Training Step: 55  | total loss: \u001b[1m\u001b[32m3.38348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 055 | loss: 3.38348 - acc: 0.6879 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 56  | total loss: \u001b[1m\u001b[32m2.90957\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 056 | loss: 2.90957 - acc: 0.7318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 57  | total loss: \u001b[1m\u001b[32m2.50919\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 057 | loss: 2.50919 - acc: 0.7689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 58  | total loss: \u001b[1m\u001b[32m2.17014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 058 | loss: 2.17014 - acc: 0.8004 -- iter: 14/14\n",
      "--\n",
      "Training Step: 59  | total loss: \u001b[1m\u001b[32m1.88236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 059 | loss: 1.88236 - acc: 0.8272 -- iter: 14/14\n",
      "--\n",
      "Training Step: 60  | total loss: \u001b[1m\u001b[32m1.63752\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 060 | loss: 1.63752 - acc: 0.8501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 61  | total loss: \u001b[1m\u001b[32m1.42870\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 061 | loss: 1.42870 - acc: 0.8697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 62  | total loss: \u001b[1m\u001b[32m1.25011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 062 | loss: 1.25011 - acc: 0.8864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 63  | total loss: \u001b[1m\u001b[32m1.09695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 063 | loss: 1.09695 - acc: 0.9008 -- iter: 14/14\n",
      "--\n",
      "Training Step: 64  | total loss: \u001b[1m\u001b[32m0.96523\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 064 | loss: 0.96523 - acc: 0.9132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 65  | total loss: \u001b[1m\u001b[32m0.85162\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 065 | loss: 0.85162 - acc: 0.9239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 66  | total loss: \u001b[1m\u001b[32m0.75338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 066 | loss: 0.75338 - acc: 0.9332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 67  | total loss: \u001b[1m\u001b[32m0.66820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 067 | loss: 0.66820 - acc: 0.9412 -- iter: 14/14\n",
      "--\n",
      "Training Step: 68  | total loss: \u001b[1m\u001b[32m1.41642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 068 | loss: 1.41642 - acc: 0.8382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 69  | total loss: \u001b[1m\u001b[32m1.25642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 069 | loss: 1.25642 - acc: 0.8571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 70  | total loss: \u001b[1m\u001b[32m1.11742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 070 | loss: 1.11742 - acc: 0.8736 -- iter: 14/14\n",
      "--\n",
      "Training Step: 71  | total loss: \u001b[1m\u001b[32m0.99645\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 071 | loss: 0.99645 - acc: 0.8880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 72  | total loss: \u001b[1m\u001b[32m0.89098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 072 | loss: 0.89098 - acc: 0.9006 -- iter: 14/14\n",
      "--\n",
      "Training Step: 73  | total loss: \u001b[1m\u001b[32m0.79882\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 073 | loss: 0.79882 - acc: 0.9116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 74  | total loss: \u001b[1m\u001b[32m1.40767\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 074 | loss: 1.40767 - acc: 0.8116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 75  | total loss: \u001b[1m\u001b[32m1.26285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 075 | loss: 1.26285 - acc: 0.8320 -- iter: 14/14\n",
      "--\n",
      "Training Step: 76  | total loss: \u001b[1m\u001b[32m1.13615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 076 | loss: 1.13615 - acc: 0.8500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 77  | total loss: \u001b[1m\u001b[32m1.02514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 077 | loss: 1.02514 - acc: 0.8659 -- iter: 14/14\n",
      "--\n",
      "Training Step: 78  | total loss: \u001b[1m\u001b[32m1.60653\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 078 | loss: 1.60653 - acc: 0.7753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 79  | total loss: \u001b[1m\u001b[32m1.45155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 079 | loss: 1.45155 - acc: 0.7985 -- iter: 14/14\n",
      "--\n",
      "Training Step: 80  | total loss: \u001b[1m\u001b[32m1.31552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 080 | loss: 1.31552 - acc: 0.8191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 81  | total loss: \u001b[1m\u001b[32m1.19593\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 081 | loss: 1.19593 - acc: 0.8374 -- iter: 14/14\n",
      "--\n",
      "Training Step: 82  | total loss: \u001b[1m\u001b[32m1.57010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 082 | loss: 1.57010 - acc: 0.7608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 83  | total loss: \u001b[1m\u001b[32m1.42926\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 083 | loss: 1.42926 - acc: 0.7847 -- iter: 14/14\n",
      "--\n",
      "Training Step: 84  | total loss: \u001b[1m\u001b[32m1.66420\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 084 | loss: 1.66420 - acc: 0.7348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 85  | total loss: \u001b[1m\u001b[32m1.51849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 085 | loss: 1.51849 - acc: 0.7614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 86  | total loss: \u001b[1m\u001b[32m1.81215\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 086 | loss: 1.81215 - acc: 0.6924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 87  | total loss: \u001b[1m\u001b[32m1.65806\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 087 | loss: 1.65806 - acc: 0.7231 -- iter: 14/14\n",
      "--\n",
      "Training Step: 88  | total loss: \u001b[1m\u001b[32m1.94458\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 088 | loss: 1.94458 - acc: 0.6508 -- iter: 14/14\n",
      "--\n",
      "Training Step: 89  | total loss: \u001b[1m\u001b[32m1.78596\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 089 | loss: 1.78596 - acc: 0.6857 -- iter: 14/14\n",
      "--\n",
      "Training Step: 90  | total loss: \u001b[1m\u001b[32m1.96832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 090 | loss: 1.96832 - acc: 0.6243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 91  | total loss: \u001b[1m\u001b[32m1.81774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 091 | loss: 1.81774 - acc: 0.6619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 92  | total loss: \u001b[1m\u001b[32m2.00123\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 092 | loss: 2.00123 - acc: 0.6028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 93  | total loss: \u001b[1m\u001b[32m1.85806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 093 | loss: 1.85806 - acc: 0.6425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 94  | total loss: \u001b[1m\u001b[32m1.73358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 094 | loss: 1.73358 - acc: 0.6783 -- iter: 14/14\n",
      "--\n",
      "Training Step: 95  | total loss: \u001b[1m\u001b[32m1.62427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 095 | loss: 1.62427 - acc: 0.7105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 96  | total loss: \u001b[1m\u001b[32m1.52697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 096 | loss: 1.52697 - acc: 0.7394 -- iter: 14/14\n",
      "--\n",
      "Training Step: 97  | total loss: \u001b[1m\u001b[32m1.43901\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 097 | loss: 1.43901 - acc: 0.7655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 98  | total loss: \u001b[1m\u001b[32m1.35817\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 098 | loss: 1.35817 - acc: 0.7889 -- iter: 14/14\n",
      "--\n",
      "Training Step: 99  | total loss: \u001b[1m\u001b[32m1.28270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 099 | loss: 1.28270 - acc: 0.8100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 100  | total loss: \u001b[1m\u001b[32m1.49977\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 100 | loss: 1.49977 - acc: 0.7362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 101  | total loss: \u001b[1m\u001b[32m1.40507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 101 | loss: 1.40507 - acc: 0.7626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 102  | total loss: \u001b[1m\u001b[32m1.31748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 102 | loss: 1.31748 - acc: 0.7863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 103  | total loss: \u001b[1m\u001b[32m1.23568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 103 | loss: 1.23568 - acc: 0.8077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 104  | total loss: \u001b[1m\u001b[32m1.15864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 104 | loss: 1.15864 - acc: 0.8269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 105  | total loss: \u001b[1m\u001b[32m1.08558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 105 | loss: 1.08558 - acc: 0.8442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 106  | total loss: \u001b[1m\u001b[32m1.36676\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 106 | loss: 1.36676 - acc: 0.7598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 107  | total loss: \u001b[1m\u001b[32m1.26732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 107 | loss: 1.26732 - acc: 0.7838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 108  | total loss: \u001b[1m\u001b[32m1.50296\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 108 | loss: 1.50296 - acc: 0.7126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 109  | total loss: \u001b[1m\u001b[32m1.38728\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 109 | loss: 1.38728 - acc: 0.7413 -- iter: 14/14\n",
      "--\n",
      "Training Step: 110  | total loss: \u001b[1m\u001b[32m1.62946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 110 | loss: 1.62946 - acc: 0.6815 -- iter: 14/14\n",
      "--\n",
      "Training Step: 111  | total loss: \u001b[1m\u001b[32m1.50059\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 111 | loss: 1.50059 - acc: 0.7133 -- iter: 14/14\n",
      "--\n",
      "Training Step: 112  | total loss: \u001b[1m\u001b[32m1.38453\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 112 | loss: 1.38453 - acc: 0.7420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 113  | total loss: \u001b[1m\u001b[32m1.27954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 113 | loss: 1.27954 - acc: 0.7678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 114  | total loss: \u001b[1m\u001b[32m1.57789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 114 | loss: 1.57789 - acc: 0.6910 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 115  | total loss: \u001b[1m\u001b[32m1.45332\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 115 | loss: 1.45332 - acc: 0.7219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 116  | total loss: \u001b[1m\u001b[32m1.34141\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 116 | loss: 1.34141 - acc: 0.7497 -- iter: 14/14\n",
      "--\n",
      "Training Step: 117  | total loss: \u001b[1m\u001b[32m1.24039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 117 | loss: 1.24039 - acc: 0.7747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 118  | total loss: \u001b[1m\u001b[32m1.54860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 118 | loss: 1.54860 - acc: 0.6973 -- iter: 14/14\n",
      "--\n",
      "Training Step: 119  | total loss: \u001b[1m\u001b[32m1.42692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 119 | loss: 1.42692 - acc: 0.7275 -- iter: 14/14\n",
      "--\n",
      "Training Step: 120  | total loss: \u001b[1m\u001b[32m1.31768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 120 | loss: 1.31768 - acc: 0.7548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 121  | total loss: \u001b[1m\u001b[32m1.21911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 121 | loss: 1.21911 - acc: 0.7793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 122  | total loss: \u001b[1m\u001b[32m1.48658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 122 | loss: 1.48658 - acc: 0.7157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 123  | total loss: \u001b[1m\u001b[32m1.37079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 123 | loss: 1.37079 - acc: 0.7441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 124  | total loss: \u001b[1m\u001b[32m1.58561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 124 | loss: 1.58561 - acc: 0.6840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 125  | total loss: \u001b[1m\u001b[32m1.46091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 125 | loss: 1.46091 - acc: 0.7156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 126  | total loss: \u001b[1m\u001b[32m1.34920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 126 | loss: 1.34920 - acc: 0.7440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 127  | total loss: \u001b[1m\u001b[32m1.24864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 127 | loss: 1.24864 - acc: 0.7696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 128  | total loss: \u001b[1m\u001b[32m1.51945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 128 | loss: 1.51945 - acc: 0.6927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 129  | total loss: \u001b[1m\u001b[32m1.40238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 129 | loss: 1.40238 - acc: 0.7234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 130  | total loss: \u001b[1m\u001b[32m1.61948\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 130 | loss: 1.61948 - acc: 0.6653 -- iter: 14/14\n",
      "--\n",
      "Training Step: 131  | total loss: \u001b[1m\u001b[32m1.49455\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 131 | loss: 1.49455 - acc: 0.6988 -- iter: 14/14\n",
      "--\n",
      "Training Step: 132  | total loss: \u001b[1m\u001b[32m1.69320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 132 | loss: 1.69320 - acc: 0.6361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 133  | total loss: \u001b[1m\u001b[32m1.56382\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 133 | loss: 1.56382 - acc: 0.6725 -- iter: 14/14\n",
      "--\n",
      "Training Step: 134  | total loss: \u001b[1m\u001b[32m1.78970\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 134 | loss: 1.78970 - acc: 0.6052 -- iter: 14/14\n",
      "--\n",
      "Training Step: 135  | total loss: \u001b[1m\u001b[32m1.65444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 135 | loss: 1.65444 - acc: 0.6447 -- iter: 14/14\n",
      "--\n",
      "Training Step: 136  | total loss: \u001b[1m\u001b[32m1.87931\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 136 | loss: 1.87931 - acc: 0.5802 -- iter: 14/14\n",
      "--\n",
      "Training Step: 137  | total loss: \u001b[1m\u001b[32m1.73989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 137 | loss: 1.73989 - acc: 0.6222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 138  | total loss: \u001b[1m\u001b[32m1.91069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 138 | loss: 1.91069 - acc: 0.5671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 139  | total loss: \u001b[1m\u001b[32m1.77330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 139 | loss: 1.77330 - acc: 0.6104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 140  | total loss: \u001b[1m\u001b[32m1.98007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 140 | loss: 1.98007 - acc: 0.5494 -- iter: 14/14\n",
      "--\n",
      "Training Step: 141  | total loss: \u001b[1m\u001b[32m1.84094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 141 | loss: 1.84094 - acc: 0.5944 -- iter: 14/14\n",
      "--\n",
      "Training Step: 142  | total loss: \u001b[1m\u001b[32m1.71769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 142 | loss: 1.71769 - acc: 0.6350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 143  | total loss: \u001b[1m\u001b[32m1.60751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 143 | loss: 1.60751 - acc: 0.6715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 144  | total loss: \u001b[1m\u001b[32m1.78203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 144 | loss: 1.78203 - acc: 0.6115 -- iter: 14/14\n",
      "--\n",
      "Training Step: 145  | total loss: \u001b[1m\u001b[32m1.66593\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 145 | loss: 1.66593 - acc: 0.6503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 146  | total loss: \u001b[1m\u001b[32m1.79220\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 146 | loss: 1.79220 - acc: 0.6067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 147  | total loss: \u001b[1m\u001b[32m1.67528\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 147 | loss: 1.67528 - acc: 0.6461 -- iter: 14/14\n",
      "--\n",
      "Training Step: 148  | total loss: \u001b[1m\u001b[32m1.85069\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 148 | loss: 1.85069 - acc: 0.5886 -- iter: 14/14\n",
      "--\n",
      "Training Step: 149  | total loss: \u001b[1m\u001b[32m1.72789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 149 | loss: 1.72789 - acc: 0.6297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 150  | total loss: \u001b[1m\u001b[32m1.90934\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 150 | loss: 1.90934 - acc: 0.5668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 151  | total loss: \u001b[1m\u001b[32m1.78105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 151 | loss: 1.78105 - acc: 0.6101 -- iter: 14/14\n",
      "--\n",
      "Training Step: 152  | total loss: \u001b[1m\u001b[32m1.96078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 152 | loss: 1.96078 - acc: 0.5491 -- iter: 14/14\n",
      "--\n",
      "Training Step: 153  | total loss: \u001b[1m\u001b[32m1.82813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 153 | loss: 1.82813 - acc: 0.5942 -- iter: 14/14\n",
      "--\n",
      "Training Step: 154  | total loss: \u001b[1m\u001b[32m1.70870\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 154 | loss: 1.70870 - acc: 0.6348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 155  | total loss: \u001b[1m\u001b[32m1.60021\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 155 | loss: 1.60021 - acc: 0.6713 -- iter: 14/14\n",
      "--\n",
      "Training Step: 156  | total loss: \u001b[1m\u001b[32m1.50072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 156 | loss: 1.50072 - acc: 0.7041 -- iter: 14/14\n",
      "--\n",
      "Training Step: 157  | total loss: \u001b[1m\u001b[32m1.40862\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 157 | loss: 1.40862 - acc: 0.7337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 158  | total loss: \u001b[1m\u001b[32m1.56604\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 158 | loss: 1.56604 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 159  | total loss: \u001b[1m\u001b[32m1.46250\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 159 | loss: 1.46250 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 160  | total loss: \u001b[1m\u001b[32m1.65076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 160 | loss: 1.65076 - acc: 0.6436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 161  | total loss: \u001b[1m\u001b[32m1.53555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 161 | loss: 1.53555 - acc: 0.6792 -- iter: 14/14\n",
      "--\n",
      "Training Step: 162  | total loss: \u001b[1m\u001b[32m1.72656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 162 | loss: 1.72656 - acc: 0.6185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 163  | total loss: \u001b[1m\u001b[32m1.60220\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 163 | loss: 1.60220 - acc: 0.6566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 164  | total loss: \u001b[1m\u001b[32m1.76651\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 164 | loss: 1.76651 - acc: 0.6052 -- iter: 14/14\n",
      "--\n",
      "Training Step: 165  | total loss: \u001b[1m\u001b[32m1.63773\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 165 | loss: 1.63773 - acc: 0.6447 -- iter: 14/14\n",
      "--\n",
      "Training Step: 166  | total loss: \u001b[1m\u001b[32m1.52149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 166 | loss: 1.52149 - acc: 0.6802 -- iter: 14/14\n",
      "--\n",
      "Training Step: 167  | total loss: \u001b[1m\u001b[32m1.41587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 167 | loss: 1.41587 - acc: 0.7122 -- iter: 14/14\n",
      "--\n",
      "Training Step: 168  | total loss: \u001b[1m\u001b[32m1.53526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 168 | loss: 1.53526 - acc: 0.6767 -- iter: 14/14\n",
      "--\n",
      "Training Step: 169  | total loss: \u001b[1m\u001b[32m1.42593\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 169 | loss: 1.42593 - acc: 0.7090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 170  | total loss: \u001b[1m\u001b[32m1.60847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 170 | loss: 1.60847 - acc: 0.6524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 171  | total loss: \u001b[1m\u001b[32m1.49028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 171 | loss: 1.49028 - acc: 0.6872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 172  | total loss: \u001b[1m\u001b[32m1.38309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 172 | loss: 1.38309 - acc: 0.7185 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 173  | total loss: \u001b[1m\u001b[32m1.28525\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 173 | loss: 1.28525 - acc: 0.7466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 174  | total loss: \u001b[1m\u001b[32m1.48701\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 174 | loss: 1.48701 - acc: 0.6791 -- iter: 14/14\n",
      "--\n",
      "Training Step: 175  | total loss: \u001b[1m\u001b[32m1.37648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 175 | loss: 1.37648 - acc: 0.7112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 176  | total loss: \u001b[1m\u001b[32m1.55051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 176 | loss: 1.55051 - acc: 0.6615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 177  | total loss: \u001b[1m\u001b[32m1.43273\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 177 | loss: 1.43273 - acc: 0.6953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 178  | total loss: \u001b[1m\u001b[32m1.65322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 178 | loss: 1.65322 - acc: 0.6330 -- iter: 14/14\n",
      "--\n",
      "Training Step: 179  | total loss: \u001b[1m\u001b[32m1.52550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 179 | loss: 1.52550 - acc: 0.6697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 180  | total loss: \u001b[1m\u001b[32m1.76760\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 180 | loss: 1.76760 - acc: 0.6027 -- iter: 14/14\n",
      "--\n",
      "Training Step: 181  | total loss: \u001b[1m\u001b[32m1.63004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 181 | loss: 1.63004 - acc: 0.6424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 182  | total loss: \u001b[1m\u001b[32m1.86844\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 182 | loss: 1.86844 - acc: 0.5782 -- iter: 14/14\n",
      "--\n",
      "Training Step: 183  | total loss: \u001b[1m\u001b[32m1.72348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 183 | loss: 1.72348 - acc: 0.6204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 184  | total loss: \u001b[1m\u001b[32m1.89298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 184 | loss: 1.89298 - acc: 0.5655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 185  | total loss: \u001b[1m\u001b[32m1.74894\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 185 | loss: 1.74894 - acc: 0.6089 -- iter: 14/14\n",
      "--\n",
      "Training Step: 186  | total loss: \u001b[1m\u001b[32m1.93645\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 186 | loss: 1.93645 - acc: 0.5480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 187  | total loss: \u001b[1m\u001b[32m1.79196\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 187 | loss: 1.79196 - acc: 0.5932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 188  | total loss: \u001b[1m\u001b[32m1.98306\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 188 | loss: 1.98306 - acc: 0.5339 -- iter: 14/14\n",
      "--\n",
      "Training Step: 189  | total loss: \u001b[1m\u001b[32m1.83814\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 189 | loss: 1.83814 - acc: 0.5805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 190  | total loss: \u001b[1m\u001b[32m1.70932\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 190 | loss: 1.70932 - acc: 0.6225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 191  | total loss: \u001b[1m\u001b[32m1.59398\u001b[0m\u001b[0m | time: 0.028s\n",
      "| Adam | epoch: 191 | loss: 1.59398 - acc: 0.6602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 192  | total loss: \u001b[1m\u001b[32m1.75812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 192 | loss: 1.75812 - acc: 0.6013 -- iter: 14/14\n",
      "--\n",
      "Training Step: 193  | total loss: \u001b[1m\u001b[32m1.63844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 193 | loss: 1.63844 - acc: 0.6412 -- iter: 14/14\n",
      "--\n",
      "Training Step: 194  | total loss: \u001b[1m\u001b[32m1.53065\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 194 | loss: 1.53065 - acc: 0.6771 -- iter: 14/14\n",
      "--\n",
      "Training Step: 195  | total loss: \u001b[1m\u001b[32m1.43273\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 195 | loss: 1.43273 - acc: 0.7094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 196  | total loss: \u001b[1m\u001b[32m1.60000\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 196 | loss: 1.60000 - acc: 0.6527 -- iter: 14/14\n",
      "--\n",
      "Training Step: 197  | total loss: \u001b[1m\u001b[32m1.49299\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 197 | loss: 1.49299 - acc: 0.6875 -- iter: 14/14\n",
      "--\n",
      "Training Step: 198  | total loss: \u001b[1m\u001b[32m1.67079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 198 | loss: 1.67079 - acc: 0.6330 -- iter: 14/14\n",
      "--\n",
      "Training Step: 199  | total loss: \u001b[1m\u001b[32m1.55544\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 199 | loss: 1.55544 - acc: 0.6697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 200  | total loss: \u001b[1m\u001b[32m1.72196\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 200 | loss: 1.72196 - acc: 0.6099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 201  | total loss: \u001b[1m\u001b[32m1.60119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 201 | loss: 1.60119 - acc: 0.6489 -- iter: 14/14\n",
      "--\n",
      "Training Step: 202  | total loss: \u001b[1m\u001b[32m1.49218\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 202 | loss: 1.49218 - acc: 0.6840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 203  | total loss: \u001b[1m\u001b[32m1.39304\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 203 | loss: 1.39304 - acc: 0.7156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 204  | total loss: \u001b[1m\u001b[32m1.64628\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 204 | loss: 1.64628 - acc: 0.6440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 205  | total loss: \u001b[1m\u001b[32m1.53002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 205 | loss: 1.53002 - acc: 0.6796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 206  | total loss: \u001b[1m\u001b[32m1.72396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 206 | loss: 1.72396 - acc: 0.6188 -- iter: 14/14\n",
      "--\n",
      "Training Step: 207  | total loss: \u001b[1m\u001b[32m1.59961\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 207 | loss: 1.59961 - acc: 0.6569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 208  | total loss: \u001b[1m\u001b[32m1.48740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 208 | loss: 1.48740 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 209  | total loss: \u001b[1m\u001b[32m1.38545\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 209 | loss: 1.38545 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 210  | total loss: \u001b[1m\u001b[32m1.29216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 210 | loss: 1.29216 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 211  | total loss: \u001b[1m\u001b[32m1.20619\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 211 | loss: 1.20619 - acc: 0.7749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 212  | total loss: \u001b[1m\u001b[32m1.45781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 212 | loss: 1.45781 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 213  | total loss: \u001b[1m\u001b[32m1.35199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 213 | loss: 1.35199 - acc: 0.7277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 214  | total loss: \u001b[1m\u001b[32m1.58409\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 214 | loss: 1.58409 - acc: 0.6621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 215  | total loss: \u001b[1m\u001b[32m1.46420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 215 | loss: 1.46420 - acc: 0.6958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 216  | total loss: \u001b[1m\u001b[32m1.69246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 216 | loss: 1.69246 - acc: 0.6334 -- iter: 14/14\n",
      "--\n",
      "Training Step: 217  | total loss: \u001b[1m\u001b[32m1.56189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 217 | loss: 1.56189 - acc: 0.6701 -- iter: 14/14\n",
      "--\n",
      "Training Step: 218  | total loss: \u001b[1m\u001b[32m1.44453\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 218 | loss: 1.44453 - acc: 0.7031 -- iter: 14/14\n",
      "--\n",
      "Training Step: 219  | total loss: \u001b[1m\u001b[32m1.33852\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 219 | loss: 1.33852 - acc: 0.7328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 220  | total loss: \u001b[1m\u001b[32m1.24223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 220 | loss: 1.24223 - acc: 0.7595 -- iter: 14/14\n",
      "--\n",
      "Training Step: 221  | total loss: \u001b[1m\u001b[32m1.15426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 221 | loss: 1.15426 - acc: 0.7835 -- iter: 14/14\n",
      "--\n",
      "Training Step: 222  | total loss: \u001b[1m\u001b[32m1.39393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 222 | loss: 1.39393 - acc: 0.7123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 223  | total loss: \u001b[1m\u001b[32m1.28868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 223 | loss: 1.28868 - acc: 0.7411 -- iter: 14/14\n",
      "--\n",
      "Training Step: 224  | total loss: \u001b[1m\u001b[32m1.19310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 224 | loss: 1.19310 - acc: 0.7670 -- iter: 14/14\n",
      "--\n",
      "Training Step: 225  | total loss: \u001b[1m\u001b[32m1.10587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 225 | loss: 1.10587 - acc: 0.7903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 226  | total loss: \u001b[1m\u001b[32m1.36529\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 226 | loss: 1.36529 - acc: 0.7255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 227  | total loss: \u001b[1m\u001b[32m1.25896\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 227 | loss: 1.25896 - acc: 0.7530 -- iter: 14/14\n",
      "--\n",
      "Training Step: 228  | total loss: \u001b[1m\u001b[32m1.56336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 228 | loss: 1.56336 - acc: 0.6777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 229  | total loss: \u001b[1m\u001b[32m1.43715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 229 | loss: 1.43715 - acc: 0.7099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 230  | total loss: \u001b[1m\u001b[32m1.32378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 230 | loss: 1.32378 - acc: 0.7389 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 231  | total loss: \u001b[1m\u001b[32m1.22155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 231 | loss: 1.22155 - acc: 0.7650 -- iter: 14/14\n",
      "--\n",
      "Training Step: 232  | total loss: \u001b[1m\u001b[32m1.12900\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 232 | loss: 1.12900 - acc: 0.7885 -- iter: 14/14\n",
      "--\n",
      "Training Step: 233  | total loss: \u001b[1m\u001b[32m1.04485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 233 | loss: 1.04485 - acc: 0.8097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 234  | total loss: \u001b[1m\u001b[32m0.96799\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 234 | loss: 0.96799 - acc: 0.8287 -- iter: 14/14\n",
      "--\n",
      "Training Step: 235  | total loss: \u001b[1m\u001b[32m0.89751\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 235 | loss: 0.89751 - acc: 0.8458 -- iter: 14/14\n",
      "--\n",
      "Training Step: 236  | total loss: \u001b[1m\u001b[32m0.83261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 236 | loss: 0.83261 - acc: 0.8613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 237  | total loss: \u001b[1m\u001b[32m0.77265\u001b[0m\u001b[0m | time: 0.024s\n",
      "| Adam | epoch: 237 | loss: 0.77265 - acc: 0.8751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 238  | total loss: \u001b[1m\u001b[32m1.08128\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 238 | loss: 1.08128 - acc: 0.8019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 239  | total loss: \u001b[1m\u001b[32m0.99436\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 239 | loss: 0.99436 - acc: 0.8217 -- iter: 14/14\n",
      "--\n",
      "Training Step: 240  | total loss: \u001b[1m\u001b[32m0.91549\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 240 | loss: 0.91549 - acc: 0.8395 -- iter: 14/14\n",
      "--\n",
      "Training Step: 241  | total loss: \u001b[1m\u001b[32m0.84375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 241 | loss: 0.84375 - acc: 0.8556 -- iter: 14/14\n",
      "--\n",
      "Training Step: 242  | total loss: \u001b[1m\u001b[32m0.77831\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 242 | loss: 0.77831 - acc: 0.8700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 243  | total loss: \u001b[1m\u001b[32m0.71847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 243 | loss: 0.71847 - acc: 0.8830 -- iter: 14/14\n",
      "--\n",
      "Training Step: 244  | total loss: \u001b[1m\u001b[32m1.06559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 244 | loss: 1.06559 - acc: 0.8090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 245  | total loss: \u001b[1m\u001b[32m0.97604\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 245 | loss: 0.97604 - acc: 0.8281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 246  | total loss: \u001b[1m\u001b[32m0.89532\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 246 | loss: 0.89532 - acc: 0.8453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 247  | total loss: \u001b[1m\u001b[32m0.82241\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 247 | loss: 0.82241 - acc: 0.8608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 248  | total loss: \u001b[1m\u001b[32m0.75639\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 248 | loss: 0.75639 - acc: 0.8747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 249  | total loss: \u001b[1m\u001b[32m0.69647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 249 | loss: 0.69647 - acc: 0.8872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 250  | total loss: \u001b[1m\u001b[32m0.64196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 250 | loss: 0.64196 - acc: 0.8985 -- iter: 14/14\n",
      "--\n",
      "Training Step: 251  | total loss: \u001b[1m\u001b[32m0.59223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 251 | loss: 0.59223 - acc: 0.9086 -- iter: 14/14\n",
      "--\n",
      "Training Step: 252  | total loss: \u001b[1m\u001b[32m0.97510\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 252 | loss: 0.97510 - acc: 0.8321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 253  | total loss: \u001b[1m\u001b[32m0.89147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 253 | loss: 0.89147 - acc: 0.8489 -- iter: 14/14\n",
      "--\n",
      "Training Step: 254  | total loss: \u001b[1m\u001b[32m0.81620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 254 | loss: 0.81620 - acc: 0.8640 -- iter: 14/14\n",
      "--\n",
      "Training Step: 255  | total loss: \u001b[1m\u001b[32m0.74833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 255 | loss: 0.74833 - acc: 0.8776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 256  | total loss: \u001b[1m\u001b[32m1.15372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 256 | loss: 1.15372 - acc: 0.7970 -- iter: 14/14\n",
      "--\n",
      "Training Step: 257  | total loss: \u001b[1m\u001b[32m1.05249\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 257 | loss: 1.05249 - acc: 0.8173 -- iter: 14/14\n",
      "--\n",
      "Training Step: 258  | total loss: \u001b[1m\u001b[32m0.96182\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 258 | loss: 0.96182 - acc: 0.8355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 259  | total loss: \u001b[1m\u001b[32m0.88049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 259 | loss: 0.88049 - acc: 0.8520 -- iter: 14/14\n",
      "--\n",
      "Training Step: 260  | total loss: \u001b[1m\u001b[32m0.80742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 260 | loss: 0.80742 - acc: 0.8668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 261  | total loss: \u001b[1m\u001b[32m0.74161\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 261 | loss: 0.74161 - acc: 0.8801 -- iter: 14/14\n",
      "--\n",
      "Training Step: 262  | total loss: \u001b[1m\u001b[32m1.08924\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 262 | loss: 1.08924 - acc: 0.8064 -- iter: 14/14\n",
      "--\n",
      "Training Step: 263  | total loss: \u001b[1m\u001b[32m0.99564\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 263 | loss: 0.99564 - acc: 0.8257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 264  | total loss: \u001b[1m\u001b[32m1.32367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 264 | loss: 1.32367 - acc: 0.7503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 265  | total loss: \u001b[1m\u001b[32m1.20832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 265 | loss: 1.20832 - acc: 0.7753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 266  | total loss: \u001b[1m\u001b[32m1.10558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 266 | loss: 1.10558 - acc: 0.7978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 267  | total loss: \u001b[1m\u001b[32m1.01396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 267 | loss: 1.01396 - acc: 0.8180 -- iter: 14/14\n",
      "--\n",
      "Training Step: 268  | total loss: \u001b[1m\u001b[32m1.33137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 268 | loss: 1.33137 - acc: 0.7433 -- iter: 14/14\n",
      "--\n",
      "Training Step: 269  | total loss: \u001b[1m\u001b[32m1.21933\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 269 | loss: 1.21933 - acc: 0.7690 -- iter: 14/14\n",
      "--\n",
      "Training Step: 270  | total loss: \u001b[1m\u001b[32m1.51101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 270 | loss: 1.51101 - acc: 0.6921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 271  | total loss: \u001b[1m\u001b[32m1.38456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 271 | loss: 1.38456 - acc: 0.7229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 272  | total loss: \u001b[1m\u001b[32m1.27265\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 272 | loss: 1.27265 - acc: 0.7506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 273  | total loss: \u001b[1m\u001b[32m1.17337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 273 | loss: 1.17337 - acc: 0.7755 -- iter: 14/14\n",
      "--\n",
      "Training Step: 274  | total loss: \u001b[1m\u001b[32m1.40059\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 274 | loss: 1.40059 - acc: 0.7123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 275  | total loss: \u001b[1m\u001b[32m1.29135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 275 | loss: 1.29135 - acc: 0.7410 -- iter: 14/14\n",
      "--\n",
      "Training Step: 276  | total loss: \u001b[1m\u001b[32m1.52068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 276 | loss: 1.52068 - acc: 0.6741 -- iter: 14/14\n",
      "--\n",
      "Training Step: 277  | total loss: \u001b[1m\u001b[32m1.40304\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 277 | loss: 1.40304 - acc: 0.7067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 278  | total loss: \u001b[1m\u001b[32m1.29883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 278 | loss: 1.29883 - acc: 0.7360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 279  | total loss: \u001b[1m\u001b[32m1.20606\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 279 | loss: 1.20606 - acc: 0.7624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 280  | total loss: \u001b[1m\u001b[32m1.48402\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 280 | loss: 1.48402 - acc: 0.6862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 281  | total loss: \u001b[1m\u001b[32m1.37489\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 281 | loss: 1.37489 - acc: 0.7175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 282  | total loss: \u001b[1m\u001b[32m1.58456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 282 | loss: 1.58456 - acc: 0.6529 -- iter: 14/14\n",
      "--\n",
      "Training Step: 283  | total loss: \u001b[1m\u001b[32m1.46856\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 283 | loss: 1.46856 - acc: 0.6876 -- iter: 14/14\n",
      "--\n",
      "Training Step: 284  | total loss: \u001b[1m\u001b[32m1.36549\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 284 | loss: 1.36549 - acc: 0.7189 -- iter: 14/14\n",
      "--\n",
      "Training Step: 285  | total loss: \u001b[1m\u001b[32m1.27326\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 285 | loss: 1.27326 - acc: 0.7470 -- iter: 14/14\n",
      "--\n",
      "Training Step: 286  | total loss: \u001b[1m\u001b[32m1.46358\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 286 | loss: 1.46358 - acc: 0.6866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 287  | total loss: \u001b[1m\u001b[32m1.36217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 287 | loss: 1.36217 - acc: 0.7179 -- iter: 14/14\n",
      "--\n",
      "Training Step: 288  | total loss: \u001b[1m\u001b[32m1.27096\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 288 | loss: 1.27096 - acc: 0.7461 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 289  | total loss: \u001b[1m\u001b[32m1.18823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 289 | loss: 1.18823 - acc: 0.7715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 290  | total loss: \u001b[1m\u001b[32m1.11253\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 290 | loss: 1.11253 - acc: 0.7944 -- iter: 14/14\n",
      "--\n",
      "Training Step: 291  | total loss: \u001b[1m\u001b[32m1.04266\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 291 | loss: 1.04266 - acc: 0.8149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 292  | total loss: \u001b[1m\u001b[32m0.97764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 292 | loss: 0.97764 - acc: 0.8334 -- iter: 14/14\n",
      "--\n",
      "Training Step: 293  | total loss: \u001b[1m\u001b[32m0.91670\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 293 | loss: 0.91670 - acc: 0.8501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 294  | total loss: \u001b[1m\u001b[32m0.85925\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 294 | loss: 0.85925 - acc: 0.8651 -- iter: 14/14\n",
      "--\n",
      "Training Step: 295  | total loss: \u001b[1m\u001b[32m0.80484\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 295 | loss: 0.80484 - acc: 0.8786 -- iter: 14/14\n",
      "--\n",
      "Training Step: 296  | total loss: \u001b[1m\u001b[32m1.10486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 296 | loss: 1.10486 - acc: 0.7907 -- iter: 14/14\n",
      "--\n",
      "Training Step: 297  | total loss: \u001b[1m\u001b[32m1.02194\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 297 | loss: 1.02194 - acc: 0.8116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 298  | total loss: \u001b[1m\u001b[32m1.31864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 298 | loss: 1.31864 - acc: 0.7376 -- iter: 14/14\n",
      "--\n",
      "Training Step: 299  | total loss: \u001b[1m\u001b[32m1.21276\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 299 | loss: 1.21276 - acc: 0.7639 -- iter: 14/14\n",
      "--\n",
      "Training Step: 300  | total loss: \u001b[1m\u001b[32m1.11703\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 300 | loss: 1.11703 - acc: 0.7875 -- iter: 14/14\n",
      "--\n",
      "Training Step: 301  | total loss: \u001b[1m\u001b[32m1.03019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 301 | loss: 1.03019 - acc: 0.8087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 302  | total loss: \u001b[1m\u001b[32m1.32953\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 302 | loss: 1.32953 - acc: 0.7350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 303  | total loss: \u001b[1m\u001b[32m1.22081\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 303 | loss: 1.22081 - acc: 0.7615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 304  | total loss: \u001b[1m\u001b[32m1.54182\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 304 | loss: 1.54182 - acc: 0.6853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 305  | total loss: \u001b[1m\u001b[32m1.41294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 305 | loss: 1.41294 - acc: 0.7168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 306  | total loss: \u001b[1m\u001b[32m1.63669\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 306 | loss: 1.63669 - acc: 0.6594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 307  | total loss: \u001b[1m\u001b[32m1.50083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 307 | loss: 1.50083 - acc: 0.6935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 308  | total loss: \u001b[1m\u001b[32m1.37984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 308 | loss: 1.37984 - acc: 0.7241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 309  | total loss: \u001b[1m\u001b[32m1.27179\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 309 | loss: 1.27179 - acc: 0.7517 -- iter: 14/14\n",
      "--\n",
      "Training Step: 310  | total loss: \u001b[1m\u001b[32m1.17492\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 310 | loss: 1.17492 - acc: 0.7765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 311  | total loss: \u001b[1m\u001b[32m1.08768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 311 | loss: 1.08768 - acc: 0.7989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 312  | total loss: \u001b[1m\u001b[32m1.35856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 312 | loss: 1.35856 - acc: 0.7190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 313  | total loss: \u001b[1m\u001b[32m1.25334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 313 | loss: 1.25334 - acc: 0.7471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 314  | total loss: \u001b[1m\u001b[32m1.53719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 314 | loss: 1.53719 - acc: 0.6724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 315  | total loss: \u001b[1m\u001b[32m1.41599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 315 | loss: 1.41599 - acc: 0.7052 -- iter: 14/14\n",
      "--\n",
      "Training Step: 316  | total loss: \u001b[1m\u001b[32m1.61615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 316 | loss: 1.61615 - acc: 0.6489 -- iter: 14/14\n",
      "--\n",
      "Training Step: 317  | total loss: \u001b[1m\u001b[32m1.48995\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 317 | loss: 1.48995 - acc: 0.6840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 318  | total loss: \u001b[1m\u001b[32m1.64314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 318 | loss: 1.64314 - acc: 0.6442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 319  | total loss: \u001b[1m\u001b[32m1.51754\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 319 | loss: 1.51754 - acc: 0.6798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 320  | total loss: \u001b[1m\u001b[32m1.40581\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 320 | loss: 1.40581 - acc: 0.7118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 321  | total loss: \u001b[1m\u001b[32m1.30589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 321 | loss: 1.30589 - acc: 0.7406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 322  | total loss: \u001b[1m\u001b[32m1.21594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 322 | loss: 1.21594 - acc: 0.7666 -- iter: 14/14\n",
      "--\n",
      "Training Step: 323  | total loss: \u001b[1m\u001b[32m1.13437\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 323 | loss: 1.13437 - acc: 0.7899 -- iter: 14/14\n",
      "--\n",
      "Training Step: 324  | total loss: \u001b[1m\u001b[32m1.05982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 324 | loss: 1.05982 - acc: 0.8109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 325  | total loss: \u001b[1m\u001b[32m0.99116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 325 | loss: 0.99116 - acc: 0.8298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 326  | total loss: \u001b[1m\u001b[32m1.24224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 326 | loss: 1.24224 - acc: 0.7540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 327  | total loss: \u001b[1m\u001b[32m1.15279\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 327 | loss: 1.15279 - acc: 0.7786 -- iter: 14/14\n",
      "--\n",
      "Training Step: 328  | total loss: \u001b[1m\u001b[32m1.40932\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 328 | loss: 1.40932 - acc: 0.7079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 329  | total loss: \u001b[1m\u001b[32m1.30235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 329 | loss: 1.30235 - acc: 0.7371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 330  | total loss: \u001b[1m\u001b[32m1.49621\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 330 | loss: 1.49621 - acc: 0.6848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 331  | total loss: \u001b[1m\u001b[32m1.38106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 331 | loss: 1.38106 - acc: 0.7163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 332  | total loss: \u001b[1m\u001b[32m1.27766\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 332 | loss: 1.27766 - acc: 0.7447 -- iter: 14/14\n",
      "--\n",
      "Training Step: 333  | total loss: \u001b[1m\u001b[32m1.18435\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 333 | loss: 1.18435 - acc: 0.7702 -- iter: 14/14\n",
      "--\n",
      "Training Step: 334  | total loss: \u001b[1m\u001b[32m1.09969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 334 | loss: 1.09969 - acc: 0.7932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 335  | total loss: \u001b[1m\u001b[32m1.02244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 335 | loss: 1.02244 - acc: 0.8139 -- iter: 14/14\n",
      "--\n",
      "Training Step: 336  | total loss: \u001b[1m\u001b[32m1.32508\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 336 | loss: 1.32508 - acc: 0.7325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 337  | total loss: \u001b[1m\u001b[32m1.22394\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 337 | loss: 1.22394 - acc: 0.7592 -- iter: 14/14\n",
      "--\n",
      "Training Step: 338  | total loss: \u001b[1m\u001b[32m1.13252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 338 | loss: 1.13252 - acc: 0.7833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 339  | total loss: \u001b[1m\u001b[32m1.04950\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 339 | loss: 1.04950 - acc: 0.8050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 340  | total loss: \u001b[1m\u001b[32m1.33721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 340 | loss: 1.33721 - acc: 0.7245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 341  | total loss: \u001b[1m\u001b[32m1.23294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 341 | loss: 1.23294 - acc: 0.7520 -- iter: 14/14\n",
      "--\n",
      "Training Step: 342  | total loss: \u001b[1m\u001b[32m1.49855\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 342 | loss: 1.49855 - acc: 0.6840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 343  | total loss: \u001b[1m\u001b[32m1.37907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 343 | loss: 1.37907 - acc: 0.7156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 344  | total loss: \u001b[1m\u001b[32m1.64279\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 344 | loss: 1.64279 - acc: 0.6512 -- iter: 14/14\n",
      "--\n",
      "Training Step: 345  | total loss: \u001b[1m\u001b[32m1.51121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 345 | loss: 1.51121 - acc: 0.6860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 346  | total loss: \u001b[1m\u001b[32m1.72957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 346 | loss: 1.72957 - acc: 0.6317 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 347  | total loss: \u001b[1m\u001b[32m1.59282\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 347 | loss: 1.59282 - acc: 0.6686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 348  | total loss: \u001b[1m\u001b[32m1.84222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 348 | loss: 1.84222 - acc: 0.6017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 349  | total loss: \u001b[1m\u001b[32m1.69864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 349 | loss: 1.69864 - acc: 0.6415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 350  | total loss: \u001b[1m\u001b[32m1.88280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 350 | loss: 1.88280 - acc: 0.5845 -- iter: 14/14\n",
      "--\n",
      "Training Step: 351  | total loss: \u001b[1m\u001b[32m1.74012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 351 | loss: 1.74012 - acc: 0.6261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 352  | total loss: \u001b[1m\u001b[32m1.86927\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 352 | loss: 1.86927 - acc: 0.5777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 353  | total loss: \u001b[1m\u001b[32m1.73299\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 353 | loss: 1.73299 - acc: 0.6200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 354  | total loss: \u001b[1m\u001b[32m1.61233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 354 | loss: 1.61233 - acc: 0.6580 -- iter: 14/14\n",
      "--\n",
      "Training Step: 355  | total loss: \u001b[1m\u001b[32m1.50473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 355 | loss: 1.50473 - acc: 0.6922 -- iter: 14/14\n",
      "--\n",
      "Training Step: 356  | total loss: \u001b[1m\u001b[32m1.40793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 356 | loss: 1.40793 - acc: 0.7230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 357  | total loss: \u001b[1m\u001b[32m1.31999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 357 | loss: 1.31999 - acc: 0.7507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 358  | total loss: \u001b[1m\u001b[32m1.49180\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 358 | loss: 1.49180 - acc: 0.6827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 359  | total loss: \u001b[1m\u001b[32m1.39354\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 359 | loss: 1.39354 - acc: 0.7145 -- iter: 14/14\n",
      "--\n",
      "Training Step: 360  | total loss: \u001b[1m\u001b[32m1.30400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 360 | loss: 1.30400 - acc: 0.7430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 361  | total loss: \u001b[1m\u001b[32m1.22165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 361 | loss: 1.22165 - acc: 0.7687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 362  | total loss: \u001b[1m\u001b[32m1.41829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 362 | loss: 1.41829 - acc: 0.6990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 363  | total loss: \u001b[1m\u001b[32m1.32126\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 363 | loss: 1.32126 - acc: 0.7291 -- iter: 14/14\n",
      "--\n",
      "Training Step: 364  | total loss: \u001b[1m\u001b[32m1.46388\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 364 | loss: 1.46388 - acc: 0.6848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 365  | total loss: \u001b[1m\u001b[32m1.36014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 365 | loss: 1.36014 - acc: 0.7163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 366  | total loss: \u001b[1m\u001b[32m1.26561\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 366 | loss: 1.26561 - acc: 0.7446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 367  | total loss: \u001b[1m\u001b[32m1.17893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 367 | loss: 1.17893 - acc: 0.7702 -- iter: 14/14\n",
      "--\n",
      "Training Step: 368  | total loss: \u001b[1m\u001b[32m1.41910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 368 | loss: 1.41910 - acc: 0.6932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 369  | total loss: \u001b[1m\u001b[32m1.31459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 369 | loss: 1.31459 - acc: 0.7238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 370  | total loss: \u001b[1m\u001b[32m1.52713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 370 | loss: 1.52713 - acc: 0.6658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 371  | total loss: \u001b[1m\u001b[32m1.41101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 371 | loss: 1.41101 - acc: 0.6992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 372  | total loss: \u001b[1m\u001b[32m1.64302\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 372 | loss: 1.64302 - acc: 0.6293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 373  | total loss: \u001b[1m\u001b[32m1.51584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 373 | loss: 1.51584 - acc: 0.6663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 374  | total loss: \u001b[1m\u001b[32m1.40166\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 374 | loss: 1.40166 - acc: 0.6997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 375  | total loss: \u001b[1m\u001b[32m1.29864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 375 | loss: 1.29864 - acc: 0.7297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 376  | total loss: \u001b[1m\u001b[32m1.20517\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 376 | loss: 1.20517 - acc: 0.7568 -- iter: 14/14\n",
      "--\n",
      "Training Step: 377  | total loss: \u001b[1m\u001b[32m1.11989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 377 | loss: 1.11989 - acc: 0.7811 -- iter: 14/14\n",
      "--\n",
      "Training Step: 378  | total loss: \u001b[1m\u001b[32m1.04164\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 378 | loss: 1.04164 - acc: 0.8030 -- iter: 14/14\n",
      "--\n",
      "Training Step: 379  | total loss: \u001b[1m\u001b[32m0.96945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 379 | loss: 0.96945 - acc: 0.8227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 380  | total loss: \u001b[1m\u001b[32m0.90254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 380 | loss: 0.90254 - acc: 0.8404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 381  | total loss: \u001b[1m\u001b[32m0.84028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 381 | loss: 0.84028 - acc: 0.8564 -- iter: 14/14\n",
      "--\n",
      "Training Step: 382  | total loss: \u001b[1m\u001b[32m0.78216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 382 | loss: 0.78216 - acc: 0.8707 -- iter: 14/14\n",
      "--\n",
      "Training Step: 383  | total loss: \u001b[1m\u001b[32m0.72776\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 383 | loss: 0.72776 - acc: 0.8837 -- iter: 14/14\n",
      "--\n",
      "Training Step: 384  | total loss: \u001b[1m\u001b[32m0.67678\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 384 | loss: 0.67678 - acc: 0.8953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 385  | total loss: \u001b[1m\u001b[32m0.62896\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 385 | loss: 0.62896 - acc: 0.9058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 386  | total loss: \u001b[1m\u001b[32m0.58410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 386 | loss: 0.58410 - acc: 0.9152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 387  | total loss: \u001b[1m\u001b[32m0.54204\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 387 | loss: 0.54204 - acc: 0.9237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 388  | total loss: \u001b[1m\u001b[32m0.93334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 388 | loss: 0.93334 - acc: 0.8384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 389  | total loss: \u001b[1m\u001b[32m0.85428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 389 | loss: 0.85428 - acc: 0.8546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 390  | total loss: \u001b[1m\u001b[32m1.28168\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 390 | loss: 1.28168 - acc: 0.7691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 391  | total loss: \u001b[1m\u001b[32m1.16757\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 391 | loss: 1.16757 - acc: 0.7922 -- iter: 14/14\n",
      "--\n",
      "Training Step: 392  | total loss: \u001b[1m\u001b[32m1.51471\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 392 | loss: 1.51471 - acc: 0.7130 -- iter: 14/14\n",
      "--\n",
      "Training Step: 393  | total loss: \u001b[1m\u001b[32m1.37856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 393 | loss: 1.37856 - acc: 0.7417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 394  | total loss: \u001b[1m\u001b[32m1.58758\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 394 | loss: 1.58758 - acc: 0.6961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 395  | total loss: \u001b[1m\u001b[32m1.44659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 395 | loss: 1.44659 - acc: 0.7265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 396  | total loss: \u001b[1m\u001b[32m1.74852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 396 | loss: 1.74852 - acc: 0.6610 -- iter: 14/14\n",
      "--\n",
      "Training Step: 397  | total loss: \u001b[1m\u001b[32m1.59509\u001b[0m\u001b[0m | time: 0.024s\n",
      "| Adam | epoch: 397 | loss: 1.59509 - acc: 0.6949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 398  | total loss: \u001b[1m\u001b[32m1.45905\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 398 | loss: 1.45905 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 399  | total loss: \u001b[1m\u001b[32m1.33833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 399 | loss: 1.33833 - acc: 0.7529 -- iter: 14/14\n",
      "--\n",
      "Training Step: 400  | total loss: \u001b[1m\u001b[32m1.63338\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 400 | loss: 1.63338 - acc: 0.6776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 401  | total loss: \u001b[1m\u001b[32m1.49884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 401 | loss: 1.49884 - acc: 0.7098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 402  | total loss: \u001b[1m\u001b[32m1.76307\u001b[0m\u001b[0m | time: 0.028s\n",
      "| Adam | epoch: 402 | loss: 1.76307 - acc: 0.6388 -- iter: 14/14\n",
      "--\n",
      "Training Step: 403  | total loss: \u001b[1m\u001b[32m1.62041\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 403 | loss: 1.62041 - acc: 0.6750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 404  | total loss: \u001b[1m\u001b[32m1.85454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 404 | loss: 1.85454 - acc: 0.6075 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 405  | total loss: \u001b[1m\u001b[32m1.70850\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 405 | loss: 1.70850 - acc: 0.6467 -- iter: 14/14\n",
      "--\n",
      "Training Step: 406  | total loss: \u001b[1m\u001b[32m1.57966\u001b[0m\u001b[0m | time: 0.024s\n",
      "| Adam | epoch: 406 | loss: 1.57966 - acc: 0.6820 -- iter: 14/14\n",
      "--\n",
      "Training Step: 407  | total loss: \u001b[1m\u001b[32m1.46545\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 407 | loss: 1.46545 - acc: 0.7138 -- iter: 14/14\n",
      "--\n",
      "Training Step: 408  | total loss: \u001b[1m\u001b[32m1.36360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 408 | loss: 1.36360 - acc: 0.7425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 409  | total loss: \u001b[1m\u001b[32m1.27209\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 409 | loss: 1.27209 - acc: 0.7682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 410  | total loss: \u001b[1m\u001b[32m1.18921\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 410 | loss: 1.18921 - acc: 0.7914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 411  | total loss: \u001b[1m\u001b[32m1.11348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 411 | loss: 1.11348 - acc: 0.8122 -- iter: 14/14\n",
      "--\n",
      "Training Step: 412  | total loss: \u001b[1m\u001b[32m1.31662\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 412 | loss: 1.31662 - acc: 0.7453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 413  | total loss: \u001b[1m\u001b[32m1.22604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 413 | loss: 1.22604 - acc: 0.7708 -- iter: 14/14\n",
      "--\n",
      "Training Step: 414  | total loss: \u001b[1m\u001b[32m1.14352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 414 | loss: 1.14352 - acc: 0.7937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 415  | total loss: \u001b[1m\u001b[32m1.06782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 415 | loss: 1.06782 - acc: 0.8143 -- iter: 14/14\n",
      "--\n",
      "Training Step: 416  | total loss: \u001b[1m\u001b[32m1.29307\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 416 | loss: 1.29307 - acc: 0.7472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 417  | total loss: \u001b[1m\u001b[32m1.20004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 417 | loss: 1.20004 - acc: 0.7725 -- iter: 14/14\n",
      "--\n",
      "Training Step: 418  | total loss: \u001b[1m\u001b[32m1.45451\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 418 | loss: 1.45451 - acc: 0.6952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 419  | total loss: \u001b[1m\u001b[32m1.34476\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 419 | loss: 1.34476 - acc: 0.7257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 420  | total loss: \u001b[1m\u001b[32m1.24589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 420 | loss: 1.24589 - acc: 0.7531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 421  | total loss: \u001b[1m\u001b[32m1.15636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 421 | loss: 1.15636 - acc: 0.7778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 422  | total loss: \u001b[1m\u001b[32m1.38274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 422 | loss: 1.38274 - acc: 0.7000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 423  | total loss: \u001b[1m\u001b[32m1.27882\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 423 | loss: 1.27882 - acc: 0.7300 -- iter: 14/14\n",
      "--\n",
      "Training Step: 424  | total loss: \u001b[1m\u001b[32m1.58386\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 424 | loss: 1.58386 - acc: 0.6570 -- iter: 14/14\n",
      "--\n",
      "Training Step: 425  | total loss: \u001b[1m\u001b[32m1.46070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 425 | loss: 1.46070 - acc: 0.6913 -- iter: 14/14\n",
      "--\n",
      "Training Step: 426  | total loss: \u001b[1m\u001b[32m1.35041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 426 | loss: 1.35041 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 427  | total loss: \u001b[1m\u001b[32m1.25116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 427 | loss: 1.25116 - acc: 0.7500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 428  | total loss: \u001b[1m\u001b[32m1.16137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 428 | loss: 1.16137 - acc: 0.7750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 429  | total loss: \u001b[1m\u001b[32m1.07967\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 429 | loss: 1.07967 - acc: 0.7975 -- iter: 14/14\n",
      "--\n",
      "Training Step: 430  | total loss: \u001b[1m\u001b[32m1.34378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 430 | loss: 1.34378 - acc: 0.7249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 431  | total loss: \u001b[1m\u001b[32m1.24254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 431 | loss: 1.24254 - acc: 0.7524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 432  | total loss: \u001b[1m\u001b[32m1.15096\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 432 | loss: 1.15096 - acc: 0.7771 -- iter: 14/14\n",
      "--\n",
      "Training Step: 433  | total loss: \u001b[1m\u001b[32m1.06768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 433 | loss: 1.06768 - acc: 0.7994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 434  | total loss: \u001b[1m\u001b[32m1.33699\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 434 | loss: 1.33699 - acc: 0.7266 -- iter: 14/14\n",
      "--\n",
      "Training Step: 435  | total loss: \u001b[1m\u001b[32m1.23394\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 435 | loss: 1.23394 - acc: 0.7540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 436  | total loss: \u001b[1m\u001b[32m1.47942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 436 | loss: 1.47942 - acc: 0.6857 -- iter: 14/14\n",
      "--\n",
      "Training Step: 437  | total loss: \u001b[1m\u001b[32m1.36252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 437 | loss: 1.36252 - acc: 0.7171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 438  | total loss: \u001b[1m\u001b[32m1.54228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 438 | loss: 1.54228 - acc: 0.6669 -- iter: 14/14\n",
      "--\n",
      "Training Step: 439  | total loss: \u001b[1m\u001b[32m1.42061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 439 | loss: 1.42061 - acc: 0.7002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 440  | total loss: \u001b[1m\u001b[32m1.60507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 440 | loss: 1.60507 - acc: 0.6516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 441  | total loss: \u001b[1m\u001b[32m1.47932\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 441 | loss: 1.47932 - acc: 0.6864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 442  | total loss: \u001b[1m\u001b[32m1.69052\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 442 | loss: 1.69052 - acc: 0.6249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 443  | total loss: \u001b[1m\u001b[32m1.55922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 443 | loss: 1.55922 - acc: 0.6624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 444  | total loss: \u001b[1m\u001b[32m1.79526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 444 | loss: 1.79526 - acc: 0.5962 -- iter: 14/14\n",
      "--\n",
      "Training Step: 445  | total loss: \u001b[1m\u001b[32m1.65734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 445 | loss: 1.65734 - acc: 0.6366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 446  | total loss: \u001b[1m\u001b[32m1.53495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 446 | loss: 1.53495 - acc: 0.6729 -- iter: 14/14\n",
      "--\n",
      "Training Step: 447  | total loss: \u001b[1m\u001b[32m1.42575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 447 | loss: 1.42575 - acc: 0.7056 -- iter: 14/14\n",
      "--\n",
      "Training Step: 448  | total loss: \u001b[1m\u001b[32m1.61178\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 448 | loss: 1.61178 - acc: 0.6565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 449  | total loss: \u001b[1m\u001b[32m1.49614\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 449 | loss: 1.49614 - acc: 0.6908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 450  | total loss: \u001b[1m\u001b[32m1.39234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 450 | loss: 1.39234 - acc: 0.7218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 451  | total loss: \u001b[1m\u001b[32m1.29849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 451 | loss: 1.29849 - acc: 0.7496 -- iter: 14/14\n",
      "--\n",
      "Training Step: 452  | total loss: \u001b[1m\u001b[32m1.54058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 452 | loss: 1.54058 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 453  | total loss: \u001b[1m\u001b[32m1.43115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 453 | loss: 1.43115 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 454  | total loss: \u001b[1m\u001b[32m1.33228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 454 | loss: 1.33228 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 455  | total loss: \u001b[1m\u001b[32m1.24233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 455 | loss: 1.24233 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 456  | total loss: \u001b[1m\u001b[32m1.41606\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 456 | loss: 1.41606 - acc: 0.7079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 457  | total loss: \u001b[1m\u001b[32m1.31577\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 457 | loss: 1.31577 - acc: 0.7372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 458  | total loss: \u001b[1m\u001b[32m1.22448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 458 | loss: 1.22448 - acc: 0.7634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 459  | total loss: \u001b[1m\u001b[32m1.14086\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 459 | loss: 1.14086 - acc: 0.7871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 460  | total loss: \u001b[1m\u001b[32m1.06378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 460 | loss: 1.06378 - acc: 0.8084 -- iter: 14/14\n",
      "--\n",
      "Training Step: 461  | total loss: \u001b[1m\u001b[32m0.99232\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 461 | loss: 0.99232 - acc: 0.8275 -- iter: 14/14\n",
      "--\n",
      "Training Step: 462  | total loss: \u001b[1m\u001b[32m1.21469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 462 | loss: 1.21469 - acc: 0.7591 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 463  | total loss: \u001b[1m\u001b[32m1.12477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 463 | loss: 1.12477 - acc: 0.7832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 464  | total loss: \u001b[1m\u001b[32m1.37844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 464 | loss: 1.37844 - acc: 0.7120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 465  | total loss: \u001b[1m\u001b[32m1.27061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 465 | loss: 1.27061 - acc: 0.7408 -- iter: 14/14\n",
      "--\n",
      "Training Step: 466  | total loss: \u001b[1m\u001b[32m1.17302\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 466 | loss: 1.17302 - acc: 0.7667 -- iter: 14/14\n",
      "--\n",
      "Training Step: 467  | total loss: \u001b[1m\u001b[32m1.08434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 467 | loss: 1.08434 - acc: 0.7900 -- iter: 14/14\n",
      "--\n",
      "Training Step: 468  | total loss: \u001b[1m\u001b[32m1.38396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 468 | loss: 1.38396 - acc: 0.7110 -- iter: 14/14\n",
      "--\n",
      "Training Step: 469  | total loss: \u001b[1m\u001b[32m1.27324\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 469 | loss: 1.27324 - acc: 0.7399 -- iter: 14/14\n",
      "--\n",
      "Training Step: 470  | total loss: \u001b[1m\u001b[32m1.54256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 470 | loss: 1.54256 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 471  | total loss: \u001b[1m\u001b[32m1.41676\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 471 | loss: 1.41676 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 472  | total loss: \u001b[1m\u001b[32m1.30410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 472 | loss: 1.30410 - acc: 0.7352 -- iter: 14/14\n",
      "--\n",
      "Training Step: 473  | total loss: \u001b[1m\u001b[32m1.20283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 473 | loss: 1.20283 - acc: 0.7617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 474  | total loss: \u001b[1m\u001b[32m1.11145\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 474 | loss: 1.11145 - acc: 0.7855 -- iter: 14/14\n",
      "--\n",
      "Training Step: 475  | total loss: \u001b[1m\u001b[32m1.02861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 475 | loss: 1.02861 - acc: 0.8070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 476  | total loss: \u001b[1m\u001b[32m0.95318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 476 | loss: 0.95318 - acc: 0.8263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 477  | total loss: \u001b[1m\u001b[32m0.88417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 477 | loss: 0.88417 - acc: 0.8436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 478  | total loss: \u001b[1m\u001b[32m1.22818\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 478 | loss: 1.22818 - acc: 0.7593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 479  | total loss: \u001b[1m\u001b[32m1.13042\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 479 | loss: 1.13042 - acc: 0.7833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 480  | total loss: \u001b[1m\u001b[32m1.04220\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 480 | loss: 1.04220 - acc: 0.8050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 481  | total loss: \u001b[1m\u001b[32m0.96228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 481 | loss: 0.96228 - acc: 0.8245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 482  | total loss: \u001b[1m\u001b[32m0.88961\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 482 | loss: 0.88961 - acc: 0.8421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 483  | total loss: \u001b[1m\u001b[32m0.82329\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 483 | loss: 0.82329 - acc: 0.8579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 484  | total loss: \u001b[1m\u001b[32m0.76253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 484 | loss: 0.76253 - acc: 0.8721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 485  | total loss: \u001b[1m\u001b[32m0.70669\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 485 | loss: 0.70669 - acc: 0.8849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 486  | total loss: \u001b[1m\u001b[32m0.65521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 486 | loss: 0.65521 - acc: 0.8964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 487  | total loss: \u001b[1m\u001b[32m0.60762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 487 | loss: 0.60762 - acc: 0.9067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 488  | total loss: \u001b[1m\u001b[32m0.98041\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 488 | loss: 0.98041 - acc: 0.8161 -- iter: 14/14\n",
      "--\n",
      "Training Step: 489  | total loss: \u001b[1m\u001b[32m0.89888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 489 | loss: 0.89888 - acc: 0.8345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 490  | total loss: \u001b[1m\u001b[32m1.25165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 490 | loss: 1.25165 - acc: 0.7510 -- iter: 14/14\n",
      "--\n",
      "Training Step: 491  | total loss: \u001b[1m\u001b[32m1.14333\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 491 | loss: 1.14333 - acc: 0.7759 -- iter: 14/14\n",
      "--\n",
      "Training Step: 492  | total loss: \u001b[1m\u001b[32m1.45971\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 492 | loss: 1.45971 - acc: 0.7055 -- iter: 14/14\n",
      "--\n",
      "Training Step: 493  | total loss: \u001b[1m\u001b[32m1.33233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 493 | loss: 1.33233 - acc: 0.7349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 494  | total loss: \u001b[1m\u001b[32m1.21873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 494 | loss: 1.21873 - acc: 0.7614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 495  | total loss: \u001b[1m\u001b[32m1.11729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 495 | loss: 1.11729 - acc: 0.7853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 496  | total loss: \u001b[1m\u001b[32m1.02650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 496 | loss: 1.02650 - acc: 0.8068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 497  | total loss: \u001b[1m\u001b[32m0.94502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 497 | loss: 0.94502 - acc: 0.8261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 498  | total loss: \u001b[1m\u001b[32m1.30178\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 498 | loss: 1.30178 - acc: 0.7435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 499  | total loss: \u001b[1m\u001b[32m1.19388\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 499 | loss: 1.19388 - acc: 0.7691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 500  | total loss: \u001b[1m\u001b[32m1.49706\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 500 | loss: 1.49706 - acc: 0.6922 -- iter: 14/14\n",
      "--\n",
      "Training Step: 501  | total loss: \u001b[1m\u001b[32m1.37234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 501 | loss: 1.37234 - acc: 0.7230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 502  | total loss: \u001b[1m\u001b[32m1.62695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 502 | loss: 1.62695 - acc: 0.6578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 503  | total loss: \u001b[1m\u001b[32m1.49342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 503 | loss: 1.49342 - acc: 0.6921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 504  | total loss: \u001b[1m\u001b[32m1.70206\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 504 | loss: 1.70206 - acc: 0.6371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 505  | total loss: \u001b[1m\u001b[32m1.56619\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 505 | loss: 1.56619 - acc: 0.6734 -- iter: 14/14\n",
      "--\n",
      "Training Step: 506  | total loss: \u001b[1m\u001b[32m1.75461\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 506 | loss: 1.75461 - acc: 0.6204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 507  | total loss: \u001b[1m\u001b[32m1.61920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 507 | loss: 1.61920 - acc: 0.6583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 508  | total loss: \u001b[1m\u001b[32m1.49986\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 508 | loss: 1.49986 - acc: 0.6925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 509  | total loss: \u001b[1m\u001b[32m1.39416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 509 | loss: 1.39416 - acc: 0.7232 -- iter: 14/14\n",
      "--\n",
      "Training Step: 510  | total loss: \u001b[1m\u001b[32m1.29991\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 510 | loss: 1.29991 - acc: 0.7509 -- iter: 14/14\n",
      "--\n",
      "Training Step: 511  | total loss: \u001b[1m\u001b[32m1.21519\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 511 | loss: 1.21519 - acc: 0.7758 -- iter: 14/14\n",
      "--\n",
      "Training Step: 512  | total loss: \u001b[1m\u001b[32m1.13834\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 512 | loss: 1.13834 - acc: 0.7982 -- iter: 14/14\n",
      "--\n",
      "Training Step: 513  | total loss: \u001b[1m\u001b[32m1.06797\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 513 | loss: 1.06797 - acc: 0.8184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 514  | total loss: \u001b[1m\u001b[32m1.34082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 514 | loss: 1.34082 - acc: 0.7366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 515  | total loss: \u001b[1m\u001b[32m1.24811\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 515 | loss: 1.24811 - acc: 0.7629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 516  | total loss: \u001b[1m\u001b[32m1.48844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 516 | loss: 1.48844 - acc: 0.6866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 517  | total loss: \u001b[1m\u001b[32m1.38053\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 517 | loss: 1.38053 - acc: 0.7180 -- iter: 14/14\n",
      "--\n",
      "Training Step: 518  | total loss: \u001b[1m\u001b[32m1.59971\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 518 | loss: 1.59971 - acc: 0.6533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 519  | total loss: \u001b[1m\u001b[32m1.48144\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 519 | loss: 1.48144 - acc: 0.6880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 520  | total loss: \u001b[1m\u001b[32m1.37524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 520 | loss: 1.37524 - acc: 0.7192 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 521  | total loss: \u001b[1m\u001b[32m1.27929\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 521 | loss: 1.27929 - acc: 0.7473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 522  | total loss: \u001b[1m\u001b[32m1.19200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 522 | loss: 1.19200 - acc: 0.7725 -- iter: 14/14\n",
      "--\n",
      "Training Step: 523  | total loss: \u001b[1m\u001b[32m1.11204\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 523 | loss: 1.11204 - acc: 0.7953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 524  | total loss: \u001b[1m\u001b[32m1.37021\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 524 | loss: 1.37021 - acc: 0.7229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 525  | total loss: \u001b[1m\u001b[32m1.27018\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 525 | loss: 1.27018 - acc: 0.7506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 526  | total loss: \u001b[1m\u001b[32m1.17925\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 526 | loss: 1.17925 - acc: 0.7755 -- iter: 14/14\n",
      "--\n",
      "Training Step: 527  | total loss: \u001b[1m\u001b[32m1.09613\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 527 | loss: 1.09613 - acc: 0.7980 -- iter: 14/14\n",
      "--\n",
      "Training Step: 528  | total loss: \u001b[1m\u001b[32m1.42074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 528 | loss: 1.42074 - acc: 0.7182 -- iter: 14/14\n",
      "--\n",
      "Training Step: 529  | total loss: \u001b[1m\u001b[32m1.31179\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 529 | loss: 1.31179 - acc: 0.7464 -- iter: 14/14\n",
      "--\n",
      "Training Step: 530  | total loss: \u001b[1m\u001b[32m1.58229\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 530 | loss: 1.58229 - acc: 0.6717 -- iter: 14/14\n",
      "--\n",
      "Training Step: 531  | total loss: \u001b[1m\u001b[32m1.45733\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 531 | loss: 1.45733 - acc: 0.7046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 532  | total loss: \u001b[1m\u001b[32m1.68398\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 532 | loss: 1.68398 - acc: 0.6412 -- iter: 14/14\n",
      "--\n",
      "Training Step: 533  | total loss: \u001b[1m\u001b[32m1.55033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 533 | loss: 1.55033 - acc: 0.6771 -- iter: 14/14\n",
      "--\n",
      "Training Step: 534  | total loss: \u001b[1m\u001b[32m1.75902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 534 | loss: 1.75902 - acc: 0.6166 -- iter: 14/14\n",
      "--\n",
      "Training Step: 535  | total loss: \u001b[1m\u001b[32m1.62044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 535 | loss: 1.62044 - acc: 0.6549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 536  | total loss: \u001b[1m\u001b[32m1.82817\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 536 | loss: 1.82817 - acc: 0.5894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 537  | total loss: \u001b[1m\u001b[32m1.68619\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 537 | loss: 1.68619 - acc: 0.6305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 538  | total loss: \u001b[1m\u001b[32m1.56000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 538 | loss: 1.56000 - acc: 0.6674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 539  | total loss: \u001b[1m\u001b[32m1.44730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 539 | loss: 1.44730 - acc: 0.7007 -- iter: 14/14\n",
      "--\n",
      "Training Step: 540  | total loss: \u001b[1m\u001b[32m1.34604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 540 | loss: 1.34604 - acc: 0.7306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 541  | total loss: \u001b[1m\u001b[32m1.25444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 541 | loss: 1.25444 - acc: 0.7576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 542  | total loss: \u001b[1m\u001b[32m1.17096\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 542 | loss: 1.17096 - acc: 0.7818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 543  | total loss: \u001b[1m\u001b[32m1.09433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 543 | loss: 1.09433 - acc: 0.8036 -- iter: 14/14\n",
      "--\n",
      "Training Step: 544  | total loss: \u001b[1m\u001b[32m1.38753\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 544 | loss: 1.38753 - acc: 0.7233 -- iter: 14/14\n",
      "--\n",
      "Training Step: 545  | total loss: \u001b[1m\u001b[32m1.28687\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 545 | loss: 1.28687 - acc: 0.7509 -- iter: 14/14\n",
      "--\n",
      "Training Step: 546  | total loss: \u001b[1m\u001b[32m1.53956\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 546 | loss: 1.53956 - acc: 0.6758 -- iter: 14/14\n",
      "--\n",
      "Training Step: 547  | total loss: \u001b[1m\u001b[32m1.42311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 547 | loss: 1.42311 - acc: 0.7083 -- iter: 14/14\n",
      "--\n",
      "Training Step: 548  | total loss: \u001b[1m\u001b[32m1.64008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 548 | loss: 1.64008 - acc: 0.6446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 549  | total loss: \u001b[1m\u001b[32m1.51429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 549 | loss: 1.51429 - acc: 0.6801 -- iter: 14/14\n",
      "--\n",
      "Training Step: 550  | total loss: \u001b[1m\u001b[32m1.76137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 550 | loss: 1.76137 - acc: 0.6121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 551  | total loss: \u001b[1m\u001b[32m1.62525\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 551 | loss: 1.62525 - acc: 0.6509 -- iter: 14/14\n",
      "--\n",
      "Training Step: 552  | total loss: \u001b[1m\u001b[32m1.50355\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 552 | loss: 1.50355 - acc: 0.6858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 553  | total loss: \u001b[1m\u001b[32m1.39421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 553 | loss: 1.39421 - acc: 0.7172 -- iter: 14/14\n",
      "--\n",
      "Training Step: 554  | total loss: \u001b[1m\u001b[32m1.59590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 554 | loss: 1.59590 - acc: 0.6526 -- iter: 14/14\n",
      "--\n",
      "Training Step: 555  | total loss: \u001b[1m\u001b[32m1.47759\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 555 | loss: 1.47759 - acc: 0.6874 -- iter: 14/14\n",
      "--\n",
      "Training Step: 556  | total loss: \u001b[1m\u001b[32m1.67636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 556 | loss: 1.67636 - acc: 0.6258 -- iter: 14/14\n",
      "--\n",
      "Training Step: 557  | total loss: \u001b[1m\u001b[32m1.55124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 557 | loss: 1.55124 - acc: 0.6632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 558  | total loss: \u001b[1m\u001b[32m1.72568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 558 | loss: 1.72568 - acc: 0.6112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 559  | total loss: \u001b[1m\u001b[32m1.59756\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 559 | loss: 1.59756 - acc: 0.6501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 560  | total loss: \u001b[1m\u001b[32m1.48296\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 560 | loss: 1.48296 - acc: 0.6850 -- iter: 14/14\n",
      "--\n",
      "Training Step: 561  | total loss: \u001b[1m\u001b[32m1.37980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 561 | loss: 1.37980 - acc: 0.7165 -- iter: 14/14\n",
      "--\n",
      "Training Step: 562  | total loss: \u001b[1m\u001b[32m1.28631\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 562 | loss: 1.28631 - acc: 0.7449 -- iter: 14/14\n",
      "--\n",
      "Training Step: 563  | total loss: \u001b[1m\u001b[32m1.20094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 563 | loss: 1.20094 - acc: 0.7704 -- iter: 14/14\n",
      "--\n",
      "Training Step: 564  | total loss: \u001b[1m\u001b[32m1.12243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 564 | loss: 1.12243 - acc: 0.7934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 565  | total loss: \u001b[1m\u001b[32m1.04970\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 565 | loss: 1.04970 - acc: 0.8140 -- iter: 14/14\n",
      "--\n",
      "Training Step: 566  | total loss: \u001b[1m\u001b[32m1.31423\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 566 | loss: 1.31423 - acc: 0.7398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 567  | total loss: \u001b[1m\u001b[32m1.21903\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 567 | loss: 1.21903 - acc: 0.7658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 568  | total loss: \u001b[1m\u001b[32m1.13203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 568 | loss: 1.13203 - acc: 0.7892 -- iter: 14/14\n",
      "--\n",
      "Training Step: 569  | total loss: \u001b[1m\u001b[32m1.05212\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 569 | loss: 1.05212 - acc: 0.8103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 570  | total loss: \u001b[1m\u001b[32m0.97838\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 570 | loss: 0.97838 - acc: 0.8293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 571  | total loss: \u001b[1m\u001b[32m0.91004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 571 | loss: 0.91004 - acc: 0.8463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 572  | total loss: \u001b[1m\u001b[32m1.16858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 572 | loss: 1.16858 - acc: 0.7760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 573  | total loss: \u001b[1m\u001b[32m1.07823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 573 | loss: 1.07823 - acc: 0.7984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 574  | total loss: \u001b[1m\u001b[32m1.35730\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 574 | loss: 1.35730 - acc: 0.7257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 575  | total loss: \u001b[1m\u001b[32m1.24695\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 575 | loss: 1.24695 - acc: 0.7531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 576  | total loss: \u001b[1m\u001b[32m1.14734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 576 | loss: 1.14734 - acc: 0.7778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 577  | total loss: \u001b[1m\u001b[32m1.05716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 577 | loss: 1.05716 - acc: 0.8000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 578  | total loss: \u001b[1m\u001b[32m1.37119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 578 | loss: 1.37119 - acc: 0.7200 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 579  | total loss: \u001b[1m\u001b[32m1.25836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 579 | loss: 1.25836 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 580  | total loss: \u001b[1m\u001b[32m1.55804\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 580 | loss: 1.55804 - acc: 0.6732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 581  | total loss: \u001b[1m\u001b[32m1.42800\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 581 | loss: 1.42800 - acc: 0.7059 -- iter: 14/14\n",
      "--\n",
      "Training Step: 582  | total loss: \u001b[1m\u001b[32m1.31188\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 582 | loss: 1.31188 - acc: 0.7353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 583  | total loss: \u001b[1m\u001b[32m1.20790\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 583 | loss: 1.20790 - acc: 0.7618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 584  | total loss: \u001b[1m\u001b[32m1.11446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 584 | loss: 1.11446 - acc: 0.7856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 585  | total loss: \u001b[1m\u001b[32m1.03017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 585 | loss: 1.03017 - acc: 0.8070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 586  | total loss: \u001b[1m\u001b[32m0.95381\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 586 | loss: 0.95381 - acc: 0.8263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 587  | total loss: \u001b[1m\u001b[32m0.88429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 587 | loss: 0.88429 - acc: 0.8437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 588  | total loss: \u001b[1m\u001b[32m1.19385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 588 | loss: 1.19385 - acc: 0.7665 -- iter: 14/14\n",
      "--\n",
      "Training Step: 589  | total loss: \u001b[1m\u001b[32m1.09948\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 589 | loss: 1.09948 - acc: 0.7898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 590  | total loss: \u001b[1m\u001b[32m1.40045\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 590 | loss: 1.40045 - acc: 0.7108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 591  | total loss: \u001b[1m\u001b[32m1.28625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 591 | loss: 1.28625 - acc: 0.7398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 592  | total loss: \u001b[1m\u001b[32m1.58643\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 592 | loss: 1.58643 - acc: 0.6658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 593  | total loss: \u001b[1m\u001b[32m1.45591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 593 | loss: 1.45591 - acc: 0.6992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 594  | total loss: \u001b[1m\u001b[32m1.68892\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 594 | loss: 1.68892 - acc: 0.6364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 595  | total loss: \u001b[1m\u001b[32m1.55162\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 595 | loss: 1.55162 - acc: 0.6728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 596  | total loss: \u001b[1m\u001b[32m1.42976\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 596 | loss: 1.42976 - acc: 0.7055 -- iter: 14/14\n",
      "--\n",
      "Training Step: 597  | total loss: \u001b[1m\u001b[32m1.32123\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 597 | loss: 1.32123 - acc: 0.7350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 598  | total loss: \u001b[1m\u001b[32m1.59457\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 598 | loss: 1.59457 - acc: 0.6615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 599  | total loss: \u001b[1m\u001b[32m1.47195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 599 | loss: 1.47195 - acc: 0.6953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 600  | total loss: \u001b[1m\u001b[32m1.71187\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 600 | loss: 1.71187 - acc: 0.6258 -- iter: 14/14\n",
      "--\n",
      "Training Step: 601  | total loss: \u001b[1m\u001b[32m1.58106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 601 | loss: 1.58106 - acc: 0.6632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 602  | total loss: \u001b[1m\u001b[32m1.78638\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 602 | loss: 1.78638 - acc: 0.5969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 603  | total loss: \u001b[1m\u001b[32m1.65234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 603 | loss: 1.65234 - acc: 0.6372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 604  | total loss: \u001b[1m\u001b[32m1.53345\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 604 | loss: 1.53345 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 605  | total loss: \u001b[1m\u001b[32m1.42736\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 605 | loss: 1.42736 - acc: 0.7061 -- iter: 14/14\n",
      "--\n",
      "Training Step: 606  | total loss: \u001b[1m\u001b[32m1.33197\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 606 | loss: 1.33197 - acc: 0.7355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 607  | total loss: \u001b[1m\u001b[32m1.24550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 607 | loss: 1.24550 - acc: 0.7620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 608  | total loss: \u001b[1m\u001b[32m1.16641\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 608 | loss: 1.16641 - acc: 0.7858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 609  | total loss: \u001b[1m\u001b[32m1.09344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 609 | loss: 1.09344 - acc: 0.8072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 610  | total loss: \u001b[1m\u001b[32m1.02556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 610 | loss: 1.02556 - acc: 0.8265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 611  | total loss: \u001b[1m\u001b[32m0.96197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 611 | loss: 0.96197 - acc: 0.8438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 612  | total loss: \u001b[1m\u001b[32m1.23964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 612 | loss: 1.23964 - acc: 0.7666 -- iter: 14/14\n",
      "--\n",
      "Training Step: 613  | total loss: \u001b[1m\u001b[32m1.15069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 613 | loss: 1.15069 - acc: 0.7899 -- iter: 14/14\n",
      "--\n",
      "Training Step: 614  | total loss: \u001b[1m\u001b[32m1.45111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 614 | loss: 1.45111 - acc: 0.7109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 615  | total loss: \u001b[1m\u001b[32m1.33946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 615 | loss: 1.33946 - acc: 0.7398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 616  | total loss: \u001b[1m\u001b[32m1.56351\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 616 | loss: 1.56351 - acc: 0.6730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 617  | total loss: \u001b[1m\u001b[32m1.44084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 617 | loss: 1.44084 - acc: 0.7057 -- iter: 14/14\n",
      "--\n",
      "Training Step: 618  | total loss: \u001b[1m\u001b[32m1.33060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 618 | loss: 1.33060 - acc: 0.7351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 619  | total loss: \u001b[1m\u001b[32m1.23111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 619 | loss: 1.23111 - acc: 0.7616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 620  | total loss: \u001b[1m\u001b[32m1.46124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 620 | loss: 1.46124 - acc: 0.6997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 621  | total loss: \u001b[1m\u001b[32m1.34838\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 621 | loss: 1.34838 - acc: 0.7298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 622  | total loss: \u001b[1m\u001b[32m1.24670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 622 | loss: 1.24670 - acc: 0.7568 -- iter: 14/14\n",
      "--\n",
      "Training Step: 623  | total loss: \u001b[1m\u001b[32m1.15468\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 623 | loss: 1.15468 - acc: 0.7811 -- iter: 14/14\n",
      "--\n",
      "Training Step: 624  | total loss: \u001b[1m\u001b[32m1.37872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 624 | loss: 1.37872 - acc: 0.7173 -- iter: 14/14\n",
      "--\n",
      "Training Step: 625  | total loss: \u001b[1m\u001b[32m1.27289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 625 | loss: 1.27289 - acc: 0.7456 -- iter: 14/14\n",
      "--\n",
      "Training Step: 626  | total loss: \u001b[1m\u001b[32m1.54764\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 626 | loss: 1.54764 - acc: 0.6710 -- iter: 14/14\n",
      "--\n",
      "Training Step: 627  | total loss: \u001b[1m\u001b[32m1.42575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 627 | loss: 1.42575 - acc: 0.7039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 628  | total loss: \u001b[1m\u001b[32m1.31654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 628 | loss: 1.31654 - acc: 0.7335 -- iter: 14/14\n",
      "--\n",
      "Training Step: 629  | total loss: \u001b[1m\u001b[32m1.21826\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 629 | loss: 1.21826 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 630  | total loss: \u001b[1m\u001b[32m1.44005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 630 | loss: 1.44005 - acc: 0.6913 -- iter: 14/14\n",
      "--\n",
      "Training Step: 631  | total loss: \u001b[1m\u001b[32m1.32972\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 631 | loss: 1.32972 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 632  | total loss: \u001b[1m\u001b[32m1.52374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 632 | loss: 1.52374 - acc: 0.6642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 633  | total loss: \u001b[1m\u001b[32m1.40653\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 633 | loss: 1.40653 - acc: 0.6978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 634  | total loss: \u001b[1m\u001b[32m1.30175\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 634 | loss: 1.30175 - acc: 0.7280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 635  | total loss: \u001b[1m\u001b[32m1.20762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 635 | loss: 1.20762 - acc: 0.7552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 636  | total loss: \u001b[1m\u001b[32m1.47250\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 636 | loss: 1.47250 - acc: 0.6797 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 637  | total loss: \u001b[1m\u001b[32m1.36191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 637 | loss: 1.36191 - acc: 0.7117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 638  | total loss: \u001b[1m\u001b[32m1.26274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 638 | loss: 1.26274 - acc: 0.7406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 639  | total loss: \u001b[1m\u001b[32m1.17327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 639 | loss: 1.17327 - acc: 0.7665 -- iter: 14/14\n",
      "--\n",
      "Training Step: 640  | total loss: \u001b[1m\u001b[32m1.41624\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 640 | loss: 1.41624 - acc: 0.7041 -- iter: 14/14\n",
      "--\n",
      "Training Step: 641  | total loss: \u001b[1m\u001b[32m1.31099\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 641 | loss: 1.31099 - acc: 0.7337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 642  | total loss: \u001b[1m\u001b[32m1.51118\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 642 | loss: 1.51118 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 643  | total loss: \u001b[1m\u001b[32m1.39692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 643 | loss: 1.39692 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 644  | total loss: \u001b[1m\u001b[32m1.57333\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 644 | loss: 1.57333 - acc: 0.6507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 645  | total loss: \u001b[1m\u001b[32m1.45415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 645 | loss: 1.45415 - acc: 0.6857 -- iter: 14/14\n",
      "--\n",
      "Training Step: 646  | total loss: \u001b[1m\u001b[32m1.64959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 646 | loss: 1.64959 - acc: 0.6314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 647  | total loss: \u001b[1m\u001b[32m1.52475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 647 | loss: 1.52475 - acc: 0.6682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 648  | total loss: \u001b[1m\u001b[32m1.70727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 648 | loss: 1.70727 - acc: 0.6086 -- iter: 14/14\n",
      "--\n",
      "Training Step: 649  | total loss: \u001b[1m\u001b[32m1.57922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 649 | loss: 1.57922 - acc: 0.6477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 650  | total loss: \u001b[1m\u001b[32m1.78365\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 650 | loss: 1.78365 - acc: 0.5829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 651  | total loss: \u001b[1m\u001b[32m1.65119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 651 | loss: 1.65119 - acc: 0.6246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 652  | total loss: \u001b[1m\u001b[32m1.53333\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 652 | loss: 1.53333 - acc: 0.6622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 653  | total loss: \u001b[1m\u001b[32m1.42778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 653 | loss: 1.42778 - acc: 0.6960 -- iter: 14/14\n",
      "--\n",
      "Training Step: 654  | total loss: \u001b[1m\u001b[32m1.66123\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 654 | loss: 1.66123 - acc: 0.6264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 655  | total loss: \u001b[1m\u001b[32m1.54374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 655 | loss: 1.54374 - acc: 0.6637 -- iter: 14/14\n",
      "--\n",
      "Training Step: 656  | total loss: \u001b[1m\u001b[32m1.73533\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 656 | loss: 1.73533 - acc: 0.6045 -- iter: 14/14\n",
      "--\n",
      "Training Step: 657  | total loss: \u001b[1m\u001b[32m1.61211\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 657 | loss: 1.61211 - acc: 0.6440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 658  | total loss: \u001b[1m\u001b[32m1.82943\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 658 | loss: 1.82943 - acc: 0.5796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 659  | total loss: \u001b[1m\u001b[32m1.69905\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 659 | loss: 1.69905 - acc: 0.6217 -- iter: 14/14\n",
      "--\n",
      "Training Step: 660  | total loss: \u001b[1m\u001b[32m1.88157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 660 | loss: 1.88157 - acc: 0.5667 -- iter: 14/14\n",
      "--\n",
      "Training Step: 661  | total loss: \u001b[1m\u001b[32m1.74859\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 661 | loss: 1.74859 - acc: 0.6100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 662  | total loss: \u001b[1m\u001b[32m1.92061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 662 | loss: 1.92061 - acc: 0.5561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 663  | total loss: \u001b[1m\u001b[32m1.78652\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 663 | loss: 1.78652 - acc: 0.6005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 664  | total loss: \u001b[1m\u001b[32m1.96444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 664 | loss: 1.96444 - acc: 0.5405 -- iter: 14/14\n",
      "--\n",
      "Training Step: 665  | total loss: \u001b[1m\u001b[32m1.82890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 665 | loss: 1.82890 - acc: 0.5864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 666  | total loss: \u001b[1m\u001b[32m1.95567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 666 | loss: 1.95567 - acc: 0.5421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 667  | total loss: \u001b[1m\u001b[32m1.82375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 667 | loss: 1.82375 - acc: 0.5879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 668  | total loss: \u001b[1m\u001b[32m1.93900\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 668 | loss: 1.93900 - acc: 0.5434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 669  | total loss: \u001b[1m\u001b[32m1.81084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 669 | loss: 1.81084 - acc: 0.5890 -- iter: 14/14\n",
      "--\n",
      "Training Step: 670  | total loss: \u001b[1m\u001b[32m1.69578\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 670 | loss: 1.69578 - acc: 0.6301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 671  | total loss: \u001b[1m\u001b[32m1.59150\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 671 | loss: 1.59150 - acc: 0.6671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 672  | total loss: \u001b[1m\u001b[32m1.75924\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 672 | loss: 1.75924 - acc: 0.6075 -- iter: 14/14\n",
      "--\n",
      "Training Step: 673  | total loss: \u001b[1m\u001b[32m1.64654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 673 | loss: 1.64654 - acc: 0.6468 -- iter: 14/14\n",
      "--\n",
      "Training Step: 674  | total loss: \u001b[1m\u001b[32m1.82306\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 674 | loss: 1.82306 - acc: 0.5893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 675  | total loss: \u001b[1m\u001b[32m1.70252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 675 | loss: 1.70252 - acc: 0.6303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 676  | total loss: \u001b[1m\u001b[32m1.59301\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 676 | loss: 1.59301 - acc: 0.6673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 677  | total loss: \u001b[1m\u001b[32m1.49263\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 677 | loss: 1.49263 - acc: 0.7006 -- iter: 14/14\n",
      "--\n",
      "Training Step: 678  | total loss: \u001b[1m\u001b[32m1.66277\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 678 | loss: 1.66277 - acc: 0.6448 -- iter: 14/14\n",
      "--\n",
      "Training Step: 679  | total loss: \u001b[1m\u001b[32m1.55160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 679 | loss: 1.55160 - acc: 0.6803 -- iter: 14/14\n",
      "--\n",
      "Training Step: 680  | total loss: \u001b[1m\u001b[32m1.68700\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 680 | loss: 1.68700 - acc: 0.6337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 681  | total loss: \u001b[1m\u001b[32m1.57057\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 681 | loss: 1.57057 - acc: 0.6703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 682  | total loss: \u001b[1m\u001b[32m1.75550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 682 | loss: 1.75550 - acc: 0.6104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 683  | total loss: \u001b[1m\u001b[32m1.63048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 683 | loss: 1.63048 - acc: 0.6494 -- iter: 14/14\n",
      "--\n",
      "Training Step: 684  | total loss: \u001b[1m\u001b[32m1.51704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 684 | loss: 1.51704 - acc: 0.6845 -- iter: 14/14\n",
      "--\n",
      "Training Step: 685  | total loss: \u001b[1m\u001b[32m1.41345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 685 | loss: 1.41345 - acc: 0.7160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 686  | total loss: \u001b[1m\u001b[32m1.31823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 686 | loss: 1.31823 - acc: 0.7444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 687  | total loss: \u001b[1m\u001b[32m1.23017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 687 | loss: 1.23017 - acc: 0.7700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 688  | total loss: \u001b[1m\u001b[32m1.14828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 688 | loss: 1.14828 - acc: 0.7930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 689  | total loss: \u001b[1m\u001b[32m1.07176\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 689 | loss: 1.07176 - acc: 0.8137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 690  | total loss: \u001b[1m\u001b[32m0.99996\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 690 | loss: 0.99996 - acc: 0.8323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 691  | total loss: \u001b[1m\u001b[32m0.93240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 691 | loss: 0.93240 - acc: 0.8491 -- iter: 14/14\n",
      "--\n",
      "Training Step: 692  | total loss: \u001b[1m\u001b[32m0.86870\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 692 | loss: 0.86870 - acc: 0.8642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 693  | total loss: \u001b[1m\u001b[32m0.80857\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 693 | loss: 0.80857 - acc: 0.8778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 694  | total loss: \u001b[1m\u001b[32m1.16563\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 694 | loss: 1.16563 - acc: 0.7900 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 695  | total loss: \u001b[1m\u001b[32m1.07190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 695 | loss: 1.07190 - acc: 0.8110 -- iter: 14/14\n",
      "--\n",
      "Training Step: 696  | total loss: \u001b[1m\u001b[32m0.98622\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 696 | loss: 0.98622 - acc: 0.8299 -- iter: 14/14\n",
      "--\n",
      "Training Step: 697  | total loss: \u001b[1m\u001b[32m0.90774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 697 | loss: 0.90774 - acc: 0.8469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 698  | total loss: \u001b[1m\u001b[32m1.27334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 698 | loss: 1.27334 - acc: 0.7622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 699  | total loss: \u001b[1m\u001b[32m1.16454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 699 | loss: 1.16454 - acc: 0.7860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 700  | total loss: \u001b[1m\u001b[32m1.06624\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 700 | loss: 1.06624 - acc: 0.8074 -- iter: 14/14\n",
      "--\n",
      "Training Step: 701  | total loss: \u001b[1m\u001b[32m0.97727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 701 | loss: 0.97727 - acc: 0.8266 -- iter: 14/14\n",
      "--\n",
      "Training Step: 702  | total loss: \u001b[1m\u001b[32m1.27557\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 702 | loss: 1.27557 - acc: 0.7583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 703  | total loss: \u001b[1m\u001b[32m1.16527\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 703 | loss: 1.16527 - acc: 0.7824 -- iter: 14/14\n",
      "--\n",
      "Training Step: 704  | total loss: \u001b[1m\u001b[32m1.49873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 704 | loss: 1.49873 - acc: 0.7042 -- iter: 14/14\n",
      "--\n",
      "Training Step: 705  | total loss: \u001b[1m\u001b[32m1.36719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 705 | loss: 1.36719 - acc: 0.7338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 706  | total loss: \u001b[1m\u001b[32m1.63459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 706 | loss: 1.63459 - acc: 0.6675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 707  | total loss: \u001b[1m\u001b[32m1.49202\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 707 | loss: 1.49202 - acc: 0.7008 -- iter: 14/14\n",
      "--\n",
      "Training Step: 708  | total loss: \u001b[1m\u001b[32m1.36521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 708 | loss: 1.36521 - acc: 0.7307 -- iter: 14/14\n",
      "--\n",
      "Training Step: 709  | total loss: \u001b[1m\u001b[32m1.25228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 709 | loss: 1.25228 - acc: 0.7576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 710  | total loss: \u001b[1m\u001b[32m1.55109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 710 | loss: 1.55109 - acc: 0.6819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 711  | total loss: \u001b[1m\u001b[32m1.42233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 711 | loss: 1.42233 - acc: 0.7137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 712  | total loss: \u001b[1m\u001b[32m1.30792\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 712 | loss: 1.30792 - acc: 0.7423 -- iter: 14/14\n",
      "--\n",
      "Training Step: 713  | total loss: \u001b[1m\u001b[32m1.20599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 713 | loss: 1.20599 - acc: 0.7681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 714  | total loss: \u001b[1m\u001b[32m1.51439\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 714 | loss: 1.51439 - acc: 0.6913 -- iter: 14/14\n",
      "--\n",
      "Training Step: 715  | total loss: \u001b[1m\u001b[32m1.39414\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 715 | loss: 1.39414 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 716  | total loss: \u001b[1m\u001b[32m1.61323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 716 | loss: 1.61323 - acc: 0.6571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 717  | total loss: \u001b[1m\u001b[32m1.48649\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 717 | loss: 1.48649 - acc: 0.6914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 718  | total loss: \u001b[1m\u001b[32m1.69675\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 718 | loss: 1.69675 - acc: 0.6365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 719  | total loss: \u001b[1m\u001b[32m1.56559\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 719 | loss: 1.56559 - acc: 0.6729 -- iter: 14/14\n",
      "--\n",
      "Training Step: 720  | total loss: \u001b[1m\u001b[32m1.71756\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 720 | loss: 1.71756 - acc: 0.6199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 721  | total loss: \u001b[1m\u001b[32m1.58843\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 721 | loss: 1.58843 - acc: 0.6579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 722  | total loss: \u001b[1m\u001b[32m1.47385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 722 | loss: 1.47385 - acc: 0.6921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 723  | total loss: \u001b[1m\u001b[32m1.37157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 723 | loss: 1.37157 - acc: 0.7229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 724  | total loss: \u001b[1m\u001b[32m1.56451\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 724 | loss: 1.56451 - acc: 0.6649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 725  | total loss: \u001b[1m\u001b[32m1.45425\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 725 | loss: 1.45425 - acc: 0.6984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 726  | total loss: \u001b[1m\u001b[32m1.67633\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 726 | loss: 1.67633 - acc: 0.6286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 727  | total loss: \u001b[1m\u001b[32m1.55650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 727 | loss: 1.55650 - acc: 0.6657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 728  | total loss: \u001b[1m\u001b[32m1.44923\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 728 | loss: 1.44923 - acc: 0.6991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 729  | total loss: \u001b[1m\u001b[32m1.35256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 729 | loss: 1.35256 - acc: 0.7292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 730  | total loss: \u001b[1m\u001b[32m1.53679\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 730 | loss: 1.53679 - acc: 0.6706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 731  | total loss: \u001b[1m\u001b[32m1.43074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 731 | loss: 1.43074 - acc: 0.7035 -- iter: 14/14\n",
      "--\n",
      "Training Step: 732  | total loss: \u001b[1m\u001b[32m1.67285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 732 | loss: 1.67285 - acc: 0.6332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 733  | total loss: \u001b[1m\u001b[32m1.55335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 733 | loss: 1.55335 - acc: 0.6699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 734  | total loss: \u001b[1m\u001b[32m1.76023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 734 | loss: 1.76023 - acc: 0.6100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 735  | total loss: \u001b[1m\u001b[32m1.63304\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 735 | loss: 1.63304 - acc: 0.6490 -- iter: 14/14\n",
      "--\n",
      "Training Step: 736  | total loss: \u001b[1m\u001b[32m1.82899\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 736 | loss: 1.82899 - acc: 0.5841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 737  | total loss: \u001b[1m\u001b[32m1.69672\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 737 | loss: 1.69672 - acc: 0.6257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 738  | total loss: \u001b[1m\u001b[32m1.89463\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 738 | loss: 1.89463 - acc: 0.5631 -- iter: 14/14\n",
      "--\n",
      "Training Step: 739  | total loss: \u001b[1m\u001b[32m1.75817\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 739 | loss: 1.75817 - acc: 0.6068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 740  | total loss: \u001b[1m\u001b[32m1.89708\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 740 | loss: 1.89708 - acc: 0.5533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 741  | total loss: \u001b[1m\u001b[32m1.76299\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 741 | loss: 1.76299 - acc: 0.5979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 742  | total loss: \u001b[1m\u001b[32m1.93591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 742 | loss: 1.93591 - acc: 0.5453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 743  | total loss: \u001b[1m\u001b[32m1.80063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 743 | loss: 1.80063 - acc: 0.5908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 744  | total loss: \u001b[1m\u001b[32m1.67977\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 744 | loss: 1.67977 - acc: 0.6317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 745  | total loss: \u001b[1m\u001b[32m1.57098\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 745 | loss: 1.57098 - acc: 0.6685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 746  | total loss: \u001b[1m\u001b[32m1.47227\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 746 | loss: 1.47227 - acc: 0.7017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 747  | total loss: \u001b[1m\u001b[32m1.38190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 747 | loss: 1.38190 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 748  | total loss: \u001b[1m\u001b[32m1.29844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 748 | loss: 1.29844 - acc: 0.7584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 749  | total loss: \u001b[1m\u001b[32m1.22070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 749 | loss: 1.22070 - acc: 0.7825 -- iter: 14/14\n",
      "--\n",
      "Training Step: 750  | total loss: \u001b[1m\u001b[32m1.14773\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 750 | loss: 1.14773 - acc: 0.8043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 751  | total loss: \u001b[1m\u001b[32m1.07878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 751 | loss: 1.07878 - acc: 0.8238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 752  | total loss: \u001b[1m\u001b[32m1.33260\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 752 | loss: 1.33260 - acc: 0.7486 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 753  | total loss: \u001b[1m\u001b[32m1.23982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 753 | loss: 1.23982 - acc: 0.7737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 754  | total loss: \u001b[1m\u001b[32m1.15415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 754 | loss: 1.15415 - acc: 0.7964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 755  | total loss: \u001b[1m\u001b[32m1.07468\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 755 | loss: 1.07468 - acc: 0.8167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 756  | total loss: \u001b[1m\u001b[32m1.33138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 756 | loss: 1.33138 - acc: 0.7422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 757  | total loss: \u001b[1m\u001b[32m1.23055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 757 | loss: 1.23055 - acc: 0.7680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 758  | total loss: \u001b[1m\u001b[32m1.49723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 758 | loss: 1.49723 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 759  | total loss: \u001b[1m\u001b[32m1.37827\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 759 | loss: 1.37827 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 760  | total loss: \u001b[1m\u001b[32m1.63711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 760 | loss: 1.63711 - acc: 0.6499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 761  | total loss: \u001b[1m\u001b[32m1.50431\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 761 | loss: 1.50431 - acc: 0.6849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 762  | total loss: \u001b[1m\u001b[32m1.73475\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 762 | loss: 1.73475 - acc: 0.6235 -- iter: 14/14\n",
      "--\n",
      "Training Step: 763  | total loss: \u001b[1m\u001b[32m1.59369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 763 | loss: 1.59369 - acc: 0.6612 -- iter: 14/14\n",
      "--\n",
      "Training Step: 764  | total loss: \u001b[1m\u001b[32m1.77387\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 764 | loss: 1.77387 - acc: 0.6093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 765  | total loss: \u001b[1m\u001b[32m1.63131\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 765 | loss: 1.63131 - acc: 0.6484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 766  | total loss: \u001b[1m\u001b[32m1.81386\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 766 | loss: 1.81386 - acc: 0.5979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 767  | total loss: \u001b[1m\u001b[32m1.67032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 767 | loss: 1.67032 - acc: 0.6381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 768  | total loss: \u001b[1m\u001b[32m1.54244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 768 | loss: 1.54244 - acc: 0.6743 -- iter: 14/14\n",
      "--\n",
      "Training Step: 769  | total loss: \u001b[1m\u001b[32m1.42803\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 769 | loss: 1.42803 - acc: 0.7068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 770  | total loss: \u001b[1m\u001b[32m1.64586\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 770 | loss: 1.64586 - acc: 0.6433 -- iter: 14/14\n",
      "--\n",
      "Training Step: 771  | total loss: \u001b[1m\u001b[32m1.52234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 771 | loss: 1.52234 - acc: 0.6790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 772  | total loss: \u001b[1m\u001b[32m1.41167\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 772 | loss: 1.41167 - acc: 0.7111 -- iter: 14/14\n",
      "--\n",
      "Training Step: 773  | total loss: \u001b[1m\u001b[32m1.31196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 773 | loss: 1.31196 - acc: 0.7400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 774  | total loss: \u001b[1m\u001b[32m1.53801\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 774 | loss: 1.53801 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 775  | total loss: \u001b[1m\u001b[32m1.42540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 775 | loss: 1.42540 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 776  | total loss: \u001b[1m\u001b[32m1.32387\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 776 | loss: 1.32387 - acc: 0.7352 -- iter: 14/14\n",
      "--\n",
      "Training Step: 777  | total loss: \u001b[1m\u001b[32m1.23178\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 777 | loss: 1.23178 - acc: 0.7617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 778  | total loss: \u001b[1m\u001b[32m1.46663\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 778 | loss: 1.46663 - acc: 0.6927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 779  | total loss: \u001b[1m\u001b[32m1.35914\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 779 | loss: 1.35914 - acc: 0.7234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 780  | total loss: \u001b[1m\u001b[32m1.26193\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 780 | loss: 1.26193 - acc: 0.7511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 781  | total loss: \u001b[1m\u001b[32m1.17351\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 781 | loss: 1.17351 - acc: 0.7760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 782  | total loss: \u001b[1m\u001b[32m1.39095\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 782 | loss: 1.39095 - acc: 0.7055 -- iter: 14/14\n",
      "--\n",
      "Training Step: 783  | total loss: \u001b[1m\u001b[32m1.28809\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 783 | loss: 1.28809 - acc: 0.7350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 784  | total loss: \u001b[1m\u001b[32m1.19485\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 784 | loss: 1.19485 - acc: 0.7615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 785  | total loss: \u001b[1m\u001b[32m1.10991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 785 | loss: 1.10991 - acc: 0.7853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 786  | total loss: \u001b[1m\u001b[32m1.40401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 786 | loss: 1.40401 - acc: 0.7068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 787  | total loss: \u001b[1m\u001b[32m1.29682\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 787 | loss: 1.29682 - acc: 0.7361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 788  | total loss: \u001b[1m\u001b[32m1.49058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 788 | loss: 1.49058 - acc: 0.6839 -- iter: 14/14\n",
      "--\n",
      "Training Step: 789  | total loss: \u001b[1m\u001b[32m1.37481\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 789 | loss: 1.37481 - acc: 0.7155 -- iter: 14/14\n",
      "--\n",
      "Training Step: 790  | total loss: \u001b[1m\u001b[32m1.62131\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 790 | loss: 1.62131 - acc: 0.6440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 791  | total loss: \u001b[1m\u001b[32m1.49357\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 791 | loss: 1.49357 - acc: 0.6796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 792  | total loss: \u001b[1m\u001b[32m1.37915\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 792 | loss: 1.37915 - acc: 0.7116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 793  | total loss: \u001b[1m\u001b[32m1.27623\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 793 | loss: 1.27623 - acc: 0.7405 -- iter: 14/14\n",
      "--\n",
      "Training Step: 794  | total loss: \u001b[1m\u001b[32m1.50646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 794 | loss: 1.50646 - acc: 0.6736 -- iter: 14/14\n",
      "--\n",
      "Training Step: 795  | total loss: \u001b[1m\u001b[32m1.39101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 795 | loss: 1.39101 - acc: 0.7062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 796  | total loss: \u001b[1m\u001b[32m1.28721\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 796 | loss: 1.28721 - acc: 0.7356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 797  | total loss: \u001b[1m\u001b[32m1.19343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 797 | loss: 1.19343 - acc: 0.7620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 798  | total loss: \u001b[1m\u001b[32m1.10825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 798 | loss: 1.10825 - acc: 0.7858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 799  | total loss: \u001b[1m\u001b[32m1.03045\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 799 | loss: 1.03045 - acc: 0.8072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 800  | total loss: \u001b[1m\u001b[32m0.95902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 800 | loss: 0.95902 - acc: 0.8265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 801  | total loss: \u001b[1m\u001b[32m0.89309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 801 | loss: 0.89309 - acc: 0.8439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 802  | total loss: \u001b[1m\u001b[32m1.18191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 802 | loss: 1.18191 - acc: 0.7666 -- iter: 14/14\n",
      "--\n",
      "Training Step: 803  | total loss: \u001b[1m\u001b[32m1.09136\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 803 | loss: 1.09136 - acc: 0.7900 -- iter: 14/14\n",
      "--\n",
      "Training Step: 804  | total loss: \u001b[1m\u001b[32m1.00906\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 804 | loss: 1.00906 - acc: 0.8110 -- iter: 14/14\n",
      "--\n",
      "Training Step: 805  | total loss: \u001b[1m\u001b[32m0.93398\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 805 | loss: 0.93398 - acc: 0.8299 -- iter: 14/14\n",
      "--\n",
      "Training Step: 806  | total loss: \u001b[1m\u001b[32m1.27474\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 806 | loss: 1.27474 - acc: 0.7469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 807  | total loss: \u001b[1m\u001b[32m1.17194\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 807 | loss: 1.17194 - acc: 0.7722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 808  | total loss: \u001b[1m\u001b[32m1.44775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 808 | loss: 1.44775 - acc: 0.7093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 809  | total loss: \u001b[1m\u001b[32m1.32808\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 809 | loss: 1.32808 - acc: 0.7383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 810  | total loss: \u001b[1m\u001b[32m1.22074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 810 | loss: 1.22074 - acc: 0.7645 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 811  | total loss: \u001b[1m\u001b[32m1.12418\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 811 | loss: 1.12418 - acc: 0.7880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 812  | total loss: \u001b[1m\u001b[32m1.44246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 812 | loss: 1.44246 - acc: 0.7092 -- iter: 14/14\n",
      "--\n",
      "Training Step: 813  | total loss: \u001b[1m\u001b[32m1.32442\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 813 | loss: 1.32442 - acc: 0.7383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 814  | total loss: \u001b[1m\u001b[32m1.60529\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 814 | loss: 1.60529 - acc: 0.6645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 815  | total loss: \u001b[1m\u001b[32m1.47312\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 815 | loss: 1.47312 - acc: 0.6980 -- iter: 14/14\n",
      "--\n",
      "Training Step: 816  | total loss: \u001b[1m\u001b[32m1.72703\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 816 | loss: 1.72703 - acc: 0.6282 -- iter: 14/14\n",
      "--\n",
      "Training Step: 817  | total loss: \u001b[1m\u001b[32m1.58616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 817 | loss: 1.58616 - acc: 0.6654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 818  | total loss: \u001b[1m\u001b[32m1.46115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 818 | loss: 1.46115 - acc: 0.6989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 819  | total loss: \u001b[1m\u001b[32m1.34985\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 819 | loss: 1.34985 - acc: 0.7290 -- iter: 14/14\n",
      "--\n",
      "Training Step: 820  | total loss: \u001b[1m\u001b[32m1.25034\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 820 | loss: 1.25034 - acc: 0.7561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 821  | total loss: \u001b[1m\u001b[32m1.16090\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 821 | loss: 1.16090 - acc: 0.7805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 822  | total loss: \u001b[1m\u001b[32m1.08003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 822 | loss: 1.08003 - acc: 0.8024 -- iter: 14/14\n",
      "--\n",
      "Training Step: 823  | total loss: \u001b[1m\u001b[32m1.00644\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 823 | loss: 1.00644 - acc: 0.8222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 824  | total loss: \u001b[1m\u001b[32m1.20983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 824 | loss: 1.20983 - acc: 0.7543 -- iter: 14/14\n",
      "--\n",
      "Training Step: 825  | total loss: \u001b[1m\u001b[32m1.12200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 825 | loss: 1.12200 - acc: 0.7788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 826  | total loss: \u001b[1m\u001b[32m1.04243\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 826 | loss: 1.04243 - acc: 0.8009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 827  | total loss: \u001b[1m\u001b[32m0.96993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 827 | loss: 0.96993 - acc: 0.8209 -- iter: 14/14\n",
      "--\n",
      "Training Step: 828  | total loss: \u001b[1m\u001b[32m0.90348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 828 | loss: 0.90348 - acc: 0.8388 -- iter: 14/14\n",
      "--\n",
      "Training Step: 829  | total loss: \u001b[1m\u001b[32m0.84225\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 829 | loss: 0.84225 - acc: 0.8549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 830  | total loss: \u001b[1m\u001b[32m1.15085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 830 | loss: 1.15085 - acc: 0.7694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 831  | total loss: \u001b[1m\u001b[32m1.06303\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 831 | loss: 1.06303 - acc: 0.7925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 832  | total loss: \u001b[1m\u001b[32m1.36836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 832 | loss: 1.36836 - acc: 0.7204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 833  | total loss: \u001b[1m\u001b[32m1.25881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 833 | loss: 1.25881 - acc: 0.7483 -- iter: 14/14\n",
      "--\n",
      "Training Step: 834  | total loss: \u001b[1m\u001b[32m1.47683\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 834 | loss: 1.47683 - acc: 0.6878 -- iter: 14/14\n",
      "--\n",
      "Training Step: 835  | total loss: \u001b[1m\u001b[32m1.35772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 835 | loss: 1.35772 - acc: 0.7190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 836  | total loss: \u001b[1m\u001b[32m1.63517\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 836 | loss: 1.63517 - acc: 0.6542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 837  | total loss: \u001b[1m\u001b[32m1.50259\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 837 | loss: 1.50259 - acc: 0.6888 -- iter: 14/14\n",
      "--\n",
      "Training Step: 838  | total loss: \u001b[1m\u001b[32m1.67202\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 838 | loss: 1.67202 - acc: 0.6414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 839  | total loss: \u001b[1m\u001b[32m1.53899\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 839 | loss: 1.53899 - acc: 0.6772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 840  | total loss: \u001b[1m\u001b[32m1.42074\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 840 | loss: 1.42074 - acc: 0.7095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 841  | total loss: \u001b[1m\u001b[32m1.31518\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 841 | loss: 1.31518 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 842  | total loss: \u001b[1m\u001b[32m1.57853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 842 | loss: 1.57853 - acc: 0.6647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 843  | total loss: \u001b[1m\u001b[32m1.45886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 843 | loss: 1.45886 - acc: 0.6982 -- iter: 14/14\n",
      "--\n",
      "Training Step: 844  | total loss: \u001b[1m\u001b[32m1.35189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 844 | loss: 1.35189 - acc: 0.7284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 845  | total loss: \u001b[1m\u001b[32m1.25573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 845 | loss: 1.25573 - acc: 0.7556 -- iter: 14/14\n",
      "--\n",
      "Training Step: 846  | total loss: \u001b[1m\u001b[32m1.16872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 846 | loss: 1.16872 - acc: 0.7800 -- iter: 14/14\n",
      "--\n",
      "Training Step: 847  | total loss: \u001b[1m\u001b[32m1.08947\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 847 | loss: 1.08947 - acc: 0.8020 -- iter: 14/14\n",
      "--\n",
      "Training Step: 848  | total loss: \u001b[1m\u001b[32m1.33448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 848 | loss: 1.33448 - acc: 0.7361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 849  | total loss: \u001b[1m\u001b[32m1.23700\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 849 | loss: 1.23700 - acc: 0.7625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 850  | total loss: \u001b[1m\u001b[32m1.47374\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 850 | loss: 1.47374 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 851  | total loss: \u001b[1m\u001b[32m1.36207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 851 | loss: 1.36207 - acc: 0.7240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 852  | total loss: \u001b[1m\u001b[32m1.60926\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 852 | loss: 1.60926 - acc: 0.6588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 853  | total loss: \u001b[1m\u001b[32m1.48507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 853 | loss: 1.48507 - acc: 0.6929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 854  | total loss: \u001b[1m\u001b[32m1.67006\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 854 | loss: 1.67006 - acc: 0.6379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 855  | total loss: \u001b[1m\u001b[32m1.54177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 855 | loss: 1.54177 - acc: 0.6741 -- iter: 14/14\n",
      "--\n",
      "Training Step: 856  | total loss: \u001b[1m\u001b[32m1.42718\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 856 | loss: 1.42718 - acc: 0.7067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 857  | total loss: \u001b[1m\u001b[32m1.32429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 857 | loss: 1.32429 - acc: 0.7360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 858  | total loss: \u001b[1m\u001b[32m1.23139\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 858 | loss: 1.23139 - acc: 0.7624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 859  | total loss: \u001b[1m\u001b[32m1.14697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 859 | loss: 1.14697 - acc: 0.7862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 860  | total loss: \u001b[1m\u001b[32m1.06975\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 860 | loss: 1.06975 - acc: 0.8076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 861  | total loss: \u001b[1m\u001b[32m0.99867\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 861 | loss: 0.99867 - acc: 0.8268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 862  | total loss: \u001b[1m\u001b[32m0.93284\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 862 | loss: 0.93284 - acc: 0.8441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 863  | total loss: \u001b[1m\u001b[32m0.87155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 863 | loss: 0.87155 - acc: 0.8597 -- iter: 14/14\n",
      "--\n",
      "Training Step: 864  | total loss: \u001b[1m\u001b[32m0.81421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 864 | loss: 0.81421 - acc: 0.8737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 865  | total loss: \u001b[1m\u001b[32m0.76038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 865 | loss: 0.76038 - acc: 0.8864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 866  | total loss: \u001b[1m\u001b[32m0.70970\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 866 | loss: 0.70970 - acc: 0.8977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 867  | total loss: \u001b[1m\u001b[32m0.66193\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 867 | loss: 0.66193 - acc: 0.9080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 868  | total loss: \u001b[1m\u001b[32m0.61684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 868 | loss: 0.61684 - acc: 0.9172 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 869  | total loss: \u001b[1m\u001b[32m0.57429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 869 | loss: 0.57429 - acc: 0.9254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 870  | total loss: \u001b[1m\u001b[32m0.96827\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 870 | loss: 0.96827 - acc: 0.8400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 871  | total loss: \u001b[1m\u001b[32m0.88806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 871 | loss: 0.88806 - acc: 0.8560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 872  | total loss: \u001b[1m\u001b[32m1.16541\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 872 | loss: 1.16541 - acc: 0.7919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 873  | total loss: \u001b[1m\u001b[32m1.06476\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 873 | loss: 1.06476 - acc: 0.8127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 874  | total loss: \u001b[1m\u001b[32m0.97406\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 874 | loss: 0.97406 - acc: 0.8314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 875  | total loss: \u001b[1m\u001b[32m0.89221\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 875 | loss: 0.89221 - acc: 0.8483 -- iter: 14/14\n",
      "--\n",
      "Training Step: 876  | total loss: \u001b[1m\u001b[32m1.16093\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 876 | loss: 1.16093 - acc: 0.7849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 877  | total loss: \u001b[1m\u001b[32m1.06044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 877 | loss: 1.06044 - acc: 0.8064 -- iter: 14/14\n",
      "--\n",
      "Training Step: 878  | total loss: \u001b[1m\u001b[32m1.40469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 878 | loss: 1.40469 - acc: 0.7257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 879  | total loss: \u001b[1m\u001b[32m1.28116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 879 | loss: 1.28116 - acc: 0.7532 -- iter: 14/14\n",
      "--\n",
      "Training Step: 880  | total loss: \u001b[1m\u001b[32m1.17091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 880 | loss: 1.17091 - acc: 0.7779 -- iter: 14/14\n",
      "--\n",
      "Training Step: 881  | total loss: \u001b[1m\u001b[32m1.07236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 881 | loss: 1.07236 - acc: 0.8001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 882  | total loss: \u001b[1m\u001b[32m0.98413\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 882 | loss: 0.98413 - acc: 0.8201 -- iter: 14/14\n",
      "--\n",
      "Training Step: 883  | total loss: \u001b[1m\u001b[32m0.90494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 883 | loss: 0.90494 - acc: 0.8381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 884  | total loss: \u001b[1m\u001b[32m1.19178\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 884 | loss: 1.19178 - acc: 0.7685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 885  | total loss: \u001b[1m\u001b[32m1.09265\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 885 | loss: 1.09265 - acc: 0.7917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 886  | total loss: \u001b[1m\u001b[32m1.32263\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 886 | loss: 1.32263 - acc: 0.7339 -- iter: 14/14\n",
      "--\n",
      "Training Step: 887  | total loss: \u001b[1m\u001b[32m1.21221\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 887 | loss: 1.21221 - acc: 0.7605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 888  | total loss: \u001b[1m\u001b[32m1.44920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 888 | loss: 1.44920 - acc: 0.6988 -- iter: 14/14\n",
      "--\n",
      "Training Step: 889  | total loss: \u001b[1m\u001b[32m1.32883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 889 | loss: 1.32883 - acc: 0.7289 -- iter: 14/14\n",
      "--\n",
      "Training Step: 890  | total loss: \u001b[1m\u001b[32m1.22190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 890 | loss: 1.22190 - acc: 0.7560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 891  | total loss: \u001b[1m\u001b[32m1.12667\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 891 | loss: 1.12667 - acc: 0.7804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 892  | total loss: \u001b[1m\u001b[32m1.42165\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 892 | loss: 1.42165 - acc: 0.7024 -- iter: 14/14\n",
      "--\n",
      "Training Step: 893  | total loss: \u001b[1m\u001b[32m1.30881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 893 | loss: 1.30881 - acc: 0.7321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 894  | total loss: \u001b[1m\u001b[32m1.20852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 894 | loss: 1.20852 - acc: 0.7589 -- iter: 14/14\n",
      "--\n",
      "Training Step: 895  | total loss: \u001b[1m\u001b[32m1.11904\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 895 | loss: 1.11904 - acc: 0.7830 -- iter: 14/14\n",
      "--\n",
      "Training Step: 896  | total loss: \u001b[1m\u001b[32m1.03877\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 896 | loss: 1.03877 - acc: 0.8047 -- iter: 14/14\n",
      "--\n",
      "Training Step: 897  | total loss: \u001b[1m\u001b[32m0.96635\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 897 | loss: 0.96635 - acc: 0.8243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 898  | total loss: \u001b[1m\u001b[32m0.90058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 898 | loss: 0.90058 - acc: 0.8418 -- iter: 14/14\n",
      "--\n",
      "Training Step: 899  | total loss: \u001b[1m\u001b[32m0.84044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 899 | loss: 0.84044 - acc: 0.8576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 900  | total loss: \u001b[1m\u001b[32m1.10358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 900 | loss: 1.10358 - acc: 0.7862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 901  | total loss: \u001b[1m\u001b[32m1.02181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 901 | loss: 1.02181 - acc: 0.8075 -- iter: 14/14\n",
      "--\n",
      "Training Step: 902  | total loss: \u001b[1m\u001b[32m1.30674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 902 | loss: 1.30674 - acc: 0.7411 -- iter: 14/14\n",
      "--\n",
      "Training Step: 903  | total loss: \u001b[1m\u001b[32m1.20477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 903 | loss: 1.20477 - acc: 0.7670 -- iter: 14/14\n",
      "--\n",
      "Training Step: 904  | total loss: \u001b[1m\u001b[32m1.11315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 904 | loss: 1.11315 - acc: 0.7903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 905  | total loss: \u001b[1m\u001b[32m1.03048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 905 | loss: 1.03048 - acc: 0.8112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 906  | total loss: \u001b[1m\u001b[32m1.31790\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 906 | loss: 1.31790 - acc: 0.7373 -- iter: 14/14\n",
      "--\n",
      "Training Step: 907  | total loss: \u001b[1m\u001b[32m1.21479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 907 | loss: 1.21479 - acc: 0.7635 -- iter: 14/14\n",
      "--\n",
      "Training Step: 908  | total loss: \u001b[1m\u001b[32m1.12218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 908 | loss: 1.12218 - acc: 0.7872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 909  | total loss: \u001b[1m\u001b[32m1.03863\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 909 | loss: 1.03863 - acc: 0.8085 -- iter: 14/14\n",
      "--\n",
      "Training Step: 910  | total loss: \u001b[1m\u001b[32m1.26554\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 910 | loss: 1.26554 - acc: 0.7490 -- iter: 14/14\n",
      "--\n",
      "Training Step: 911  | total loss: \u001b[1m\u001b[32m1.16741\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 911 | loss: 1.16741 - acc: 0.7741 -- iter: 14/14\n",
      "--\n",
      "Training Step: 912  | total loss: \u001b[1m\u001b[32m1.07900\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 912 | loss: 1.07900 - acc: 0.7967 -- iter: 14/14\n",
      "--\n",
      "Training Step: 913  | total loss: \u001b[1m\u001b[32m0.99902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 913 | loss: 0.99902 - acc: 0.8171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 914  | total loss: \u001b[1m\u001b[32m0.92632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 914 | loss: 0.92632 - acc: 0.8354 -- iter: 14/14\n",
      "--\n",
      "Training Step: 915  | total loss: \u001b[1m\u001b[32m0.85994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 915 | loss: 0.85994 - acc: 0.8518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 916  | total loss: \u001b[1m\u001b[32m1.16094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 916 | loss: 1.16094 - acc: 0.7809 -- iter: 14/14\n",
      "--\n",
      "Training Step: 917  | total loss: \u001b[1m\u001b[32m1.06990\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 917 | loss: 1.06990 - acc: 0.8028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 918  | total loss: \u001b[1m\u001b[32m1.35759\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 918 | loss: 1.35759 - acc: 0.7297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 919  | total loss: \u001b[1m\u001b[32m1.24718\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 919 | loss: 1.24718 - acc: 0.7567 -- iter: 14/14\n",
      "--\n",
      "Training Step: 920  | total loss: \u001b[1m\u001b[32m1.54623\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 920 | loss: 1.54623 - acc: 0.6810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 921  | total loss: \u001b[1m\u001b[32m1.41874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 921 | loss: 1.41874 - acc: 0.7129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 922  | total loss: \u001b[1m\u001b[32m1.30505\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 922 | loss: 1.30505 - acc: 0.7416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 923  | total loss: \u001b[1m\u001b[32m1.20337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 923 | loss: 1.20337 - acc: 0.7675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 924  | total loss: \u001b[1m\u001b[32m1.47525\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 924 | loss: 1.47525 - acc: 0.6979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 925  | total loss: \u001b[1m\u001b[32m1.35801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 925 | loss: 1.35801 - acc: 0.7281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 926  | total loss: \u001b[1m\u001b[32m1.60507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 926 | loss: 1.60507 - acc: 0.6624 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 927  | total loss: \u001b[1m\u001b[32m1.47738\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 927 | loss: 1.47738 - acc: 0.6962 -- iter: 14/14\n",
      "--\n",
      "Training Step: 928  | total loss: \u001b[1m\u001b[32m1.70401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 928 | loss: 1.70401 - acc: 0.6266 -- iter: 14/14\n",
      "--\n",
      "Training Step: 929  | total loss: \u001b[1m\u001b[32m1.57002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 929 | loss: 1.57002 - acc: 0.6639 -- iter: 14/14\n",
      "--\n",
      "Training Step: 930  | total loss: \u001b[1m\u001b[32m1.79452\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 930 | loss: 1.79452 - acc: 0.6047 -- iter: 14/14\n",
      "--\n",
      "Training Step: 931  | total loss: \u001b[1m\u001b[32m1.65590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 931 | loss: 1.65590 - acc: 0.6442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 932  | total loss: \u001b[1m\u001b[32m1.53307\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 932 | loss: 1.53307 - acc: 0.6798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 933  | total loss: \u001b[1m\u001b[32m1.42370\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 933 | loss: 1.42370 - acc: 0.7118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 934  | total loss: \u001b[1m\u001b[32m1.64992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 934 | loss: 1.64992 - acc: 0.6406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 935  | total loss: \u001b[1m\u001b[32m1.53082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 935 | loss: 1.53082 - acc: 0.6766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 936  | total loss: \u001b[1m\u001b[32m1.42436\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 936 | loss: 1.42436 - acc: 0.7089 -- iter: 14/14\n",
      "--\n",
      "Training Step: 937  | total loss: \u001b[1m\u001b[32m1.32854\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 937 | loss: 1.32854 - acc: 0.7380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 938  | total loss: \u001b[1m\u001b[32m1.53565\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 938 | loss: 1.53565 - acc: 0.6714 -- iter: 14/14\n",
      "--\n",
      "Training Step: 939  | total loss: \u001b[1m\u001b[32m1.42842\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 939 | loss: 1.42842 - acc: 0.7042 -- iter: 14/14\n",
      "--\n",
      "Training Step: 940  | total loss: \u001b[1m\u001b[32m1.64601\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 940 | loss: 1.64601 - acc: 0.6338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 941  | total loss: \u001b[1m\u001b[32m1.52841\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 941 | loss: 1.52841 - acc: 0.6704 -- iter: 14/14\n",
      "--\n",
      "Training Step: 942  | total loss: \u001b[1m\u001b[32m1.72174\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 942 | loss: 1.72174 - acc: 0.6105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 943  | total loss: \u001b[1m\u001b[32m1.59801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 943 | loss: 1.59801 - acc: 0.6495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 944  | total loss: \u001b[1m\u001b[32m1.77078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 944 | loss: 1.77078 - acc: 0.5917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 945  | total loss: \u001b[1m\u001b[32m1.64415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 945 | loss: 1.64415 - acc: 0.6325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 946  | total loss: \u001b[1m\u001b[32m1.81933\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 946 | loss: 1.81933 - acc: 0.5764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 947  | total loss: \u001b[1m\u001b[32m1.69020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 947 | loss: 1.69020 - acc: 0.6187 -- iter: 14/14\n",
      "--\n",
      "Training Step: 948  | total loss: \u001b[1m\u001b[32m1.57471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 948 | loss: 1.57471 - acc: 0.6569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 949  | total loss: \u001b[1m\u001b[32m1.47064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 949 | loss: 1.47064 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 950  | total loss: \u001b[1m\u001b[32m1.66075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 950 | loss: 1.66075 - acc: 0.6292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 951  | total loss: \u001b[1m\u001b[32m1.54742\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 951 | loss: 1.54742 - acc: 0.6663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 952  | total loss: \u001b[1m\u001b[32m1.69832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 952 | loss: 1.69832 - acc: 0.6068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 953  | total loss: \u001b[1m\u001b[32m1.58122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 953 | loss: 1.58122 - acc: 0.6461 -- iter: 14/14\n",
      "--\n",
      "Training Step: 954  | total loss: \u001b[1m\u001b[32m1.79360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 954 | loss: 1.79360 - acc: 0.5815 -- iter: 14/14\n",
      "--\n",
      "Training Step: 955  | total loss: \u001b[1m\u001b[32m1.66762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 955 | loss: 1.66762 - acc: 0.6234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 956  | total loss: \u001b[1m\u001b[32m1.55430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 956 | loss: 1.55430 - acc: 0.6610 -- iter: 14/14\n",
      "--\n",
      "Training Step: 957  | total loss: \u001b[1m\u001b[32m1.45159\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 957 | loss: 1.45159 - acc: 0.6949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 958  | total loss: \u001b[1m\u001b[32m1.35775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 958 | loss: 1.35775 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 959  | total loss: \u001b[1m\u001b[32m1.27131\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 959 | loss: 1.27131 - acc: 0.7529 -- iter: 14/14\n",
      "--\n",
      "Training Step: 960  | total loss: \u001b[1m\u001b[32m1.50493\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 960 | loss: 1.50493 - acc: 0.6776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 961  | total loss: \u001b[1m\u001b[32m1.40037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 961 | loss: 1.40037 - acc: 0.7098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 962  | total loss: \u001b[1m\u001b[32m1.58273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 962 | loss: 1.58273 - acc: 0.6531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 963  | total loss: \u001b[1m\u001b[32m1.46856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 963 | loss: 1.46856 - acc: 0.6878 -- iter: 14/14\n",
      "--\n",
      "Training Step: 964  | total loss: \u001b[1m\u001b[32m1.36489\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 964 | loss: 1.36489 - acc: 0.7190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 965  | total loss: \u001b[1m\u001b[32m1.27021\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 965 | loss: 1.27021 - acc: 0.7471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 966  | total loss: \u001b[1m\u001b[32m1.18320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 966 | loss: 1.18320 - acc: 0.7724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 967  | total loss: \u001b[1m\u001b[32m1.10280\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 967 | loss: 1.10280 - acc: 0.7952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 968  | total loss: \u001b[1m\u001b[32m1.02811\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 968 | loss: 1.02811 - acc: 0.8157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 969  | total loss: \u001b[1m\u001b[32m0.95843\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 969 | loss: 0.95843 - acc: 0.8341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 970  | total loss: \u001b[1m\u001b[32m1.19050\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 970 | loss: 1.19050 - acc: 0.7650 -- iter: 14/14\n",
      "--\n",
      "Training Step: 971  | total loss: \u001b[1m\u001b[32m1.10078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 971 | loss: 1.10078 - acc: 0.7885 -- iter: 14/14\n",
      "--\n",
      "Training Step: 972  | total loss: \u001b[1m\u001b[32m1.36463\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 972 | loss: 1.36463 - acc: 0.7168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 973  | total loss: \u001b[1m\u001b[32m1.25571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 973 | loss: 1.25571 - acc: 0.7451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 974  | total loss: \u001b[1m\u001b[32m1.15708\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 974 | loss: 1.15708 - acc: 0.7706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 975  | total loss: \u001b[1m\u001b[32m1.06750\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 975 | loss: 1.06750 - acc: 0.7935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 976  | total loss: \u001b[1m\u001b[32m0.98587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 976 | loss: 0.98587 - acc: 0.8142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 977  | total loss: \u001b[1m\u001b[32m0.91125\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 977 | loss: 0.91125 - acc: 0.8328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 978  | total loss: \u001b[1m\u001b[32m1.24534\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 978 | loss: 1.24534 - acc: 0.7495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 979  | total loss: \u001b[1m\u001b[32m1.14346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 979 | loss: 1.14346 - acc: 0.7745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 980  | total loss: \u001b[1m\u001b[32m1.05148\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 980 | loss: 1.05148 - acc: 0.7971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 981  | total loss: \u001b[1m\u001b[32m0.96822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 981 | loss: 0.96822 - acc: 0.8174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 982  | total loss: \u001b[1m\u001b[32m1.25911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 982 | loss: 1.25911 - acc: 0.7428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 983  | total loss: \u001b[1m\u001b[32m1.15486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 983 | loss: 1.15486 - acc: 0.7685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 984  | total loss: \u001b[1m\u001b[32m1.06121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 984 | loss: 1.06121 - acc: 0.7916 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 985  | total loss: \u001b[1m\u001b[32m0.97685\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 985 | loss: 0.97685 - acc: 0.8125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 986  | total loss: \u001b[1m\u001b[32m1.29467\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 986 | loss: 1.29467 - acc: 0.7312 -- iter: 14/14\n",
      "--\n",
      "Training Step: 987  | total loss: \u001b[1m\u001b[32m1.18737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 987 | loss: 1.18737 - acc: 0.7581 -- iter: 14/14\n",
      "--\n",
      "Training Step: 988  | total loss: \u001b[1m\u001b[32m1.47078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 988 | loss: 1.47078 - acc: 0.6894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 989  | total loss: \u001b[1m\u001b[32m1.34761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 989 | loss: 1.34761 - acc: 0.7205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 990  | total loss: \u001b[1m\u001b[32m1.62369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 990 | loss: 1.62369 - acc: 0.6484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 991  | total loss: \u001b[1m\u001b[32m1.48821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 991 | loss: 1.48821 - acc: 0.6836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 992  | total loss: \u001b[1m\u001b[32m1.36784\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 992 | loss: 1.36784 - acc: 0.7152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 993  | total loss: \u001b[1m\u001b[32m1.26061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 993 | loss: 1.26061 - acc: 0.7437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 994  | total loss: \u001b[1m\u001b[32m1.51047\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 994 | loss: 1.51047 - acc: 0.6765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 995  | total loss: \u001b[1m\u001b[32m1.39120\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 995 | loss: 1.39120 - acc: 0.7088 -- iter: 14/14\n",
      "--\n",
      "Training Step: 996  | total loss: \u001b[1m\u001b[32m1.59941\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 996 | loss: 1.59941 - acc: 0.6451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 997  | total loss: \u001b[1m\u001b[32m1.47429\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 997 | loss: 1.47429 - acc: 0.6806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 998  | total loss: \u001b[1m\u001b[32m1.73064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 998 | loss: 1.73064 - acc: 0.6125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 999  | total loss: \u001b[1m\u001b[32m1.59634\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 999 | loss: 1.59634 - acc: 0.6513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1000  | total loss: \u001b[1m\u001b[32m1.76364\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1000 | loss: 1.76364 - acc: 0.6004 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1001  | total loss: \u001b[1m\u001b[32m1.63063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1001 | loss: 1.63063 - acc: 0.6404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1002  | total loss: \u001b[1m\u001b[32m1.82684\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1002 | loss: 1.82684 - acc: 0.5835 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1003  | total loss: \u001b[1m\u001b[32m1.69243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1003 | loss: 1.69243 - acc: 0.6251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1004  | total loss: \u001b[1m\u001b[32m1.87767\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1004 | loss: 1.87767 - acc: 0.5698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1005  | total loss: \u001b[1m\u001b[32m1.74321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1005 | loss: 1.74321 - acc: 0.6128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1006  | total loss: \u001b[1m\u001b[32m1.62412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1006 | loss: 1.62412 - acc: 0.6515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1007  | total loss: \u001b[1m\u001b[32m1.51788\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1007 | loss: 1.51788 - acc: 0.6864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1008  | total loss: \u001b[1m\u001b[32m1.67134\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1008 | loss: 1.67134 - acc: 0.6249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1009  | total loss: \u001b[1m\u001b[32m1.56135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1009 | loss: 1.56135 - acc: 0.6624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1010  | total loss: \u001b[1m\u001b[32m1.46240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1010 | loss: 1.46240 - acc: 0.6961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1011  | total loss: \u001b[1m\u001b[32m1.37252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1011 | loss: 1.37252 - acc: 0.7265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1012  | total loss: \u001b[1m\u001b[32m1.58651\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1012 | loss: 1.58651 - acc: 0.6610 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1013  | total loss: \u001b[1m\u001b[32m1.48230\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1013 | loss: 1.48230 - acc: 0.6949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1014  | total loss: \u001b[1m\u001b[32m1.38740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1014 | loss: 1.38740 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1015  | total loss: \u001b[1m\u001b[32m1.30025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1015 | loss: 1.30025 - acc: 0.7529 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1016  | total loss: \u001b[1m\u001b[32m1.54672\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1016 | loss: 1.54672 - acc: 0.6776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1017  | total loss: \u001b[1m\u001b[32m1.44065\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1017 | loss: 1.44065 - acc: 0.7098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1018  | total loss: \u001b[1m\u001b[32m1.58917\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1018 | loss: 1.58917 - acc: 0.6603 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1019  | total loss: \u001b[1m\u001b[32m1.47713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1019 | loss: 1.47713 - acc: 0.6943 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1020  | total loss: \u001b[1m\u001b[32m1.37528\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1020 | loss: 1.37528 - acc: 0.7248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1021  | total loss: \u001b[1m\u001b[32m1.28212\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1021 | loss: 1.28212 - acc: 0.7523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1022  | total loss: \u001b[1m\u001b[32m1.48020\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1022 | loss: 1.48020 - acc: 0.6914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1023  | total loss: \u001b[1m\u001b[32m1.37396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1023 | loss: 1.37396 - acc: 0.7223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1024  | total loss: \u001b[1m\u001b[32m1.62401\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1024 | loss: 1.62401 - acc: 0.6500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1025  | total loss: \u001b[1m\u001b[32m1.50243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1025 | loss: 1.50243 - acc: 0.6850 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1026  | total loss: \u001b[1m\u001b[32m1.71401\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1026 | loss: 1.71401 - acc: 0.6237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1027  | total loss: \u001b[1m\u001b[32m1.58382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1027 | loss: 1.58382 - acc: 0.6613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1028  | total loss: \u001b[1m\u001b[32m1.80856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1028 | loss: 1.80856 - acc: 0.5952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1029  | total loss: \u001b[1m\u001b[32m1.67053\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1029 | loss: 1.67053 - acc: 0.6357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1030  | total loss: \u001b[1m\u001b[32m1.54706\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1030 | loss: 1.54706 - acc: 0.6721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1031  | total loss: \u001b[1m\u001b[32m1.43602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1031 | loss: 1.43602 - acc: 0.7049 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1032  | total loss: \u001b[1m\u001b[32m1.33557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1032 | loss: 1.33557 - acc: 0.7344 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1033  | total loss: \u001b[1m\u001b[32m1.24409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1033 | loss: 1.24409 - acc: 0.7610 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1034  | total loss: \u001b[1m\u001b[32m1.16025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1034 | loss: 1.16025 - acc: 0.7849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1035  | total loss: \u001b[1m\u001b[32m1.08291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1035 | loss: 1.08291 - acc: 0.8064 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1036  | total loss: \u001b[1m\u001b[32m1.01114\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1036 | loss: 1.01114 - acc: 0.8257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1037  | total loss: \u001b[1m\u001b[32m0.94420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1037 | loss: 0.94420 - acc: 0.8432 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1038  | total loss: \u001b[1m\u001b[32m0.88150\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1038 | loss: 0.88150 - acc: 0.8588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1039  | total loss: \u001b[1m\u001b[32m0.82258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1039 | loss: 0.82258 - acc: 0.8730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1040  | total loss: \u001b[1m\u001b[32m1.17647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1040 | loss: 1.17647 - acc: 0.7857 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1041  | total loss: \u001b[1m\u001b[32m1.08459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1041 | loss: 1.08459 - acc: 0.8071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1042  | total loss: \u001b[1m\u001b[32m1.41226\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1042 | loss: 1.41226 - acc: 0.7264 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1043  | total loss: \u001b[1m\u001b[32m1.29570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1043 | loss: 1.29570 - acc: 0.7537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1044  | total loss: \u001b[1m\u001b[32m1.19057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1044 | loss: 1.19057 - acc: 0.7784 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1045  | total loss: \u001b[1m\u001b[32m1.09550\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1045 | loss: 1.09550 - acc: 0.8005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1046  | total loss: \u001b[1m\u001b[32m1.38411\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1046 | loss: 1.38411 - acc: 0.7276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1047  | total loss: \u001b[1m\u001b[32m1.26939\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1047 | loss: 1.26939 - acc: 0.7549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1048  | total loss: \u001b[1m\u001b[32m1.52337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1048 | loss: 1.52337 - acc: 0.6937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1049  | total loss: \u001b[1m\u001b[32m1.39586\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1049 | loss: 1.39586 - acc: 0.7243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1050  | total loss: \u001b[1m\u001b[32m1.28180\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1050 | loss: 1.28180 - acc: 0.7519 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1051  | total loss: \u001b[1m\u001b[32m1.17949\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1051 | loss: 1.17949 - acc: 0.7767 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1052  | total loss: \u001b[1m\u001b[32m1.08743\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1052 | loss: 1.08743 - acc: 0.7990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1053  | total loss: \u001b[1m\u001b[32m1.00430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1053 | loss: 1.00430 - acc: 0.8191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1054  | total loss: \u001b[1m\u001b[32m0.92894\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1054 | loss: 0.92894 - acc: 0.8372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1055  | total loss: \u001b[1m\u001b[32m0.86034\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1055 | loss: 0.86034 - acc: 0.8535 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1056  | total loss: \u001b[1m\u001b[32m0.79764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1056 | loss: 0.79764 - acc: 0.8681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1057  | total loss: \u001b[1m\u001b[32m0.74011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1057 | loss: 0.74011 - acc: 0.8813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1058  | total loss: \u001b[1m\u001b[32m0.68714\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1058 | loss: 0.68714 - acc: 0.8932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1059  | total loss: \u001b[1m\u001b[32m0.63821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1059 | loss: 0.63821 - acc: 0.9039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1060  | total loss: \u001b[1m\u001b[32m0.99890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1060 | loss: 0.99890 - acc: 0.8135 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1061  | total loss: \u001b[1m\u001b[32m0.91734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1061 | loss: 0.91734 - acc: 0.8321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1062  | total loss: \u001b[1m\u001b[32m1.30351\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1062 | loss: 1.30351 - acc: 0.7489 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1063  | total loss: \u001b[1m\u001b[32m1.19185\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1063 | loss: 1.19185 - acc: 0.7740 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1064  | total loss: \u001b[1m\u001b[32m1.09183\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1064 | loss: 1.09183 - acc: 0.7966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1065  | total loss: \u001b[1m\u001b[32m1.00205\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1065 | loss: 1.00205 - acc: 0.8170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1066  | total loss: \u001b[1m\u001b[32m1.31720\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1066 | loss: 1.31720 - acc: 0.7424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1067  | total loss: \u001b[1m\u001b[32m1.20581\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1067 | loss: 1.20581 - acc: 0.7682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1068  | total loss: \u001b[1m\u001b[32m1.49628\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1068 | loss: 1.49628 - acc: 0.6985 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1069  | total loss: \u001b[1m\u001b[32m1.36924\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1069 | loss: 1.36924 - acc: 0.7286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1070  | total loss: \u001b[1m\u001b[32m1.67732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1070 | loss: 1.67732 - acc: 0.6558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1071  | total loss: \u001b[1m\u001b[32m1.53584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1071 | loss: 1.53584 - acc: 0.6902 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1072  | total loss: \u001b[1m\u001b[32m1.76335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1072 | loss: 1.76335 - acc: 0.6283 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1073  | total loss: \u001b[1m\u001b[32m1.61805\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1073 | loss: 1.61805 - acc: 0.6655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1074  | total loss: \u001b[1m\u001b[32m1.86630\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1074 | loss: 1.86630 - acc: 0.5989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1075  | total loss: \u001b[1m\u001b[32m1.71643\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1075 | loss: 1.71643 - acc: 0.6390 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1076  | total loss: \u001b[1m\u001b[32m1.87919\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1076 | loss: 1.87919 - acc: 0.5894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1077  | total loss: \u001b[1m\u001b[32m1.73430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1077 | loss: 1.73430 - acc: 0.6305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1078  | total loss: \u001b[1m\u001b[32m1.89269\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1078 | loss: 1.89269 - acc: 0.5746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1079  | total loss: \u001b[1m\u001b[32m1.75272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1079 | loss: 1.75272 - acc: 0.6171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1080  | total loss: \u001b[1m\u001b[32m1.92774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1080 | loss: 1.92774 - acc: 0.5626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1081  | total loss: \u001b[1m\u001b[32m1.79030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1081 | loss: 1.79030 - acc: 0.6063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1082  | total loss: \u001b[1m\u001b[32m1.95625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1082 | loss: 1.95625 - acc: 0.5457 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1083  | total loss: \u001b[1m\u001b[32m1.82153\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1083 | loss: 1.82153 - acc: 0.5911 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1084  | total loss: \u001b[1m\u001b[32m1.70233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1084 | loss: 1.70233 - acc: 0.6320 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1085  | total loss: \u001b[1m\u001b[32m1.59600\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1085 | loss: 1.59600 - acc: 0.6688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1086  | total loss: \u001b[1m\u001b[32m1.50024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1086 | loss: 1.50024 - acc: 0.7019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1087  | total loss: \u001b[1m\u001b[32m1.41307\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1087 | loss: 1.41307 - acc: 0.7317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1088  | total loss: \u001b[1m\u001b[32m1.60080\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1088 | loss: 1.60080 - acc: 0.6657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1089  | total loss: \u001b[1m\u001b[32m1.50124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1089 | loss: 1.50124 - acc: 0.6991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1090  | total loss: \u001b[1m\u001b[32m1.41028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1090 | loss: 1.41028 - acc: 0.7292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1091  | total loss: \u001b[1m\u001b[32m1.32639\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1091 | loss: 1.32639 - acc: 0.7563 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1092  | total loss: \u001b[1m\u001b[32m1.24832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1092 | loss: 1.24832 - acc: 0.7807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1093  | total loss: \u001b[1m\u001b[32m1.17505\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1093 | loss: 1.17505 - acc: 0.8026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1094  | total loss: \u001b[1m\u001b[32m1.10581\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1094 | loss: 1.10581 - acc: 0.8223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1095  | total loss: \u001b[1m\u001b[32m1.03999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1095 | loss: 1.03999 - acc: 0.8401 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1096  | total loss: \u001b[1m\u001b[32m0.97716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1096 | loss: 0.97716 - acc: 0.8561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1097  | total loss: \u001b[1m\u001b[32m0.91703\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1097 | loss: 0.91703 - acc: 0.8705 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1098  | total loss: \u001b[1m\u001b[32m0.85941\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1098 | loss: 0.85941 - acc: 0.8834 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1099  | total loss: \u001b[1m\u001b[32m0.80419\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1099 | loss: 0.80419 - acc: 0.8951 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1100  | total loss: \u001b[1m\u001b[32m1.09381\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1100 | loss: 1.09381 - acc: 0.8127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1101  | total loss: \u001b[1m\u001b[32m1.01022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1101 | loss: 1.01022 - acc: 0.8315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1102  | total loss: \u001b[1m\u001b[32m0.93321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1102 | loss: 0.93321 - acc: 0.8483 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1103  | total loss: \u001b[1m\u001b[32m0.86214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1103 | loss: 0.86214 - acc: 0.8635 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1104  | total loss: \u001b[1m\u001b[32m1.19696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1104 | loss: 1.19696 - acc: 0.7843 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1105  | total loss: \u001b[1m\u001b[32m1.09718\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1105 | loss: 1.09718 - acc: 0.8058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1106  | total loss: \u001b[1m\u001b[32m1.00667\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1106 | loss: 1.00667 - acc: 0.8253 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1107  | total loss: \u001b[1m\u001b[32m0.92442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1107 | loss: 0.92442 - acc: 0.8427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1108  | total loss: \u001b[1m\u001b[32m1.28885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1108 | loss: 1.28885 - acc: 0.7656 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1109  | total loss: \u001b[1m\u001b[32m1.17766\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1109 | loss: 1.17766 - acc: 0.7890 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1110  | total loss: \u001b[1m\u001b[32m1.42570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1110 | loss: 1.42570 - acc: 0.7244 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1111  | total loss: \u001b[1m\u001b[32m1.30152\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1111 | loss: 1.30152 - acc: 0.7520 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1112  | total loss: \u001b[1m\u001b[32m1.57604\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1112 | loss: 1.57604 - acc: 0.6911 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1113  | total loss: \u001b[1m\u001b[32m1.43874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1113 | loss: 1.43874 - acc: 0.7220 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1114  | total loss: \u001b[1m\u001b[32m1.70358\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1114 | loss: 1.70358 - acc: 0.6569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1115  | total loss: \u001b[1m\u001b[32m1.55669\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1115 | loss: 1.55669 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1116  | total loss: \u001b[1m\u001b[32m1.42618\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1116 | loss: 1.42618 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1117  | total loss: \u001b[1m\u001b[32m1.31004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1117 | loss: 1.31004 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1118  | total loss: \u001b[1m\u001b[32m1.20642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1118 | loss: 1.20642 - acc: 0.7749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1119  | total loss: \u001b[1m\u001b[32m1.11366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1119 | loss: 1.11366 - acc: 0.7974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1120  | total loss: \u001b[1m\u001b[32m1.03029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1120 | loss: 1.03029 - acc: 0.8177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1121  | total loss: \u001b[1m\u001b[32m0.95501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1121 | loss: 0.95501 - acc: 0.8359 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1122  | total loss: \u001b[1m\u001b[32m1.22269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1122 | loss: 1.22269 - acc: 0.7666 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1123  | total loss: \u001b[1m\u001b[32m1.12806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1123 | loss: 1.12806 - acc: 0.7899 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1124  | total loss: \u001b[1m\u001b[32m1.41617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1124 | loss: 1.41617 - acc: 0.7181 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1125  | total loss: \u001b[1m\u001b[32m1.30339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1125 | loss: 1.30339 - acc: 0.7463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1126  | total loss: \u001b[1m\u001b[32m1.55690\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1126 | loss: 1.55690 - acc: 0.6716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1127  | total loss: \u001b[1m\u001b[32m1.43261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1127 | loss: 1.43261 - acc: 0.7045 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1128  | total loss: \u001b[1m\u001b[32m1.65528\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1128 | loss: 1.65528 - acc: 0.6412 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1129  | total loss: \u001b[1m\u001b[32m1.52479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1129 | loss: 1.52479 - acc: 0.6771 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1130  | total loss: \u001b[1m\u001b[32m1.73725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1130 | loss: 1.73725 - acc: 0.6165 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1131  | total loss: \u001b[1m\u001b[32m1.60287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1131 | loss: 1.60287 - acc: 0.6548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1132  | total loss: \u001b[1m\u001b[32m1.82085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1132 | loss: 1.82085 - acc: 0.5894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1133  | total loss: \u001b[1m\u001b[32m1.68308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1133 | loss: 1.68308 - acc: 0.6304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1134  | total loss: \u001b[1m\u001b[32m1.56132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1134 | loss: 1.56132 - acc: 0.6674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1135  | total loss: \u001b[1m\u001b[32m1.45313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1135 | loss: 1.45313 - acc: 0.7006 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1136  | total loss: \u001b[1m\u001b[32m1.66897\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1136 | loss: 1.66897 - acc: 0.6306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1137  | total loss: \u001b[1m\u001b[32m1.55230\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1137 | loss: 1.55230 - acc: 0.6675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1138  | total loss: \u001b[1m\u001b[32m1.73096\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1138 | loss: 1.73096 - acc: 0.6079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1139  | total loss: \u001b[1m\u001b[32m1.61074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1139 | loss: 1.61074 - acc: 0.6471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1140  | total loss: \u001b[1m\u001b[32m1.79429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1140 | loss: 1.79429 - acc: 0.5896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1141  | total loss: \u001b[1m\u001b[32m1.67032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1141 | loss: 1.67032 - acc: 0.6306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1142  | total loss: \u001b[1m\u001b[32m1.79440\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1142 | loss: 1.79440 - acc: 0.5890 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1143  | total loss: \u001b[1m\u001b[32m1.67256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1143 | loss: 1.67256 - acc: 0.6301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1144  | total loss: \u001b[1m\u001b[32m1.82696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1144 | loss: 1.82696 - acc: 0.5742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1145  | total loss: \u001b[1m\u001b[32m1.70352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1145 | loss: 1.70352 - acc: 0.6168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1146  | total loss: \u001b[1m\u001b[32m1.88058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1146 | loss: 1.88058 - acc: 0.5551 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1147  | total loss: \u001b[1m\u001b[32m1.75345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1147 | loss: 1.75345 - acc: 0.5996 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1148  | total loss: \u001b[1m\u001b[32m1.89373\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1148 | loss: 1.89373 - acc: 0.5468 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1149  | total loss: \u001b[1m\u001b[32m1.76707\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1149 | loss: 1.76707 - acc: 0.5921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1150  | total loss: \u001b[1m\u001b[32m1.92093\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1150 | loss: 1.92093 - acc: 0.5400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1151  | total loss: \u001b[1m\u001b[32m1.79325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1151 | loss: 1.79325 - acc: 0.5860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1152  | total loss: \u001b[1m\u001b[32m1.67865\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1152 | loss: 1.67865 - acc: 0.6274 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1153  | total loss: \u001b[1m\u001b[32m1.57485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1153 | loss: 1.57485 - acc: 0.6647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1154  | total loss: \u001b[1m\u001b[32m1.72560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1154 | loss: 1.72560 - acc: 0.6054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1155  | total loss: \u001b[1m\u001b[32m1.61522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1155 | loss: 1.61522 - acc: 0.6448 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1156  | total loss: \u001b[1m\u001b[32m1.76350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1156 | loss: 1.76350 - acc: 0.5875 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1157  | total loss: \u001b[1m\u001b[32m1.64792\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1157 | loss: 1.64792 - acc: 0.6287 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1158  | total loss: \u001b[1m\u001b[32m1.79194\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1158 | loss: 1.79194 - acc: 0.5730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1159  | total loss: \u001b[1m\u001b[32m1.67248\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1159 | loss: 1.67248 - acc: 0.6157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1160  | total loss: \u001b[1m\u001b[32m1.56413\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1160 | loss: 1.56413 - acc: 0.6541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1161  | total loss: \u001b[1m\u001b[32m1.46502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1161 | loss: 1.46502 - acc: 0.6887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1162  | total loss: \u001b[1m\u001b[32m1.37360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1162 | loss: 1.37360 - acc: 0.7198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1163  | total loss: \u001b[1m\u001b[32m1.28858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1163 | loss: 1.28858 - acc: 0.7479 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1164  | total loss: \u001b[1m\u001b[32m1.41760\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1164 | loss: 1.41760 - acc: 0.7016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1165  | total loss: \u001b[1m\u001b[32m1.32305\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1165 | loss: 1.32305 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1166  | total loss: \u001b[1m\u001b[32m1.54583\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1166 | loss: 1.54583 - acc: 0.6726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1167  | total loss: \u001b[1m\u001b[32m1.43483\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1167 | loss: 1.43483 - acc: 0.7054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1168  | total loss: \u001b[1m\u001b[32m1.65128\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1168 | loss: 1.65128 - acc: 0.6420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1169  | total loss: \u001b[1m\u001b[32m1.52767\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1169 | loss: 1.52767 - acc: 0.6778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1170  | total loss: \u001b[1m\u001b[32m1.76728\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1170 | loss: 1.76728 - acc: 0.6100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1171  | total loss: \u001b[1m\u001b[32m1.63154\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1171 | loss: 1.63154 - acc: 0.6490 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1172  | total loss: \u001b[1m\u001b[32m1.82831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1172 | loss: 1.82831 - acc: 0.5912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1173  | total loss: \u001b[1m\u001b[32m1.68715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1173 | loss: 1.68715 - acc: 0.6321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1174  | total loss: \u001b[1m\u001b[32m1.86951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1174 | loss: 1.86951 - acc: 0.5760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1175  | total loss: \u001b[1m\u001b[32m1.72575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1175 | loss: 1.72575 - acc: 0.6184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1176  | total loss: \u001b[1m\u001b[32m1.59696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1176 | loss: 1.59696 - acc: 0.6566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1177  | total loss: \u001b[1m\u001b[32m1.48102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1177 | loss: 1.48102 - acc: 0.6909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1178  | total loss: \u001b[1m\u001b[32m1.72561\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1178 | loss: 1.72561 - acc: 0.6218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1179  | total loss: \u001b[1m\u001b[32m1.59680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1179 | loss: 1.59680 - acc: 0.6597 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1180  | total loss: \u001b[1m\u001b[32m1.74817\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1180 | loss: 1.74817 - acc: 0.6151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1181  | total loss: \u001b[1m\u001b[32m1.61777\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1181 | loss: 1.61777 - acc: 0.6536 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1182  | total loss: \u001b[1m\u001b[32m1.81869\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1182 | loss: 1.81869 - acc: 0.5882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1183  | total loss: \u001b[1m\u001b[32m1.68241\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1183 | loss: 1.68241 - acc: 0.6294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1184  | total loss: \u001b[1m\u001b[32m1.88785\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1184 | loss: 1.88785 - acc: 0.5665 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1185  | total loss: \u001b[1m\u001b[32m1.74659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1185 | loss: 1.74659 - acc: 0.6098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1186  | total loss: \u001b[1m\u001b[32m1.91023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1186 | loss: 1.91023 - acc: 0.5560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1187  | total loss: \u001b[1m\u001b[32m1.76906\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1187 | loss: 1.76906 - acc: 0.6004 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1188  | total loss: \u001b[1m\u001b[32m1.97523\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1188 | loss: 1.97523 - acc: 0.5404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1189  | total loss: \u001b[1m\u001b[32m1.83018\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1189 | loss: 1.83018 - acc: 0.5863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1190  | total loss: \u001b[1m\u001b[32m1.70061\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1190 | loss: 1.70061 - acc: 0.6277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1191  | total loss: \u001b[1m\u001b[32m1.58416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1191 | loss: 1.58416 - acc: 0.6649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1192  | total loss: \u001b[1m\u001b[32m1.47878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1192 | loss: 1.47878 - acc: 0.6984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1193  | total loss: \u001b[1m\u001b[32m1.38271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1193 | loss: 1.38271 - acc: 0.7286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1194  | total loss: \u001b[1m\u001b[32m1.29448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1194 | loss: 1.29448 - acc: 0.7557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1195  | total loss: \u001b[1m\u001b[32m1.21284\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1195 | loss: 1.21284 - acc: 0.7802 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1196  | total loss: \u001b[1m\u001b[32m1.44313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1196 | loss: 1.44313 - acc: 0.7093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1197  | total loss: \u001b[1m\u001b[32m1.34282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1197 | loss: 1.34282 - acc: 0.7384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1198  | total loss: \u001b[1m\u001b[32m1.25088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1198 | loss: 1.25088 - acc: 0.7645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1199  | total loss: \u001b[1m\u001b[32m1.16615\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1199 | loss: 1.16615 - acc: 0.7881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1200  | total loss: \u001b[1m\u001b[32m1.45913\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1200 | loss: 1.45913 - acc: 0.7093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1201  | total loss: \u001b[1m\u001b[32m1.35058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1201 | loss: 1.35058 - acc: 0.7383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1202  | total loss: \u001b[1m\u001b[32m1.58863\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1202 | loss: 1.58863 - acc: 0.6645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1203  | total loss: \u001b[1m\u001b[32m1.46608\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1203 | loss: 1.46608 - acc: 0.6980 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1204  | total loss: \u001b[1m\u001b[32m1.67417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1204 | loss: 1.67417 - acc: 0.6354 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1205  | total loss: \u001b[1m\u001b[32m1.54339\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1205 | loss: 1.54339 - acc: 0.6718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1206  | total loss: \u001b[1m\u001b[32m1.73767\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1206 | loss: 1.73767 - acc: 0.6189 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1207  | total loss: \u001b[1m\u001b[32m1.60185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1207 | loss: 1.60185 - acc: 0.6571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1208  | total loss: \u001b[1m\u001b[32m1.79731\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1208 | loss: 1.79731 - acc: 0.5985 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1209  | total loss: \u001b[1m\u001b[32m1.65776\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1209 | loss: 1.65776 - acc: 0.6386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1210  | total loss: \u001b[1m\u001b[32m1.81742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1210 | loss: 1.81742 - acc: 0.5819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1211  | total loss: \u001b[1m\u001b[32m1.67882\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1211 | loss: 1.67882 - acc: 0.6237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1212  | total loss: \u001b[1m\u001b[32m1.78961\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1212 | loss: 1.78961 - acc: 0.5828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1213  | total loss: \u001b[1m\u001b[32m1.65691\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1213 | loss: 1.65691 - acc: 0.6245 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1214  | total loss: \u001b[1m\u001b[32m1.83521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1214 | loss: 1.83521 - acc: 0.5692 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1215  | total loss: \u001b[1m\u001b[32m1.70106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1215 | loss: 1.70106 - acc: 0.6123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1216  | total loss: \u001b[1m\u001b[32m1.58148\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1216 | loss: 1.58148 - acc: 0.6511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1217  | total loss: \u001b[1m\u001b[32m1.47421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1217 | loss: 1.47421 - acc: 0.6859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1218  | total loss: \u001b[1m\u001b[32m1.68194\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1218 | loss: 1.68194 - acc: 0.6245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1219  | total loss: \u001b[1m\u001b[32m1.56496\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1219 | loss: 1.56496 - acc: 0.6620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1220  | total loss: \u001b[1m\u001b[32m1.69888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1220 | loss: 1.69888 - acc: 0.6173 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1221  | total loss: \u001b[1m\u001b[32m1.58084\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1221 | loss: 1.58084 - acc: 0.6555 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1222  | total loss: \u001b[1m\u001b[32m1.74022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1222 | loss: 1.74022 - acc: 0.6043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1223  | total loss: \u001b[1m\u001b[32m1.61885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1223 | loss: 1.61885 - acc: 0.6438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1224  | total loss: \u001b[1m\u001b[32m1.50972\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1224 | loss: 1.50972 - acc: 0.6795 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1225  | total loss: \u001b[1m\u001b[32m1.41087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1225 | loss: 1.41087 - acc: 0.7115 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1226  | total loss: \u001b[1m\u001b[32m1.32064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1226 | loss: 1.32064 - acc: 0.7404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1227  | total loss: \u001b[1m\u001b[32m1.23762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1227 | loss: 1.23762 - acc: 0.7663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1228  | total loss: \u001b[1m\u001b[32m1.50267\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1228 | loss: 1.50267 - acc: 0.6897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1229  | total loss: \u001b[1m\u001b[32m1.39836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1229 | loss: 1.39836 - acc: 0.7207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1230  | total loss: \u001b[1m\u001b[32m1.30312\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1230 | loss: 1.30312 - acc: 0.7487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1231  | total loss: \u001b[1m\u001b[32m1.21561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1231 | loss: 1.21561 - acc: 0.7738 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1232  | total loss: \u001b[1m\u001b[32m1.13469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1232 | loss: 1.13469 - acc: 0.7964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1233  | total loss: \u001b[1m\u001b[32m1.05945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1233 | loss: 1.05945 - acc: 0.8168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1234  | total loss: \u001b[1m\u001b[32m0.98914\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1234 | loss: 0.98914 - acc: 0.8351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1235  | total loss: \u001b[1m\u001b[32m0.92318\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1235 | loss: 0.92318 - acc: 0.8516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1236  | total loss: \u001b[1m\u001b[32m0.86112\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1236 | loss: 0.86112 - acc: 0.8664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1237  | total loss: \u001b[1m\u001b[32m0.80262\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1237 | loss: 0.80262 - acc: 0.8798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1238  | total loss: \u001b[1m\u001b[32m0.74743\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1238 | loss: 0.74743 - acc: 0.8918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1239  | total loss: \u001b[1m\u001b[32m0.69535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1239 | loss: 0.69535 - acc: 0.9026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1240  | total loss: \u001b[1m\u001b[32m0.64623\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1240 | loss: 0.64623 - acc: 0.9124 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1241  | total loss: \u001b[1m\u001b[32m0.59996\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1241 | loss: 0.59996 - acc: 0.9211 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1242  | total loss: \u001b[1m\u001b[32m1.04260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1242 | loss: 1.04260 - acc: 0.8290 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1243  | total loss: \u001b[1m\u001b[32m0.95408\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1243 | loss: 0.95408 - acc: 0.8461 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1244  | total loss: \u001b[1m\u001b[32m1.28706\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1244 | loss: 1.28706 - acc: 0.7686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1245  | total loss: \u001b[1m\u001b[32m1.17344\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1245 | loss: 1.17344 - acc: 0.7918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1246  | total loss: \u001b[1m\u001b[32m1.44953\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1246 | loss: 1.44953 - acc: 0.7269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1247  | total loss: \u001b[1m\u001b[32m1.32037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1247 | loss: 1.32037 - acc: 0.7542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1248  | total loss: \u001b[1m\u001b[32m1.62254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1248 | loss: 1.62254 - acc: 0.6859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1249  | total loss: \u001b[1m\u001b[32m1.47800\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1249 | loss: 1.47800 - acc: 0.7173 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1250  | total loss: \u001b[1m\u001b[32m1.76245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1250 | loss: 1.76245 - acc: 0.6527 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1251  | total loss: \u001b[1m\u001b[32m1.60697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1251 | loss: 1.60697 - acc: 0.6875 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1252  | total loss: \u001b[1m\u001b[32m1.46869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1252 | loss: 1.46869 - acc: 0.7187 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1253  | total loss: \u001b[1m\u001b[32m1.34555\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1253 | loss: 1.34555 - acc: 0.7468 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1254  | total loss: \u001b[1m\u001b[32m1.23570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1254 | loss: 1.23570 - acc: 0.7722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1255  | total loss: \u001b[1m\u001b[32m1.13744\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1255 | loss: 1.13744 - acc: 0.7949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1256  | total loss: \u001b[1m\u001b[32m1.39031\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1256 | loss: 1.39031 - acc: 0.7297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1257  | total loss: \u001b[1m\u001b[32m1.27797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1257 | loss: 1.27797 - acc: 0.7568 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1258  | total loss: \u001b[1m\u001b[32m1.48582\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1258 | loss: 1.48582 - acc: 0.7025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1259  | total loss: \u001b[1m\u001b[32m1.36613\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1259 | loss: 1.36613 - acc: 0.7323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1260  | total loss: \u001b[1m\u001b[32m1.25946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1260 | loss: 1.25946 - acc: 0.7590 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1261  | total loss: \u001b[1m\u001b[32m1.16407\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1261 | loss: 1.16407 - acc: 0.7831 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1262  | total loss: \u001b[1m\u001b[32m1.07843\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1262 | loss: 1.07843 - acc: 0.8048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1263  | total loss: \u001b[1m\u001b[32m1.00119\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1263 | loss: 1.00119 - acc: 0.8243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1264  | total loss: \u001b[1m\u001b[32m1.23912\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1264 | loss: 1.23912 - acc: 0.7562 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1265  | total loss: \u001b[1m\u001b[32m1.14558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1265 | loss: 1.14558 - acc: 0.7806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1266  | total loss: \u001b[1m\u001b[32m1.42538\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1266 | loss: 1.42538 - acc: 0.7097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1267  | total loss: \u001b[1m\u001b[32m1.31410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1267 | loss: 1.31410 - acc: 0.7387 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1268  | total loss: \u001b[1m\u001b[32m1.54108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1268 | loss: 1.54108 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1269  | total loss: \u001b[1m\u001b[32m1.42024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1269 | loss: 1.42024 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1270  | total loss: \u001b[1m\u001b[32m1.31247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1270 | loss: 1.31247 - acc: 0.7343 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1271  | total loss: \u001b[1m\u001b[32m1.21595\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1271 | loss: 1.21595 - acc: 0.7609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1272  | total loss: \u001b[1m\u001b[32m1.12909\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1272 | loss: 1.12909 - acc: 0.7848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1273  | total loss: \u001b[1m\u001b[32m1.05050\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1273 | loss: 1.05050 - acc: 0.8063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1274  | total loss: \u001b[1m\u001b[32m1.28748\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1274 | loss: 1.28748 - acc: 0.7400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1275  | total loss: \u001b[1m\u001b[32m1.19243\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1275 | loss: 1.19243 - acc: 0.7660 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1276  | total loss: \u001b[1m\u001b[32m1.10664\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1276 | loss: 1.10664 - acc: 0.7894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1277  | total loss: \u001b[1m\u001b[32m1.02880\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1277 | loss: 1.02880 - acc: 0.8104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1278  | total loss: \u001b[1m\u001b[32m1.32714\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1278 | loss: 1.32714 - acc: 0.7294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1279  | total loss: \u001b[1m\u001b[32m1.22655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1279 | loss: 1.22655 - acc: 0.7564 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1280  | total loss: \u001b[1m\u001b[32m1.50778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1280 | loss: 1.50778 - acc: 0.6808 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1281  | total loss: \u001b[1m\u001b[32m1.38986\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1281 | loss: 1.38986 - acc: 0.7127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1282  | total loss: \u001b[1m\u001b[32m1.28415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1282 | loss: 1.28415 - acc: 0.7414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1283  | total loss: \u001b[1m\u001b[32m1.18899\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1283 | loss: 1.18899 - acc: 0.7673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1284  | total loss: \u001b[1m\u001b[32m1.10292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1284 | loss: 1.10292 - acc: 0.7906 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1285  | total loss: \u001b[1m\u001b[32m1.02466\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1285 | loss: 1.02466 - acc: 0.8115 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1286  | total loss: \u001b[1m\u001b[32m0.95314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1286 | loss: 0.95314 - acc: 0.8304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1287  | total loss: \u001b[1m\u001b[32m0.88745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1287 | loss: 0.88745 - acc: 0.8473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1288  | total loss: \u001b[1m\u001b[32m0.82683\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1288 | loss: 0.82683 - acc: 0.8626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1289  | total loss: \u001b[1m\u001b[32m0.77064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1289 | loss: 0.77064 - acc: 0.8763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1290  | total loss: \u001b[1m\u001b[32m0.71837\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1290 | loss: 0.71837 - acc: 0.8887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1291  | total loss: \u001b[1m\u001b[32m0.66960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1291 | loss: 0.66960 - acc: 0.8998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1292  | total loss: \u001b[1m\u001b[32m0.62399\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1292 | loss: 0.62399 - acc: 0.9098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1293  | total loss: \u001b[1m\u001b[32m0.58127\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1293 | loss: 0.58127 - acc: 0.9189 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1294  | total loss: \u001b[1m\u001b[32m0.92783\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1294 | loss: 0.92783 - acc: 0.8341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1295  | total loss: \u001b[1m\u001b[32m0.85258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1295 | loss: 0.85258 - acc: 0.8507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1296  | total loss: \u001b[1m\u001b[32m1.20643\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1296 | loss: 1.20643 - acc: 0.7728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1297  | total loss: \u001b[1m\u001b[32m1.10298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1297 | loss: 1.10298 - acc: 0.7955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1298  | total loss: \u001b[1m\u001b[32m1.42878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1298 | loss: 1.42878 - acc: 0.7231 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1299  | total loss: \u001b[1m\u001b[32m1.30421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1299 | loss: 1.30421 - acc: 0.7508 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1300  | total loss: \u001b[1m\u001b[32m1.60253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1300 | loss: 1.60253 - acc: 0.6828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1301  | total loss: \u001b[1m\u001b[32m1.46308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1301 | loss: 1.46308 - acc: 0.7146 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1302  | total loss: \u001b[1m\u001b[32m1.73280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1302 | loss: 1.73280 - acc: 0.6503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1303  | total loss: \u001b[1m\u001b[32m1.58409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1303 | loss: 1.58409 - acc: 0.6852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1304  | total loss: \u001b[1m\u001b[32m1.78875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1304 | loss: 1.78875 - acc: 0.6310 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1305  | total loss: \u001b[1m\u001b[32m1.63924\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1305 | loss: 1.63924 - acc: 0.6679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1306  | total loss: \u001b[1m\u001b[32m1.80576\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1306 | loss: 1.80576 - acc: 0.6225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1307  | total loss: \u001b[1m\u001b[32m1.66005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1307 | loss: 1.66005 - acc: 0.6603 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1308  | total loss: \u001b[1m\u001b[32m1.78261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1308 | loss: 1.78261 - acc: 0.6228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1309  | total loss: \u001b[1m\u001b[32m1.64482\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1309 | loss: 1.64482 - acc: 0.6605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1310  | total loss: \u001b[1m\u001b[32m1.52314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1310 | loss: 1.52314 - acc: 0.6945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1311  | total loss: \u001b[1m\u001b[32m1.41520\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1311 | loss: 1.41520 - acc: 0.7250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1312  | total loss: \u001b[1m\u001b[32m1.61296\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1312 | loss: 1.61296 - acc: 0.6597 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1313  | total loss: \u001b[1m\u001b[32m1.49856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1313 | loss: 1.49856 - acc: 0.6937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1314  | total loss: \u001b[1m\u001b[32m1.67000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1314 | loss: 1.67000 - acc: 0.6386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1315  | total loss: \u001b[1m\u001b[32m1.55247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1315 | loss: 1.55247 - acc: 0.6748 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1316  | total loss: \u001b[1m\u001b[32m1.75303\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1316 | loss: 1.75303 - acc: 0.6073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1317  | total loss: \u001b[1m\u001b[32m1.62997\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1317 | loss: 1.62997 - acc: 0.6466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1318  | total loss: \u001b[1m\u001b[32m1.52026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1318 | loss: 1.52026 - acc: 0.6819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1319  | total loss: \u001b[1m\u001b[32m1.42170\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1319 | loss: 1.42170 - acc: 0.7137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1320  | total loss: \u001b[1m\u001b[32m1.64105\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1320 | loss: 1.64105 - acc: 0.6423 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1321  | total loss: \u001b[1m\u001b[32m1.53047\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1321 | loss: 1.53047 - acc: 0.6781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1322  | total loss: \u001b[1m\u001b[32m1.43078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1322 | loss: 1.43078 - acc: 0.7103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1323  | total loss: \u001b[1m\u001b[32m1.34013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1323 | loss: 1.34013 - acc: 0.7393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1324  | total loss: \u001b[1m\u001b[32m1.25699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1324 | loss: 1.25699 - acc: 0.7653 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1325  | total loss: \u001b[1m\u001b[32m1.18007\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1325 | loss: 1.18007 - acc: 0.7888 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1326  | total loss: \u001b[1m\u001b[32m1.10832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1326 | loss: 1.10832 - acc: 0.8099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1327  | total loss: \u001b[1m\u001b[32m1.04092\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1327 | loss: 1.04092 - acc: 0.8289 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1328  | total loss: \u001b[1m\u001b[32m0.97722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1328 | loss: 0.97722 - acc: 0.8460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1329  | total loss: \u001b[1m\u001b[32m0.91677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1329 | loss: 0.91677 - acc: 0.8614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1330  | total loss: \u001b[1m\u001b[32m0.85920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1330 | loss: 0.85920 - acc: 0.8753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1331  | total loss: \u001b[1m\u001b[32m0.80430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1331 | loss: 0.80430 - acc: 0.8878 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1332  | total loss: \u001b[1m\u001b[32m0.75191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1332 | loss: 0.75191 - acc: 0.8990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1333  | total loss: \u001b[1m\u001b[32m0.70195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1333 | loss: 0.70195 - acc: 0.9091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1334  | total loss: \u001b[1m\u001b[32m0.65438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1334 | loss: 0.65438 - acc: 0.9182 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1335  | total loss: \u001b[1m\u001b[32m0.60915\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1335 | loss: 0.60915 - acc: 0.9264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1336  | total loss: \u001b[1m\u001b[32m1.00214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1336 | loss: 1.00214 - acc: 0.8337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1337  | total loss: \u001b[1m\u001b[32m0.91903\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1337 | loss: 0.91903 - acc: 0.8504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1338  | total loss: \u001b[1m\u001b[32m0.84328\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1338 | loss: 0.84328 - acc: 0.8653 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1339  | total loss: \u001b[1m\u001b[32m0.77415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1339 | loss: 0.77415 - acc: 0.8788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1340  | total loss: \u001b[1m\u001b[32m1.18577\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1340 | loss: 1.18577 - acc: 0.7909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1341  | total loss: \u001b[1m\u001b[32m1.08136\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1341 | loss: 1.08136 - acc: 0.8118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1342  | total loss: \u001b[1m\u001b[32m1.36040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1342 | loss: 1.36040 - acc: 0.7521 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1343  | total loss: \u001b[1m\u001b[32m1.23886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1343 | loss: 1.23886 - acc: 0.7769 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1344  | total loss: \u001b[1m\u001b[32m1.12985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1344 | loss: 1.12985 - acc: 0.7992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1345  | total loss: \u001b[1m\u001b[32m1.03195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1345 | loss: 1.03195 - acc: 0.8193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1346  | total loss: \u001b[1m\u001b[32m1.35498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1346 | loss: 1.35498 - acc: 0.7445 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1347  | total loss: \u001b[1m\u001b[32m1.23550\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1347 | loss: 1.23550 - acc: 0.7700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1348  | total loss: \u001b[1m\u001b[32m1.55986\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1348 | loss: 1.55986 - acc: 0.6930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1349  | total loss: \u001b[1m\u001b[32m1.42212\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1349 | loss: 1.42212 - acc: 0.7237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1350  | total loss: \u001b[1m\u001b[32m1.29947\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1350 | loss: 1.29947 - acc: 0.7513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1351  | total loss: \u001b[1m\u001b[32m1.19014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1351 | loss: 1.19014 - acc: 0.7762 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1352  | total loss: \u001b[1m\u001b[32m1.50591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1352 | loss: 1.50591 - acc: 0.6986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1353  | total loss: \u001b[1m\u001b[32m1.37845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1353 | loss: 1.37845 - acc: 0.7287 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1354  | total loss: \u001b[1m\u001b[32m1.59768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1354 | loss: 1.59768 - acc: 0.6701 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1355  | total loss: \u001b[1m\u001b[32m1.46465\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1355 | loss: 1.46465 - acc: 0.7031 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1356  | total loss: \u001b[1m\u001b[32m1.69011\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1356 | loss: 1.69011 - acc: 0.6400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1357  | total loss: \u001b[1m\u001b[32m1.55232\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1357 | loss: 1.55232 - acc: 0.6760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1358  | total loss: \u001b[1m\u001b[32m1.81983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1358 | loss: 1.81983 - acc: 0.6084 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1359  | total loss: \u001b[1m\u001b[32m1.67454\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1359 | loss: 1.67454 - acc: 0.6475 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1360  | total loss: \u001b[1m\u001b[32m1.89085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1360 | loss: 1.89085 - acc: 0.5828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1361  | total loss: \u001b[1m\u001b[32m1.74483\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1361 | loss: 1.74483 - acc: 0.6245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1362  | total loss: \u001b[1m\u001b[32m1.61632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1362 | loss: 1.61632 - acc: 0.6621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1363  | total loss: \u001b[1m\u001b[32m1.50271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1363 | loss: 1.50271 - acc: 0.6958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1364  | total loss: \u001b[1m\u001b[32m1.73853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1364 | loss: 1.73853 - acc: 0.6263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1365  | total loss: \u001b[1m\u001b[32m1.61609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1365 | loss: 1.61609 - acc: 0.6636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1366  | total loss: \u001b[1m\u001b[32m1.77850\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1366 | loss: 1.77850 - acc: 0.6044 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1367  | total loss: \u001b[1m\u001b[32m1.65554\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1367 | loss: 1.65554 - acc: 0.6440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1368  | total loss: \u001b[1m\u001b[32m1.83193\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1368 | loss: 1.83193 - acc: 0.5867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1369  | total loss: \u001b[1m\u001b[32m1.70693\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1369 | loss: 1.70693 - acc: 0.6280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1370  | total loss: \u001b[1m\u001b[32m1.88783\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1370 | loss: 1.88783 - acc: 0.5652 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1371  | total loss: \u001b[1m\u001b[32m1.76038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1371 | loss: 1.76038 - acc: 0.6087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1372  | total loss: \u001b[1m\u001b[32m1.88072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1372 | loss: 1.88072 - acc: 0.5550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1373  | total loss: \u001b[1m\u001b[32m1.75677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1373 | loss: 1.75677 - acc: 0.5995 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1374  | total loss: \u001b[1m\u001b[32m1.90421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1374 | loss: 1.90421 - acc: 0.5467 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1375  | total loss: \u001b[1m\u001b[32m1.78022\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1375 | loss: 1.78022 - acc: 0.5920 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1376  | total loss: \u001b[1m\u001b[32m1.88222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1376 | loss: 1.88222 - acc: 0.5471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1377  | total loss: \u001b[1m\u001b[32m1.76218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1377 | loss: 1.76218 - acc: 0.5924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1378  | total loss: \u001b[1m\u001b[32m1.65430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1378 | loss: 1.65430 - acc: 0.6332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1379  | total loss: \u001b[1m\u001b[32m1.55639\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1379 | loss: 1.55639 - acc: 0.6698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1380  | total loss: \u001b[1m\u001b[32m1.69117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1380 | loss: 1.69117 - acc: 0.6100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1381  | total loss: \u001b[1m\u001b[32m1.58719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1381 | loss: 1.58719 - acc: 0.6490 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1382  | total loss: \u001b[1m\u001b[32m1.78214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1382 | loss: 1.78214 - acc: 0.5841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1383  | total loss: \u001b[1m\u001b[32m1.66713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1383 | loss: 1.66713 - acc: 0.6257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1384  | total loss: \u001b[1m\u001b[32m1.83227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1384 | loss: 1.83227 - acc: 0.5703 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1385  | total loss: \u001b[1m\u001b[32m1.71089\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1385 | loss: 1.71089 - acc: 0.6132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1386  | total loss: \u001b[1m\u001b[32m1.84181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1386 | loss: 1.84181 - acc: 0.5662 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1387  | total loss: \u001b[1m\u001b[32m1.71838\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1387 | loss: 1.71838 - acc: 0.6096 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1388  | total loss: \u001b[1m\u001b[32m1.86049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1388 | loss: 1.86049 - acc: 0.5558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1389  | total loss: \u001b[1m\u001b[32m1.73442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1389 | loss: 1.73442 - acc: 0.6002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1390  | total loss: \u001b[1m\u001b[32m1.90905\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1390 | loss: 1.90905 - acc: 0.5402 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1391  | total loss: \u001b[1m\u001b[32m1.77803\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1391 | loss: 1.77803 - acc: 0.5862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1392  | total loss: \u001b[1m\u001b[32m1.93355\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1392 | loss: 1.93355 - acc: 0.5275 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1393  | total loss: \u001b[1m\u001b[32m1.80061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1393 | loss: 1.80061 - acc: 0.5748 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1394  | total loss: \u001b[1m\u001b[32m1.94343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1394 | loss: 1.94343 - acc: 0.5244 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1395  | total loss: \u001b[1m\u001b[32m1.81029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1395 | loss: 1.81029 - acc: 0.5720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1396  | total loss: \u001b[1m\u001b[32m1.93923\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1396 | loss: 1.93923 - acc: 0.5219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1397  | total loss: \u001b[1m\u001b[32m1.80728\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1397 | loss: 1.80728 - acc: 0.5698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1398  | total loss: \u001b[1m\u001b[32m1.91677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1398 | loss: 1.91677 - acc: 0.5271 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1399  | total loss: \u001b[1m\u001b[32m1.78769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1399 | loss: 1.78769 - acc: 0.5744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1400  | total loss: \u001b[1m\u001b[32m1.67129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1400 | loss: 1.67129 - acc: 0.6169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1401  | total loss: \u001b[1m\u001b[32m1.56548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1401 | loss: 1.56548 - acc: 0.6552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1402  | total loss: \u001b[1m\u001b[32m1.73865\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1402 | loss: 1.73865 - acc: 0.5897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1403  | total loss: \u001b[1m\u001b[32m1.62387\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1403 | loss: 1.62387 - acc: 0.6307 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1404  | total loss: \u001b[1m\u001b[32m1.83022\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1404 | loss: 1.83022 - acc: 0.5677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1405  | total loss: \u001b[1m\u001b[32m1.70511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1405 | loss: 1.70511 - acc: 0.6109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1406  | total loss: \u001b[1m\u001b[32m1.85874\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1406 | loss: 1.85874 - acc: 0.5569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1407  | total loss: \u001b[1m\u001b[32m1.73037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1407 | loss: 1.73037 - acc: 0.6013 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1408  | total loss: \u001b[1m\u001b[32m1.61436\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1408 | loss: 1.61436 - acc: 0.6411 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1409  | total loss: \u001b[1m\u001b[32m1.50875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1409 | loss: 1.50875 - acc: 0.6770 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1410  | total loss: \u001b[1m\u001b[32m1.41186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1410 | loss: 1.41186 - acc: 0.7093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1411  | total loss: \u001b[1m\u001b[32m1.32230\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1411 | loss: 1.32230 - acc: 0.7384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1412  | total loss: \u001b[1m\u001b[32m1.57137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1412 | loss: 1.57137 - acc: 0.6645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1413  | total loss: \u001b[1m\u001b[32m1.46177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1413 | loss: 1.46177 - acc: 0.6981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1414  | total loss: \u001b[1m\u001b[32m1.68319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1414 | loss: 1.68319 - acc: 0.6283 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1415  | total loss: \u001b[1m\u001b[32m1.56015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1415 | loss: 1.56015 - acc: 0.6655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1416  | total loss: \u001b[1m\u001b[32m1.78345\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1416 | loss: 1.78345 - acc: 0.5989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1417  | total loss: \u001b[1m\u001b[32m1.64963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1417 | loss: 1.64963 - acc: 0.6390 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1418  | total loss: \u001b[1m\u001b[32m1.52884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1418 | loss: 1.52884 - acc: 0.6751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1419  | total loss: \u001b[1m\u001b[32m1.41926\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1419 | loss: 1.41926 - acc: 0.7076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1420  | total loss: \u001b[1m\u001b[32m1.63529\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1420 | loss: 1.63529 - acc: 0.6440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1421  | total loss: \u001b[1m\u001b[32m1.51362\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1421 | loss: 1.51362 - acc: 0.6796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1422  | total loss: \u001b[1m\u001b[32m1.73346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1422 | loss: 1.73346 - acc: 0.6188 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1423  | total loss: \u001b[1m\u001b[32m1.60195\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1423 | loss: 1.60195 - acc: 0.6569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1424  | total loss: \u001b[1m\u001b[32m1.48362\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1424 | loss: 1.48362 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1425  | total loss: \u001b[1m\u001b[32m1.37659\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1425 | loss: 1.37659 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1426  | total loss: \u001b[1m\u001b[32m1.60427\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1426 | loss: 1.60427 - acc: 0.6570 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1427  | total loss: \u001b[1m\u001b[32m1.48424\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1427 | loss: 1.48424 - acc: 0.6913 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1428  | total loss: \u001b[1m\u001b[32m1.37576\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1428 | loss: 1.37576 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1429  | total loss: \u001b[1m\u001b[32m1.27720\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1429 | loss: 1.27720 - acc: 0.7500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1430  | total loss: \u001b[1m\u001b[32m1.53162\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1430 | loss: 1.53162 - acc: 0.6750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1431  | total loss: \u001b[1m\u001b[32m1.41613\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1431 | loss: 1.41613 - acc: 0.7075 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1432  | total loss: \u001b[1m\u001b[32m1.66257\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1432 | loss: 1.66257 - acc: 0.6367 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1433  | total loss: \u001b[1m\u001b[32m1.53425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1433 | loss: 1.53425 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1434  | total loss: \u001b[1m\u001b[32m1.74846\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1434 | loss: 1.74846 - acc: 0.6057 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1435  | total loss: \u001b[1m\u001b[32m1.61307\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1435 | loss: 1.61307 - acc: 0.6452 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1436  | total loss: \u001b[1m\u001b[32m1.49191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1436 | loss: 1.49191 - acc: 0.6807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1437  | total loss: \u001b[1m\u001b[32m1.38296\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1437 | loss: 1.38296 - acc: 0.7126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1438  | total loss: \u001b[1m\u001b[32m1.63123\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1438 | loss: 1.63123 - acc: 0.6413 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1439  | total loss: \u001b[1m\u001b[32m1.50866\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1439 | loss: 1.50866 - acc: 0.6772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1440  | total loss: \u001b[1m\u001b[32m1.39848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1440 | loss: 1.39848 - acc: 0.7095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1441  | total loss: \u001b[1m\u001b[32m1.29891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1441 | loss: 1.29891 - acc: 0.7385 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1442  | total loss: \u001b[1m\u001b[32m1.20841\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1442 | loss: 1.20841 - acc: 0.7647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1443  | total loss: \u001b[1m\u001b[32m1.12565\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1443 | loss: 1.12565 - acc: 0.7882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1444  | total loss: \u001b[1m\u001b[32m1.04955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1444 | loss: 1.04955 - acc: 0.8094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1445  | total loss: \u001b[1m\u001b[32m0.97916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1445 | loss: 0.97916 - acc: 0.8284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1446  | total loss: \u001b[1m\u001b[32m1.27856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1446 | loss: 1.27856 - acc: 0.7527 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1447  | total loss: \u001b[1m\u001b[32m1.18244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1447 | loss: 1.18244 - acc: 0.7775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1448  | total loss: \u001b[1m\u001b[32m1.09487\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1448 | loss: 1.09487 - acc: 0.7997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1449  | total loss: \u001b[1m\u001b[32m1.01475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1449 | loss: 1.01475 - acc: 0.8198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1450  | total loss: \u001b[1m\u001b[32m1.29809\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1450 | loss: 1.29809 - acc: 0.7449 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1451  | total loss: \u001b[1m\u001b[32m1.19582\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1451 | loss: 1.19582 - acc: 0.7704 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1452  | total loss: \u001b[1m\u001b[32m1.41821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1452 | loss: 1.41821 - acc: 0.7148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1453  | total loss: \u001b[1m\u001b[32m1.30361\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1453 | loss: 1.30361 - acc: 0.7433 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1454  | total loss: \u001b[1m\u001b[32m1.20045\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1454 | loss: 1.20045 - acc: 0.7690 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1455  | total loss: \u001b[1m\u001b[32m1.10731\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1455 | loss: 1.10731 - acc: 0.7921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1456  | total loss: \u001b[1m\u001b[32m1.38543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1456 | loss: 1.38543 - acc: 0.7200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1457  | total loss: \u001b[1m\u001b[32m1.27366\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1457 | loss: 1.27366 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1458  | total loss: \u001b[1m\u001b[32m1.17314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1458 | loss: 1.17314 - acc: 0.7732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1459  | total loss: \u001b[1m\u001b[32m1.08246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1459 | loss: 1.08246 - acc: 0.7959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1460  | total loss: \u001b[1m\u001b[32m1.00035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1460 | loss: 1.00035 - acc: 0.8163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1461  | total loss: \u001b[1m\u001b[32m0.92571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1461 | loss: 0.92571 - acc: 0.8347 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1462  | total loss: \u001b[1m\u001b[32m0.85761\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1462 | loss: 0.85761 - acc: 0.8512 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1463  | total loss: \u001b[1m\u001b[32m0.79524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1463 | loss: 0.79524 - acc: 0.8661 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1464  | total loss: \u001b[1m\u001b[32m0.73792\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1464 | loss: 0.73792 - acc: 0.8795 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1465  | total loss: \u001b[1m\u001b[32m0.68507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1465 | loss: 0.68507 - acc: 0.8915 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1466  | total loss: \u001b[1m\u001b[32m0.63621\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1466 | loss: 0.63621 - acc: 0.9024 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1467  | total loss: \u001b[1m\u001b[32m0.59093\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1467 | loss: 0.59093 - acc: 0.9121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1468  | total loss: \u001b[1m\u001b[32m0.93942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1468 | loss: 0.93942 - acc: 0.8281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1469  | total loss: \u001b[1m\u001b[32m0.86224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1469 | loss: 0.86224 - acc: 0.8453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1470  | total loss: \u001b[1m\u001b[32m1.18424\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1470 | loss: 1.18424 - acc: 0.7750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1471  | total loss: \u001b[1m\u001b[32m1.08262\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1471 | loss: 1.08262 - acc: 0.7975 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1472  | total loss: \u001b[1m\u001b[32m1.38441\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1472 | loss: 1.38441 - acc: 0.7321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1473  | total loss: \u001b[1m\u001b[32m1.26417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1473 | loss: 1.26417 - acc: 0.7588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1474  | total loss: \u001b[1m\u001b[32m1.53900\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1474 | loss: 1.53900 - acc: 0.6973 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1475  | total loss: \u001b[1m\u001b[32m1.40604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1475 | loss: 1.40604 - acc: 0.7275 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1476  | total loss: \u001b[1m\u001b[32m1.28794\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1476 | loss: 1.28794 - acc: 0.7548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1477  | total loss: \u001b[1m\u001b[32m1.18291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1477 | loss: 1.18291 - acc: 0.7793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1478  | total loss: \u001b[1m\u001b[32m1.41614\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1478 | loss: 1.41614 - acc: 0.7157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1479  | total loss: \u001b[1m\u001b[32m1.30093\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1479 | loss: 1.30093 - acc: 0.7441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1480  | total loss: \u001b[1m\u001b[32m1.61427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1480 | loss: 1.61427 - acc: 0.6697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1481  | total loss: \u001b[1m\u001b[32m1.48299\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1481 | loss: 1.48299 - acc: 0.7027 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1482  | total loss: \u001b[1m\u001b[32m1.36673\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1482 | loss: 1.36673 - acc: 0.7324 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1483  | total loss: \u001b[1m\u001b[32m1.26344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1483 | loss: 1.26344 - acc: 0.7592 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1484  | total loss: \u001b[1m\u001b[32m1.17124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1484 | loss: 1.17124 - acc: 0.7833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1485  | total loss: \u001b[1m\u001b[32m1.08849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1485 | loss: 1.08849 - acc: 0.8049 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1486  | total loss: \u001b[1m\u001b[32m1.36009\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1486 | loss: 1.36009 - acc: 0.7316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1487  | total loss: \u001b[1m\u001b[32m1.25897\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1487 | loss: 1.25897 - acc: 0.7584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1488  | total loss: \u001b[1m\u001b[32m1.16822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1488 | loss: 1.16822 - acc: 0.7826 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1489  | total loss: \u001b[1m\u001b[32m1.08630\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1489 | loss: 1.08630 - acc: 0.8043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1490  | total loss: \u001b[1m\u001b[32m1.01187\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1490 | loss: 1.01187 - acc: 0.8239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1491  | total loss: \u001b[1m\u001b[32m0.94381\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1491 | loss: 0.94381 - acc: 0.8415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1492  | total loss: \u001b[1m\u001b[32m0.88117\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1492 | loss: 0.88117 - acc: 0.8574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1493  | total loss: \u001b[1m\u001b[32m0.82320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1493 | loss: 0.82320 - acc: 0.8716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1494  | total loss: \u001b[1m\u001b[32m0.76925\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1494 | loss: 0.76925 - acc: 0.8845 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1495  | total loss: \u001b[1m\u001b[32m0.71883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1495 | loss: 0.71883 - acc: 0.8960 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1496  | total loss: \u001b[1m\u001b[32m1.01920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1496 | loss: 1.01920 - acc: 0.8207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1497  | total loss: \u001b[1m\u001b[32m0.94111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1497 | loss: 0.94111 - acc: 0.8386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1498  | total loss: \u001b[1m\u001b[32m1.24344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1498 | loss: 1.24344 - acc: 0.7619 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1499  | total loss: \u001b[1m\u001b[32m1.14205\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1499 | loss: 1.14205 - acc: 0.7857 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1500  | total loss: \u001b[1m\u001b[32m1.46236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1500 | loss: 1.46236 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1501  | total loss: \u001b[1m\u001b[32m1.33983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1501 | loss: 1.33983 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1502  | total loss: \u001b[1m\u001b[32m1.23019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1502 | loss: 1.23019 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1503  | total loss: \u001b[1m\u001b[32m1.13183\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1503 | loss: 1.13183 - acc: 0.7865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1504  | total loss: \u001b[1m\u001b[32m1.04331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1504 | loss: 1.04331 - acc: 0.8079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1505  | total loss: \u001b[1m\u001b[32m0.96337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1505 | loss: 0.96337 - acc: 0.8271 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1506  | total loss: \u001b[1m\u001b[32m1.23684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1506 | loss: 1.23684 - acc: 0.7587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1507  | total loss: \u001b[1m\u001b[32m1.13747\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1507 | loss: 1.13747 - acc: 0.7828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1508  | total loss: \u001b[1m\u001b[32m1.04817\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1508 | loss: 1.04817 - acc: 0.8045 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1509  | total loss: \u001b[1m\u001b[32m0.96764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1509 | loss: 0.96764 - acc: 0.8241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1510  | total loss: \u001b[1m\u001b[32m0.89475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1510 | loss: 0.89475 - acc: 0.8417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1511  | total loss: \u001b[1m\u001b[32m0.82851\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1511 | loss: 0.82851 - acc: 0.8575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1512  | total loss: \u001b[1m\u001b[32m0.76807\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1512 | loss: 0.76807 - acc: 0.8717 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1513  | total loss: \u001b[1m\u001b[32m0.71271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1513 | loss: 0.71271 - acc: 0.8846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1514  | total loss: \u001b[1m\u001b[32m0.66181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1514 | loss: 0.66181 - acc: 0.8961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1515  | total loss: \u001b[1m\u001b[32m0.61486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1515 | loss: 0.61486 - acc: 0.9065 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1516  | total loss: \u001b[1m\u001b[32m0.57141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1516 | loss: 0.57141 - acc: 0.9158 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1517  | total loss: \u001b[1m\u001b[32m0.53112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1517 | loss: 0.53112 - acc: 0.9243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1518  | total loss: \u001b[1m\u001b[32m0.49368\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1518 | loss: 0.49368 - acc: 0.9318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1519  | total loss: \u001b[1m\u001b[32m0.45884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1519 | loss: 0.45884 - acc: 0.9387 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1520  | total loss: \u001b[1m\u001b[32m0.87795\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1520 | loss: 0.87795 - acc: 0.8519 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1521  | total loss: \u001b[1m\u001b[32m0.80339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1521 | loss: 0.80339 - acc: 0.8667 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1522  | total loss: \u001b[1m\u001b[32m0.73599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1522 | loss: 0.73599 - acc: 0.8801 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1523  | total loss: \u001b[1m\u001b[32m0.67498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1523 | loss: 0.67498 - acc: 0.8921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1524  | total loss: \u001b[1m\u001b[32m0.61967\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1524 | loss: 0.61967 - acc: 0.9029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1525  | total loss: \u001b[1m\u001b[32m0.56943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1525 | loss: 0.56943 - acc: 0.9126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1526  | total loss: \u001b[1m\u001b[32m0.52374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1526 | loss: 0.52374 - acc: 0.9213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1527  | total loss: \u001b[1m\u001b[32m0.48211\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1527 | loss: 0.48211 - acc: 0.9292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1528  | total loss: \u001b[1m\u001b[32m0.44414\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1528 | loss: 0.44414 - acc: 0.9363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1529  | total loss: \u001b[1m\u001b[32m0.40945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1529 | loss: 0.40945 - acc: 0.9426 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1530  | total loss: \u001b[1m\u001b[32m0.89195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1530 | loss: 0.89195 - acc: 0.8484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1531  | total loss: \u001b[1m\u001b[32m0.81209\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1531 | loss: 0.81209 - acc: 0.8635 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1532  | total loss: \u001b[1m\u001b[32m0.74028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1532 | loss: 0.74028 - acc: 0.8772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1533  | total loss: \u001b[1m\u001b[32m0.67563\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1533 | loss: 0.67563 - acc: 0.8895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1534  | total loss: \u001b[1m\u001b[32m1.08689\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1534 | loss: 1.08689 - acc: 0.8077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1535  | total loss: \u001b[1m\u001b[32m0.98804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1535 | loss: 0.98804 - acc: 0.8269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1536  | total loss: \u001b[1m\u001b[32m0.89950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1536 | loss: 0.89950 - acc: 0.8442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1537  | total loss: \u001b[1m\u001b[32m0.82015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1537 | loss: 0.82015 - acc: 0.8598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1538  | total loss: \u001b[1m\u001b[32m1.19180\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1538 | loss: 1.19180 - acc: 0.7809 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1539  | total loss: \u001b[1m\u001b[32m1.08430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1539 | loss: 1.08430 - acc: 0.8029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1540  | total loss: \u001b[1m\u001b[32m0.98827\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1540 | loss: 0.98827 - acc: 0.8226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1541  | total loss: \u001b[1m\u001b[32m0.90244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1541 | loss: 0.90244 - acc: 0.8403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1542  | total loss: \u001b[1m\u001b[32m1.27254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1542 | loss: 1.27254 - acc: 0.7634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1543  | total loss: \u001b[1m\u001b[32m1.15990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1543 | loss: 1.15990 - acc: 0.7871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1544  | total loss: \u001b[1m\u001b[32m1.46830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1544 | loss: 1.46830 - acc: 0.7155 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1545  | total loss: \u001b[1m\u001b[32m1.33893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1545 | loss: 1.33893 - acc: 0.7440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1546  | total loss: \u001b[1m\u001b[32m1.63505\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1546 | loss: 1.63505 - acc: 0.6696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1547  | total loss: \u001b[1m\u001b[32m1.49325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1547 | loss: 1.49325 - acc: 0.7026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1548  | total loss: \u001b[1m\u001b[32m1.36798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1548 | loss: 1.36798 - acc: 0.7323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1549  | total loss: \u001b[1m\u001b[32m1.25721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1549 | loss: 1.25721 - acc: 0.7591 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1550  | total loss: \u001b[1m\u001b[32m1.15903\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1550 | loss: 1.15903 - acc: 0.7832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1551  | total loss: \u001b[1m\u001b[32m1.07172\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1551 | loss: 1.07172 - acc: 0.8049 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1552  | total loss: \u001b[1m\u001b[32m1.35310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1552 | loss: 1.35310 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1553  | total loss: \u001b[1m\u001b[32m1.24846\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1553 | loss: 1.24846 - acc: 0.7584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1554  | total loss: \u001b[1m\u001b[32m1.49443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1554 | loss: 1.49443 - acc: 0.6897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1555  | total loss: \u001b[1m\u001b[32m1.37865\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1555 | loss: 1.37865 - acc: 0.7207 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1556  | total loss: \u001b[1m\u001b[32m1.59430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1556 | loss: 1.59430 - acc: 0.6558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1557  | total loss: \u001b[1m\u001b[32m1.47242\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1557 | loss: 1.47242 - acc: 0.6902 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1558  | total loss: \u001b[1m\u001b[32m1.36450\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1558 | loss: 1.36450 - acc: 0.7212 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1559  | total loss: \u001b[1m\u001b[32m1.26841\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1559 | loss: 1.26841 - acc: 0.7491 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1560  | total loss: \u001b[1m\u001b[32m1.53950\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1560 | loss: 1.53950 - acc: 0.6742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1561  | total loss: \u001b[1m\u001b[32m1.42791\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1561 | loss: 1.42791 - acc: 0.7067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1562  | total loss: \u001b[1m\u001b[32m1.64128\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1562 | loss: 1.64128 - acc: 0.6432 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1563  | total loss: \u001b[1m\u001b[32m1.52222\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1563 | loss: 1.52222 - acc: 0.6789 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1564  | total loss: \u001b[1m\u001b[32m1.41608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1564 | loss: 1.41608 - acc: 0.7110 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1565  | total loss: \u001b[1m\u001b[32m1.32078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1565 | loss: 1.32078 - acc: 0.7399 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1566  | total loss: \u001b[1m\u001b[32m1.52275\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1566 | loss: 1.52275 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1567  | total loss: \u001b[1m\u001b[32m1.41704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1567 | loss: 1.41704 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1568  | total loss: \u001b[1m\u001b[32m1.32189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1568 | loss: 1.32189 - acc: 0.7352 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1569  | total loss: \u001b[1m\u001b[32m1.23556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1569 | loss: 1.23556 - acc: 0.7617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1570  | total loss: \u001b[1m\u001b[32m1.15657\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1570 | loss: 1.15657 - acc: 0.7855 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1571  | total loss: \u001b[1m\u001b[32m1.08370\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1571 | loss: 1.08370 - acc: 0.8069 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1572  | total loss: \u001b[1m\u001b[32m1.01595\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1572 | loss: 1.01595 - acc: 0.8262 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1573  | total loss: \u001b[1m\u001b[32m0.95253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1573 | loss: 0.95253 - acc: 0.8436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1574  | total loss: \u001b[1m\u001b[32m0.89282\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1574 | loss: 0.89282 - acc: 0.8593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1575  | total loss: \u001b[1m\u001b[32m0.83635\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1575 | loss: 0.83635 - acc: 0.8733 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1576  | total loss: \u001b[1m\u001b[32m0.78280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1576 | loss: 0.78280 - acc: 0.8860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1577  | total loss: \u001b[1m\u001b[32m0.73191\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1577 | loss: 0.73191 - acc: 0.8974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1578  | total loss: \u001b[1m\u001b[32m0.68353\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1578 | loss: 0.68353 - acc: 0.9077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1579  | total loss: \u001b[1m\u001b[32m0.63756\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1579 | loss: 0.63756 - acc: 0.9169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1580  | total loss: \u001b[1m\u001b[32m1.01762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1580 | loss: 1.01762 - acc: 0.8252 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1581  | total loss: \u001b[1m\u001b[32m0.93501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1581 | loss: 0.93501 - acc: 0.8427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1582  | total loss: \u001b[1m\u001b[32m1.25443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1582 | loss: 1.25443 - acc: 0.7727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1583  | total loss: \u001b[1m\u001b[32m1.14704\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1583 | loss: 1.14704 - acc: 0.7954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1584  | total loss: \u001b[1m\u001b[32m1.50980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1584 | loss: 1.50980 - acc: 0.7159 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1585  | total loss: \u001b[1m\u001b[32m1.37736\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1585 | loss: 1.37736 - acc: 0.7443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1586  | total loss: \u001b[1m\u001b[32m1.65343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1586 | loss: 1.65343 - acc: 0.6699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1587  | total loss: \u001b[1m\u001b[32m1.50857\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1587 | loss: 1.50857 - acc: 0.7029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1588  | total loss: \u001b[1m\u001b[32m1.72391\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1588 | loss: 1.72391 - acc: 0.6469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1589  | total loss: \u001b[1m\u001b[32m1.57516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1589 | loss: 1.57516 - acc: 0.6822 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1590  | total loss: \u001b[1m\u001b[32m1.79486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1590 | loss: 1.79486 - acc: 0.6211 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1591  | total loss: \u001b[1m\u001b[32m1.64319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1591 | loss: 1.64319 - acc: 0.6590 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1592  | total loss: \u001b[1m\u001b[32m1.50878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1592 | loss: 1.50878 - acc: 0.6931 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1593  | total loss: \u001b[1m\u001b[32m1.38941\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1593 | loss: 1.38941 - acc: 0.7238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1594  | total loss: \u001b[1m\u001b[32m1.60677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1594 | loss: 1.60677 - acc: 0.6586 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1595  | total loss: \u001b[1m\u001b[32m1.48072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1595 | loss: 1.48072 - acc: 0.6927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1596  | total loss: \u001b[1m\u001b[32m1.36874\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1596 | loss: 1.36874 - acc: 0.7234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1597  | total loss: \u001b[1m\u001b[32m1.26880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1597 | loss: 1.26880 - acc: 0.7511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1598  | total loss: \u001b[1m\u001b[32m1.17910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1598 | loss: 1.17910 - acc: 0.7760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1599  | total loss: \u001b[1m\u001b[32m1.09809\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1599 | loss: 1.09809 - acc: 0.7984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1600  | total loss: \u001b[1m\u001b[32m1.02441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1600 | loss: 1.02441 - acc: 0.8185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1601  | total loss: \u001b[1m\u001b[32m0.95691\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1601 | loss: 0.95691 - acc: 0.8367 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1602  | total loss: \u001b[1m\u001b[32m1.23396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1602 | loss: 1.23396 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1603  | total loss: \u001b[1m\u001b[32m1.14369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1603 | loss: 1.14369 - acc: 0.7841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1604  | total loss: \u001b[1m\u001b[32m1.43463\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1604 | loss: 1.43463 - acc: 0.7057 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1605  | total loss: \u001b[1m\u001b[32m1.32425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1605 | loss: 1.32425 - acc: 0.7352 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1606  | total loss: \u001b[1m\u001b[32m1.55068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1606 | loss: 1.55068 - acc: 0.6688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1607  | total loss: \u001b[1m\u001b[32m1.43013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1607 | loss: 1.43013 - acc: 0.7019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1608  | total loss: \u001b[1m\u001b[32m1.66152\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1608 | loss: 1.66152 - acc: 0.6317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1609  | total loss: \u001b[1m\u001b[32m1.53248\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1609 | loss: 1.53248 - acc: 0.6685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1610  | total loss: \u001b[1m\u001b[32m1.70941\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1610 | loss: 1.70941 - acc: 0.6160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1611  | total loss: \u001b[1m\u001b[32m1.57897\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1611 | loss: 1.57897 - acc: 0.6544 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1612  | total loss: \u001b[1m\u001b[32m1.78181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1612 | loss: 1.78181 - acc: 0.5961 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1613  | total loss: \u001b[1m\u001b[32m1.64798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1613 | loss: 1.64798 - acc: 0.6365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1614  | total loss: \u001b[1m\u001b[32m1.87275\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1614 | loss: 1.87275 - acc: 0.5728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1615  | total loss: \u001b[1m\u001b[32m1.73423\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1615 | loss: 1.73423 - acc: 0.6155 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1616  | total loss: \u001b[1m\u001b[32m1.91551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1616 | loss: 1.91551 - acc: 0.5611 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1617  | total loss: \u001b[1m\u001b[32m1.77732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1617 | loss: 1.77732 - acc: 0.6050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1618  | total loss: \u001b[1m\u001b[32m1.91333\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1618 | loss: 1.91333 - acc: 0.5588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1619  | total loss: \u001b[1m\u001b[32m1.77953\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1619 | loss: 1.77953 - acc: 0.6029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1620  | total loss: \u001b[1m\u001b[32m1.90573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1620 | loss: 1.90573 - acc: 0.5498 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1621  | total loss: \u001b[1m\u001b[32m1.77622\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1621 | loss: 1.77622 - acc: 0.5948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1622  | total loss: \u001b[1m\u001b[32m1.92810\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1622 | loss: 1.92810 - acc: 0.5425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1623  | total loss: \u001b[1m\u001b[32m1.79931\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1623 | loss: 1.79931 - acc: 0.5882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1624  | total loss: \u001b[1m\u001b[32m1.93327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1624 | loss: 1.93327 - acc: 0.5365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1625  | total loss: \u001b[1m\u001b[32m1.80644\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1625 | loss: 1.80644 - acc: 0.5829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1626  | total loss: \u001b[1m\u001b[32m1.98609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1626 | loss: 1.98609 - acc: 0.5246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1627  | total loss: \u001b[1m\u001b[32m1.85619\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1627 | loss: 1.85619 - acc: 0.5721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1628  | total loss: \u001b[1m\u001b[32m1.73981\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1628 | loss: 1.73981 - acc: 0.6149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1629  | total loss: \u001b[1m\u001b[32m1.63456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1629 | loss: 1.63456 - acc: 0.6534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1630  | total loss: \u001b[1m\u001b[32m1.81366\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1630 | loss: 1.81366 - acc: 0.5881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1631  | total loss: \u001b[1m\u001b[32m1.69939\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1631 | loss: 1.69939 - acc: 0.6293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1632  | total loss: \u001b[1m\u001b[32m1.88286\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1632 | loss: 1.88286 - acc: 0.5663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1633  | total loss: \u001b[1m\u001b[32m1.76055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1633 | loss: 1.76055 - acc: 0.6097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1634  | total loss: \u001b[1m\u001b[32m1.90502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1634 | loss: 1.90502 - acc: 0.5487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1635  | total loss: \u001b[1m\u001b[32m1.77989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1635 | loss: 1.77989 - acc: 0.5939 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1636  | total loss: \u001b[1m\u001b[32m1.93049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1636 | loss: 1.93049 - acc: 0.5345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1637  | total loss: \u001b[1m\u001b[32m1.80255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1637 | loss: 1.80255 - acc: 0.5810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1638  | total loss: \u001b[1m\u001b[32m1.93248\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1638 | loss: 1.93248 - acc: 0.5301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1639  | total loss: \u001b[1m\u001b[32m1.80412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1639 | loss: 1.80412 - acc: 0.5771 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1640  | total loss: \u001b[1m\u001b[32m1.98828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1640 | loss: 1.98828 - acc: 0.5194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1641  | total loss: \u001b[1m\u001b[32m1.85443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1641 | loss: 1.85443 - acc: 0.5674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1642  | total loss: \u001b[1m\u001b[32m1.99521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1642 | loss: 1.99521 - acc: 0.5107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1643  | total loss: \u001b[1m\u001b[32m1.86105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1643 | loss: 1.86105 - acc: 0.5596 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1644  | total loss: \u001b[1m\u001b[32m2.01211\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1644 | loss: 2.01211 - acc: 0.5108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1645  | total loss: \u001b[1m\u001b[32m1.87678\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1645 | loss: 1.87678 - acc: 0.5597 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1646  | total loss: \u001b[1m\u001b[32m2.01185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1646 | loss: 2.01185 - acc: 0.5109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1647  | total loss: \u001b[1m\u001b[32m1.87707\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1647 | loss: 1.87707 - acc: 0.5598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1648  | total loss: \u001b[1m\u001b[32m1.96459\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1648 | loss: 1.96459 - acc: 0.5252 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1649  | total loss: \u001b[1m\u001b[32m1.83463\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1649 | loss: 1.83463 - acc: 0.5727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1650  | total loss: \u001b[1m\u001b[32m1.97603\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1650 | loss: 1.97603 - acc: 0.5226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1651  | total loss: \u001b[1m\u001b[32m1.84472\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1651 | loss: 1.84472 - acc: 0.5703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1652  | total loss: \u001b[1m\u001b[32m1.72597\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1652 | loss: 1.72597 - acc: 0.6133 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1653  | total loss: \u001b[1m\u001b[32m1.61769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1653 | loss: 1.61769 - acc: 0.6520 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1654  | total loss: \u001b[1m\u001b[32m1.79498\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1654 | loss: 1.79498 - acc: 0.5939 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1655  | total loss: \u001b[1m\u001b[32m1.67673\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1655 | loss: 1.67673 - acc: 0.6345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1656  | total loss: \u001b[1m\u001b[32m1.56864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1656 | loss: 1.56864 - acc: 0.6711 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1657  | total loss: \u001b[1m\u001b[32m1.46909\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1657 | loss: 1.46909 - acc: 0.7040 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1658  | total loss: \u001b[1m\u001b[32m1.64209\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1658 | loss: 1.64209 - acc: 0.6407 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1659  | total loss: \u001b[1m\u001b[32m1.53097\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1659 | loss: 1.53097 - acc: 0.6766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1660  | total loss: \u001b[1m\u001b[32m1.42897\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1660 | loss: 1.42897 - acc: 0.7090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1661  | total loss: \u001b[1m\u001b[32m1.33476\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1661 | loss: 1.33476 - acc: 0.7381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1662  | total loss: \u001b[1m\u001b[32m1.55769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1662 | loss: 1.55769 - acc: 0.6714 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1663  | total loss: \u001b[1m\u001b[32m1.44648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1663 | loss: 1.44648 - acc: 0.7043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1664  | total loss: \u001b[1m\u001b[32m1.34462\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1664 | loss: 1.34462 - acc: 0.7338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1665  | total loss: \u001b[1m\u001b[32m1.25084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1665 | loss: 1.25084 - acc: 0.7605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1666  | total loss: \u001b[1m\u001b[32m1.50278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1666 | loss: 1.50278 - acc: 0.6844 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1667  | total loss: \u001b[1m\u001b[32m1.38999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1667 | loss: 1.38999 - acc: 0.7160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1668  | total loss: \u001b[1m\u001b[32m1.28725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1668 | loss: 1.28725 - acc: 0.7444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1669  | total loss: \u001b[1m\u001b[32m1.19327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1669 | loss: 1.19327 - acc: 0.7699 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1670  | total loss: \u001b[1m\u001b[32m1.45179\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1670 | loss: 1.45179 - acc: 0.7001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1671  | total loss: \u001b[1m\u001b[32m1.33910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1671 | loss: 1.33910 - acc: 0.7301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1672  | total loss: \u001b[1m\u001b[32m1.56006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1672 | loss: 1.56006 - acc: 0.6714 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1673  | total loss: \u001b[1m\u001b[32m1.43598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1673 | loss: 1.43598 - acc: 0.7042 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1674  | total loss: \u001b[1m\u001b[32m1.68153\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1674 | loss: 1.68153 - acc: 0.6338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1675  | total loss: \u001b[1m\u001b[32m1.54618\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1675 | loss: 1.54618 - acc: 0.6704 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1676  | total loss: \u001b[1m\u001b[32m1.71442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1676 | loss: 1.71442 - acc: 0.6248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1677  | total loss: \u001b[1m\u001b[32m1.57758\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1677 | loss: 1.57758 - acc: 0.6623 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1678  | total loss: \u001b[1m\u001b[32m1.77915\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1678 | loss: 1.77915 - acc: 0.6032 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1679  | total loss: \u001b[1m\u001b[32m1.63829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1679 | loss: 1.63829 - acc: 0.6429 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1680  | total loss: \u001b[1m\u001b[32m1.51263\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1680 | loss: 1.51263 - acc: 0.6786 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1681  | total loss: \u001b[1m\u001b[32m1.40005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1681 | loss: 1.40005 - acc: 0.7108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1682  | total loss: \u001b[1m\u001b[32m1.29869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1682 | loss: 1.29869 - acc: 0.7397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1683  | total loss: \u001b[1m\u001b[32m1.20693\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1683 | loss: 1.20693 - acc: 0.7657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1684  | total loss: \u001b[1m\u001b[32m1.48088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1684 | loss: 1.48088 - acc: 0.6891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1685  | total loss: \u001b[1m\u001b[32m1.37015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1685 | loss: 1.37015 - acc: 0.7202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1686  | total loss: \u001b[1m\u001b[32m1.57075\u001b[0m\u001b[0m | time: 0.036s\n",
      "| Adam | epoch: 1686 | loss: 1.57075 - acc: 0.6625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1687  | total loss: \u001b[1m\u001b[32m1.45147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1687 | loss: 1.45147 - acc: 0.6962 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1688  | total loss: \u001b[1m\u001b[32m1.60991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1688 | loss: 1.60991 - acc: 0.6480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1689  | total loss: \u001b[1m\u001b[32m1.48779\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1689 | loss: 1.48779 - acc: 0.6832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1690  | total loss: \u001b[1m\u001b[32m1.73011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1690 | loss: 1.73011 - acc: 0.6149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1691  | total loss: \u001b[1m\u001b[32m1.59785\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1691 | loss: 1.59785 - acc: 0.6534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1692  | total loss: \u001b[1m\u001b[32m1.84002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1692 | loss: 1.84002 - acc: 0.5881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1693  | total loss: \u001b[1m\u001b[32m1.69951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1693 | loss: 1.69951 - acc: 0.6293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1694  | total loss: \u001b[1m\u001b[32m1.89983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1694 | loss: 1.89983 - acc: 0.5663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1695  | total loss: \u001b[1m\u001b[32m1.75667\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 1695 | loss: 1.75667 - acc: 0.6097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1696  | total loss: \u001b[1m\u001b[32m1.92130\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1696 | loss: 1.92130 - acc: 0.5487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1697  | total loss: \u001b[1m\u001b[32m1.77974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1697 | loss: 1.77974 - acc: 0.5939 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1698  | total loss: \u001b[1m\u001b[32m1.95139\u001b[0m\u001b[0m | time: 0.020s\n",
      "| Adam | epoch: 1698 | loss: 1.95139 - acc: 0.5345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1699  | total loss: \u001b[1m\u001b[32m1.81066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1699 | loss: 1.81066 - acc: 0.5810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1700  | total loss: \u001b[1m\u001b[32m1.95588\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1700 | loss: 1.95588 - acc: 0.5301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1701  | total loss: \u001b[1m\u001b[32m1.81844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1701 | loss: 1.81844 - acc: 0.5771 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1702  | total loss: \u001b[1m\u001b[32m1.96567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1702 | loss: 1.96567 - acc: 0.5265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1703  | total loss: \u001b[1m\u001b[32m1.83064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1703 | loss: 1.83064 - acc: 0.5739 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1704  | total loss: \u001b[1m\u001b[32m1.71016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1704 | loss: 1.71016 - acc: 0.6165 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1705  | total loss: \u001b[1m\u001b[32m1.60179\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1705 | loss: 1.60179 - acc: 0.6548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1706  | total loss: \u001b[1m\u001b[32m1.77216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1706 | loss: 1.77216 - acc: 0.5965 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1707  | total loss: \u001b[1m\u001b[32m1.65694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1707 | loss: 1.65694 - acc: 0.6368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1708  | total loss: \u001b[1m\u001b[32m1.55254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1708 | loss: 1.55254 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1709  | total loss: \u001b[1m\u001b[32m1.45710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1709 | loss: 1.45710 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1710  | total loss: \u001b[1m\u001b[32m1.36909\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1710 | loss: 1.36909 - acc: 0.7353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1711  | total loss: \u001b[1m\u001b[32m1.28723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1711 | loss: 1.28723 - acc: 0.7617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1712  | total loss: \u001b[1m\u001b[32m1.51202\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1712 | loss: 1.51202 - acc: 0.6856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1713  | total loss: \u001b[1m\u001b[32m1.41124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1713 | loss: 1.41124 - acc: 0.7170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1714  | total loss: \u001b[1m\u001b[32m1.62541\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1714 | loss: 1.62541 - acc: 0.6453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1715  | total loss: \u001b[1m\u001b[32m1.51049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1715 | loss: 1.51049 - acc: 0.6808 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1716  | total loss: \u001b[1m\u001b[32m1.70342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1716 | loss: 1.70342 - acc: 0.6270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1717  | total loss: \u001b[1m\u001b[32m1.57917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1717 | loss: 1.57917 - acc: 0.6643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1718  | total loss: \u001b[1m\u001b[32m1.78709\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1718 | loss: 1.78709 - acc: 0.5979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1719  | total loss: \u001b[1m\u001b[32m1.65414\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1719 | loss: 1.65414 - acc: 0.6381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1720  | total loss: \u001b[1m\u001b[32m1.53433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1720 | loss: 1.53433 - acc: 0.6743 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1721  | total loss: \u001b[1m\u001b[32m1.42579\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1721 | loss: 1.42579 - acc: 0.7068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1722  | total loss: \u001b[1m\u001b[32m1.32688\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1722 | loss: 1.32688 - acc: 0.7362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1723  | total loss: \u001b[1m\u001b[32m1.23623\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1723 | loss: 1.23623 - acc: 0.7625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1724  | total loss: \u001b[1m\u001b[32m1.48241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1724 | loss: 1.48241 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1725  | total loss: \u001b[1m\u001b[32m1.37360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1725 | loss: 1.37360 - acc: 0.7241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1726  | total loss: \u001b[1m\u001b[32m1.58221\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1726 | loss: 1.58221 - acc: 0.6588 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1727  | total loss: \u001b[1m\u001b[32m1.46239\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1727 | loss: 1.46239 - acc: 0.6929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1728  | total loss: \u001b[1m\u001b[32m1.35409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1728 | loss: 1.35409 - acc: 0.7236 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1729  | total loss: \u001b[1m\u001b[32m1.25574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1729 | loss: 1.25574 - acc: 0.7513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1730  | total loss: \u001b[1m\u001b[32m1.46141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1730 | loss: 1.46141 - acc: 0.6904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1731  | total loss: \u001b[1m\u001b[32m1.35087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1731 | loss: 1.35087 - acc: 0.7214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1732  | total loss: \u001b[1m\u001b[32m1.25076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1732 | loss: 1.25076 - acc: 0.7493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1733  | total loss: \u001b[1m\u001b[32m1.15968\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1733 | loss: 1.15968 - acc: 0.7743 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1734  | total loss: \u001b[1m\u001b[32m1.45877\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1734 | loss: 1.45877 - acc: 0.6969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1735  | total loss: \u001b[1m\u001b[32m1.34569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1735 | loss: 1.34569 - acc: 0.7272 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1736  | total loss: \u001b[1m\u001b[32m1.51367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1736 | loss: 1.51367 - acc: 0.6759 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1737  | total loss: \u001b[1m\u001b[32m1.39528\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1737 | loss: 1.39528 - acc: 0.7083 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1738  | total loss: \u001b[1m\u001b[32m1.61363\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1738 | loss: 1.61363 - acc: 0.6446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1739  | total loss: \u001b[1m\u001b[32m1.48648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1739 | loss: 1.48648 - acc: 0.6802 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1740  | total loss: \u001b[1m\u001b[32m1.69698\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1740 | loss: 1.69698 - acc: 0.6193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1741  | total loss: \u001b[1m\u001b[32m1.56393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1741 | loss: 1.56393 - acc: 0.6574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1742  | total loss: \u001b[1m\u001b[32m1.77754\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1742 | loss: 1.77754 - acc: 0.5916 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1743  | total loss: \u001b[1m\u001b[32m1.63979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1743 | loss: 1.63979 - acc: 0.6325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1744  | total loss: \u001b[1m\u001b[32m1.51730\u001b[0m\u001b[0m | time: 0.028s\n",
      "| Adam | epoch: 1744 | loss: 1.51730 - acc: 0.6692 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1745  | total loss: \u001b[1m\u001b[32m1.40786\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1745 | loss: 1.40786 - acc: 0.7023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1746  | total loss: \u001b[1m\u001b[32m1.30950\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1746 | loss: 1.30950 - acc: 0.7321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1747  | total loss: \u001b[1m\u001b[32m1.22049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1747 | loss: 1.22049 - acc: 0.7589 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1748  | total loss: \u001b[1m\u001b[32m1.46692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1748 | loss: 1.46692 - acc: 0.6901 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1749  | total loss: \u001b[1m\u001b[32m1.36134\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1749 | loss: 1.36134 - acc: 0.7211 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1750  | total loss: \u001b[1m\u001b[32m1.58104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1750 | loss: 1.58104 - acc: 0.6561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1751  | total loss: \u001b[1m\u001b[32m1.46428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1751 | loss: 1.46428 - acc: 0.6905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1752  | total loss: \u001b[1m\u001b[32m1.71383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1752 | loss: 1.71383 - acc: 0.6215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1753  | total loss: \u001b[1m\u001b[32m1.58495\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1753 | loss: 1.58495 - acc: 0.6593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1754  | total loss: \u001b[1m\u001b[32m1.46942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1754 | loss: 1.46942 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1755  | total loss: \u001b[1m\u001b[32m1.36525\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1755 | loss: 1.36525 - acc: 0.7241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1756  | total loss: \u001b[1m\u001b[32m1.57952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1756 | loss: 1.57952 - acc: 0.6659 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1757  | total loss: \u001b[1m\u001b[32m1.46385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1757 | loss: 1.46385 - acc: 0.6993 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1758  | total loss: \u001b[1m\u001b[32m1.61451\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1758 | loss: 1.61451 - acc: 0.6437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1759  | total loss: \u001b[1m\u001b[32m1.49562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1759 | loss: 1.49562 - acc: 0.6793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1760  | total loss: \u001b[1m\u001b[32m1.38858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1760 | loss: 1.38858 - acc: 0.7114 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1761  | total loss: \u001b[1m\u001b[32m1.29165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1761 | loss: 1.29165 - acc: 0.7403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1762  | total loss: \u001b[1m\u001b[32m1.53533\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1762 | loss: 1.53533 - acc: 0.6734 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1763  | total loss: \u001b[1m\u001b[32m1.42266\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1763 | loss: 1.42266 - acc: 0.7060 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1764  | total loss: \u001b[1m\u001b[32m1.32073\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1764 | loss: 1.32073 - acc: 0.7354 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1765  | total loss: \u001b[1m\u001b[32m1.22802\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1765 | loss: 1.22802 - acc: 0.7619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1766  | total loss: \u001b[1m\u001b[32m1.46093\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1766 | loss: 1.46093 - acc: 0.6928 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1767  | total loss: \u001b[1m\u001b[32m1.35261\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1767 | loss: 1.35261 - acc: 0.7236 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1768  | total loss: \u001b[1m\u001b[32m1.54551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1768 | loss: 1.54551 - acc: 0.6726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1769  | total loss: \u001b[1m\u001b[32m1.42828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1769 | loss: 1.42828 - acc: 0.7054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1770  | total loss: \u001b[1m\u001b[32m1.66471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1770 | loss: 1.66471 - acc: 0.6348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1771  | total loss: \u001b[1m\u001b[32m1.53610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1771 | loss: 1.53610 - acc: 0.6713 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1772  | total loss: \u001b[1m\u001b[32m1.77419\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1772 | loss: 1.77419 - acc: 0.6042 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1773  | total loss: \u001b[1m\u001b[32m1.63626\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1773 | loss: 1.63626 - acc: 0.6438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1774  | total loss: \u001b[1m\u001b[32m1.51287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1774 | loss: 1.51287 - acc: 0.6794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1775  | total loss: \u001b[1m\u001b[32m1.40198\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1775 | loss: 1.40198 - acc: 0.7115 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1776  | total loss: \u001b[1m\u001b[32m1.64601\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1776 | loss: 1.64601 - acc: 0.6403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1777  | total loss: \u001b[1m\u001b[32m1.52222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1777 | loss: 1.52222 - acc: 0.6763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1778  | total loss: \u001b[1m\u001b[32m1.41099\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1778 | loss: 1.41099 - acc: 0.7087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1779  | total loss: \u001b[1m\u001b[32m1.31053\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1779 | loss: 1.31053 - acc: 0.7378 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1780  | total loss: \u001b[1m\u001b[32m1.50588\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1780 | loss: 1.50588 - acc: 0.6854 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1781  | total loss: \u001b[1m\u001b[32m1.39517\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1781 | loss: 1.39517 - acc: 0.7169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1782  | total loss: \u001b[1m\u001b[32m1.56998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1782 | loss: 1.56998 - acc: 0.6595 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1783  | total loss: \u001b[1m\u001b[32m1.45283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1783 | loss: 1.45283 - acc: 0.6935 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1784  | total loss: \u001b[1m\u001b[32m1.34727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1784 | loss: 1.34727 - acc: 0.7242 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1785  | total loss: \u001b[1m\u001b[32m1.25166\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1785 | loss: 1.25166 - acc: 0.7518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1786  | total loss: \u001b[1m\u001b[32m1.16459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1786 | loss: 1.16459 - acc: 0.7766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1787  | total loss: \u001b[1m\u001b[32m1.08487\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1787 | loss: 1.08487 - acc: 0.7989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1788  | total loss: \u001b[1m\u001b[32m1.01149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1788 | loss: 1.01149 - acc: 0.8190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1789  | total loss: \u001b[1m\u001b[32m0.94359\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1789 | loss: 0.94359 - acc: 0.8371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1790  | total loss: \u001b[1m\u001b[32m1.23895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1790 | loss: 1.23895 - acc: 0.7606 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1791  | total loss: \u001b[1m\u001b[32m1.14557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1791 | loss: 1.14557 - acc: 0.7845 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1792  | total loss: \u001b[1m\u001b[32m1.43375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1792 | loss: 1.43375 - acc: 0.7132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1793  | total loss: \u001b[1m\u001b[32m1.32003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1793 | loss: 1.32003 - acc: 0.7419 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1794  | total loss: \u001b[1m\u001b[32m1.53647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1794 | loss: 1.53647 - acc: 0.6891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1795  | total loss: \u001b[1m\u001b[32m1.41286\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1795 | loss: 1.41286 - acc: 0.7202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1796  | total loss: \u001b[1m\u001b[32m1.64402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1796 | loss: 1.64402 - acc: 0.6553 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1797  | total loss: \u001b[1m\u001b[32m1.51104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1797 | loss: 1.51104 - acc: 0.6898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1798  | total loss: \u001b[1m\u001b[32m1.74430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1798 | loss: 1.74430 - acc: 0.6280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1799  | total loss: \u001b[1m\u001b[32m1.60380\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1799 | loss: 1.60380 - acc: 0.6652 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1800  | total loss: \u001b[1m\u001b[32m1.80001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1800 | loss: 1.80001 - acc: 0.6058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1801  | total loss: \u001b[1m\u001b[32m1.65743\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1801 | loss: 1.65743 - acc: 0.6452 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1802  | total loss: \u001b[1m\u001b[32m1.53076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1802 | loss: 1.53076 - acc: 0.6807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1803  | total loss: \u001b[1m\u001b[32m1.41779\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1803 | loss: 1.41779 - acc: 0.7126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1804  | total loss: \u001b[1m\u001b[32m1.64402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1804 | loss: 1.64402 - acc: 0.6414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1805  | total loss: \u001b[1m\u001b[32m1.52169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1805 | loss: 1.52169 - acc: 0.6772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1806  | total loss: \u001b[1m\u001b[32m1.41242\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1806 | loss: 1.41242 - acc: 0.7095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1807  | total loss: \u001b[1m\u001b[32m1.31426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1807 | loss: 1.31426 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1808  | total loss: \u001b[1m\u001b[32m1.50790\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1808 | loss: 1.50790 - acc: 0.6790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1809  | total loss: \u001b[1m\u001b[32m1.40022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1809 | loss: 1.40022 - acc: 0.7111 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1810  | total loss: \u001b[1m\u001b[32m1.63236\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1810 | loss: 1.63236 - acc: 0.6400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1811  | total loss: \u001b[1m\u001b[32m1.51311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1811 | loss: 1.51311 - acc: 0.6760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1812  | total loss: \u001b[1m\u001b[32m1.69556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1812 | loss: 1.69556 - acc: 0.6155 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1813  | total loss: \u001b[1m\u001b[32m1.57165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1813 | loss: 1.57165 - acc: 0.6540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1814  | total loss: \u001b[1m\u001b[32m1.46070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1814 | loss: 1.46070 - acc: 0.6886 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1815  | total loss: \u001b[1m\u001b[32m1.36074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1815 | loss: 1.36074 - acc: 0.7197 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1816  | total loss: \u001b[1m\u001b[32m1.55292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1816 | loss: 1.55292 - acc: 0.6549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1817  | total loss: \u001b[1m\u001b[32m1.44333\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1817 | loss: 1.44333 - acc: 0.6894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1818  | total loss: \u001b[1m\u001b[32m1.62869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1818 | loss: 1.62869 - acc: 0.6347 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1819  | total loss: \u001b[1m\u001b[32m1.51181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1819 | loss: 1.51181 - acc: 0.6713 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1820  | total loss: \u001b[1m\u001b[32m1.69329\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1820 | loss: 1.69329 - acc: 0.6113 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1821  | total loss: \u001b[1m\u001b[32m1.57083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1821 | loss: 1.57083 - acc: 0.6502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1822  | total loss: \u001b[1m\u001b[32m1.74490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1822 | loss: 1.74490 - acc: 0.5994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1823  | total loss: \u001b[1m\u001b[32m1.61860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1823 | loss: 1.61860 - acc: 0.6395 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1824  | total loss: \u001b[1m\u001b[32m1.77943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1824 | loss: 1.77943 - acc: 0.5898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1825  | total loss: \u001b[1m\u001b[32m1.65119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1825 | loss: 1.65119 - acc: 0.6308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1826  | total loss: \u001b[1m\u001b[32m1.53617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1826 | loss: 1.53617 - acc: 0.6678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1827  | total loss: \u001b[1m\u001b[32m1.43234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1827 | loss: 1.43234 - acc: 0.7010 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1828  | total loss: \u001b[1m\u001b[32m1.64979\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1828 | loss: 1.64979 - acc: 0.6309 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1829  | total loss: \u001b[1m\u001b[32m1.53402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1829 | loss: 1.53402 - acc: 0.6678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1830  | total loss: \u001b[1m\u001b[32m1.72558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1830 | loss: 1.72558 - acc: 0.6082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1831  | total loss: \u001b[1m\u001b[32m1.60260\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1831 | loss: 1.60260 - acc: 0.6473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1832  | total loss: \u001b[1m\u001b[32m1.82198\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1832 | loss: 1.82198 - acc: 0.5826 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1833  | total loss: \u001b[1m\u001b[32m1.69049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1833 | loss: 1.69049 - acc: 0.6243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1834  | total loss: \u001b[1m\u001b[32m1.84798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1834 | loss: 1.84798 - acc: 0.5691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1835  | total loss: \u001b[1m\u001b[32m1.71570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1835 | loss: 1.71570 - acc: 0.6121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1836  | total loss: \u001b[1m\u001b[32m1.85297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1836 | loss: 1.85297 - acc: 0.5652 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1837  | total loss: \u001b[1m\u001b[32m1.72214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1837 | loss: 1.72214 - acc: 0.6087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1838  | total loss: \u001b[1m\u001b[32m1.60488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1838 | loss: 1.60488 - acc: 0.6478 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1839  | total loss: \u001b[1m\u001b[32m1.49903\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1839 | loss: 1.49903 - acc: 0.6830 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1840  | total loss: \u001b[1m\u001b[32m1.40275\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1840 | loss: 1.40275 - acc: 0.7147 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1841  | total loss: \u001b[1m\u001b[32m1.31447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1841 | loss: 1.31447 - acc: 0.7433 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1842  | total loss: \u001b[1m\u001b[32m1.50345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1842 | loss: 1.50345 - acc: 0.6832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1843  | total loss: \u001b[1m\u001b[32m1.40189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1843 | loss: 1.40189 - acc: 0.7149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1844  | total loss: \u001b[1m\u001b[32m1.30888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1844 | loss: 1.30888 - acc: 0.7434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1845  | total loss: \u001b[1m\u001b[32m1.22315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1845 | loss: 1.22315 - acc: 0.7691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1846  | total loss: \u001b[1m\u001b[32m1.14363\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1846 | loss: 1.14363 - acc: 0.7922 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1847  | total loss: \u001b[1m\u001b[32m1.06945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1847 | loss: 1.06945 - acc: 0.8129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1848  | total loss: \u001b[1m\u001b[32m1.32247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1848 | loss: 1.32247 - acc: 0.7388 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1849  | total loss: \u001b[1m\u001b[32m1.22626\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1849 | loss: 1.22626 - acc: 0.7649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1850  | total loss: \u001b[1m\u001b[32m1.13801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1850 | loss: 1.13801 - acc: 0.7884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1851  | total loss: \u001b[1m\u001b[32m1.05673\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1851 | loss: 1.05673 - acc: 0.8096 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1852  | total loss: \u001b[1m\u001b[32m1.31600\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1852 | loss: 1.31600 - acc: 0.7358 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1853  | total loss: \u001b[1m\u001b[32m1.21415\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1853 | loss: 1.21415 - acc: 0.7622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1854  | total loss: \u001b[1m\u001b[32m1.45818\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1854 | loss: 1.45818 - acc: 0.7003 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1855  | total loss: \u001b[1m\u001b[32m1.34115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1855 | loss: 1.34115 - acc: 0.7302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1856  | total loss: \u001b[1m\u001b[32m1.23557\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1856 | loss: 1.23557 - acc: 0.7572 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1857  | total loss: \u001b[1m\u001b[32m1.13998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1857 | loss: 1.13998 - acc: 0.7815 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1858  | total loss: \u001b[1m\u001b[32m1.05315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1858 | loss: 1.05315 - acc: 0.8033 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1859  | total loss: \u001b[1m\u001b[32m0.97399\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1859 | loss: 0.97399 - acc: 0.8230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1860  | total loss: \u001b[1m\u001b[32m1.19432\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1860 | loss: 1.19432 - acc: 0.7621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1861  | total loss: \u001b[1m\u001b[32m1.09953\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1861 | loss: 1.09953 - acc: 0.7859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1862  | total loss: \u001b[1m\u001b[32m1.34821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1862 | loss: 1.34821 - acc: 0.7216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1863  | total loss: \u001b[1m\u001b[32m1.23783\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1863 | loss: 1.23783 - acc: 0.7495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1864  | total loss: \u001b[1m\u001b[32m1.54662\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1864 | loss: 1.54662 - acc: 0.6745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1865  | total loss: \u001b[1m\u001b[32m1.41757\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1865 | loss: 1.41757 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1866  | total loss: \u001b[1m\u001b[32m1.30217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1866 | loss: 1.30217 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1867  | total loss: \u001b[1m\u001b[32m1.19868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1867 | loss: 1.19868 - acc: 0.7627 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1868  | total loss: \u001b[1m\u001b[32m1.10557\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1868 | loss: 1.10557 - acc: 0.7864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1869  | total loss: \u001b[1m\u001b[32m1.02147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1869 | loss: 1.02147 - acc: 0.8078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1870  | total loss: \u001b[1m\u001b[32m0.94521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1870 | loss: 0.94521 - acc: 0.8270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1871  | total loss: \u001b[1m\u001b[32m0.87577\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1871 | loss: 0.87577 - acc: 0.8443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1872  | total loss: \u001b[1m\u001b[32m0.81227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1872 | loss: 0.81227 - acc: 0.8599 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1873  | total loss: \u001b[1m\u001b[32m0.75397\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1873 | loss: 0.75397 - acc: 0.8739 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1874  | total loss: \u001b[1m\u001b[32m0.70025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1874 | loss: 0.70025 - acc: 0.8865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1875  | total loss: \u001b[1m\u001b[32m0.65059\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1875 | loss: 0.65059 - acc: 0.8979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1876  | total loss: \u001b[1m\u001b[32m1.01219\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1876 | loss: 1.01219 - acc: 0.8081 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1877  | total loss: \u001b[1m\u001b[32m0.92979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1877 | loss: 0.92979 - acc: 0.8273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1878  | total loss: \u001b[1m\u001b[32m1.25949\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1878 | loss: 1.25949 - acc: 0.7517 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1879  | total loss: \u001b[1m\u001b[32m1.15259\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1879 | loss: 1.15259 - acc: 0.7765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1880  | total loss: \u001b[1m\u001b[32m1.05675\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1880 | loss: 1.05675 - acc: 0.7989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1881  | total loss: \u001b[1m\u001b[32m0.97065\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1881 | loss: 0.97065 - acc: 0.8190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1882  | total loss: \u001b[1m\u001b[32m0.89311\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1882 | loss: 0.89311 - acc: 0.8371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1883  | total loss: \u001b[1m\u001b[32m0.82309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1883 | loss: 0.82309 - acc: 0.8534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1884  | total loss: \u001b[1m\u001b[32m1.19040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1884 | loss: 1.19040 - acc: 0.7680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1885  | total loss: \u001b[1m\u001b[32m1.09081\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1885 | loss: 1.09081 - acc: 0.7912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1886  | total loss: \u001b[1m\u001b[32m1.38201\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1886 | loss: 1.38201 - acc: 0.7192 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1887  | total loss: \u001b[1m\u001b[32m1.26479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1887 | loss: 1.26479 - acc: 0.7473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1888  | total loss: \u001b[1m\u001b[32m1.55899\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1888 | loss: 1.55899 - acc: 0.6726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1889  | total loss: \u001b[1m\u001b[32m1.42687\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1889 | loss: 1.42687 - acc: 0.7053 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1890  | total loss: \u001b[1m\u001b[32m1.30951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1890 | loss: 1.30951 - acc: 0.7348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1891  | total loss: \u001b[1m\u001b[32m1.20501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1891 | loss: 1.20501 - acc: 0.7613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1892  | total loss: \u001b[1m\u001b[32m1.44824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1892 | loss: 1.44824 - acc: 0.6995 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1893  | total loss: \u001b[1m\u001b[32m1.33216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1893 | loss: 1.33216 - acc: 0.7295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1894  | total loss: \u001b[1m\u001b[32m1.61347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1894 | loss: 1.61347 - acc: 0.6566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1895  | total loss: \u001b[1m\u001b[32m1.48419\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1895 | loss: 1.48419 - acc: 0.6909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1896  | total loss: \u001b[1m\u001b[32m1.36950\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1896 | loss: 1.36950 - acc: 0.7218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1897  | total loss: \u001b[1m\u001b[32m1.26737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1897 | loss: 1.26737 - acc: 0.7496 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1898  | total loss: \u001b[1m\u001b[32m1.56022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1898 | loss: 1.56022 - acc: 0.6747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1899  | total loss: \u001b[1m\u001b[32m1.44113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1899 | loss: 1.44113 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1900  | total loss: \u001b[1m\u001b[32m1.69573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1900 | loss: 1.69573 - acc: 0.6365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1901  | total loss: \u001b[1m\u001b[32m1.56617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1901 | loss: 1.56617 - acc: 0.6728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1902  | total loss: \u001b[1m\u001b[32m1.72732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1902 | loss: 1.72732 - acc: 0.6198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1903  | total loss: \u001b[1m\u001b[32m1.59825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1903 | loss: 1.59825 - acc: 0.6579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1904  | total loss: \u001b[1m\u001b[32m1.78513\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1904 | loss: 1.78513 - acc: 0.5992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1905  | total loss: \u001b[1m\u001b[32m1.65415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1905 | loss: 1.65415 - acc: 0.6393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1906  | total loss: \u001b[1m\u001b[32m1.53780\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1906 | loss: 1.53780 - acc: 0.6754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1907  | total loss: \u001b[1m\u001b[32m1.43378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1907 | loss: 1.43378 - acc: 0.7078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1908  | total loss: \u001b[1m\u001b[32m1.64668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1908 | loss: 1.64668 - acc: 0.6442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1909  | total loss: \u001b[1m\u001b[32m1.53262\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1909 | loss: 1.53262 - acc: 0.6798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1910  | total loss: \u001b[1m\u001b[32m1.43010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1910 | loss: 1.43010 - acc: 0.7118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1911  | total loss: \u001b[1m\u001b[32m1.33722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1911 | loss: 1.33722 - acc: 0.7406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1912  | total loss: \u001b[1m\u001b[32m1.53546\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1912 | loss: 1.53546 - acc: 0.6737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1913  | total loss: \u001b[1m\u001b[32m1.43065\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1913 | loss: 1.43065 - acc: 0.7063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1914  | total loss: \u001b[1m\u001b[32m1.33551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1914 | loss: 1.33551 - acc: 0.7357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1915  | total loss: \u001b[1m\u001b[32m1.24850\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1915 | loss: 1.24850 - acc: 0.7621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1916  | total loss: \u001b[1m\u001b[32m1.16833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1916 | loss: 1.16833 - acc: 0.7859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1917  | total loss: \u001b[1m\u001b[32m1.09393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1917 | loss: 1.09393 - acc: 0.8073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1918  | total loss: \u001b[1m\u001b[32m1.34473\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1918 | loss: 1.34473 - acc: 0.7266 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1919  | total loss: \u001b[1m\u001b[32m1.24914\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1919 | loss: 1.24914 - acc: 0.7539 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1920  | total loss: \u001b[1m\u001b[32m1.53420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1920 | loss: 1.53420 - acc: 0.6785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1921  | total loss: \u001b[1m\u001b[32m1.41812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1921 | loss: 1.41812 - acc: 0.7107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1922  | total loss: \u001b[1m\u001b[32m1.67218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1922 | loss: 1.67218 - acc: 0.6396 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1923  | total loss: \u001b[1m\u001b[32m1.54244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1923 | loss: 1.54244 - acc: 0.6757 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1924  | total loss: \u001b[1m\u001b[32m1.76807\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1924 | loss: 1.76807 - acc: 0.6081 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1925  | total loss: \u001b[1m\u001b[32m1.63020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1925 | loss: 1.63020 - acc: 0.6473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1926  | total loss: \u001b[1m\u001b[32m1.50678\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1926 | loss: 1.50678 - acc: 0.6826 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1927  | total loss: \u001b[1m\u001b[32m1.39576\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1927 | loss: 1.39576 - acc: 0.7143 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1928  | total loss: \u001b[1m\u001b[32m1.29539\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1928 | loss: 1.29539 - acc: 0.7429 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1929  | total loss: \u001b[1m\u001b[32m1.20412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1929 | loss: 1.20412 - acc: 0.7686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1930  | total loss: \u001b[1m\u001b[32m1.12065\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1930 | loss: 1.12065 - acc: 0.7917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1931  | total loss: \u001b[1m\u001b[32m1.04389\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1931 | loss: 1.04389 - acc: 0.8125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1932  | total loss: \u001b[1m\u001b[32m0.97293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1932 | loss: 0.97293 - acc: 0.8313 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1933  | total loss: \u001b[1m\u001b[32m0.90702\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1933 | loss: 0.90702 - acc: 0.8482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1934  | total loss: \u001b[1m\u001b[32m1.14960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1934 | loss: 1.14960 - acc: 0.7776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1935  | total loss: \u001b[1m\u001b[32m1.06289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1935 | loss: 1.06289 - acc: 0.7999 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1936  | total loss: \u001b[1m\u001b[32m0.98367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1936 | loss: 0.98367 - acc: 0.8199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1937  | total loss: \u001b[1m\u001b[32m0.91102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1937 | loss: 0.91102 - acc: 0.8379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1938  | total loss: \u001b[1m\u001b[32m0.84421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1938 | loss: 0.84421 - acc: 0.8541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1939  | total loss: \u001b[1m\u001b[32m0.78259\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1939 | loss: 0.78259 - acc: 0.8687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1940  | total loss: \u001b[1m\u001b[32m0.72562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1940 | loss: 0.72562 - acc: 0.8818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1941  | total loss: \u001b[1m\u001b[32m0.67284\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1941 | loss: 0.67284 - acc: 0.8936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1942  | total loss: \u001b[1m\u001b[32m1.04830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1942 | loss: 1.04830 - acc: 0.8043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1943  | total loss: \u001b[1m\u001b[32m0.96138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1943 | loss: 0.96138 - acc: 0.8239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1944  | total loss: \u001b[1m\u001b[32m1.30123\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1944 | loss: 1.30123 - acc: 0.7486 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1945  | total loss: \u001b[1m\u001b[32m1.18888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1945 | loss: 1.18888 - acc: 0.7737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1946  | total loss: \u001b[1m\u001b[32m1.46626\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1946 | loss: 1.46626 - acc: 0.7107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1947  | total loss: \u001b[1m\u001b[32m1.33861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1947 | loss: 1.33861 - acc: 0.7396 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1948  | total loss: \u001b[1m\u001b[32m1.22448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1948 | loss: 1.22448 - acc: 0.7656 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1949  | total loss: \u001b[1m\u001b[32m1.12229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1949 | loss: 1.12229 - acc: 0.7891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1950  | total loss: \u001b[1m\u001b[32m1.03060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1950 | loss: 1.03060 - acc: 0.8102 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1951  | total loss: \u001b[1m\u001b[32m0.94813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1951 | loss: 0.94813 - acc: 0.8291 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1952  | total loss: \u001b[1m\u001b[32m1.26062\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1952 | loss: 1.26062 - acc: 0.7534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1953  | total loss: \u001b[1m\u001b[32m1.15574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1953 | loss: 1.15574 - acc: 0.7780 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1954  | total loss: \u001b[1m\u001b[32m1.44374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1954 | loss: 1.44374 - acc: 0.7074 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1955  | total loss: \u001b[1m\u001b[32m1.32247\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1955 | loss: 1.32247 - acc: 0.7366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1956  | total loss: \u001b[1m\u001b[32m1.21443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1956 | loss: 1.21443 - acc: 0.7630 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1957  | total loss: \u001b[1m\u001b[32m1.11793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1957 | loss: 1.11793 - acc: 0.7867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1958  | total loss: \u001b[1m\u001b[32m1.39141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1958 | loss: 1.39141 - acc: 0.7152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1959  | total loss: \u001b[1m\u001b[32m1.27892\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1959 | loss: 1.27892 - acc: 0.7436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1960  | total loss: \u001b[1m\u001b[32m1.17859\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1960 | loss: 1.17859 - acc: 0.7693 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1961  | total loss: \u001b[1m\u001b[32m1.08878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1961 | loss: 1.08878 - acc: 0.7923 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1962  | total loss: \u001b[1m\u001b[32m1.00806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1962 | loss: 1.00806 - acc: 0.8131 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1963  | total loss: \u001b[1m\u001b[32m0.93516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1963 | loss: 0.93516 - acc: 0.8318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1964  | total loss: \u001b[1m\u001b[32m1.20648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1964 | loss: 1.20648 - acc: 0.7629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1965  | total loss: \u001b[1m\u001b[32m1.11355\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1965 | loss: 1.11355 - acc: 0.7866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1966  | total loss: \u001b[1m\u001b[32m1.40089\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1966 | loss: 1.40089 - acc: 0.7151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1967  | total loss: \u001b[1m\u001b[32m1.28960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1967 | loss: 1.28960 - acc: 0.7436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1968  | total loss: \u001b[1m\u001b[32m1.48867\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1968 | loss: 1.48867 - acc: 0.6907 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1969  | total loss: \u001b[1m\u001b[32m1.37069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1969 | loss: 1.37069 - acc: 0.7216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1970  | total loss: \u001b[1m\u001b[32m1.26547\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 1970 | loss: 1.26547 - acc: 0.7494 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1971  | total loss: \u001b[1m\u001b[32m1.17126\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1971 | loss: 1.17126 - acc: 0.7745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1972  | total loss: \u001b[1m\u001b[32m1.43850\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1972 | loss: 1.43850 - acc: 0.7042 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1973  | total loss: \u001b[1m\u001b[32m1.32810\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1973 | loss: 1.32810 - acc: 0.7338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1974  | total loss: \u001b[1m\u001b[32m1.54985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1974 | loss: 1.54985 - acc: 0.6675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1975  | total loss: \u001b[1m\u001b[32m1.43040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1975 | loss: 1.43040 - acc: 0.7008 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1976  | total loss: \u001b[1m\u001b[32m1.32385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1976 | loss: 1.32385 - acc: 0.7307 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1977  | total loss: \u001b[1m\u001b[32m1.22835\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1977 | loss: 1.22835 - acc: 0.7576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1978  | total loss: \u001b[1m\u001b[32m1.44098\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1978 | loss: 1.44098 - acc: 0.6890 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1979  | total loss: \u001b[1m\u001b[32m1.33460\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1979 | loss: 1.33460 - acc: 0.7201 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1980  | total loss: \u001b[1m\u001b[32m1.57636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1980 | loss: 1.57636 - acc: 0.6552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1981  | total loss: \u001b[1m\u001b[32m1.45818\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1981 | loss: 1.45818 - acc: 0.6897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1982  | total loss: \u001b[1m\u001b[32m1.67010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1982 | loss: 1.67010 - acc: 0.6279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1983  | total loss: \u001b[1m\u001b[32m1.54497\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1983 | loss: 1.54497 - acc: 0.6651 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1984  | total loss: \u001b[1m\u001b[32m1.70166\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1984 | loss: 1.70166 - acc: 0.6129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1985  | total loss: \u001b[1m\u001b[32m1.57621\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1985 | loss: 1.57621 - acc: 0.6516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1986  | total loss: \u001b[1m\u001b[32m1.46438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1986 | loss: 1.46438 - acc: 0.6864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1987  | total loss: \u001b[1m\u001b[32m1.36409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1987 | loss: 1.36409 - acc: 0.7178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1988  | total loss: \u001b[1m\u001b[32m1.49169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1988 | loss: 1.49169 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1989  | total loss: \u001b[1m\u001b[32m1.38876\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1989 | loss: 1.38876 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1990  | total loss: \u001b[1m\u001b[32m1.29587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1990 | loss: 1.29587 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1991  | total loss: \u001b[1m\u001b[32m1.21140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1991 | loss: 1.21140 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1992  | total loss: \u001b[1m\u001b[32m1.13400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1992 | loss: 1.13400 - acc: 0.7865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1993  | total loss: \u001b[1m\u001b[32m1.06252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1993 | loss: 1.06252 - acc: 0.8078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1994  | total loss: \u001b[1m\u001b[32m1.30648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1994 | loss: 1.30648 - acc: 0.7342 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1995  | total loss: \u001b[1m\u001b[32m1.21465\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 1995 | loss: 1.21465 - acc: 0.7608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1996  | total loss: \u001b[1m\u001b[32m1.45173\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1996 | loss: 1.45173 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1997  | total loss: \u001b[1m\u001b[32m1.34393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 1997 | loss: 1.34393 - acc: 0.7227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1998  | total loss: \u001b[1m\u001b[32m1.54232\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1998 | loss: 1.54232 - acc: 0.6647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 1999  | total loss: \u001b[1m\u001b[32m1.42521\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 1999 | loss: 1.42521 - acc: 0.6982 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2000  | total loss: \u001b[1m\u001b[32m1.31961\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2000 | loss: 1.31961 - acc: 0.7284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2001  | total loss: \u001b[1m\u001b[32m1.22390\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2001 | loss: 1.22390 - acc: 0.7556 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2002  | total loss: \u001b[1m\u001b[32m1.13671\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2002 | loss: 1.13671 - acc: 0.7800 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2003  | total loss: \u001b[1m\u001b[32m1.05685\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2003 | loss: 1.05685 - acc: 0.8020 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2004  | total loss: \u001b[1m\u001b[32m0.98334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2004 | loss: 0.98334 - acc: 0.8218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2005  | total loss: \u001b[1m\u001b[32m0.91535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2005 | loss: 0.91535 - acc: 0.8396 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2006  | total loss: \u001b[1m\u001b[32m1.20159\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2006 | loss: 1.20159 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2007  | total loss: \u001b[1m\u001b[32m1.10919\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2007 | loss: 1.10919 - acc: 0.7865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2008  | total loss: \u001b[1m\u001b[32m1.35513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2008 | loss: 1.35513 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2009  | total loss: \u001b[1m\u001b[32m1.24658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2009 | loss: 1.24658 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2010  | total loss: \u001b[1m\u001b[32m1.54688\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2010 | loss: 1.54688 - acc: 0.6749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2011  | total loss: \u001b[1m\u001b[32m1.41979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2011 | loss: 1.41979 - acc: 0.7074 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2012  | total loss: \u001b[1m\u001b[32m1.30590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2012 | loss: 1.30590 - acc: 0.7367 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2013  | total loss: \u001b[1m\u001b[32m1.20350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2013 | loss: 1.20350 - acc: 0.7630 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2014  | total loss: \u001b[1m\u001b[32m1.11112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2014 | loss: 1.11112 - acc: 0.7867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2015  | total loss: \u001b[1m\u001b[32m1.02745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2015 | loss: 1.02745 - acc: 0.8081 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2016  | total loss: \u001b[1m\u001b[32m1.30458\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2016 | loss: 1.30458 - acc: 0.7344 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2017  | total loss: \u001b[1m\u001b[32m1.20105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2017 | loss: 1.20105 - acc: 0.7610 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2018  | total loss: \u001b[1m\u001b[32m1.10781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2018 | loss: 1.10781 - acc: 0.7849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2019  | total loss: \u001b[1m\u001b[32m1.02355\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2019 | loss: 1.02355 - acc: 0.8064 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2020  | total loss: \u001b[1m\u001b[32m0.94710\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2020 | loss: 0.94710 - acc: 0.8257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2021  | total loss: \u001b[1m\u001b[32m0.87745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2021 | loss: 0.87745 - acc: 0.8432 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2022  | total loss: \u001b[1m\u001b[32m0.81376\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2022 | loss: 0.81376 - acc: 0.8588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2023  | total loss: \u001b[1m\u001b[32m0.75530\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2023 | loss: 0.75530 - acc: 0.8730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2024  | total loss: \u001b[1m\u001b[32m1.05465\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2024 | loss: 1.05465 - acc: 0.8000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2025  | total loss: \u001b[1m\u001b[32m0.97058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2025 | loss: 0.97058 - acc: 0.8200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2026  | total loss: \u001b[1m\u001b[32m1.32446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2026 | loss: 1.32446 - acc: 0.7380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2027  | total loss: \u001b[1m\u001b[32m1.21353\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2027 | loss: 1.21353 - acc: 0.7642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2028  | total loss: \u001b[1m\u001b[32m1.51066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2028 | loss: 1.51066 - acc: 0.6949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2029  | total loss: \u001b[1m\u001b[32m1.38269\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2029 | loss: 1.38269 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2030  | total loss: \u001b[1m\u001b[32m1.66520\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2030 | loss: 1.66520 - acc: 0.6529 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2031  | total loss: \u001b[1m\u001b[32m1.52470\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2031 | loss: 1.52470 - acc: 0.6876 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2032  | total loss: \u001b[1m\u001b[32m1.77398\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2032 | loss: 1.77398 - acc: 0.6188 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2033  | total loss: \u001b[1m\u001b[32m1.62687\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2033 | loss: 1.62687 - acc: 0.6569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2034  | total loss: \u001b[1m\u001b[32m1.49666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2034 | loss: 1.49666 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2035  | total loss: \u001b[1m\u001b[32m1.38111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2035 | loss: 1.38111 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2036  | total loss: \u001b[1m\u001b[32m1.27819\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2036 | loss: 1.27819 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2037  | total loss: \u001b[1m\u001b[32m1.18609\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2037 | loss: 1.18609 - acc: 0.7749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2038  | total loss: \u001b[1m\u001b[32m1.10319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2038 | loss: 1.10319 - acc: 0.7974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2039  | total loss: \u001b[1m\u001b[32m1.02810\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2039 | loss: 1.02810 - acc: 0.8177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2040  | total loss: \u001b[1m\u001b[32m1.26485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2040 | loss: 1.26485 - acc: 0.7502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2041  | total loss: \u001b[1m\u001b[32m1.17288\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2041 | loss: 1.17288 - acc: 0.7752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2042  | total loss: \u001b[1m\u001b[32m1.45589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2042 | loss: 1.45589 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2043  | total loss: \u001b[1m\u001b[32m1.34537\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2043 | loss: 1.34537 - acc: 0.7343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2044  | total loss: \u001b[1m\u001b[32m1.24622\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2044 | loss: 1.24622 - acc: 0.7609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2045  | total loss: \u001b[1m\u001b[32m1.15680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2045 | loss: 1.15680 - acc: 0.7848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2046  | total loss: \u001b[1m\u001b[32m1.35196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2046 | loss: 1.35196 - acc: 0.7278 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2047  | total loss: \u001b[1m\u001b[32m1.25166\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2047 | loss: 1.25166 - acc: 0.7550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2048  | total loss: \u001b[1m\u001b[32m1.46432\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2048 | loss: 1.46432 - acc: 0.6938 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2049  | total loss: \u001b[1m\u001b[32m1.35336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2049 | loss: 1.35336 - acc: 0.7244 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2050  | total loss: \u001b[1m\u001b[32m1.60648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2050 | loss: 1.60648 - acc: 0.6519 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2051  | total loss: \u001b[1m\u001b[32m1.48299\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2051 | loss: 1.48299 - acc: 0.6868 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2052  | total loss: \u001b[1m\u001b[32m1.37269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2052 | loss: 1.37269 - acc: 0.7181 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2053  | total loss: \u001b[1m\u001b[32m1.27369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2053 | loss: 1.27369 - acc: 0.7463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2054  | total loss: \u001b[1m\u001b[32m1.51944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2054 | loss: 1.51944 - acc: 0.6716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2055  | total loss: \u001b[1m\u001b[32m1.40644\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2055 | loss: 1.40644 - acc: 0.7045 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2056  | total loss: \u001b[1m\u001b[32m1.30509\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2056 | loss: 1.30509 - acc: 0.7340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2057  | total loss: \u001b[1m\u001b[32m1.21365\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2057 | loss: 1.21365 - acc: 0.7606 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2058  | total loss: \u001b[1m\u001b[32m1.48681\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2058 | loss: 1.48681 - acc: 0.6846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2059  | total loss: \u001b[1m\u001b[32m1.37690\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2059 | loss: 1.37690 - acc: 0.7161 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2060  | total loss: \u001b[1m\u001b[32m1.61129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2060 | loss: 1.61129 - acc: 0.6516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2061  | total loss: \u001b[1m\u001b[32m1.48975\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2061 | loss: 1.48975 - acc: 0.6865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2062  | total loss: \u001b[1m\u001b[32m1.68050\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2062 | loss: 1.68050 - acc: 0.6321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2063  | total loss: \u001b[1m\u001b[32m1.55365\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2063 | loss: 1.55365 - acc: 0.6689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2064  | total loss: \u001b[1m\u001b[32m1.72917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2064 | loss: 1.72917 - acc: 0.6092 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2065  | total loss: \u001b[1m\u001b[32m1.59979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2065 | loss: 1.59979 - acc: 0.6482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2066  | total loss: \u001b[1m\u001b[32m1.80604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2066 | loss: 1.80604 - acc: 0.5834 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2067  | total loss: \u001b[1m\u001b[32m1.67212\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2067 | loss: 1.67212 - acc: 0.6251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2068  | total loss: \u001b[1m\u001b[32m1.84887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2068 | loss: 1.84887 - acc: 0.5626 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2069  | total loss: \u001b[1m\u001b[32m1.71434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2069 | loss: 1.71434 - acc: 0.6063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2070  | total loss: \u001b[1m\u001b[32m1.59469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2070 | loss: 1.59469 - acc: 0.6457 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2071  | total loss: \u001b[1m\u001b[32m1.48753\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2071 | loss: 1.48753 - acc: 0.6811 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2072  | total loss: \u001b[1m\u001b[32m1.39076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2072 | loss: 1.39076 - acc: 0.7130 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2073  | total loss: \u001b[1m\u001b[32m1.30262\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2073 | loss: 1.30262 - acc: 0.7417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2074  | total loss: \u001b[1m\u001b[32m1.22160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2074 | loss: 1.22160 - acc: 0.7675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2075  | total loss: \u001b[1m\u001b[32m1.14648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2075 | loss: 1.14648 - acc: 0.7908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2076  | total loss: \u001b[1m\u001b[32m1.40616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2076 | loss: 1.40616 - acc: 0.7117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2077  | total loss: \u001b[1m\u001b[32m1.30880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2077 | loss: 1.30880 - acc: 0.7405 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2078  | total loss: \u001b[1m\u001b[32m1.21955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2078 | loss: 1.21955 - acc: 0.7665 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2079  | total loss: \u001b[1m\u001b[32m1.13723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2079 | loss: 1.13723 - acc: 0.7898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2080  | total loss: \u001b[1m\u001b[32m1.06088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2080 | loss: 1.06088 - acc: 0.8108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2081  | total loss: \u001b[1m\u001b[32m0.98974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2081 | loss: 0.98974 - acc: 0.8298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2082  | total loss: \u001b[1m\u001b[32m1.20557\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2082 | loss: 1.20557 - acc: 0.7682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2083  | total loss: \u001b[1m\u001b[32m1.11602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2083 | loss: 1.11602 - acc: 0.7914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2084  | total loss: \u001b[1m\u001b[32m1.41655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2084 | loss: 1.41655 - acc: 0.7123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2085  | total loss: \u001b[1m\u001b[32m1.30408\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2085 | loss: 1.30408 - acc: 0.7410 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2086  | total loss: \u001b[1m\u001b[32m1.59769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2086 | loss: 1.59769 - acc: 0.6669 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2087  | total loss: \u001b[1m\u001b[32m1.46714\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2087 | loss: 1.46714 - acc: 0.7002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2088  | total loss: \u001b[1m\u001b[32m1.34986\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2088 | loss: 1.34986 - acc: 0.7302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2089  | total loss: \u001b[1m\u001b[32m1.24415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2089 | loss: 1.24415 - acc: 0.7572 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2090  | total loss: \u001b[1m\u001b[32m1.52796\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2090 | loss: 1.52796 - acc: 0.6815 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2091  | total loss: \u001b[1m\u001b[32m1.40475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2091 | loss: 1.40475 - acc: 0.7133 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2092  | total loss: \u001b[1m\u001b[32m1.65821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2092 | loss: 1.65821 - acc: 0.6491 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2093  | total loss: \u001b[1m\u001b[32m1.52385\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2093 | loss: 1.52385 - acc: 0.6842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2094  | total loss: \u001b[1m\u001b[32m1.40394\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2094 | loss: 1.40394 - acc: 0.7158 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2095  | total loss: \u001b[1m\u001b[32m1.29653\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2095 | loss: 1.29653 - acc: 0.7442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2096  | total loss: \u001b[1m\u001b[32m1.51499\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2096 | loss: 1.51499 - acc: 0.6841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2097  | total loss: \u001b[1m\u001b[32m1.39745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2097 | loss: 1.39745 - acc: 0.7157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2098  | total loss: \u001b[1m\u001b[32m1.63824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2098 | loss: 1.63824 - acc: 0.6441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2099  | total loss: \u001b[1m\u001b[32m1.51035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2099 | loss: 1.51035 - acc: 0.6797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2100  | total loss: \u001b[1m\u001b[32m1.71203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2100 | loss: 1.71203 - acc: 0.6260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2101  | total loss: \u001b[1m\u001b[32m1.57964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2101 | loss: 1.57964 - acc: 0.6634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2102  | total loss: \u001b[1m\u001b[32m1.46173\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2102 | loss: 1.46173 - acc: 0.6971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2103  | total loss: \u001b[1m\u001b[32m1.35620\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2103 | loss: 1.35620 - acc: 0.7274 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2104  | total loss: \u001b[1m\u001b[32m1.57881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2104 | loss: 1.57881 - acc: 0.6618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2105  | total loss: \u001b[1m\u001b[32m1.46248\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2105 | loss: 1.46248 - acc: 0.6956 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2106  | total loss: \u001b[1m\u001b[32m1.68883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2106 | loss: 1.68883 - acc: 0.6332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2107  | total loss: \u001b[1m\u001b[32m1.56322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2107 | loss: 1.56322 - acc: 0.6699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2108  | total loss: \u001b[1m\u001b[32m1.45091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2108 | loss: 1.45091 - acc: 0.7029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2109  | total loss: \u001b[1m\u001b[32m1.34987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2109 | loss: 1.34987 - acc: 0.7326 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2110  | total loss: \u001b[1m\u001b[32m1.61390\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2110 | loss: 1.61390 - acc: 0.6593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2111  | total loss: \u001b[1m\u001b[32m1.49659\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2111 | loss: 1.49659 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2112  | total loss: \u001b[1m\u001b[32m1.74109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2112 | loss: 1.74109 - acc: 0.6241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2113  | total loss: \u001b[1m\u001b[32m1.61219\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2113 | loss: 1.61219 - acc: 0.6616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2114  | total loss: \u001b[1m\u001b[32m1.49666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2114 | loss: 1.49666 - acc: 0.6955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2115  | total loss: \u001b[1m\u001b[32m1.39249\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2115 | loss: 1.39249 - acc: 0.7259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2116  | total loss: \u001b[1m\u001b[32m1.29795\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2116 | loss: 1.29795 - acc: 0.7533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2117  | total loss: \u001b[1m\u001b[32m1.21156\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2117 | loss: 1.21156 - acc: 0.7780 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2118  | total loss: \u001b[1m\u001b[32m1.42917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2118 | loss: 1.42917 - acc: 0.7074 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2119  | total loss: \u001b[1m\u001b[32m1.32745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2119 | loss: 1.32745 - acc: 0.7366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2120  | total loss: \u001b[1m\u001b[32m1.55185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2120 | loss: 1.55185 - acc: 0.6701 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2121  | total loss: \u001b[1m\u001b[32m1.43702\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2121 | loss: 1.43702 - acc: 0.7031 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2122  | total loss: \u001b[1m\u001b[32m1.61201\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2122 | loss: 1.61201 - acc: 0.6471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2123  | total loss: \u001b[1m\u001b[32m1.49130\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2123 | loss: 1.49130 - acc: 0.6824 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2124  | total loss: \u001b[1m\u001b[32m1.38263\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2124 | loss: 1.38263 - acc: 0.7141 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2125  | total loss: \u001b[1m\u001b[32m1.28428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2125 | loss: 1.28428 - acc: 0.7427 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2126  | total loss: \u001b[1m\u001b[32m1.52399\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2126 | loss: 1.52399 - acc: 0.6756 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2127  | total loss: \u001b[1m\u001b[32m1.41066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2127 | loss: 1.41066 - acc: 0.7080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2128  | total loss: \u001b[1m\u001b[32m1.61162\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2128 | loss: 1.61162 - acc: 0.6444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2129  | total loss: \u001b[1m\u001b[32m1.48985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2129 | loss: 1.48985 - acc: 0.6799 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2130  | total loss: \u001b[1m\u001b[32m1.70384\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2130 | loss: 1.70384 - acc: 0.6191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2131  | total loss: \u001b[1m\u001b[32m1.57410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2131 | loss: 1.57410 - acc: 0.6572 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2132  | total loss: \u001b[1m\u001b[32m1.73591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2132 | loss: 1.73591 - acc: 0.6129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2133  | total loss: \u001b[1m\u001b[32m1.60478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2133 | loss: 1.60478 - acc: 0.6516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2134  | total loss: \u001b[1m\u001b[32m1.48737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2134 | loss: 1.48737 - acc: 0.6864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2135  | total loss: \u001b[1m\u001b[32m1.38166\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2135 | loss: 1.38166 - acc: 0.7178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2136  | total loss: \u001b[1m\u001b[32m1.63566\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2136 | loss: 1.63566 - acc: 0.6460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2137  | total loss: \u001b[1m\u001b[32m1.51514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2137 | loss: 1.51514 - acc: 0.6814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2138  | total loss: \u001b[1m\u001b[32m1.69755\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2138 | loss: 1.69755 - acc: 0.6204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2139  | total loss: \u001b[1m\u001b[32m1.57189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2139 | loss: 1.57189 - acc: 0.6584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2140  | total loss: \u001b[1m\u001b[32m1.45918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2140 | loss: 1.45918 - acc: 0.6925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2141  | total loss: \u001b[1m\u001b[32m1.35746\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2141 | loss: 1.35746 - acc: 0.7233 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2142  | total loss: \u001b[1m\u001b[32m1.26507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2142 | loss: 1.26507 - acc: 0.7510 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2143  | total loss: \u001b[1m\u001b[32m1.18057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2143 | loss: 1.18057 - acc: 0.7759 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2144  | total loss: \u001b[1m\u001b[32m1.10277\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2144 | loss: 1.10277 - acc: 0.7983 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2145  | total loss: \u001b[1m\u001b[32m1.03068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2145 | loss: 1.03068 - acc: 0.8184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2146  | total loss: \u001b[1m\u001b[32m1.25664\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2146 | loss: 1.25664 - acc: 0.7580 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2147  | total loss: \u001b[1m\u001b[32m1.16569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2147 | loss: 1.16569 - acc: 0.7822 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2148  | total loss: \u001b[1m\u001b[32m1.36513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2148 | loss: 1.36513 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2149  | total loss: \u001b[1m\u001b[32m1.26140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2149 | loss: 1.26140 - acc: 0.7529 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2150  | total loss: \u001b[1m\u001b[32m1.16724\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2150 | loss: 1.16724 - acc: 0.7776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2151  | total loss: \u001b[1m\u001b[32m1.08140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2151 | loss: 1.08140 - acc: 0.7998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2152  | total loss: \u001b[1m\u001b[32m1.00281\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2152 | loss: 1.00281 - acc: 0.8199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2153  | total loss: \u001b[1m\u001b[32m0.93057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2153 | loss: 0.93057 - acc: 0.8379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2154  | total loss: \u001b[1m\u001b[32m0.86391\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2154 | loss: 0.86391 - acc: 0.8541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2155  | total loss: \u001b[1m\u001b[32m0.80222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2155 | loss: 0.80222 - acc: 0.8687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2156  | total loss: \u001b[1m\u001b[32m0.74495\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2156 | loss: 0.74495 - acc: 0.8818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2157  | total loss: \u001b[1m\u001b[32m0.69168\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2157 | loss: 0.69168 - acc: 0.8936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2158  | total loss: \u001b[1m\u001b[32m0.64205\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2158 | loss: 0.64205 - acc: 0.9043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2159  | total loss: \u001b[1m\u001b[32m0.59576\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2159 | loss: 0.59576 - acc: 0.9138 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2160  | total loss: \u001b[1m\u001b[32m0.95856\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2160 | loss: 0.95856 - acc: 0.8367 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2161  | total loss: \u001b[1m\u001b[32m0.87844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2161 | loss: 0.87844 - acc: 0.8531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2162  | total loss: \u001b[1m\u001b[32m1.18761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2162 | loss: 1.18761 - acc: 0.7820 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2163  | total loss: \u001b[1m\u001b[32m1.08404\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2163 | loss: 1.08404 - acc: 0.8038 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2164  | total loss: \u001b[1m\u001b[32m1.43710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2164 | loss: 1.43710 - acc: 0.7235 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2165  | total loss: \u001b[1m\u001b[32m1.30936\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2165 | loss: 1.30936 - acc: 0.7511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2166  | total loss: \u001b[1m\u001b[32m1.19499\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2166 | loss: 1.19499 - acc: 0.7760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2167  | total loss: \u001b[1m\u001b[32m1.09245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2167 | loss: 1.09245 - acc: 0.7984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2168  | total loss: \u001b[1m\u001b[32m1.38266\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2168 | loss: 1.38266 - acc: 0.7257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2169  | total loss: \u001b[1m\u001b[32m1.26256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2169 | loss: 1.26256 - acc: 0.7531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2170  | total loss: \u001b[1m\u001b[32m1.58686\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2170 | loss: 1.58686 - acc: 0.6778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2171  | total loss: \u001b[1m\u001b[32m1.44877\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2171 | loss: 1.44877 - acc: 0.7100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2172  | total loss: \u001b[1m\u001b[32m1.69255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2172 | loss: 1.69255 - acc: 0.6462 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2173  | total loss: \u001b[1m\u001b[32m1.54756\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2173 | loss: 1.54756 - acc: 0.6816 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2174  | total loss: \u001b[1m\u001b[32m1.76537\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2174 | loss: 1.76537 - acc: 0.6205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2175  | total loss: \u001b[1m\u001b[32m1.61791\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2175 | loss: 1.61791 - acc: 0.6585 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2176  | total loss: \u001b[1m\u001b[32m1.86494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2176 | loss: 1.86494 - acc: 0.5926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2177  | total loss: \u001b[1m\u001b[32m1.71343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2177 | loss: 1.71343 - acc: 0.6334 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2178  | total loss: \u001b[1m\u001b[32m1.57995\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2178 | loss: 1.57995 - acc: 0.6700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2179  | total loss: \u001b[1m\u001b[32m1.46203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2179 | loss: 1.46203 - acc: 0.7030 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2180  | total loss: \u001b[1m\u001b[32m1.62246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2180 | loss: 1.62246 - acc: 0.6470 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2181  | total loss: \u001b[1m\u001b[32m1.50405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2181 | loss: 1.50405 - acc: 0.6823 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2182  | total loss: \u001b[1m\u001b[32m1.72321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2182 | loss: 1.72321 - acc: 0.6212 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2183  | total loss: \u001b[1m\u001b[32m1.59854\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2183 | loss: 1.59854 - acc: 0.6591 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2184  | total loss: \u001b[1m\u001b[32m1.76274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2184 | loss: 1.76274 - acc: 0.6003 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2185  | total loss: \u001b[1m\u001b[32m1.63794\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2185 | loss: 1.63794 - acc: 0.6403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2186  | total loss: \u001b[1m\u001b[32m1.77500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2186 | loss: 1.77500 - acc: 0.5977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2187  | total loss: \u001b[1m\u001b[32m1.65241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2187 | loss: 1.65241 - acc: 0.6379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2188  | total loss: \u001b[1m\u001b[32m1.80575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2188 | loss: 1.80575 - acc: 0.5813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2189  | total loss: \u001b[1m\u001b[32m1.68323\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2189 | loss: 1.68323 - acc: 0.6232 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2190  | total loss: \u001b[1m\u001b[32m1.84076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2190 | loss: 1.84076 - acc: 0.5680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2191  | total loss: \u001b[1m\u001b[32m1.71784\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2191 | loss: 1.71784 - acc: 0.6112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2192  | total loss: \u001b[1m\u001b[32m1.60822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2192 | loss: 1.60822 - acc: 0.6501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2193  | total loss: \u001b[1m\u001b[32m1.50964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2193 | loss: 1.50964 - acc: 0.6851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2194  | total loss: \u001b[1m\u001b[32m1.70388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2194 | loss: 1.70388 - acc: 0.6166 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2195  | total loss: \u001b[1m\u001b[32m1.59532\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2195 | loss: 1.59532 - acc: 0.6549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2196  | total loss: \u001b[1m\u001b[32m1.49712\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2196 | loss: 1.49712 - acc: 0.6894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2197  | total loss: \u001b[1m\u001b[32m1.40747\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2197 | loss: 1.40747 - acc: 0.7205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2198  | total loss: \u001b[1m\u001b[32m1.32484\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2198 | loss: 1.32484 - acc: 0.7484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2199  | total loss: \u001b[1m\u001b[32m1.24797\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2199 | loss: 1.24797 - acc: 0.7736 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2200  | total loss: \u001b[1m\u001b[32m1.45256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2200 | loss: 1.45256 - acc: 0.7034 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2201  | total loss: \u001b[1m\u001b[32m1.35831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2201 | loss: 1.35831 - acc: 0.7330 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2202  | total loss: \u001b[1m\u001b[32m1.58268\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2202 | loss: 1.58268 - acc: 0.6669 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2203  | total loss: \u001b[1m\u001b[32m1.47246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2203 | loss: 1.47246 - acc: 0.7002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2204  | total loss: \u001b[1m\u001b[32m1.37189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2204 | loss: 1.37189 - acc: 0.7302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2205  | total loss: \u001b[1m\u001b[32m1.27957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2205 | loss: 1.27957 - acc: 0.7571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2206  | total loss: \u001b[1m\u001b[32m1.48738\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2206 | loss: 1.48738 - acc: 0.6957 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2207  | total loss: \u001b[1m\u001b[32m1.38027\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2207 | loss: 1.38027 - acc: 0.7261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2208  | total loss: \u001b[1m\u001b[32m1.60325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2208 | loss: 1.60325 - acc: 0.6535 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2209  | total loss: \u001b[1m\u001b[32m1.48285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2209 | loss: 1.48285 - acc: 0.6882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2210  | total loss: \u001b[1m\u001b[32m1.37379\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2210 | loss: 1.37379 - acc: 0.7194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2211  | total loss: \u001b[1m\u001b[32m1.27453\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2211 | loss: 1.27453 - acc: 0.7474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2212  | total loss: \u001b[1m\u001b[32m1.52290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2212 | loss: 1.52290 - acc: 0.6727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2213  | total loss: \u001b[1m\u001b[32m1.40714\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2213 | loss: 1.40714 - acc: 0.7054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2214  | total loss: \u001b[1m\u001b[32m1.30238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2214 | loss: 1.30238 - acc: 0.7349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2215  | total loss: \u001b[1m\u001b[32m1.20713\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2215 | loss: 1.20713 - acc: 0.7614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2216  | total loss: \u001b[1m\u001b[32m1.12012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2216 | loss: 1.12012 - acc: 0.7852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2217  | total loss: \u001b[1m\u001b[32m1.04026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2217 | loss: 1.04026 - acc: 0.8067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2218  | total loss: \u001b[1m\u001b[32m1.28191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2218 | loss: 1.28191 - acc: 0.7403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2219  | total loss: \u001b[1m\u001b[32m1.18346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2219 | loss: 1.18346 - acc: 0.7663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2220  | total loss: \u001b[1m\u001b[32m1.49313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2220 | loss: 1.49313 - acc: 0.6897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2221  | total loss: \u001b[1m\u001b[32m1.37289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2221 | loss: 1.37289 - acc: 0.7207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2222  | total loss: \u001b[1m\u001b[32m1.62200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2222 | loss: 1.62200 - acc: 0.6558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2223  | total loss: \u001b[1m\u001b[32m1.48962\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2223 | loss: 1.48962 - acc: 0.6902 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2224  | total loss: \u001b[1m\u001b[32m1.68565\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2224 | loss: 1.68565 - acc: 0.6355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2225  | total loss: \u001b[1m\u001b[32m1.54865\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2225 | loss: 1.54865 - acc: 0.6719 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2226  | total loss: \u001b[1m\u001b[32m1.42620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2226 | loss: 1.42620 - acc: 0.7047 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2227  | total loss: \u001b[1m\u001b[32m1.31636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2227 | loss: 1.31636 - acc: 0.7343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2228  | total loss: \u001b[1m\u001b[32m1.21745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2228 | loss: 1.21745 - acc: 0.7608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2229  | total loss: \u001b[1m\u001b[32m1.12797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2229 | loss: 1.12797 - acc: 0.7847 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2230  | total loss: \u001b[1m\u001b[32m1.38318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2230 | loss: 1.38318 - acc: 0.7134 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2231  | total loss: \u001b[1m\u001b[32m1.27666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2231 | loss: 1.27666 - acc: 0.7421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2232  | total loss: \u001b[1m\u001b[32m1.18072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2232 | loss: 1.18072 - acc: 0.7679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2233  | total loss: \u001b[1m\u001b[32m1.09390\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2233 | loss: 1.09390 - acc: 0.7911 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2234  | total loss: \u001b[1m\u001b[32m1.01498\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2234 | loss: 1.01498 - acc: 0.8120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2235  | total loss: \u001b[1m\u001b[32m0.94288\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2235 | loss: 0.94288 - acc: 0.8308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2236  | total loss: \u001b[1m\u001b[32m1.23485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2236 | loss: 1.23485 - acc: 0.7548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2237  | total loss: \u001b[1m\u001b[32m1.13941\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2237 | loss: 1.13941 - acc: 0.7794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2238  | total loss: \u001b[1m\u001b[32m1.41532\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2238 | loss: 1.41532 - acc: 0.7086 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2239  | total loss: \u001b[1m\u001b[32m1.30207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2239 | loss: 1.30207 - acc: 0.7377 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2240  | total loss: \u001b[1m\u001b[32m1.55066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2240 | loss: 1.55066 - acc: 0.6711 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2241  | total loss: \u001b[1m\u001b[32m1.42544\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2241 | loss: 1.42544 - acc: 0.7040 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2242  | total loss: \u001b[1m\u001b[32m1.60688\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2242 | loss: 1.60688 - acc: 0.6550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2243  | total loss: \u001b[1m\u001b[32m1.47855\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2243 | loss: 1.47855 - acc: 0.6895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2244  | total loss: \u001b[1m\u001b[32m1.36419\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2244 | loss: 1.36419 - acc: 0.7206 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2245  | total loss: \u001b[1m\u001b[32m1.26188\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2245 | loss: 1.26188 - acc: 0.7485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2246  | total loss: \u001b[1m\u001b[32m1.46810\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2246 | loss: 1.46810 - acc: 0.6879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2247  | total loss: \u001b[1m\u001b[32m1.35657\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2247 | loss: 1.35657 - acc: 0.7191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2248  | total loss: \u001b[1m\u001b[32m1.57483\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2248 | loss: 1.57483 - acc: 0.6615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2249  | total loss: \u001b[1m\u001b[32m1.45460\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2249 | loss: 1.45460 - acc: 0.6954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2250  | total loss: \u001b[1m\u001b[32m1.65952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2250 | loss: 1.65952 - acc: 0.6330 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2251  | total loss: \u001b[1m\u001b[32m1.53347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2251 | loss: 1.53347 - acc: 0.6697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2252  | total loss: \u001b[1m\u001b[32m1.42112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2252 | loss: 1.42112 - acc: 0.7027 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2253  | total loss: \u001b[1m\u001b[32m1.32044\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2253 | loss: 1.32044 - acc: 0.7324 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2254  | total loss: \u001b[1m\u001b[32m1.50768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2254 | loss: 1.50768 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2255  | total loss: \u001b[1m\u001b[32m1.39894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2255 | loss: 1.39894 - acc: 0.7061 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2256  | total loss: \u001b[1m\u001b[32m1.58751\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2256 | loss: 1.58751 - acc: 0.6427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2257  | total loss: \u001b[1m\u001b[32m1.47213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2257 | loss: 1.47213 - acc: 0.6784 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2258  | total loss: \u001b[1m\u001b[32m1.36879\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2258 | loss: 1.36879 - acc: 0.7106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2259  | total loss: \u001b[1m\u001b[32m1.27561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2259 | loss: 1.27561 - acc: 0.7395 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2260  | total loss: \u001b[1m\u001b[32m1.52087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2260 | loss: 1.52087 - acc: 0.6655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2261  | total loss: \u001b[1m\u001b[32m1.41213\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2261 | loss: 1.41213 - acc: 0.6990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2262  | total loss: \u001b[1m\u001b[32m1.61213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2262 | loss: 1.61213 - acc: 0.6362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2263  | total loss: \u001b[1m\u001b[32m1.49482\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2263 | loss: 1.49482 - acc: 0.6726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2264  | total loss: \u001b[1m\u001b[32m1.38933\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2264 | loss: 1.38933 - acc: 0.7054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2265  | total loss: \u001b[1m\u001b[32m1.29387\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2265 | loss: 1.29387 - acc: 0.7348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2266  | total loss: \u001b[1m\u001b[32m1.20689\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2266 | loss: 1.20689 - acc: 0.7613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2267  | total loss: \u001b[1m\u001b[32m1.12709\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2267 | loss: 1.12709 - acc: 0.7852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2268  | total loss: \u001b[1m\u001b[32m1.33243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2268 | loss: 1.33243 - acc: 0.7138 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2269  | total loss: \u001b[1m\u001b[32m1.23756\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2269 | loss: 1.23756 - acc: 0.7424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2270  | total loss: \u001b[1m\u001b[32m1.48776\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2270 | loss: 1.48776 - acc: 0.6753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2271  | total loss: \u001b[1m\u001b[32m1.37639\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2271 | loss: 1.37639 - acc: 0.7078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2272  | total loss: \u001b[1m\u001b[32m1.57194\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2272 | loss: 1.57194 - acc: 0.6513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2273  | total loss: \u001b[1m\u001b[32m1.45235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2273 | loss: 1.45235 - acc: 0.6862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2274  | total loss: \u001b[1m\u001b[32m1.34477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2274 | loss: 1.34477 - acc: 0.7176 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2275  | total loss: \u001b[1m\u001b[32m1.24752\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2275 | loss: 1.24752 - acc: 0.7458 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2276  | total loss: \u001b[1m\u001b[32m1.15913\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2276 | loss: 1.15913 - acc: 0.7712 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2277  | total loss: \u001b[1m\u001b[32m1.07836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2277 | loss: 1.07836 - acc: 0.7941 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2278  | total loss: \u001b[1m\u001b[32m1.26822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2278 | loss: 1.26822 - acc: 0.7361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2279  | total loss: \u001b[1m\u001b[32m1.17440\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2279 | loss: 1.17440 - acc: 0.7625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2280  | total loss: \u001b[1m\u001b[32m1.38441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2280 | loss: 1.38441 - acc: 0.7077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2281  | total loss: \u001b[1m\u001b[32m1.27808\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2281 | loss: 1.27808 - acc: 0.7369 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2282  | total loss: \u001b[1m\u001b[32m1.18204\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2282 | loss: 1.18204 - acc: 0.7632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2283  | total loss: \u001b[1m\u001b[32m1.09491\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2283 | loss: 1.09491 - acc: 0.7869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2284  | total loss: \u001b[1m\u001b[32m1.34806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2284 | loss: 1.34806 - acc: 0.7225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2285  | total loss: \u001b[1m\u001b[32m1.24341\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2285 | loss: 1.24341 - acc: 0.7502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2286  | total loss: \u001b[1m\u001b[32m1.14891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2286 | loss: 1.14891 - acc: 0.7752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2287  | total loss: \u001b[1m\u001b[32m1.06323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2287 | loss: 1.06323 - acc: 0.7977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2288  | total loss: \u001b[1m\u001b[32m0.98522\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2288 | loss: 0.98522 - acc: 0.8179 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2289  | total loss: \u001b[1m\u001b[32m0.91388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2289 | loss: 0.91388 - acc: 0.8361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2290  | total loss: \u001b[1m\u001b[32m1.25204\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2290 | loss: 1.25204 - acc: 0.7525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2291  | total loss: \u001b[1m\u001b[32m1.15264\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2291 | loss: 1.15264 - acc: 0.7773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2292  | total loss: \u001b[1m\u001b[32m1.06283\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2292 | loss: 1.06283 - acc: 0.7995 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2293  | total loss: \u001b[1m\u001b[32m0.98139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2293 | loss: 0.98139 - acc: 0.8196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2294  | total loss: \u001b[1m\u001b[32m0.90730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2294 | loss: 0.90730 - acc: 0.8376 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2295  | total loss: \u001b[1m\u001b[32m0.83964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2295 | loss: 0.83964 - acc: 0.8539 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2296  | total loss: \u001b[1m\u001b[32m0.77765\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2296 | loss: 0.77765 - acc: 0.8685 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2297  | total loss: \u001b[1m\u001b[32m0.72068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2297 | loss: 0.72068 - acc: 0.8816 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2298  | total loss: \u001b[1m\u001b[32m0.66817\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2298 | loss: 0.66817 - acc: 0.8935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2299  | total loss: \u001b[1m\u001b[32m0.61967\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2299 | loss: 0.61967 - acc: 0.9041 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2300  | total loss: \u001b[1m\u001b[32m0.57477\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2300 | loss: 0.57477 - acc: 0.9137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2301  | total loss: \u001b[1m\u001b[32m0.53315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2301 | loss: 0.53315 - acc: 0.9223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2302  | total loss: \u001b[1m\u001b[32m0.95131\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2302 | loss: 0.95131 - acc: 0.8301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2303  | total loss: \u001b[1m\u001b[32m0.87061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2303 | loss: 0.87061 - acc: 0.8471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2304  | total loss: \u001b[1m\u001b[32m1.27556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2304 | loss: 1.27556 - acc: 0.7624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2305  | total loss: \u001b[1m\u001b[32m1.16258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2305 | loss: 1.16258 - acc: 0.7861 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2306  | total loss: \u001b[1m\u001b[32m1.49420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2306 | loss: 1.49420 - acc: 0.7147 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2307  | total loss: \u001b[1m\u001b[32m1.36077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2307 | loss: 1.36077 - acc: 0.7432 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2308  | total loss: \u001b[1m\u001b[32m1.24156\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2308 | loss: 1.24156 - acc: 0.7689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2309  | total loss: \u001b[1m\u001b[32m1.13494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2309 | loss: 1.13494 - acc: 0.7920 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2310  | total loss: \u001b[1m\u001b[32m1.36559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2310 | loss: 1.36559 - acc: 0.7342 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2311  | total loss: \u001b[1m\u001b[32m1.24813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2311 | loss: 1.24813 - acc: 0.7608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2312  | total loss: \u001b[1m\u001b[32m1.14328\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2312 | loss: 1.14328 - acc: 0.7847 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2313  | total loss: \u001b[1m\u001b[32m1.04951\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2313 | loss: 1.04951 - acc: 0.8063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2314  | total loss: \u001b[1m\u001b[32m0.96545\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2314 | loss: 0.96545 - acc: 0.8256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2315  | total loss: \u001b[1m\u001b[32m0.88988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2315 | loss: 0.88988 - acc: 0.8431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2316  | total loss: \u001b[1m\u001b[32m0.82172\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2316 | loss: 0.82172 - acc: 0.8588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2317  | total loss: \u001b[1m\u001b[32m0.76002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2317 | loss: 0.76002 - acc: 0.8729 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2318  | total loss: \u001b[1m\u001b[32m0.70396\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2318 | loss: 0.70396 - acc: 0.8856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2319  | total loss: \u001b[1m\u001b[32m0.65283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2319 | loss: 0.65283 - acc: 0.8970 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2320  | total loss: \u001b[1m\u001b[32m1.02539\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2320 | loss: 1.02539 - acc: 0.8145 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2321  | total loss: \u001b[1m\u001b[32m0.94142\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2321 | loss: 0.94142 - acc: 0.8330 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2322  | total loss: \u001b[1m\u001b[32m1.26366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2322 | loss: 1.26366 - acc: 0.7569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2323  | total loss: \u001b[1m\u001b[32m1.15660\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2323 | loss: 1.15660 - acc: 0.7812 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2324  | total loss: \u001b[1m\u001b[32m1.49039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2324 | loss: 1.49039 - acc: 0.7031 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2325  | total loss: \u001b[1m\u001b[32m1.36274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2325 | loss: 1.36274 - acc: 0.7328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2326  | total loss: \u001b[1m\u001b[32m1.65007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2326 | loss: 1.65007 - acc: 0.6595 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2327  | total loss: \u001b[1m\u001b[32m1.50985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2327 | loss: 1.50985 - acc: 0.6935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2328  | total loss: \u001b[1m\u001b[32m1.38549\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2328 | loss: 1.38549 - acc: 0.7242 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2329  | total loss: \u001b[1m\u001b[32m1.27500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2329 | loss: 1.27500 - acc: 0.7518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2330  | total loss: \u001b[1m\u001b[32m1.17655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2330 | loss: 1.17655 - acc: 0.7766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2331  | total loss: \u001b[1m\u001b[32m1.08853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2331 | loss: 1.08853 - acc: 0.7989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2332  | total loss: \u001b[1m\u001b[32m1.39743\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2332 | loss: 1.39743 - acc: 0.7190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2333  | total loss: \u001b[1m\u001b[32m1.28875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2333 | loss: 1.28875 - acc: 0.7471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2334  | total loss: \u001b[1m\u001b[32m1.19175\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2334 | loss: 1.19175 - acc: 0.7724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2335  | total loss: \u001b[1m\u001b[32m1.10478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2335 | loss: 1.10478 - acc: 0.7952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2336  | total loss: \u001b[1m\u001b[32m1.36878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2336 | loss: 1.36878 - acc: 0.7157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2337  | total loss: \u001b[1m\u001b[32m1.26504\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 2337 | loss: 1.26504 - acc: 0.7441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2338  | total loss: \u001b[1m\u001b[32m1.51077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2338 | loss: 1.51077 - acc: 0.6768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2339  | total loss: \u001b[1m\u001b[32m1.39484\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2339 | loss: 1.39484 - acc: 0.7091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2340  | total loss: \u001b[1m\u001b[32m1.62374\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2340 | loss: 1.62374 - acc: 0.6454 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2341  | total loss: \u001b[1m\u001b[32m1.49945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2341 | loss: 1.49945 - acc: 0.6808 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2342  | total loss: \u001b[1m\u001b[32m1.71839\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2342 | loss: 1.71839 - acc: 0.6128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2343  | total loss: \u001b[1m\u001b[32m1.58831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2343 | loss: 1.58831 - acc: 0.6515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2344  | total loss: \u001b[1m\u001b[32m1.81835\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2344 | loss: 1.81835 - acc: 0.5863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2345  | total loss: \u001b[1m\u001b[32m1.68246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2345 | loss: 1.68246 - acc: 0.6277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2346  | total loss: \u001b[1m\u001b[32m1.56190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2346 | loss: 1.56190 - acc: 0.6649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2347  | total loss: \u001b[1m\u001b[32m1.45433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2347 | loss: 1.45433 - acc: 0.6984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2348  | total loss: \u001b[1m\u001b[32m1.35767\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2348 | loss: 1.35767 - acc: 0.7286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2349  | total loss: \u001b[1m\u001b[32m1.27012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2349 | loss: 1.27012 - acc: 0.7557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2350  | total loss: \u001b[1m\u001b[32m1.19018\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2350 | loss: 1.19018 - acc: 0.7802 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2351  | total loss: \u001b[1m\u001b[32m1.11655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2351 | loss: 1.11655 - acc: 0.8021 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2352  | total loss: \u001b[1m\u001b[32m1.35907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2352 | loss: 1.35907 - acc: 0.7291 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2353  | total loss: \u001b[1m\u001b[32m1.26556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2353 | loss: 1.26556 - acc: 0.7562 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2354  | total loss: \u001b[1m\u001b[32m1.18005\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2354 | loss: 1.18005 - acc: 0.7805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2355  | total loss: \u001b[1m\u001b[32m1.10136\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2355 | loss: 1.10136 - acc: 0.8025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2356  | total loss: \u001b[1m\u001b[32m1.38677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2356 | loss: 1.38677 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2357  | total loss: \u001b[1m\u001b[32m1.28481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2357 | loss: 1.28481 - acc: 0.7500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2358  | total loss: \u001b[1m\u001b[32m1.19206\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2358 | loss: 1.19206 - acc: 0.7750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2359  | total loss: \u001b[1m\u001b[32m1.10729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2359 | loss: 1.10729 - acc: 0.7975 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2360  | total loss: \u001b[1m\u001b[32m1.31169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2360 | loss: 1.31169 - acc: 0.7392 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2361  | total loss: \u001b[1m\u001b[32m1.21279\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2361 | loss: 1.21279 - acc: 0.7653 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2362  | total loss: \u001b[1m\u001b[32m1.12285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2362 | loss: 1.12285 - acc: 0.7887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2363  | total loss: \u001b[1m\u001b[32m1.04074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2363 | loss: 1.04074 - acc: 0.8099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2364  | total loss: \u001b[1m\u001b[32m1.35586\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2364 | loss: 1.35586 - acc: 0.7289 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2365  | total loss: \u001b[1m\u001b[32m1.24900\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 2365 | loss: 1.24900 - acc: 0.7560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2366  | total loss: \u001b[1m\u001b[32m1.15244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2366 | loss: 1.15244 - acc: 0.7804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2367  | total loss: \u001b[1m\u001b[32m1.06486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2367 | loss: 1.06486 - acc: 0.8024 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2368  | total loss: \u001b[1m\u001b[32m1.37363\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2368 | loss: 1.37363 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2369  | total loss: \u001b[1m\u001b[32m1.26335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2369 | loss: 1.26335 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2370  | total loss: \u001b[1m\u001b[32m1.16406\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2370 | loss: 1.16406 - acc: 0.7749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2371  | total loss: \u001b[1m\u001b[32m1.07437\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2371 | loss: 1.07437 - acc: 0.7974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2372  | total loss: \u001b[1m\u001b[32m1.34681\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2372 | loss: 1.34681 - acc: 0.7248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2373  | total loss: \u001b[1m\u001b[32m1.23864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2373 | loss: 1.23864 - acc: 0.7523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2374  | total loss: \u001b[1m\u001b[32m1.49508\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2374 | loss: 1.49508 - acc: 0.6771 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2375  | total loss: \u001b[1m\u001b[32m1.37318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2375 | loss: 1.37318 - acc: 0.7094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2376  | total loss: \u001b[1m\u001b[32m1.63033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2376 | loss: 1.63033 - acc: 0.6385 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2377  | total loss: \u001b[1m\u001b[32m1.49729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2377 | loss: 1.49729 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2378  | total loss: \u001b[1m\u001b[32m1.37882\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2378 | loss: 1.37882 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2379  | total loss: \u001b[1m\u001b[32m1.27297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2379 | loss: 1.27297 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2380  | total loss: \u001b[1m\u001b[32m1.52004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2380 | loss: 1.52004 - acc: 0.6628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2381  | total loss: \u001b[1m\u001b[32m1.40169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2381 | loss: 1.40169 - acc: 0.6965 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2382  | total loss: \u001b[1m\u001b[32m1.29597\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2382 | loss: 1.29597 - acc: 0.7269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2383  | total loss: \u001b[1m\u001b[32m1.20109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2383 | loss: 1.20109 - acc: 0.7542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2384  | total loss: \u001b[1m\u001b[32m1.11548\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2384 | loss: 1.11548 - acc: 0.7788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2385  | total loss: \u001b[1m\u001b[32m1.03781\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2385 | loss: 1.03781 - acc: 0.8009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2386  | total loss: \u001b[1m\u001b[32m1.31884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2386 | loss: 1.31884 - acc: 0.7279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2387  | total loss: \u001b[1m\u001b[32m1.22009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2387 | loss: 1.22009 - acc: 0.7551 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2388  | total loss: \u001b[1m\u001b[32m1.45447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2388 | loss: 1.45447 - acc: 0.6868 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2389  | total loss: \u001b[1m\u001b[32m1.34290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2389 | loss: 1.34290 - acc: 0.7181 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2390  | total loss: \u001b[1m\u001b[32m1.54481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2390 | loss: 1.54481 - acc: 0.6534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2391  | total loss: \u001b[1m\u001b[32m1.42604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2391 | loss: 1.42604 - acc: 0.6881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2392  | total loss: \u001b[1m\u001b[32m1.32000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2392 | loss: 1.32000 - acc: 0.7193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2393  | total loss: \u001b[1m\u001b[32m1.22485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2393 | loss: 1.22485 - acc: 0.7473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2394  | total loss: \u001b[1m\u001b[32m1.13899\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2394 | loss: 1.13899 - acc: 0.7726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2395  | total loss: \u001b[1m\u001b[32m1.06102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2395 | loss: 1.06102 - acc: 0.7954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2396  | total loss: \u001b[1m\u001b[32m0.98976\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2396 | loss: 0.98976 - acc: 0.8158 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2397  | total loss: \u001b[1m\u001b[32m0.92421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2397 | loss: 0.92421 - acc: 0.8342 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2398  | total loss: \u001b[1m\u001b[32m1.19201\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2398 | loss: 1.19201 - acc: 0.7580 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2399  | total loss: \u001b[1m\u001b[32m1.10408\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2399 | loss: 1.10408 - acc: 0.7822 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2400  | total loss: \u001b[1m\u001b[32m1.02413\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2400 | loss: 1.02413 - acc: 0.8039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2401  | total loss: \u001b[1m\u001b[32m0.95109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2401 | loss: 0.95109 - acc: 0.8235 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2402  | total loss: \u001b[1m\u001b[32m0.88405\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2402 | loss: 0.88405 - acc: 0.8412 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2403  | total loss: \u001b[1m\u001b[32m0.82224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2403 | loss: 0.82224 - acc: 0.8571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2404  | total loss: \u001b[1m\u001b[32m1.13440\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2404 | loss: 1.13440 - acc: 0.7785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2405  | total loss: \u001b[1m\u001b[32m1.04559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2405 | loss: 1.04559 - acc: 0.8007 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2406  | total loss: \u001b[1m\u001b[32m0.96503\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2406 | loss: 0.96503 - acc: 0.8206 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2407  | total loss: \u001b[1m\u001b[32m0.89173\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2407 | loss: 0.89173 - acc: 0.8385 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2408  | total loss: \u001b[1m\u001b[32m0.82480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2408 | loss: 0.82480 - acc: 0.8547 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2409  | total loss: \u001b[1m\u001b[32m0.76351\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2409 | loss: 0.76351 - acc: 0.8692 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2410  | total loss: \u001b[1m\u001b[32m0.70721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2410 | loss: 0.70721 - acc: 0.8823 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2411  | total loss: \u001b[1m\u001b[32m0.65537\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2411 | loss: 0.65537 - acc: 0.8941 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2412  | total loss: \u001b[1m\u001b[32m0.60752\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2412 | loss: 0.60752 - acc: 0.9047 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2413  | total loss: \u001b[1m\u001b[32m0.56327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2413 | loss: 0.56327 - acc: 0.9142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2414  | total loss: \u001b[1m\u001b[32m0.98815\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2414 | loss: 0.98815 - acc: 0.8228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2415  | total loss: \u001b[1m\u001b[32m0.90450\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2415 | loss: 0.90450 - acc: 0.8405 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2416  | total loss: \u001b[1m\u001b[32m1.25977\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2416 | loss: 1.25977 - acc: 0.7636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2417  | total loss: \u001b[1m\u001b[32m1.14910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2417 | loss: 1.14910 - acc: 0.7872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2418  | total loss: \u001b[1m\u001b[32m1.04978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2418 | loss: 1.04978 - acc: 0.8085 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2419  | total loss: \u001b[1m\u001b[32m0.96052\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2419 | loss: 0.96052 - acc: 0.8277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2420  | total loss: \u001b[1m\u001b[32m1.29340\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2420 | loss: 1.29340 - acc: 0.7520 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2421  | total loss: \u001b[1m\u001b[32m1.18052\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2421 | loss: 1.18052 - acc: 0.7768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2422  | total loss: \u001b[1m\u001b[32m1.07949\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2422 | loss: 1.07949 - acc: 0.7991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2423  | total loss: \u001b[1m\u001b[32m0.98893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2423 | loss: 0.98893 - acc: 0.8192 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2424  | total loss: \u001b[1m\u001b[32m1.33460\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2424 | loss: 1.33460 - acc: 0.7373 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2425  | total loss: \u001b[1m\u001b[32m1.21978\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2425 | loss: 1.21978 - acc: 0.7636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2426  | total loss: \u001b[1m\u001b[32m1.11727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2426 | loss: 1.11727 - acc: 0.7872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2427  | total loss: \u001b[1m\u001b[32m1.02558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2427 | loss: 1.02558 - acc: 0.8085 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2428  | total loss: \u001b[1m\u001b[32m1.33087\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2428 | loss: 1.33087 - acc: 0.7348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2429  | total loss: \u001b[1m\u001b[32m1.21934\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2429 | loss: 1.21934 - acc: 0.7613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2430  | total loss: \u001b[1m\u001b[32m1.54424\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2430 | loss: 1.54424 - acc: 0.6852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2431  | total loss: \u001b[1m\u001b[32m1.41414\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2431 | loss: 1.41414 - acc: 0.7167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2432  | total loss: \u001b[1m\u001b[32m1.68727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2432 | loss: 1.68727 - acc: 0.6521 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2433  | total loss: \u001b[1m\u001b[32m1.54685\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2433 | loss: 1.54685 - acc: 0.6869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2434  | total loss: \u001b[1m\u001b[32m1.71992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2434 | loss: 1.71992 - acc: 0.6397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2435  | total loss: \u001b[1m\u001b[32m1.58101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2435 | loss: 1.58101 - acc: 0.6757 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2436  | total loss: \u001b[1m\u001b[32m1.82709\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2436 | loss: 1.82709 - acc: 0.6081 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2437  | total loss: \u001b[1m\u001b[32m1.68299\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2437 | loss: 1.68299 - acc: 0.6473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2438  | total loss: \u001b[1m\u001b[32m1.85987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2438 | loss: 1.85987 - acc: 0.5897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2439  | total loss: \u001b[1m\u001b[32m1.71861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2439 | loss: 1.71861 - acc: 0.6308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2440  | total loss: \u001b[1m\u001b[32m1.59412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2440 | loss: 1.59412 - acc: 0.6677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2441  | total loss: \u001b[1m\u001b[32m1.48385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2441 | loss: 1.48385 - acc: 0.7009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2442  | total loss: \u001b[1m\u001b[32m1.70509\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2442 | loss: 1.70509 - acc: 0.6308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2443  | total loss: \u001b[1m\u001b[32m1.58656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2443 | loss: 1.58656 - acc: 0.6677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2444  | total loss: \u001b[1m\u001b[32m1.79888\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2444 | loss: 1.79888 - acc: 0.6010 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2445  | total loss: \u001b[1m\u001b[32m1.67402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2445 | loss: 1.67402 - acc: 0.6409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2446  | total loss: \u001b[1m\u001b[32m1.87013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2446 | loss: 1.87013 - acc: 0.5768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2447  | total loss: \u001b[1m\u001b[32m1.74120\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2447 | loss: 1.74120 - acc: 0.6191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2448  | total loss: \u001b[1m\u001b[32m1.88132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2448 | loss: 1.88132 - acc: 0.5643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2449  | total loss: \u001b[1m\u001b[32m1.75420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2449 | loss: 1.75420 - acc: 0.6079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2450  | total loss: \u001b[1m\u001b[32m1.90281\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2450 | loss: 1.90281 - acc: 0.5471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2451  | total loss: \u001b[1m\u001b[32m1.77646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2451 | loss: 1.77646 - acc: 0.5924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2452  | total loss: \u001b[1m\u001b[32m1.94321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2452 | loss: 1.94321 - acc: 0.5332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2453  | total loss: \u001b[1m\u001b[32m1.81549\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2453 | loss: 1.81549 - acc: 0.5798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2454  | total loss: \u001b[1m\u001b[32m1.70119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2454 | loss: 1.70119 - acc: 0.6219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2455  | total loss: \u001b[1m\u001b[32m1.59799\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2455 | loss: 1.59799 - acc: 0.6597 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2456  | total loss: \u001b[1m\u001b[32m1.50389\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2456 | loss: 1.50389 - acc: 0.6937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2457  | total loss: \u001b[1m\u001b[32m1.41723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2457 | loss: 1.41723 - acc: 0.7243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2458  | total loss: \u001b[1m\u001b[32m1.63011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2458 | loss: 1.63011 - acc: 0.6519 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2459  | total loss: \u001b[1m\u001b[32m1.52695\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2459 | loss: 1.52695 - acc: 0.6867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2460  | total loss: \u001b[1m\u001b[32m1.43217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2460 | loss: 1.43217 - acc: 0.7180 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2461  | total loss: \u001b[1m\u001b[32m1.34440\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2461 | loss: 1.34440 - acc: 0.7462 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2462  | total loss: \u001b[1m\u001b[32m1.26250\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2462 | loss: 1.26250 - acc: 0.7716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2463  | total loss: \u001b[1m\u001b[32m1.18557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2463 | loss: 1.18557 - acc: 0.7945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2464  | total loss: \u001b[1m\u001b[32m1.41599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2464 | loss: 1.41599 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2465  | total loss: \u001b[1m\u001b[32m1.31829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2465 | loss: 1.31829 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2466  | total loss: \u001b[1m\u001b[32m1.52464\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2466 | loss: 1.52464 - acc: 0.6821 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2467  | total loss: \u001b[1m\u001b[32m1.41265\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2467 | loss: 1.41265 - acc: 0.7139 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2468  | total loss: \u001b[1m\u001b[32m1.31036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2468 | loss: 1.31036 - acc: 0.7425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2469  | total loss: \u001b[1m\u001b[32m1.21651\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2469 | loss: 1.21651 - acc: 0.7682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2470  | total loss: \u001b[1m\u001b[32m1.13005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2470 | loss: 1.13005 - acc: 0.7914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2471  | total loss: \u001b[1m\u001b[32m1.05010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2471 | loss: 1.05010 - acc: 0.8123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2472  | total loss: \u001b[1m\u001b[32m1.33206\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2472 | loss: 1.33206 - acc: 0.7382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2473  | total loss: \u001b[1m\u001b[32m1.22871\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2473 | loss: 1.22871 - acc: 0.7644 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2474  | total loss: \u001b[1m\u001b[32m1.13452\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2474 | loss: 1.13452 - acc: 0.7879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2475  | total loss: \u001b[1m\u001b[32m1.04840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2475 | loss: 1.04840 - acc: 0.8091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2476  | total loss: \u001b[1m\u001b[32m1.34229\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2476 | loss: 1.34229 - acc: 0.7282 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2477  | total loss: \u001b[1m\u001b[32m1.23367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2477 | loss: 1.23367 - acc: 0.7554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2478  | total loss: \u001b[1m\u001b[32m1.13543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2478 | loss: 1.13543 - acc: 0.7799 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2479  | total loss: \u001b[1m\u001b[32m1.04630\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2479 | loss: 1.04630 - acc: 0.8019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2480  | total loss: \u001b[1m\u001b[32m1.32033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2480 | loss: 1.32033 - acc: 0.7288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2481  | total loss: \u001b[1m\u001b[32m1.21194\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2481 | loss: 1.21194 - acc: 0.7559 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2482  | total loss: \u001b[1m\u001b[32m1.11422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2482 | loss: 1.11422 - acc: 0.7804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2483  | total loss: \u001b[1m\u001b[32m1.02589\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2483 | loss: 1.02589 - acc: 0.8023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2484  | total loss: \u001b[1m\u001b[32m1.35201\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2484 | loss: 1.35201 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2485  | total loss: \u001b[1m\u001b[32m1.23981\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2485 | loss: 1.23981 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2486  | total loss: \u001b[1m\u001b[32m1.13902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2486 | loss: 1.13902 - acc: 0.7749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2487  | total loss: \u001b[1m\u001b[32m1.04826\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2487 | loss: 1.04826 - acc: 0.7974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2488  | total loss: \u001b[1m\u001b[32m0.96628\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2488 | loss: 0.96628 - acc: 0.8177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2489  | total loss: \u001b[1m\u001b[32m0.89201\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2489 | loss: 0.89201 - acc: 0.8359 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2490  | total loss: \u001b[1m\u001b[32m1.14020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2490 | loss: 1.14020 - acc: 0.7737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2491  | total loss: \u001b[1m\u001b[32m1.04798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2491 | loss: 1.04798 - acc: 0.7964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2492  | total loss: \u001b[1m\u001b[32m0.96487\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2492 | loss: 0.96487 - acc: 0.8167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2493  | total loss: \u001b[1m\u001b[32m0.88975\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2493 | loss: 0.88975 - acc: 0.8351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2494  | total loss: \u001b[1m\u001b[32m0.82165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2494 | loss: 0.82165 - acc: 0.8515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2495  | total loss: \u001b[1m\u001b[32m0.75971\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2495 | loss: 0.75971 - acc: 0.8664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2496  | total loss: \u001b[1m\u001b[32m1.13247\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2496 | loss: 1.13247 - acc: 0.7798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2497  | total loss: \u001b[1m\u001b[32m1.03890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2497 | loss: 1.03890 - acc: 0.8018 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2498  | total loss: \u001b[1m\u001b[32m1.37404\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2498 | loss: 1.37404 - acc: 0.7287 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2499  | total loss: \u001b[1m\u001b[32m1.25715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2499 | loss: 1.25715 - acc: 0.7559 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2500  | total loss: \u001b[1m\u001b[32m1.15254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2500 | loss: 1.15254 - acc: 0.7803 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2501  | total loss: \u001b[1m\u001b[32m1.05870\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2501 | loss: 1.05870 - acc: 0.8023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2502  | total loss: \u001b[1m\u001b[32m0.97434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2502 | loss: 0.97434 - acc: 0.8220 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2503  | total loss: \u001b[1m\u001b[32m0.89827\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2503 | loss: 0.89827 - acc: 0.8398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2504  | total loss: \u001b[1m\u001b[32m1.20935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2504 | loss: 1.20935 - acc: 0.7630 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2505  | total loss: \u001b[1m\u001b[32m1.11002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2505 | loss: 1.11002 - acc: 0.7867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2506  | total loss: \u001b[1m\u001b[32m1.38932\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2506 | loss: 1.38932 - acc: 0.7152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2507  | total loss: \u001b[1m\u001b[32m1.27355\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2507 | loss: 1.27355 - acc: 0.7436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2508  | total loss: \u001b[1m\u001b[32m1.57182\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2508 | loss: 1.57182 - acc: 0.6693 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2509  | total loss: \u001b[1m\u001b[32m1.44075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2509 | loss: 1.44075 - acc: 0.7024 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2510  | total loss: \u001b[1m\u001b[32m1.69651\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2510 | loss: 1.69651 - acc: 0.6321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2511  | total loss: \u001b[1m\u001b[32m1.55728\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2511 | loss: 1.55728 - acc: 0.6689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2512  | total loss: \u001b[1m\u001b[32m1.72987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2512 | loss: 1.72987 - acc: 0.6163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2513  | total loss: \u001b[1m\u001b[32m1.59255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2513 | loss: 1.59255 - acc: 0.6547 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2514  | total loss: \u001b[1m\u001b[32m1.80554\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2514 | loss: 1.80554 - acc: 0.5892 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2515  | total loss: \u001b[1m\u001b[32m1.66662\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2515 | loss: 1.66662 - acc: 0.6303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2516  | total loss: \u001b[1m\u001b[32m1.54438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2516 | loss: 1.54438 - acc: 0.6673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2517  | total loss: \u001b[1m\u001b[32m1.43632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2517 | loss: 1.43632 - acc: 0.7005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2518  | total loss: \u001b[1m\u001b[32m1.34017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2518 | loss: 1.34017 - acc: 0.7305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2519  | total loss: \u001b[1m\u001b[32m1.25395\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2519 | loss: 1.25395 - acc: 0.7574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2520  | total loss: \u001b[1m\u001b[32m1.46342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2520 | loss: 1.46342 - acc: 0.6888 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2521  | total loss: \u001b[1m\u001b[32m1.36518\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2521 | loss: 1.36518 - acc: 0.7199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2522  | total loss: \u001b[1m\u001b[32m1.27673\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2522 | loss: 1.27673 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2523  | total loss: \u001b[1m\u001b[32m1.19637\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2523 | loss: 1.19637 - acc: 0.7732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2524  | total loss: \u001b[1m\u001b[32m1.42580\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2524 | loss: 1.42580 - acc: 0.7101 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2525  | total loss: \u001b[1m\u001b[32m1.32887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2525 | loss: 1.32887 - acc: 0.7391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2526  | total loss: \u001b[1m\u001b[32m1.48660\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2526 | loss: 1.48660 - acc: 0.6866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2527  | total loss: \u001b[1m\u001b[32m1.38260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2527 | loss: 1.38260 - acc: 0.7180 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2528  | total loss: \u001b[1m\u001b[32m1.28832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2528 | loss: 1.28832 - acc: 0.7462 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2529  | total loss: \u001b[1m\u001b[32m1.20225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2529 | loss: 1.20225 - acc: 0.7716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2530  | total loss: \u001b[1m\u001b[32m1.43113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2530 | loss: 1.43113 - acc: 0.7015 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2531  | total loss: \u001b[1m\u001b[32m1.32867\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2531 | loss: 1.32867 - acc: 0.7314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2532  | total loss: \u001b[1m\u001b[32m1.57226\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2532 | loss: 1.57226 - acc: 0.6582 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2533  | total loss: \u001b[1m\u001b[32m1.45503\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2533 | loss: 1.45503 - acc: 0.6924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2534  | total loss: \u001b[1m\u001b[32m1.71448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2534 | loss: 1.71448 - acc: 0.6232 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2535  | total loss: \u001b[1m\u001b[32m1.58364\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2535 | loss: 1.58364 - acc: 0.6609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2536  | total loss: \u001b[1m\u001b[32m1.46614\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2536 | loss: 1.46614 - acc: 0.6948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2537  | total loss: \u001b[1m\u001b[32m1.36009\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2537 | loss: 1.36009 - acc: 0.7253 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2538  | total loss: \u001b[1m\u001b[32m1.59967\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2538 | loss: 1.59967 - acc: 0.6528 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2539  | total loss: \u001b[1m\u001b[32m1.47991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2539 | loss: 1.47991 - acc: 0.6875 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2540  | total loss: \u001b[1m\u001b[32m1.69953\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2540 | loss: 1.69953 - acc: 0.6187 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2541  | total loss: \u001b[1m\u001b[32m1.57067\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2541 | loss: 1.57067 - acc: 0.6569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2542  | total loss: \u001b[1m\u001b[32m1.77388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2542 | loss: 1.77388 - acc: 0.5912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2543  | total loss: \u001b[1m\u001b[32m1.63947\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2543 | loss: 1.63947 - acc: 0.6321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2544  | total loss: \u001b[1m\u001b[32m1.51931\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2544 | loss: 1.51931 - acc: 0.6689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2545  | total loss: \u001b[1m\u001b[32m1.41132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2545 | loss: 1.41132 - acc: 0.7020 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2546  | total loss: \u001b[1m\u001b[32m1.31368\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2546 | loss: 1.31368 - acc: 0.7318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2547  | total loss: \u001b[1m\u001b[32m1.22481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2547 | loss: 1.22481 - acc: 0.7586 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2548  | total loss: \u001b[1m\u001b[32m1.45636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2548 | loss: 1.45636 - acc: 0.6827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2549  | total loss: \u001b[1m\u001b[32m1.35156\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2549 | loss: 1.35156 - acc: 0.7145 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2550  | total loss: \u001b[1m\u001b[32m1.62257\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2550 | loss: 1.62257 - acc: 0.6430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2551  | total loss: \u001b[1m\u001b[32m1.50094\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2551 | loss: 1.50094 - acc: 0.6787 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2552  | total loss: \u001b[1m\u001b[32m1.39141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2552 | loss: 1.39141 - acc: 0.7108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2553  | total loss: \u001b[1m\u001b[32m1.29223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2553 | loss: 1.29223 - acc: 0.7398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2554  | total loss: \u001b[1m\u001b[32m1.20189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2554 | loss: 1.20189 - acc: 0.7658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2555  | total loss: \u001b[1m\u001b[32m1.11913\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2555 | loss: 1.11913 - acc: 0.7892 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2556  | total loss: \u001b[1m\u001b[32m1.04289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2556 | loss: 1.04289 - acc: 0.8103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2557  | total loss: \u001b[1m\u001b[32m0.97227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2557 | loss: 0.97227 - acc: 0.8293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2558  | total loss: \u001b[1m\u001b[32m1.27290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2558 | loss: 1.27290 - acc: 0.7463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2559  | total loss: \u001b[1m\u001b[32m1.17640\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2559 | loss: 1.17640 - acc: 0.7717 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2560  | total loss: \u001b[1m\u001b[32m1.45562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2560 | loss: 1.45562 - acc: 0.7017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2561  | total loss: \u001b[1m\u001b[32m1.33995\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2561 | loss: 1.33995 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2562  | total loss: \u001b[1m\u001b[32m1.62552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2562 | loss: 1.62552 - acc: 0.6584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2563  | total loss: \u001b[1m\u001b[32m1.49367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2563 | loss: 1.49367 - acc: 0.6925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2564  | total loss: \u001b[1m\u001b[32m1.75181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2564 | loss: 1.75181 - acc: 0.6233 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2565  | total loss: \u001b[1m\u001b[32m1.60972\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2565 | loss: 1.60972 - acc: 0.6609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2566  | total loss: \u001b[1m\u001b[32m1.48309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2566 | loss: 1.48309 - acc: 0.6948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2567  | total loss: \u001b[1m\u001b[32m1.36984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2567 | loss: 1.36984 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2568  | total loss: \u001b[1m\u001b[32m1.59342\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2568 | loss: 1.59342 - acc: 0.6600 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2569  | total loss: \u001b[1m\u001b[32m1.47058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2569 | loss: 1.47058 - acc: 0.6940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2570  | total loss: \u001b[1m\u001b[32m1.68958\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2570 | loss: 1.68958 - acc: 0.6317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2571  | total loss: \u001b[1m\u001b[32m1.55948\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2571 | loss: 1.55948 - acc: 0.6685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2572  | total loss: \u001b[1m\u001b[32m1.44342\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2572 | loss: 1.44342 - acc: 0.7017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2573  | total loss: \u001b[1m\u001b[32m1.33937\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2573 | loss: 1.33937 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2574  | total loss: \u001b[1m\u001b[32m1.60239\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2574 | loss: 1.60239 - acc: 0.6584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2575  | total loss: \u001b[1m\u001b[32m1.48324\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2575 | loss: 1.48324 - acc: 0.6925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2576  | total loss: \u001b[1m\u001b[32m1.37635\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2576 | loss: 1.37635 - acc: 0.7233 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2577  | total loss: \u001b[1m\u001b[32m1.27988\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2577 | loss: 1.27988 - acc: 0.7510 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2578  | total loss: \u001b[1m\u001b[32m1.52619\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2578 | loss: 1.52619 - acc: 0.6759 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2579  | total loss: \u001b[1m\u001b[32m1.41433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2579 | loss: 1.41433 - acc: 0.7083 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2580  | total loss: \u001b[1m\u001b[32m1.63172\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2580 | loss: 1.63172 - acc: 0.6446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2581  | total loss: \u001b[1m\u001b[32m1.50998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2581 | loss: 1.50998 - acc: 0.6801 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2582  | total loss: \u001b[1m\u001b[32m1.68717\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2582 | loss: 1.68717 - acc: 0.6264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2583  | total loss: \u001b[1m\u001b[32m1.56127\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2583 | loss: 1.56127 - acc: 0.6638 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2584  | total loss: \u001b[1m\u001b[32m1.76620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2584 | loss: 1.76620 - acc: 0.6045 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2585  | total loss: \u001b[1m\u001b[32m1.63444\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2585 | loss: 1.63444 - acc: 0.6441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2586  | total loss: \u001b[1m\u001b[32m1.80445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2586 | loss: 1.80445 - acc: 0.5797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2587  | total loss: \u001b[1m\u001b[32m1.67157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2587 | loss: 1.67157 - acc: 0.6217 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2588  | total loss: \u001b[1m\u001b[32m1.55308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2588 | loss: 1.55308 - acc: 0.6595 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2589  | total loss: \u001b[1m\u001b[32m1.44678\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2589 | loss: 1.44678 - acc: 0.6936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2590  | total loss: \u001b[1m\u001b[32m1.35076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2590 | loss: 1.35076 - acc: 0.7242 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2591  | total loss: \u001b[1m\u001b[32m1.26337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2591 | loss: 1.26337 - acc: 0.7518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2592  | total loss: \u001b[1m\u001b[32m1.50380\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2592 | loss: 1.50380 - acc: 0.6766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2593  | total loss: \u001b[1m\u001b[32m1.39942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2593 | loss: 1.39942 - acc: 0.7090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2594  | total loss: \u001b[1m\u001b[32m1.58214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2594 | loss: 1.58214 - acc: 0.6523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2595  | total loss: \u001b[1m\u001b[32m1.46918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2595 | loss: 1.46918 - acc: 0.6871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2596  | total loss: \u001b[1m\u001b[32m1.69671\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2596 | loss: 1.69671 - acc: 0.6184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2597  | total loss: \u001b[1m\u001b[32m1.57242\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2597 | loss: 1.57242 - acc: 0.6566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2598  | total loss: \u001b[1m\u001b[32m1.76755\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2598 | loss: 1.76755 - acc: 0.5980 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2599  | total loss: \u001b[1m\u001b[32m1.63731\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2599 | loss: 1.63731 - acc: 0.6382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2600  | total loss: \u001b[1m\u001b[32m1.52047\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2600 | loss: 1.52047 - acc: 0.6744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2601  | total loss: \u001b[1m\u001b[32m1.41504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2601 | loss: 1.41504 - acc: 0.7070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2602  | total loss: \u001b[1m\u001b[32m1.31929\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2602 | loss: 1.31929 - acc: 0.7363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2603  | total loss: \u001b[1m\u001b[32m1.23174\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2603 | loss: 1.23174 - acc: 0.7627 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2604  | total loss: \u001b[1m\u001b[32m1.47243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2604 | loss: 1.47243 - acc: 0.6935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2605  | total loss: \u001b[1m\u001b[32m1.36718\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2605 | loss: 1.36718 - acc: 0.7242 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2606  | total loss: \u001b[1m\u001b[32m1.27140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2606 | loss: 1.27140 - acc: 0.7518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2607  | total loss: \u001b[1m\u001b[32m1.18372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2607 | loss: 1.18372 - acc: 0.7766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2608  | total loss: \u001b[1m\u001b[32m1.46832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2608 | loss: 1.46832 - acc: 0.6989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2609  | total loss: \u001b[1m\u001b[32m1.35872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2609 | loss: 1.35872 - acc: 0.7290 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2610  | total loss: \u001b[1m\u001b[32m1.62460\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2610 | loss: 1.62460 - acc: 0.6561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2611  | total loss: \u001b[1m\u001b[32m1.49878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2611 | loss: 1.49878 - acc: 0.6905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2612  | total loss: \u001b[1m\u001b[32m1.75118\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2612 | loss: 1.75118 - acc: 0.6215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2613  | total loss: \u001b[1m\u001b[32m1.61343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2613 | loss: 1.61343 - acc: 0.6593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2614  | total loss: \u001b[1m\u001b[32m1.48985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2614 | loss: 1.48985 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2615  | total loss: \u001b[1m\u001b[32m1.37849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2615 | loss: 1.37849 - acc: 0.7240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2616  | total loss: \u001b[1m\u001b[32m1.27769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2616 | loss: 1.27769 - acc: 0.7516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2617  | total loss: \u001b[1m\u001b[32m1.18599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2617 | loss: 1.18599 - acc: 0.7765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2618  | total loss: \u001b[1m\u001b[32m1.44565\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2618 | loss: 1.44565 - acc: 0.7060 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2619  | total loss: \u001b[1m\u001b[32m1.33569\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2619 | loss: 1.33569 - acc: 0.7354 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2620  | total loss: \u001b[1m\u001b[32m1.51197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2620 | loss: 1.51197 - acc: 0.6833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2621  | total loss: \u001b[1m\u001b[32m1.39508\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2621 | loss: 1.39508 - acc: 0.7149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2622  | total loss: \u001b[1m\u001b[32m1.61826\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2622 | loss: 1.61826 - acc: 0.6506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2623  | total loss: \u001b[1m\u001b[32m1.49144\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2623 | loss: 1.49144 - acc: 0.6855 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2624  | total loss: \u001b[1m\u001b[32m1.65894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2624 | loss: 1.65894 - acc: 0.6384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2625  | total loss: \u001b[1m\u001b[32m1.52955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2625 | loss: 1.52955 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2626  | total loss: \u001b[1m\u001b[32m1.41369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2626 | loss: 1.41369 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2627  | total loss: \u001b[1m\u001b[32m1.30951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2627 | loss: 1.30951 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2628  | total loss: \u001b[1m\u001b[32m1.55859\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2628 | loss: 1.55859 - acc: 0.6628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2629  | total loss: \u001b[1m\u001b[32m1.44020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2629 | loss: 1.44020 - acc: 0.6965 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2630  | total loss: \u001b[1m\u001b[32m1.33378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2630 | loss: 1.33378 - acc: 0.7268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2631  | total loss: \u001b[1m\u001b[32m1.23764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2631 | loss: 1.23764 - acc: 0.7542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2632  | total loss: \u001b[1m\u001b[32m1.49316\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2632 | loss: 1.49316 - acc: 0.6787 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2633  | total loss: \u001b[1m\u001b[32m1.38063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2633 | loss: 1.38063 - acc: 0.7109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2634  | total loss: \u001b[1m\u001b[32m1.62148\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2634 | loss: 1.62148 - acc: 0.6469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2635  | total loss: \u001b[1m\u001b[32m1.49697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2635 | loss: 1.49697 - acc: 0.6822 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2636  | total loss: \u001b[1m\u001b[32m1.38535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2636 | loss: 1.38535 - acc: 0.7140 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2637  | total loss: \u001b[1m\u001b[32m1.28482\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2637 | loss: 1.28482 - acc: 0.7426 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2638  | total loss: \u001b[1m\u001b[32m1.19381\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2638 | loss: 1.19381 - acc: 0.7683 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2639  | total loss: \u001b[1m\u001b[32m1.11094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2639 | loss: 1.11094 - acc: 0.7915 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2640  | total loss: \u001b[1m\u001b[32m1.03507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2640 | loss: 1.03507 - acc: 0.8124 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2641  | total loss: \u001b[1m\u001b[32m0.96522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2641 | loss: 0.96522 - acc: 0.8311 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2642  | total loss: \u001b[1m\u001b[32m1.26194\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2642 | loss: 1.26194 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2643  | total loss: \u001b[1m\u001b[32m1.16715\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2643 | loss: 1.16715 - acc: 0.7732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2644  | total loss: \u001b[1m\u001b[32m1.08106\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2644 | loss: 1.08106 - acc: 0.7959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2645  | total loss: \u001b[1m\u001b[32m1.00251\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2645 | loss: 1.00251 - acc: 0.8163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2646  | total loss: \u001b[1m\u001b[32m1.23056\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2646 | loss: 1.23056 - acc: 0.7561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2647  | total loss: \u001b[1m\u001b[32m1.13543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2647 | loss: 1.13543 - acc: 0.7805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2648  | total loss: \u001b[1m\u001b[32m1.04918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2648 | loss: 1.04918 - acc: 0.8024 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2649  | total loss: \u001b[1m\u001b[32m0.97070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2649 | loss: 0.97070 - acc: 0.8222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2650  | total loss: \u001b[1m\u001b[32m1.27004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2650 | loss: 1.27004 - acc: 0.7471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2651  | total loss: \u001b[1m\u001b[32m1.16846\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2651 | loss: 1.16846 - acc: 0.7724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2652  | total loss: \u001b[1m\u001b[32m1.42830\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2652 | loss: 1.42830 - acc: 0.7023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2653  | total loss: \u001b[1m\u001b[32m1.31134\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2653 | loss: 1.31134 - acc: 0.7321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2654  | total loss: \u001b[1m\u001b[32m1.57636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2654 | loss: 1.57636 - acc: 0.6660 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2655  | total loss: \u001b[1m\u001b[32m1.44631\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2655 | loss: 1.44631 - acc: 0.6994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2656  | total loss: \u001b[1m\u001b[32m1.33022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2656 | loss: 1.33022 - acc: 0.7295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2657  | total loss: \u001b[1m\u001b[32m1.22629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2657 | loss: 1.22629 - acc: 0.7565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2658  | total loss: \u001b[1m\u001b[32m1.45566\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2658 | loss: 1.45566 - acc: 0.6952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2659  | total loss: \u001b[1m\u001b[32m1.34029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2659 | loss: 1.34029 - acc: 0.7256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2660  | total loss: \u001b[1m\u001b[32m1.57573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2660 | loss: 1.57573 - acc: 0.6602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2661  | total loss: \u001b[1m\u001b[32m1.45031\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2661 | loss: 1.45031 - acc: 0.6942 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2662  | total loss: \u001b[1m\u001b[32m1.68553\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2662 | loss: 1.68553 - acc: 0.6319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2663  | total loss: \u001b[1m\u001b[32m1.55205\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2663 | loss: 1.55205 - acc: 0.6687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2664  | total loss: \u001b[1m\u001b[32m1.43334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2664 | loss: 1.43334 - acc: 0.7019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2665  | total loss: \u001b[1m\u001b[32m1.32734\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2665 | loss: 1.32734 - acc: 0.7317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2666  | total loss: \u001b[1m\u001b[32m1.23223\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2666 | loss: 1.23223 - acc: 0.7585 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2667  | total loss: \u001b[1m\u001b[32m1.14642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2667 | loss: 1.14642 - acc: 0.7827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2668  | total loss: \u001b[1m\u001b[32m1.43768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2668 | loss: 1.43768 - acc: 0.7044 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2669  | total loss: \u001b[1m\u001b[32m1.33121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2669 | loss: 1.33121 - acc: 0.7339 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2670  | total loss: \u001b[1m\u001b[32m1.53206\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2670 | loss: 1.53206 - acc: 0.6677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2671  | total loss: \u001b[1m\u001b[32m1.41729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2671 | loss: 1.41729 - acc: 0.7009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2672  | total loss: \u001b[1m\u001b[32m1.31451\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2672 | loss: 1.31451 - acc: 0.7308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2673  | total loss: \u001b[1m\u001b[32m1.22197\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2673 | loss: 1.22197 - acc: 0.7578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2674  | total loss: \u001b[1m\u001b[32m1.44484\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2674 | loss: 1.44484 - acc: 0.6891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2675  | total loss: \u001b[1m\u001b[32m1.33921\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2675 | loss: 1.33921 - acc: 0.7202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2676  | total loss: \u001b[1m\u001b[32m1.24408\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2676 | loss: 1.24408 - acc: 0.7482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2677  | total loss: \u001b[1m\u001b[32m1.15789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2677 | loss: 1.15789 - acc: 0.7734 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2678  | total loss: \u001b[1m\u001b[32m1.07930\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2678 | loss: 1.07930 - acc: 0.7960 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2679  | total loss: \u001b[1m\u001b[32m1.00719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2679 | loss: 1.00719 - acc: 0.8164 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2680  | total loss: \u001b[1m\u001b[32m0.94060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2680 | loss: 0.94060 - acc: 0.8348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2681  | total loss: \u001b[1m\u001b[32m0.87877\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2681 | loss: 0.87877 - acc: 0.8513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2682  | total loss: \u001b[1m\u001b[32m1.18294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2682 | loss: 1.18294 - acc: 0.7662 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2683  | total loss: \u001b[1m\u001b[32m1.09418\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2683 | loss: 1.09418 - acc: 0.7896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2684  | total loss: \u001b[1m\u001b[32m1.01336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2684 | loss: 1.01336 - acc: 0.8106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2685  | total loss: \u001b[1m\u001b[32m0.93947\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2685 | loss: 0.93947 - acc: 0.8295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2686  | total loss: \u001b[1m\u001b[32m0.87163\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2686 | loss: 0.87163 - acc: 0.8466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2687  | total loss: \u001b[1m\u001b[32m0.80912\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2687 | loss: 0.80912 - acc: 0.8619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2688  | total loss: \u001b[1m\u001b[32m0.75132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2688 | loss: 0.75132 - acc: 0.8757 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2689  | total loss: \u001b[1m\u001b[32m0.69774\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2689 | loss: 0.69774 - acc: 0.8882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2690  | total loss: \u001b[1m\u001b[32m1.07107\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2690 | loss: 1.07107 - acc: 0.7993 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2691  | total loss: \u001b[1m\u001b[32m0.98352\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2691 | loss: 0.98352 - acc: 0.8194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2692  | total loss: \u001b[1m\u001b[32m1.32896\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2692 | loss: 1.32896 - acc: 0.7375 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2693  | total loss: \u001b[1m\u001b[32m1.21548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2693 | loss: 1.21548 - acc: 0.7637 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2694  | total loss: \u001b[1m\u001b[32m1.11354\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2694 | loss: 1.11354 - acc: 0.7874 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2695  | total loss: \u001b[1m\u001b[32m1.02178\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2695 | loss: 1.02178 - acc: 0.8086 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2696  | total loss: \u001b[1m\u001b[32m1.26780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2696 | loss: 1.26780 - acc: 0.7563 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2697  | total loss: \u001b[1m\u001b[32m1.16095\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2697 | loss: 1.16095 - acc: 0.7807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2698  | total loss: \u001b[1m\u001b[32m1.50854\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2698 | loss: 1.50854 - acc: 0.7026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2699  | total loss: \u001b[1m\u001b[32m1.37923\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2699 | loss: 1.37923 - acc: 0.7324 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2700  | total loss: \u001b[1m\u001b[32m1.63510\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2700 | loss: 1.63510 - acc: 0.6663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2701  | total loss: \u001b[1m\u001b[32m1.49604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2701 | loss: 1.49604 - acc: 0.6996 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2702  | total loss: \u001b[1m\u001b[32m1.69157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2702 | loss: 1.69157 - acc: 0.6511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2703  | total loss: \u001b[1m\u001b[32m1.55077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2703 | loss: 1.55077 - acc: 0.6860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2704  | total loss: \u001b[1m\u001b[32m1.79543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2704 | loss: 1.79543 - acc: 0.6174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2705  | total loss: \u001b[1m\u001b[32m1.64915\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2705 | loss: 1.64915 - acc: 0.6557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2706  | total loss: \u001b[1m\u001b[32m1.87198\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2706 | loss: 1.87198 - acc: 0.5901 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2707  | total loss: \u001b[1m\u001b[32m1.72388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2707 | loss: 1.72388 - acc: 0.6311 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2708  | total loss: \u001b[1m\u001b[32m1.94833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2708 | loss: 1.94833 - acc: 0.5680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2709  | total loss: \u001b[1m\u001b[32m1.79907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2709 | loss: 1.79907 - acc: 0.6112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2710  | total loss: \u001b[1m\u001b[32m1.66762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2710 | loss: 1.66762 - acc: 0.6501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2711  | total loss: \u001b[1m\u001b[32m1.55127\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2711 | loss: 1.55127 - acc: 0.6851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2712  | total loss: \u001b[1m\u001b[32m1.74928\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2712 | loss: 1.74928 - acc: 0.6237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2713  | total loss: \u001b[1m\u001b[32m1.62779\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2713 | loss: 1.62779 - acc: 0.6613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2714  | total loss: \u001b[1m\u001b[32m1.82196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2714 | loss: 1.82196 - acc: 0.5952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2715  | total loss: \u001b[1m\u001b[32m1.69607\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2715 | loss: 1.69607 - acc: 0.6357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2716  | total loss: \u001b[1m\u001b[32m1.85734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2716 | loss: 1.85734 - acc: 0.5864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2717  | total loss: \u001b[1m\u001b[32m1.73042\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2717 | loss: 1.73042 - acc: 0.6277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2718  | total loss: \u001b[1m\u001b[32m1.61686\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2718 | loss: 1.61686 - acc: 0.6650 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2719  | total loss: \u001b[1m\u001b[32m1.51442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2719 | loss: 1.51442 - acc: 0.6985 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2720  | total loss: \u001b[1m\u001b[32m1.42119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2720 | loss: 1.42119 - acc: 0.7286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2721  | total loss: \u001b[1m\u001b[32m1.33559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2721 | loss: 1.33559 - acc: 0.7558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2722  | total loss: \u001b[1m\u001b[32m1.48508\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2722 | loss: 1.48508 - acc: 0.7016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2723  | total loss: \u001b[1m\u001b[32m1.38954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2723 | loss: 1.38954 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2724  | total loss: \u001b[1m\u001b[32m1.30173\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2724 | loss: 1.30173 - acc: 0.7583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2725  | total loss: \u001b[1m\u001b[32m1.22042\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2725 | loss: 1.22042 - acc: 0.7825 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2726  | total loss: \u001b[1m\u001b[32m1.14461\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2726 | loss: 1.14461 - acc: 0.8042 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2727  | total loss: \u001b[1m\u001b[32m1.07352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2727 | loss: 1.07352 - acc: 0.8238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2728  | total loss: \u001b[1m\u001b[32m1.32973\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2728 | loss: 1.32973 - acc: 0.7486 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2729  | total loss: \u001b[1m\u001b[32m1.23550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2729 | loss: 1.23550 - acc: 0.7737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2730  | total loss: \u001b[1m\u001b[32m1.46227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2730 | loss: 1.46227 - acc: 0.7035 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2731  | total loss: \u001b[1m\u001b[32m1.35220\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2731 | loss: 1.35220 - acc: 0.7331 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2732  | total loss: \u001b[1m\u001b[32m1.25207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2732 | loss: 1.25207 - acc: 0.7598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2733  | total loss: \u001b[1m\u001b[32m1.16062\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2733 | loss: 1.16062 - acc: 0.7838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2734  | total loss: \u001b[1m\u001b[32m1.44225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2734 | loss: 1.44225 - acc: 0.7126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2735  | total loss: \u001b[1m\u001b[32m1.32984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2735 | loss: 1.32984 - acc: 0.7413 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2736  | total loss: \u001b[1m\u001b[32m1.60113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2736 | loss: 1.60113 - acc: 0.6672 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2737  | total loss: \u001b[1m\u001b[32m1.47263\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2737 | loss: 1.47263 - acc: 0.7005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2738  | total loss: \u001b[1m\u001b[32m1.64498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2738 | loss: 1.64498 - acc: 0.6519 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2739  | total loss: \u001b[1m\u001b[32m1.51308\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2739 | loss: 1.51308 - acc: 0.6867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2740  | total loss: \u001b[1m\u001b[32m1.70208\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2740 | loss: 1.70208 - acc: 0.6323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2741  | total loss: \u001b[1m\u001b[32m1.56624\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2741 | loss: 1.56624 - acc: 0.6691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2742  | total loss: \u001b[1m\u001b[32m1.44480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2742 | loss: 1.44480 - acc: 0.7022 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2743  | total loss: \u001b[1m\u001b[32m1.33583\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2743 | loss: 1.33583 - acc: 0.7319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2744  | total loss: \u001b[1m\u001b[32m1.23762\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2744 | loss: 1.23762 - acc: 0.7587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2745  | total loss: \u001b[1m\u001b[32m1.14869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2745 | loss: 1.14869 - acc: 0.7829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2746  | total loss: \u001b[1m\u001b[32m1.41177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2746 | loss: 1.41177 - acc: 0.7117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2747  | total loss: \u001b[1m\u001b[32m1.30468\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2747 | loss: 1.30468 - acc: 0.7406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2748  | total loss: \u001b[1m\u001b[32m1.54804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2748 | loss: 1.54804 - acc: 0.6736 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2749  | total loss: \u001b[1m\u001b[32m1.42782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2749 | loss: 1.42782 - acc: 0.7063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2750  | total loss: \u001b[1m\u001b[32m1.31990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2750 | loss: 1.31990 - acc: 0.7357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2751  | total loss: \u001b[1m\u001b[32m1.22262\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2751 | loss: 1.22262 - acc: 0.7621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2752  | total loss: \u001b[1m\u001b[32m1.13451\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2752 | loss: 1.13451 - acc: 0.7859 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2753  | total loss: \u001b[1m\u001b[32m1.05431\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2753 | loss: 1.05431 - acc: 0.8073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2754  | total loss: \u001b[1m\u001b[32m0.98094\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2754 | loss: 0.98094 - acc: 0.8266 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2755  | total loss: \u001b[1m\u001b[32m0.91348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2755 | loss: 0.91348 - acc: 0.8439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2756  | total loss: \u001b[1m\u001b[32m1.14405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2756 | loss: 1.14405 - acc: 0.7809 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2757  | total loss: \u001b[1m\u001b[32m1.05809\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2757 | loss: 1.05809 - acc: 0.8028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2758  | total loss: \u001b[1m\u001b[32m0.97989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2758 | loss: 0.97989 - acc: 0.8226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2759  | total loss: \u001b[1m\u001b[32m0.90847\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2759 | loss: 0.90847 - acc: 0.8403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2760  | total loss: \u001b[1m\u001b[32m0.84299\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2760 | loss: 0.84299 - acc: 0.8563 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2761  | total loss: \u001b[1m\u001b[32m0.78272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2761 | loss: 0.78272 - acc: 0.8706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2762  | total loss: \u001b[1m\u001b[32m0.72708\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2762 | loss: 0.72708 - acc: 0.8836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2763  | total loss: \u001b[1m\u001b[32m0.67556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2763 | loss: 0.67556 - acc: 0.8952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2764  | total loss: \u001b[1m\u001b[32m0.62774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2764 | loss: 0.62774 - acc: 0.9057 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2765  | total loss: \u001b[1m\u001b[32m0.58327\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2765 | loss: 0.58327 - acc: 0.9151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2766  | total loss: \u001b[1m\u001b[32m0.54186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2766 | loss: 0.54186 - acc: 0.9236 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2767  | total loss: \u001b[1m\u001b[32m0.50326\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2767 | loss: 0.50326 - acc: 0.9313 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2768  | total loss: \u001b[1m\u001b[32m0.46727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2768 | loss: 0.46727 - acc: 0.9381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2769  | total loss: \u001b[1m\u001b[32m0.43370\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2769 | loss: 0.43370 - acc: 0.9443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2770  | total loss: \u001b[1m\u001b[32m0.85566\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2770 | loss: 0.85566 - acc: 0.8570 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2771  | total loss: \u001b[1m\u001b[32m0.78184\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2771 | loss: 0.78184 - acc: 0.8713 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2772  | total loss: \u001b[1m\u001b[32m0.71504\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2772 | loss: 0.71504 - acc: 0.8842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2773  | total loss: \u001b[1m\u001b[32m0.65454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2773 | loss: 0.65454 - acc: 0.8958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2774  | total loss: \u001b[1m\u001b[32m0.59967\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2774 | loss: 0.59967 - acc: 0.9062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2775  | total loss: \u001b[1m\u001b[32m0.54986\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2775 | loss: 0.54986 - acc: 0.9156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2776  | total loss: \u001b[1m\u001b[32m0.50459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2776 | loss: 0.50459 - acc: 0.9240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2777  | total loss: \u001b[1m\u001b[32m0.46340\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2777 | loss: 0.46340 - acc: 0.9316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2778  | total loss: \u001b[1m\u001b[32m0.42589\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2778 | loss: 0.42589 - acc: 0.9385 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2779  | total loss: \u001b[1m\u001b[32m0.39169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2779 | loss: 0.39169 - acc: 0.9446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2780  | total loss: \u001b[1m\u001b[32m0.75054\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2780 | loss: 0.75054 - acc: 0.8787 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2781  | total loss: \u001b[1m\u001b[32m0.68344\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2781 | loss: 0.68344 - acc: 0.8908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2782  | total loss: \u001b[1m\u001b[32m0.62302\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2782 | loss: 0.62302 - acc: 0.9018 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2783  | total loss: \u001b[1m\u001b[32m0.56856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2783 | loss: 0.56856 - acc: 0.9116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2784  | total loss: \u001b[1m\u001b[32m0.98274\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2784 | loss: 0.98274 - acc: 0.8347 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2785  | total loss: \u001b[1m\u001b[32m0.89256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2785 | loss: 0.89256 - acc: 0.8512 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2786  | total loss: \u001b[1m\u001b[32m1.29385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2786 | loss: 1.29385 - acc: 0.7733 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2787  | total loss: \u001b[1m\u001b[32m1.17362\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2787 | loss: 1.17362 - acc: 0.7959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2788  | total loss: \u001b[1m\u001b[32m1.55835\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2788 | loss: 1.55835 - acc: 0.7235 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2789  | total loss: \u001b[1m\u001b[32m1.41367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2789 | loss: 1.41367 - acc: 0.7511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2790  | total loss: \u001b[1m\u001b[32m1.28465\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2790 | loss: 1.28465 - acc: 0.7760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2791  | total loss: \u001b[1m\u001b[32m1.16961\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2791 | loss: 1.16961 - acc: 0.7984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2792  | total loss: \u001b[1m\u001b[32m1.52218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2792 | loss: 1.52218 - acc: 0.7186 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2793  | total loss: \u001b[1m\u001b[32m1.38594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2793 | loss: 1.38594 - acc: 0.7467 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2794  | total loss: \u001b[1m\u001b[32m1.63366\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2794 | loss: 1.63366 - acc: 0.6792 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2795  | total loss: \u001b[1m\u001b[32m1.49005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2795 | loss: 1.49005 - acc: 0.7113 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2796  | total loss: \u001b[1m\u001b[32m1.36288\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2796 | loss: 1.36288 - acc: 0.7401 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2797  | total loss: \u001b[1m\u001b[32m1.25018\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2797 | loss: 1.25018 - acc: 0.7661 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2798  | total loss: \u001b[1m\u001b[32m1.52064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2798 | loss: 1.52064 - acc: 0.6967 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2799  | total loss: \u001b[1m\u001b[32m1.39575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2799 | loss: 1.39575 - acc: 0.7270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2800  | total loss: \u001b[1m\u001b[32m1.28510\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2800 | loss: 1.28510 - acc: 0.7543 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2801  | total loss: \u001b[1m\u001b[32m1.18680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2801 | loss: 1.18680 - acc: 0.7789 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2802  | total loss: \u001b[1m\u001b[32m1.45734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2802 | loss: 1.45734 - acc: 0.7081 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2803  | total loss: \u001b[1m\u001b[32m1.34431\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2803 | loss: 1.34431 - acc: 0.7373 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2804  | total loss: \u001b[1m\u001b[32m1.56798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2804 | loss: 1.56798 - acc: 0.6779 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2805  | total loss: \u001b[1m\u001b[32m1.44710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2805 | loss: 1.44710 - acc: 0.7101 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2806  | total loss: \u001b[1m\u001b[32m1.33974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2806 | loss: 1.33974 - acc: 0.7391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2807  | total loss: \u001b[1m\u001b[32m1.24393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2807 | loss: 1.24393 - acc: 0.7652 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2808  | total loss: \u001b[1m\u001b[32m1.47804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2808 | loss: 1.47804 - acc: 0.6958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2809  | total loss: \u001b[1m\u001b[32m1.36991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2809 | loss: 1.36991 - acc: 0.7262 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2810  | total loss: \u001b[1m\u001b[32m1.27323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2810 | loss: 1.27323 - acc: 0.7536 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2811  | total loss: \u001b[1m\u001b[32m1.18627\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2811 | loss: 1.18627 - acc: 0.7782 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2812  | total loss: \u001b[1m\u001b[32m1.10749\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2812 | loss: 1.10749 - acc: 0.8004 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2813  | total loss: \u001b[1m\u001b[32m1.03560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2813 | loss: 1.03560 - acc: 0.8204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2814  | total loss: \u001b[1m\u001b[32m0.96950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2814 | loss: 0.96950 - acc: 0.8383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2815  | total loss: \u001b[1m\u001b[32m0.90831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2815 | loss: 0.90831 - acc: 0.8545 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2816  | total loss: \u001b[1m\u001b[32m1.18241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2816 | loss: 1.18241 - acc: 0.7690 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2817  | total loss: \u001b[1m\u001b[32m1.09743\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2817 | loss: 1.09743 - acc: 0.7921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2818  | total loss: \u001b[1m\u001b[32m1.02005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2818 | loss: 1.02005 - acc: 0.8129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2819  | total loss: \u001b[1m\u001b[32m0.94920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2819 | loss: 0.94920 - acc: 0.8316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2820  | total loss: \u001b[1m\u001b[32m1.20375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2820 | loss: 1.20375 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2821  | total loss: \u001b[1m\u001b[32m1.11274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2821 | loss: 1.11274 - acc: 0.7865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2822  | total loss: \u001b[1m\u001b[32m1.38395\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2822 | loss: 1.38395 - acc: 0.7078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2823  | total loss: \u001b[1m\u001b[32m1.27473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2823 | loss: 1.27473 - acc: 0.7371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2824  | total loss: \u001b[1m\u001b[32m1.55655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2824 | loss: 1.55655 - acc: 0.6633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2825  | total loss: \u001b[1m\u001b[32m1.43135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2825 | loss: 1.43135 - acc: 0.6970 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2826  | total loss: \u001b[1m\u001b[32m1.31940\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2826 | loss: 1.31940 - acc: 0.7273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2827  | total loss: \u001b[1m\u001b[32m1.21893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2827 | loss: 1.21893 - acc: 0.7546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2828  | total loss: \u001b[1m\u001b[32m1.12837\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2828 | loss: 1.12837 - acc: 0.7791 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2829  | total loss: \u001b[1m\u001b[32m1.04636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2829 | loss: 1.04636 - acc: 0.8012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2830  | total loss: \u001b[1m\u001b[32m0.97171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2830 | loss: 0.97171 - acc: 0.8211 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2831  | total loss: \u001b[1m\u001b[32m0.90343\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2831 | loss: 0.90343 - acc: 0.8390 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2832  | total loss: \u001b[1m\u001b[32m1.20761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2832 | loss: 1.20761 - acc: 0.7622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2833  | total loss: \u001b[1m\u001b[32m1.11426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2833 | loss: 1.11426 - acc: 0.7860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2834  | total loss: \u001b[1m\u001b[32m1.02979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2834 | loss: 1.02979 - acc: 0.8074 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2835  | total loss: \u001b[1m\u001b[32m0.95305\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2835 | loss: 0.95305 - acc: 0.8267 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2836  | total loss: \u001b[1m\u001b[32m1.25121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2836 | loss: 1.25121 - acc: 0.7511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2837  | total loss: \u001b[1m\u001b[32m1.15149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2837 | loss: 1.15149 - acc: 0.7760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2838  | total loss: \u001b[1m\u001b[32m1.43476\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2838 | loss: 1.43476 - acc: 0.7056 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2839  | total loss: \u001b[1m\u001b[32m1.31737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2839 | loss: 1.31737 - acc: 0.7350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2840  | total loss: \u001b[1m\u001b[32m1.55032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2840 | loss: 1.55032 - acc: 0.6758 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2841  | total loss: \u001b[1m\u001b[32m1.42320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2841 | loss: 1.42320 - acc: 0.7082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2842  | total loss: \u001b[1m\u001b[32m1.30969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2842 | loss: 1.30969 - acc: 0.7374 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2843  | total loss: \u001b[1m\u001b[32m1.20802\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2843 | loss: 1.20802 - acc: 0.7637 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2844  | total loss: \u001b[1m\u001b[32m1.45330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2844 | loss: 1.45330 - acc: 0.6944 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2845  | total loss: \u001b[1m\u001b[32m1.33841\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2845 | loss: 1.33841 - acc: 0.7250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2846  | total loss: \u001b[1m\u001b[32m1.23562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2846 | loss: 1.23562 - acc: 0.7525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2847  | total loss: \u001b[1m\u001b[32m1.14328\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2847 | loss: 1.14328 - acc: 0.7772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2848  | total loss: \u001b[1m\u001b[32m1.40477\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2848 | loss: 1.40477 - acc: 0.7067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2849  | total loss: \u001b[1m\u001b[32m1.29605\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2849 | loss: 1.29605 - acc: 0.7360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2850  | total loss: \u001b[1m\u001b[32m1.49815\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2850 | loss: 1.49815 - acc: 0.6838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2851  | total loss: \u001b[1m\u001b[32m1.38150\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2851 | loss: 1.38150 - acc: 0.7154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2852  | total loss: \u001b[1m\u001b[32m1.64007\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2852 | loss: 1.64007 - acc: 0.6439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2853  | total loss: \u001b[1m\u001b[32m1.51163\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2853 | loss: 1.51163 - acc: 0.6795 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2854  | total loss: \u001b[1m\u001b[32m1.39721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2854 | loss: 1.39721 - acc: 0.7116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2855  | total loss: \u001b[1m\u001b[32m1.29484\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2855 | loss: 1.29484 - acc: 0.7404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2856  | total loss: \u001b[1m\u001b[32m1.20278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2856 | loss: 1.20278 - acc: 0.7664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2857  | total loss: \u001b[1m\u001b[32m1.11949\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2857 | loss: 1.11949 - acc: 0.7897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2858  | total loss: \u001b[1m\u001b[32m1.38947\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2858 | loss: 1.38947 - acc: 0.7108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2859  | total loss: \u001b[1m\u001b[32m1.28695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2859 | loss: 1.28695 - acc: 0.7397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2860  | total loss: \u001b[1m\u001b[32m1.50602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2860 | loss: 1.50602 - acc: 0.6800 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2861  | total loss: \u001b[1m\u001b[32m1.39240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2861 | loss: 1.39240 - acc: 0.7120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2862  | total loss: \u001b[1m\u001b[32m1.29035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2862 | loss: 1.29035 - acc: 0.7408 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2863  | total loss: \u001b[1m\u001b[32m1.19820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2863 | loss: 1.19820 - acc: 0.7667 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2864  | total loss: \u001b[1m\u001b[32m1.11454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2864 | loss: 1.11454 - acc: 0.7900 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2865  | total loss: \u001b[1m\u001b[32m1.03813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2865 | loss: 1.03813 - acc: 0.8110 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2866  | total loss: \u001b[1m\u001b[32m0.96794\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2866 | loss: 0.96794 - acc: 0.8299 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2867  | total loss: \u001b[1m\u001b[32m0.90310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2867 | loss: 0.90310 - acc: 0.8469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2868  | total loss: \u001b[1m\u001b[32m1.18360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2868 | loss: 1.18360 - acc: 0.7765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2869  | total loss: \u001b[1m\u001b[32m1.09466\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2869 | loss: 1.09466 - acc: 0.7989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2870  | total loss: \u001b[1m\u001b[32m1.01366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2870 | loss: 1.01366 - acc: 0.8190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2871  | total loss: \u001b[1m\u001b[32m0.93959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2871 | loss: 0.93959 - acc: 0.8371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2872  | total loss: \u001b[1m\u001b[32m1.12381\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2872 | loss: 1.12381 - acc: 0.7891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2873  | total loss: \u001b[1m\u001b[32m1.03685\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2873 | loss: 1.03685 - acc: 0.8102 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2874  | total loss: \u001b[1m\u001b[32m0.95783\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2874 | loss: 0.95783 - acc: 0.8292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2875  | total loss: \u001b[1m\u001b[32m0.88579\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2875 | loss: 0.88579 - acc: 0.8463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2876  | total loss: \u001b[1m\u001b[32m0.81991\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 2876 | loss: 0.81991 - acc: 0.8616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2877  | total loss: \u001b[1m\u001b[32m0.75947\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2877 | loss: 0.75947 - acc: 0.8755 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2878  | total loss: \u001b[1m\u001b[32m0.70387\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2878 | loss: 0.70387 - acc: 0.8879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2879  | total loss: \u001b[1m\u001b[32m0.65260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2879 | loss: 0.65260 - acc: 0.8991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2880  | total loss: \u001b[1m\u001b[32m0.60520\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2880 | loss: 0.60520 - acc: 0.9092 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2881  | total loss: \u001b[1m\u001b[32m0.56131\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2881 | loss: 0.56131 - acc: 0.9183 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2882  | total loss: \u001b[1m\u001b[32m0.52061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2882 | loss: 0.52061 - acc: 0.9265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2883  | total loss: \u001b[1m\u001b[32m0.48283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2883 | loss: 0.48283 - acc: 0.9338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2884  | total loss: \u001b[1m\u001b[32m0.44774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2884 | loss: 0.44774 - acc: 0.9404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2885  | total loss: \u001b[1m\u001b[32m0.41513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2885 | loss: 0.41513 - acc: 0.9464 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2886  | total loss: \u001b[1m\u001b[32m0.38483\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2886 | loss: 0.38483 - acc: 0.9518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2887  | total loss: \u001b[1m\u001b[32m0.35667\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2887 | loss: 0.35667 - acc: 0.9566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2888  | total loss: \u001b[1m\u001b[32m0.80165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2888 | loss: 0.80165 - acc: 0.8681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2889  | total loss: \u001b[1m\u001b[32m0.73079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2889 | loss: 0.73079 - acc: 0.8813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2890  | total loss: \u001b[1m\u001b[32m1.15456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2890 | loss: 1.15456 - acc: 0.8003 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2891  | total loss: \u001b[1m\u001b[32m1.04847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2891 | loss: 1.04847 - acc: 0.8202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2892  | total loss: \u001b[1m\u001b[32m1.40450\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2892 | loss: 1.40450 - acc: 0.7525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2893  | total loss: \u001b[1m\u001b[32m1.27441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2893 | loss: 1.27441 - acc: 0.7773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2894  | total loss: \u001b[1m\u001b[32m1.61098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2894 | loss: 1.61098 - acc: 0.7067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2895  | total loss: \u001b[1m\u001b[32m1.46223\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2895 | loss: 1.46223 - acc: 0.7360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2896  | total loss: \u001b[1m\u001b[32m1.73976\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2896 | loss: 1.73976 - acc: 0.6767 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2897  | total loss: \u001b[1m\u001b[32m1.58121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2897 | loss: 1.58121 - acc: 0.7090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2898  | total loss: \u001b[1m\u001b[32m1.86224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2898 | loss: 1.86224 - acc: 0.6453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2899  | total loss: \u001b[1m\u001b[32m1.69569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2899 | loss: 1.69569 - acc: 0.6807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2900  | total loss: \u001b[1m\u001b[32m1.96186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2900 | loss: 1.96186 - acc: 0.6127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2901  | total loss: \u001b[1m\u001b[32m1.79091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2901 | loss: 1.79091 - acc: 0.6514 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2902  | total loss: \u001b[1m\u001b[32m2.01148\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2902 | loss: 2.01148 - acc: 0.5934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2903  | total loss: \u001b[1m\u001b[32m1.84237\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2903 | loss: 1.84237 - acc: 0.6341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2904  | total loss: \u001b[1m\u001b[32m2.05252\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2904 | loss: 2.05252 - acc: 0.5707 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2905  | total loss: \u001b[1m\u001b[32m1.88698\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2905 | loss: 1.88698 - acc: 0.6136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2906  | total loss: \u001b[1m\u001b[32m2.05188\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2906 | loss: 2.05188 - acc: 0.5594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2907  | total loss: \u001b[1m\u001b[32m1.89438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2907 | loss: 1.89438 - acc: 0.6034 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2908  | total loss: \u001b[1m\u001b[32m2.02217\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2908 | loss: 2.02217 - acc: 0.5502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2909  | total loss: \u001b[1m\u001b[32m1.87523\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2909 | loss: 1.87523 - acc: 0.5952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2910  | total loss: \u001b[1m\u001b[32m2.02584\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2910 | loss: 2.02584 - acc: 0.5357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2911  | total loss: \u001b[1m\u001b[32m1.88568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2911 | loss: 1.88568 - acc: 0.5821 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2912  | total loss: \u001b[1m\u001b[32m1.76238\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2912 | loss: 1.76238 - acc: 0.6239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2913  | total loss: \u001b[1m\u001b[32m1.65314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2913 | loss: 1.65314 - acc: 0.6615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2914  | total loss: \u001b[1m\u001b[32m1.81751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2914 | loss: 1.81751 - acc: 0.5954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2915  | total loss: \u001b[1m\u001b[32m1.70493\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2915 | loss: 1.70493 - acc: 0.6358 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2916  | total loss: \u001b[1m\u001b[32m1.60405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2916 | loss: 1.60405 - acc: 0.6722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2917  | total loss: \u001b[1m\u001b[32m1.51273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2917 | loss: 1.51273 - acc: 0.7050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2918  | total loss: \u001b[1m\u001b[32m1.67661\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2918 | loss: 1.67661 - acc: 0.6417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2919  | total loss: \u001b[1m\u001b[32m1.57622\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2919 | loss: 1.57622 - acc: 0.6775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2920  | total loss: \u001b[1m\u001b[32m1.75964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2920 | loss: 1.75964 - acc: 0.6169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2921  | total loss: \u001b[1m\u001b[32m1.64950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2921 | loss: 1.64950 - acc: 0.6552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2922  | total loss: \u001b[1m\u001b[32m1.54933\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2922 | loss: 1.54933 - acc: 0.6897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2923  | total loss: \u001b[1m\u001b[32m1.45739\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2923 | loss: 1.45739 - acc: 0.7207 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2924  | total loss: \u001b[1m\u001b[32m1.58316\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2924 | loss: 1.58316 - acc: 0.6772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2925  | total loss: \u001b[1m\u001b[32m1.48375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2925 | loss: 1.48375 - acc: 0.7095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2926  | total loss: \u001b[1m\u001b[32m1.69513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2926 | loss: 1.69513 - acc: 0.6385 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2927  | total loss: \u001b[1m\u001b[32m1.58134\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2927 | loss: 1.58134 - acc: 0.6747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2928  | total loss: \u001b[1m\u001b[32m1.47737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2928 | loss: 1.47737 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2929  | total loss: \u001b[1m\u001b[32m1.38171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2929 | loss: 1.38171 - acc: 0.7365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2930  | total loss: \u001b[1m\u001b[32m1.29311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2930 | loss: 1.29311 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2931  | total loss: \u001b[1m\u001b[32m1.21056\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2931 | loss: 1.21056 - acc: 0.7866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2932  | total loss: \u001b[1m\u001b[32m1.13322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2932 | loss: 1.13322 - acc: 0.8079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2933  | total loss: \u001b[1m\u001b[32m1.06045\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2933 | loss: 1.06045 - acc: 0.8271 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2934  | total loss: \u001b[1m\u001b[32m1.29022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2934 | loss: 1.29022 - acc: 0.7587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2935  | total loss: \u001b[1m\u001b[32m1.19659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2935 | loss: 1.19659 - acc: 0.7828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2936  | total loss: \u001b[1m\u001b[32m1.11024\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2936 | loss: 1.11024 - acc: 0.8045 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2937  | total loss: \u001b[1m\u001b[32m1.03034\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2937 | loss: 1.03034 - acc: 0.8241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2938  | total loss: \u001b[1m\u001b[32m1.33979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2938 | loss: 1.33979 - acc: 0.7417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2939  | total loss: \u001b[1m\u001b[32m1.23384\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2939 | loss: 1.23384 - acc: 0.7675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2940  | total loss: \u001b[1m\u001b[32m1.51572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2940 | loss: 1.51572 - acc: 0.6908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2941  | total loss: \u001b[1m\u001b[32m1.39117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2941 | loss: 1.39117 - acc: 0.7217 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2942  | total loss: \u001b[1m\u001b[32m1.27887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2942 | loss: 1.27887 - acc: 0.7495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2943  | total loss: \u001b[1m\u001b[32m1.17732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2943 | loss: 1.17732 - acc: 0.7746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2944  | total loss: \u001b[1m\u001b[32m1.08524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2944 | loss: 1.08524 - acc: 0.7971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2945  | total loss: \u001b[1m\u001b[32m1.00149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2945 | loss: 1.00149 - acc: 0.8174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2946  | total loss: \u001b[1m\u001b[32m1.32431\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2946 | loss: 1.32431 - acc: 0.7357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2947  | total loss: \u001b[1m\u001b[32m1.21572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2947 | loss: 1.21572 - acc: 0.7621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2948  | total loss: \u001b[1m\u001b[32m1.11784\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2948 | loss: 1.11784 - acc: 0.7859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2949  | total loss: \u001b[1m\u001b[32m1.02938\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2949 | loss: 1.02938 - acc: 0.8073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2950  | total loss: \u001b[1m\u001b[32m1.31222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2950 | loss: 1.31222 - acc: 0.7337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2951  | total loss: \u001b[1m\u001b[32m1.20413\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2951 | loss: 1.20413 - acc: 0.7603 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2952  | total loss: \u001b[1m\u001b[32m1.48407\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2952 | loss: 1.48407 - acc: 0.6843 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2953  | total loss: \u001b[1m\u001b[32m1.36002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2953 | loss: 1.36002 - acc: 0.7159 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2954  | total loss: \u001b[1m\u001b[32m1.24915\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2954 | loss: 1.24915 - acc: 0.7443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2955  | total loss: \u001b[1m\u001b[32m1.14982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2955 | loss: 1.14982 - acc: 0.7699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2956  | total loss: \u001b[1m\u001b[32m1.44596\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2956 | loss: 1.44596 - acc: 0.7000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2957  | total loss: \u001b[1m\u001b[32m1.32818\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2957 | loss: 1.32818 - acc: 0.7300 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2958  | total loss: \u001b[1m\u001b[32m1.22288\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2958 | loss: 1.22288 - acc: 0.7570 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2959  | total loss: \u001b[1m\u001b[32m1.12843\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2959 | loss: 1.12843 - acc: 0.7813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2960  | total loss: \u001b[1m\u001b[32m1.41017\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2960 | loss: 1.41017 - acc: 0.7103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2961  | total loss: \u001b[1m\u001b[32m1.29790\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2961 | loss: 1.29790 - acc: 0.7393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2962  | total loss: \u001b[1m\u001b[32m1.51577\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2962 | loss: 1.51577 - acc: 0.6796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2963  | total loss: \u001b[1m\u001b[32m1.39491\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2963 | loss: 1.39491 - acc: 0.7117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2964  | total loss: \u001b[1m\u001b[32m1.61813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2964 | loss: 1.61813 - acc: 0.6477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2965  | total loss: \u001b[1m\u001b[32m1.48979\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 2965 | loss: 1.48979 - acc: 0.6829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2966  | total loss: \u001b[1m\u001b[32m1.69438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2966 | loss: 1.69438 - acc: 0.6217 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2967  | total loss: \u001b[1m\u001b[32m1.56175\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2967 | loss: 1.56175 - acc: 0.6596 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2968  | total loss: \u001b[1m\u001b[32m1.44383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2968 | loss: 1.44383 - acc: 0.6936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2969  | total loss: \u001b[1m\u001b[32m1.33854\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2969 | loss: 1.33854 - acc: 0.7243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2970  | total loss: \u001b[1m\u001b[32m1.24404\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2970 | loss: 1.24404 - acc: 0.7518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2971  | total loss: \u001b[1m\u001b[32m1.15872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2971 | loss: 1.15872 - acc: 0.7766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2972  | total loss: \u001b[1m\u001b[32m1.08119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2972 | loss: 1.08119 - acc: 0.7990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2973  | total loss: \u001b[1m\u001b[32m1.01026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2973 | loss: 1.01026 - acc: 0.8191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2974  | total loss: \u001b[1m\u001b[32m1.27142\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2974 | loss: 1.27142 - acc: 0.7443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2975  | total loss: \u001b[1m\u001b[32m1.17967\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2975 | loss: 1.17967 - acc: 0.7699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2976  | total loss: \u001b[1m\u001b[32m1.09639\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2976 | loss: 1.09639 - acc: 0.7929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2977  | total loss: \u001b[1m\u001b[32m1.02038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2977 | loss: 1.02038 - acc: 0.8136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2978  | total loss: \u001b[1m\u001b[32m1.28548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2978 | loss: 1.28548 - acc: 0.7394 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2979  | total loss: \u001b[1m\u001b[32m1.18913\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2979 | loss: 1.18913 - acc: 0.7654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2980  | total loss: \u001b[1m\u001b[32m1.10195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2980 | loss: 1.10195 - acc: 0.7889 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 2981  | total loss: \u001b[1m\u001b[32m1.02270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2981 | loss: 1.02270 - acc: 0.8100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2982  | total loss: \u001b[1m\u001b[32m1.29683\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2982 | loss: 1.29683 - acc: 0.7362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2983  | total loss: \u001b[1m\u001b[32m1.19702\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2983 | loss: 1.19702 - acc: 0.7625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2984  | total loss: \u001b[1m\u001b[32m1.44033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2984 | loss: 1.44033 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2985  | total loss: \u001b[1m\u001b[32m1.32644\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2985 | loss: 1.32644 - acc: 0.7241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2986  | total loss: \u001b[1m\u001b[32m1.57651\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2986 | loss: 1.57651 - acc: 0.6588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2987  | total loss: \u001b[1m\u001b[32m1.45046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2987 | loss: 1.45046 - acc: 0.6929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2988  | total loss: \u001b[1m\u001b[32m1.70972\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2988 | loss: 1.70972 - acc: 0.6236 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2989  | total loss: \u001b[1m\u001b[32m1.57303\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2989 | loss: 1.57303 - acc: 0.6613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2990  | total loss: \u001b[1m\u001b[32m1.45137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2990 | loss: 1.45137 - acc: 0.6952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2991  | total loss: \u001b[1m\u001b[32m1.34267\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2991 | loss: 1.34267 - acc: 0.7256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2992  | total loss: \u001b[1m\u001b[32m1.24510\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2992 | loss: 1.24510 - acc: 0.7531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2993  | total loss: \u001b[1m\u001b[32m1.15706\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2993 | loss: 1.15706 - acc: 0.7778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2994  | total loss: \u001b[1m\u001b[32m1.07714\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2994 | loss: 1.07714 - acc: 0.8000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2995  | total loss: \u001b[1m\u001b[32m1.00415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2995 | loss: 1.00415 - acc: 0.8200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2996  | total loss: \u001b[1m\u001b[32m1.28567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2996 | loss: 1.28567 - acc: 0.7451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2997  | total loss: \u001b[1m\u001b[32m1.19025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2997 | loss: 1.19025 - acc: 0.7706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2998  | total loss: \u001b[1m\u001b[32m1.10379\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2998 | loss: 1.10379 - acc: 0.7936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 2999  | total loss: \u001b[1m\u001b[32m1.02506\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 2999 | loss: 1.02506 - acc: 0.8142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3000  | total loss: \u001b[1m\u001b[32m1.32197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3000 | loss: 1.32197 - acc: 0.7328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3001  | total loss: \u001b[1m\u001b[32m1.22035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3001 | loss: 1.22035 - acc: 0.7595 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3002  | total loss: \u001b[1m\u001b[32m1.12863\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3002 | loss: 1.12863 - acc: 0.7836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3003  | total loss: \u001b[1m\u001b[32m1.04550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3003 | loss: 1.04550 - acc: 0.8052 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3004  | total loss: \u001b[1m\u001b[32m0.96980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3004 | loss: 0.96980 - acc: 0.8247 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3005  | total loss: \u001b[1m\u001b[32m0.90058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3005 | loss: 0.90058 - acc: 0.8422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3006  | total loss: \u001b[1m\u001b[32m0.83701\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3006 | loss: 0.83701 - acc: 0.8580 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3007  | total loss: \u001b[1m\u001b[32m0.77840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3007 | loss: 0.77840 - acc: 0.8722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3008  | total loss: \u001b[1m\u001b[32m1.08407\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3008 | loss: 1.08407 - acc: 0.7921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3009  | total loss: \u001b[1m\u001b[32m0.99887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3009 | loss: 0.99887 - acc: 0.8129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3010  | total loss: \u001b[1m\u001b[32m1.33612\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3010 | loss: 1.33612 - acc: 0.7316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3011  | total loss: \u001b[1m\u001b[32m1.22562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3011 | loss: 1.22562 - acc: 0.7585 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3012  | total loss: \u001b[1m\u001b[32m1.48873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3012 | loss: 1.48873 - acc: 0.6969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3013  | total loss: \u001b[1m\u001b[32m1.36429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3013 | loss: 1.36429 - acc: 0.7272 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3014  | total loss: \u001b[1m\u001b[32m1.66991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3014 | loss: 1.66991 - acc: 0.6545 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3015  | total loss: \u001b[1m\u001b[32m1.52992\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3015 | loss: 1.52992 - acc: 0.6890 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3016  | total loss: \u001b[1m\u001b[32m1.40529\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3016 | loss: 1.40529 - acc: 0.7201 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3017  | total loss: \u001b[1m\u001b[32m1.29406\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3017 | loss: 1.29406 - acc: 0.7481 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3018  | total loss: \u001b[1m\u001b[32m1.44077\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3018 | loss: 1.44077 - acc: 0.7090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3019  | total loss: \u001b[1m\u001b[32m1.32751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3019 | loss: 1.32751 - acc: 0.7381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3020  | total loss: \u001b[1m\u001b[32m1.22614\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3020 | loss: 1.22614 - acc: 0.7643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3021  | total loss: \u001b[1m\u001b[32m1.13503\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3021 | loss: 1.13503 - acc: 0.7879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3022  | total loss: \u001b[1m\u001b[32m1.39061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3022 | loss: 1.39061 - acc: 0.7162 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3023  | total loss: \u001b[1m\u001b[32m1.28352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3023 | loss: 1.28352 - acc: 0.7446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3024  | total loss: \u001b[1m\u001b[32m1.53068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3024 | loss: 1.53068 - acc: 0.6773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3025  | total loss: \u001b[1m\u001b[32m1.41115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3025 | loss: 1.41115 - acc: 0.7096 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3026  | total loss: \u001b[1m\u001b[32m1.66657\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3026 | loss: 1.66657 - acc: 0.6386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3027  | total loss: \u001b[1m\u001b[32m1.53615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3027 | loss: 1.53615 - acc: 0.6747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3028  | total loss: \u001b[1m\u001b[32m1.42009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3028 | loss: 1.42009 - acc: 0.7073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3029  | total loss: \u001b[1m\u001b[32m1.31636\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3029 | loss: 1.31636 - acc: 0.7365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3030  | total loss: \u001b[1m\u001b[32m1.57967\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3030 | loss: 1.57967 - acc: 0.6629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3031  | total loss: \u001b[1m\u001b[32m1.46143\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3031 | loss: 1.46143 - acc: 0.6966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3032  | total loss: \u001b[1m\u001b[32m1.35568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3032 | loss: 1.35568 - acc: 0.7269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3033  | total loss: \u001b[1m\u001b[32m1.26057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3033 | loss: 1.26057 - acc: 0.7542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3034  | total loss: \u001b[1m\u001b[32m1.17450\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3034 | loss: 1.17450 - acc: 0.7788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3035  | total loss: \u001b[1m\u001b[32m1.09609\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3035 | loss: 1.09609 - acc: 0.8009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3036  | total loss: \u001b[1m\u001b[32m1.02417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3036 | loss: 1.02417 - acc: 0.8208 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3037  | total loss: \u001b[1m\u001b[32m0.95778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3037 | loss: 0.95778 - acc: 0.8388 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3038  | total loss: \u001b[1m\u001b[32m1.25542\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3038 | loss: 1.25542 - acc: 0.7620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3039  | total loss: \u001b[1m\u001b[32m1.16337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3039 | loss: 1.16337 - acc: 0.7858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3040  | total loss: \u001b[1m\u001b[32m1.07957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3040 | loss: 1.07957 - acc: 0.8072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3041  | total loss: \u001b[1m\u001b[32m1.00292\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3041 | loss: 1.00292 - acc: 0.8265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3042  | total loss: \u001b[1m\u001b[32m1.30061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3042 | loss: 1.30061 - acc: 0.7439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3043  | total loss: \u001b[1m\u001b[32m1.20015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3043 | loss: 1.20015 - acc: 0.7695 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3044  | total loss: \u001b[1m\u001b[32m1.43439\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3044 | loss: 1.43439 - acc: 0.6997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3045  | total loss: \u001b[1m\u001b[32m1.32040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3045 | loss: 1.32040 - acc: 0.7297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3046  | total loss: \u001b[1m\u001b[32m1.58976\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3046 | loss: 1.58976 - acc: 0.6639 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3047  | total loss: \u001b[1m\u001b[32m1.46132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3047 | loss: 1.46132 - acc: 0.6975 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3048  | total loss: \u001b[1m\u001b[32m1.34632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3048 | loss: 1.34632 - acc: 0.7277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3049  | total loss: \u001b[1m\u001b[32m1.24301\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3049 | loss: 1.24301 - acc: 0.7550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3050  | total loss: \u001b[1m\u001b[32m1.14983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3050 | loss: 1.14983 - acc: 0.7795 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3051  | total loss: \u001b[1m\u001b[32m1.06543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3051 | loss: 1.06543 - acc: 0.8015 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3052  | total loss: \u001b[1m\u001b[32m1.30682\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3052 | loss: 1.30682 - acc: 0.7357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3053  | total loss: \u001b[1m\u001b[32m1.20598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3053 | loss: 1.20598 - acc: 0.7621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3054  | total loss: \u001b[1m\u001b[32m1.45889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3054 | loss: 1.45889 - acc: 0.6930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3055  | total loss: \u001b[1m\u001b[32m1.34333\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3055 | loss: 1.34333 - acc: 0.7237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3056  | total loss: \u001b[1m\u001b[32m1.60063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3056 | loss: 1.60063 - acc: 0.6585 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3057  | total loss: \u001b[1m\u001b[32m1.47248\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3057 | loss: 1.47248 - acc: 0.6926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3058  | total loss: \u001b[1m\u001b[32m1.68933\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3058 | loss: 1.68933 - acc: 0.6305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3059  | total loss: \u001b[1m\u001b[32m1.55480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3059 | loss: 1.55480 - acc: 0.6675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3060  | total loss: \u001b[1m\u001b[32m1.77049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3060 | loss: 1.77049 - acc: 0.6079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3061  | total loss: \u001b[1m\u001b[32m1.63105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3061 | loss: 1.63105 - acc: 0.6471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3062  | total loss: \u001b[1m\u001b[32m1.82742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3062 | loss: 1.82742 - acc: 0.5895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3063  | total loss: \u001b[1m\u001b[32m1.68610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3063 | loss: 1.68610 - acc: 0.6306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3064  | total loss: \u001b[1m\u001b[32m1.89880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3064 | loss: 1.89880 - acc: 0.5675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3065  | total loss: \u001b[1m\u001b[32m1.75480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3065 | loss: 1.75480 - acc: 0.6108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3066  | total loss: \u001b[1m\u001b[32m1.91882\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3066 | loss: 1.91882 - acc: 0.5568 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3067  | total loss: \u001b[1m\u001b[32m1.77754\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3067 | loss: 1.77754 - acc: 0.6011 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3068  | total loss: \u001b[1m\u001b[32m1.94735\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3068 | loss: 1.94735 - acc: 0.5482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3069  | total loss: \u001b[1m\u001b[32m1.80775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3069 | loss: 1.80775 - acc: 0.5934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3070  | total loss: \u001b[1m\u001b[32m1.99922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3070 | loss: 1.99922 - acc: 0.5340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3071  | total loss: \u001b[1m\u001b[32m1.85889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3071 | loss: 1.85889 - acc: 0.5806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3072  | total loss: \u001b[1m\u001b[32m1.73432\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3072 | loss: 1.73432 - acc: 0.6226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3073  | total loss: \u001b[1m\u001b[32m1.62297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3073 | loss: 1.62297 - acc: 0.6603 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3074  | total loss: \u001b[1m\u001b[32m1.52262\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3074 | loss: 1.52262 - acc: 0.6943 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3075  | total loss: \u001b[1m\u001b[32m1.43136\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3075 | loss: 1.43136 - acc: 0.7248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3076  | total loss: \u001b[1m\u001b[32m1.63147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3076 | loss: 1.63147 - acc: 0.6524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3077  | total loss: \u001b[1m\u001b[32m1.52722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3077 | loss: 1.52722 - acc: 0.6871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3078  | total loss: \u001b[1m\u001b[32m1.70726\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3078 | loss: 1.70726 - acc: 0.6256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3079  | total loss: \u001b[1m\u001b[32m1.59405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3079 | loss: 1.59405 - acc: 0.6630 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3080  | total loss: \u001b[1m\u001b[32m1.49124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3080 | loss: 1.49124 - acc: 0.6967 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3081  | total loss: \u001b[1m\u001b[32m1.39717\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3081 | loss: 1.39717 - acc: 0.7270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3082  | total loss: \u001b[1m\u001b[32m1.59706\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3082 | loss: 1.59706 - acc: 0.6615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3083  | total loss: \u001b[1m\u001b[32m1.48946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3083 | loss: 1.48946 - acc: 0.6953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3084  | total loss: \u001b[1m\u001b[32m1.70708\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3084 | loss: 1.70708 - acc: 0.6258 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3085  | total loss: \u001b[1m\u001b[32m1.58685\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3085 | loss: 1.58685 - acc: 0.6632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3086  | total loss: \u001b[1m\u001b[32m1.78787\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3086 | loss: 1.78787 - acc: 0.5969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3087  | total loss: \u001b[1m\u001b[32m1.65911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3087 | loss: 1.65911 - acc: 0.6372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3088  | total loss: \u001b[1m\u001b[32m1.54291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3088 | loss: 1.54291 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3089  | total loss: \u001b[1m\u001b[32m1.43740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3089 | loss: 1.43740 - acc: 0.7061 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3090  | total loss: \u001b[1m\u001b[32m1.34097\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3090 | loss: 1.34097 - acc: 0.7355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3091  | total loss: \u001b[1m\u001b[32m1.25229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3091 | loss: 1.25229 - acc: 0.7620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3092  | total loss: \u001b[1m\u001b[32m1.17022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3092 | loss: 1.17022 - acc: 0.7858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3093  | total loss: \u001b[1m\u001b[32m1.09386\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3093 | loss: 1.09386 - acc: 0.8072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3094  | total loss: \u001b[1m\u001b[32m1.02245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3094 | loss: 1.02245 - acc: 0.8265 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3095  | total loss: \u001b[1m\u001b[32m0.95542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3095 | loss: 0.95542 - acc: 0.8438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3096  | total loss: \u001b[1m\u001b[32m0.89230\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3096 | loss: 0.89230 - acc: 0.8594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3097  | total loss: \u001b[1m\u001b[32m0.83274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3097 | loss: 0.83274 - acc: 0.8735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3098  | total loss: \u001b[1m\u001b[32m1.13467\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3098 | loss: 1.13467 - acc: 0.7933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3099  | total loss: \u001b[1m\u001b[32m1.04684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3099 | loss: 1.04684 - acc: 0.8140 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3100  | total loss: \u001b[1m\u001b[32m1.31714\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3100 | loss: 1.31714 - acc: 0.7469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3101  | total loss: \u001b[1m\u001b[32m1.20920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3101 | loss: 1.20920 - acc: 0.7722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3102  | total loss: \u001b[1m\u001b[32m1.49471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3102 | loss: 1.49471 - acc: 0.7021 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3103  | total loss: \u001b[1m\u001b[32m1.36880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3103 | loss: 1.36880 - acc: 0.7319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3104  | total loss: \u001b[1m\u001b[32m1.62374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3104 | loss: 1.62374 - acc: 0.6658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3105  | total loss: \u001b[1m\u001b[32m1.48610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3105 | loss: 1.48610 - acc: 0.6993 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3106  | total loss: \u001b[1m\u001b[32m1.72416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3106 | loss: 1.72416 - acc: 0.6365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3107  | total loss: \u001b[1m\u001b[32m1.57880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3107 | loss: 1.57880 - acc: 0.6728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3108  | total loss: \u001b[1m\u001b[32m1.44920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3108 | loss: 1.44920 - acc: 0.7055 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3109  | total loss: \u001b[1m\u001b[32m1.33338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3109 | loss: 1.33338 - acc: 0.7350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3110  | total loss: \u001b[1m\u001b[32m1.58544\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3110 | loss: 1.58544 - acc: 0.6686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3111  | total loss: \u001b[1m\u001b[32m1.45781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3111 | loss: 1.45781 - acc: 0.7018 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3112  | total loss: \u001b[1m\u001b[32m1.71441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3112 | loss: 1.71441 - acc: 0.6316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3113  | total loss: \u001b[1m\u001b[32m1.57680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3113 | loss: 1.57680 - acc: 0.6684 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3114  | total loss: \u001b[1m\u001b[32m1.82657\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3114 | loss: 1.82657 - acc: 0.6016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3115  | total loss: \u001b[1m\u001b[32m1.68169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3115 | loss: 1.68169 - acc: 0.6414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3116  | total loss: \u001b[1m\u001b[32m1.55314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3116 | loss: 1.55314 - acc: 0.6773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3117  | total loss: \u001b[1m\u001b[32m1.43863\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3117 | loss: 1.43863 - acc: 0.7096 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3118  | total loss: \u001b[1m\u001b[32m1.33612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3118 | loss: 1.33612 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3119  | total loss: \u001b[1m\u001b[32m1.24381\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3119 | loss: 1.24381 - acc: 0.7647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3120  | total loss: \u001b[1m\u001b[32m1.16014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3120 | loss: 1.16014 - acc: 0.7883 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3121  | total loss: \u001b[1m\u001b[32m1.08377\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3121 | loss: 1.08377 - acc: 0.8094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3122  | total loss: \u001b[1m\u001b[32m1.33360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3122 | loss: 1.33360 - acc: 0.7356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3123  | total loss: \u001b[1m\u001b[32m1.23816\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3123 | loss: 1.23816 - acc: 0.7621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3124  | total loss: \u001b[1m\u001b[32m1.15153\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3124 | loss: 1.15153 - acc: 0.7859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3125  | total loss: \u001b[1m\u001b[32m1.07244\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3125 | loss: 1.07244 - acc: 0.8073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3126  | total loss: \u001b[1m\u001b[32m1.35799\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3126 | loss: 1.35799 - acc: 0.7266 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3127  | total loss: \u001b[1m\u001b[32m1.25665\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3127 | loss: 1.25665 - acc: 0.7539 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3128  | total loss: \u001b[1m\u001b[32m1.52139\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3128 | loss: 1.52139 - acc: 0.6785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3129  | total loss: \u001b[1m\u001b[32m1.40382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3129 | loss: 1.40382 - acc: 0.7107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3130  | total loss: \u001b[1m\u001b[32m1.62974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3130 | loss: 1.62974 - acc: 0.6467 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3131  | total loss: \u001b[1m\u001b[32m1.50270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3131 | loss: 1.50270 - acc: 0.6821 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3132  | total loss: \u001b[1m\u001b[32m1.69485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3132 | loss: 1.69485 - acc: 0.6210 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3133  | total loss: \u001b[1m\u001b[32m1.56351\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3133 | loss: 1.56351 - acc: 0.6589 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3134  | total loss: \u001b[1m\u001b[32m1.74646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3134 | loss: 1.74646 - acc: 0.6073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3135  | total loss: \u001b[1m\u001b[32m1.61274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3135 | loss: 1.61274 - acc: 0.6466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3136  | total loss: \u001b[1m\u001b[32m1.83023\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3136 | loss: 1.83023 - acc: 0.5891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3137  | total loss: \u001b[1m\u001b[32m1.69134\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3137 | loss: 1.69134 - acc: 0.6301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3138  | total loss: \u001b[1m\u001b[32m1.79171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3138 | loss: 1.79171 - acc: 0.5957 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3139  | total loss: \u001b[1m\u001b[32m1.65991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3139 | loss: 1.65991 - acc: 0.6361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3140  | total loss: \u001b[1m\u001b[32m1.87433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3140 | loss: 1.87433 - acc: 0.5725 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3141  | total loss: \u001b[1m\u001b[32m1.73756\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3141 | loss: 1.73756 - acc: 0.6153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3142  | total loss: \u001b[1m\u001b[32m1.61576\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3142 | loss: 1.61576 - acc: 0.6537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3143  | total loss: \u001b[1m\u001b[32m1.50660\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3143 | loss: 1.50660 - acc: 0.6884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3144  | total loss: \u001b[1m\u001b[32m1.72051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3144 | loss: 1.72051 - acc: 0.6195 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3145  | total loss: \u001b[1m\u001b[32m1.60132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3145 | loss: 1.60132 - acc: 0.6576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3146  | total loss: \u001b[1m\u001b[32m1.49401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3146 | loss: 1.49401 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3147  | total loss: \u001b[1m\u001b[32m1.39669\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3147 | loss: 1.39669 - acc: 0.7226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3148  | total loss: \u001b[1m\u001b[32m1.59637\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3148 | loss: 1.59637 - acc: 0.6504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3149  | total loss: \u001b[1m\u001b[32m1.48730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3149 | loss: 1.48730 - acc: 0.6853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3150  | total loss: \u001b[1m\u001b[32m1.66003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3150 | loss: 1.66003 - acc: 0.6311 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3151  | total loss: \u001b[1m\u001b[32m1.54391\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3151 | loss: 1.54391 - acc: 0.6680 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3152  | total loss: \u001b[1m\u001b[32m1.68400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3152 | loss: 1.68400 - acc: 0.6226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3153  | total loss: \u001b[1m\u001b[32m1.56511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3153 | loss: 1.56511 - acc: 0.6603 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3154  | total loss: \u001b[1m\u001b[32m1.45764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3154 | loss: 1.45764 - acc: 0.6943 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3155  | total loss: \u001b[1m\u001b[32m1.35987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3155 | loss: 1.35987 - acc: 0.7249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3156  | total loss: \u001b[1m\u001b[32m1.54847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3156 | loss: 1.54847 - acc: 0.6595 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3157  | total loss: \u001b[1m\u001b[32m1.43959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3157 | loss: 1.43959 - acc: 0.6936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3158  | total loss: \u001b[1m\u001b[32m1.34060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3158 | loss: 1.34060 - acc: 0.7242 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3159  | total loss: \u001b[1m\u001b[32m1.25005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3159 | loss: 1.25005 - acc: 0.7518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3160  | total loss: \u001b[1m\u001b[32m1.16671\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3160 | loss: 1.16671 - acc: 0.7766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3161  | total loss: \u001b[1m\u001b[32m1.08957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3161 | loss: 1.08957 - acc: 0.7990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3162  | total loss: \u001b[1m\u001b[32m1.01778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3162 | loss: 1.01778 - acc: 0.8191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3163  | total loss: \u001b[1m\u001b[32m0.95068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3163 | loss: 0.95068 - acc: 0.8372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3164  | total loss: \u001b[1m\u001b[32m0.88773\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3164 | loss: 0.88773 - acc: 0.8534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3165  | total loss: \u001b[1m\u001b[32m0.82850\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3165 | loss: 0.82850 - acc: 0.8681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3166  | total loss: \u001b[1m\u001b[32m1.15761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3166 | loss: 1.15761 - acc: 0.7813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3167  | total loss: \u001b[1m\u001b[32m1.06773\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3167 | loss: 1.06773 - acc: 0.8032 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3168  | total loss: \u001b[1m\u001b[32m1.33880\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3168 | loss: 1.33880 - acc: 0.7300 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3169  | total loss: \u001b[1m\u001b[32m1.22933\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3169 | loss: 1.22933 - acc: 0.7570 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3170  | total loss: \u001b[1m\u001b[32m1.53641\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3170 | loss: 1.53641 - acc: 0.6813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3171  | total loss: \u001b[1m\u001b[32m1.40742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3171 | loss: 1.40742 - acc: 0.7132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3172  | total loss: \u001b[1m\u001b[32m1.65506\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3172 | loss: 1.65506 - acc: 0.6561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3173  | total loss: \u001b[1m\u001b[32m1.51572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3173 | loss: 1.51572 - acc: 0.6905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3174  | total loss: \u001b[1m\u001b[32m1.39112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3174 | loss: 1.39112 - acc: 0.7215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3175  | total loss: \u001b[1m\u001b[32m1.27942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3175 | loss: 1.27942 - acc: 0.7493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3176  | total loss: \u001b[1m\u001b[32m1.57499\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3176 | loss: 1.57499 - acc: 0.6744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3177  | total loss: \u001b[1m\u001b[32m1.44613\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3177 | loss: 1.44613 - acc: 0.7069 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3178  | total loss: \u001b[1m\u001b[32m1.33085\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3178 | loss: 1.33085 - acc: 0.7363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3179  | total loss: \u001b[1m\u001b[32m1.22740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3179 | loss: 1.22740 - acc: 0.7626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3180  | total loss: \u001b[1m\u001b[32m1.13421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3180 | loss: 1.13421 - acc: 0.7864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3181  | total loss: \u001b[1m\u001b[32m1.04993\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3181 | loss: 1.04993 - acc: 0.8077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3182  | total loss: \u001b[1m\u001b[32m1.31919\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3182 | loss: 1.31919 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3183  | total loss: \u001b[1m\u001b[32m1.21604\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3183 | loss: 1.21604 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3184  | total loss: \u001b[1m\u001b[32m1.46393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3184 | loss: 1.46393 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3185  | total loss: \u001b[1m\u001b[32m1.34722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3185 | loss: 1.34722 - acc: 0.7226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3186  | total loss: \u001b[1m\u001b[32m1.63916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3186 | loss: 1.63916 - acc: 0.6503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3187  | total loss: \u001b[1m\u001b[32m1.50710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3187 | loss: 1.50710 - acc: 0.6853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3188  | total loss: \u001b[1m\u001b[32m1.38942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3188 | loss: 1.38942 - acc: 0.7168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3189  | total loss: \u001b[1m\u001b[32m1.28417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3189 | loss: 1.28417 - acc: 0.7451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3190  | total loss: \u001b[1m\u001b[32m1.51835\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3190 | loss: 1.51835 - acc: 0.6777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3191  | total loss: \u001b[1m\u001b[32m1.40154\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3191 | loss: 1.40154 - acc: 0.7100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3192  | total loss: \u001b[1m\u001b[32m1.65111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3192 | loss: 1.65111 - acc: 0.6390 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3193  | total loss: \u001b[1m\u001b[32m1.52331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3193 | loss: 1.52331 - acc: 0.6751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3194  | total loss: \u001b[1m\u001b[32m1.74521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3194 | loss: 1.74521 - acc: 0.6147 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3195  | total loss: \u001b[1m\u001b[32m1.61103\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3195 | loss: 1.61103 - acc: 0.6532 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3196  | total loss: \u001b[1m\u001b[32m1.79761\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3196 | loss: 1.79761 - acc: 0.5950 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3197  | total loss: \u001b[1m\u001b[32m1.66160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3197 | loss: 1.66160 - acc: 0.6355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3198  | total loss: \u001b[1m\u001b[32m1.54060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3198 | loss: 1.54060 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3199  | total loss: \u001b[1m\u001b[32m1.43238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3199 | loss: 1.43238 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3200  | total loss: \u001b[1m\u001b[32m1.33500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3200 | loss: 1.33500 - acc: 0.7343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3201  | total loss: \u001b[1m\u001b[32m1.24676\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3201 | loss: 1.24676 - acc: 0.7609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3202  | total loss: \u001b[1m\u001b[32m1.16622\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3202 | loss: 1.16622 - acc: 0.7848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3203  | total loss: \u001b[1m\u001b[32m1.09218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3203 | loss: 1.09218 - acc: 0.8063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3204  | total loss: \u001b[1m\u001b[32m1.35269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3204 | loss: 1.35269 - acc: 0.7328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3205  | total loss: \u001b[1m\u001b[32m1.25735\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3205 | loss: 1.25735 - acc: 0.7595 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3206  | total loss: \u001b[1m\u001b[32m1.48694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3206 | loss: 1.48694 - acc: 0.6979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3207  | total loss: \u001b[1m\u001b[32m1.37696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3207 | loss: 1.37696 - acc: 0.7281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3208  | total loss: \u001b[1m\u001b[32m1.27744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3208 | loss: 1.27744 - acc: 0.7553 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3209  | total loss: \u001b[1m\u001b[32m1.18693\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3209 | loss: 1.18693 - acc: 0.7797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3210  | total loss: \u001b[1m\u001b[32m1.46261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3210 | loss: 1.46261 - acc: 0.7018 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3211  | total loss: \u001b[1m\u001b[32m1.35233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3211 | loss: 1.35233 - acc: 0.7316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3212  | total loss: \u001b[1m\u001b[32m1.60714\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3212 | loss: 1.60714 - acc: 0.6584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3213  | total loss: \u001b[1m\u001b[32m1.48270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3213 | loss: 1.48270 - acc: 0.6926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3214  | total loss: \u001b[1m\u001b[32m1.37091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3214 | loss: 1.37091 - acc: 0.7233 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3215  | total loss: \u001b[1m\u001b[32m1.27004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3215 | loss: 1.27004 - acc: 0.7510 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3216  | total loss: \u001b[1m\u001b[32m1.17859\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3216 | loss: 1.17859 - acc: 0.7759 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3217  | total loss: \u001b[1m\u001b[32m1.09526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3217 | loss: 1.09526 - acc: 0.7983 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3218  | total loss: \u001b[1m\u001b[32m1.01895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3218 | loss: 1.01895 - acc: 0.8185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3219  | total loss: \u001b[1m\u001b[32m0.94872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3219 | loss: 0.94872 - acc: 0.8366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3220  | total loss: \u001b[1m\u001b[32m0.88379\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3220 | loss: 0.88379 - acc: 0.8530 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3221  | total loss: \u001b[1m\u001b[32m0.82353\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3221 | loss: 0.82353 - acc: 0.8677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3222  | total loss: \u001b[1m\u001b[32m1.10354\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3222 | loss: 1.10354 - acc: 0.7952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3223  | total loss: \u001b[1m\u001b[32m1.01860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3223 | loss: 1.01860 - acc: 0.8157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3224  | total loss: \u001b[1m\u001b[32m1.34207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3224 | loss: 1.34207 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3225  | total loss: \u001b[1m\u001b[32m1.23241\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 3225 | loss: 1.23241 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3226  | total loss: \u001b[1m\u001b[32m1.13358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3226 | loss: 1.13358 - acc: 0.7846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3227  | total loss: \u001b[1m\u001b[32m1.04426\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3227 | loss: 1.04426 - acc: 0.8062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3228  | total loss: \u001b[1m\u001b[32m0.96330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3228 | loss: 0.96330 - acc: 0.8255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3229  | total loss: \u001b[1m\u001b[32m0.88969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3229 | loss: 0.88969 - acc: 0.8430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3230  | total loss: \u001b[1m\u001b[32m0.82255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3230 | loss: 0.82255 - acc: 0.8587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3231  | total loss: \u001b[1m\u001b[32m0.76114\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3231 | loss: 0.76114 - acc: 0.8728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3232  | total loss: \u001b[1m\u001b[32m1.03341\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3232 | loss: 1.03341 - acc: 0.8070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3233  | total loss: \u001b[1m\u001b[32m0.94959\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 3233 | loss: 0.94959 - acc: 0.8263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3234  | total loss: \u001b[1m\u001b[32m1.22999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3234 | loss: 1.22999 - acc: 0.7579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3235  | total loss: \u001b[1m\u001b[32m1.12650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3235 | loss: 1.12650 - acc: 0.7821 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3236  | total loss: \u001b[1m\u001b[32m1.42209\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3236 | loss: 1.42209 - acc: 0.7111 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3237  | total loss: \u001b[1m\u001b[32m1.30066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3237 | loss: 1.30066 - acc: 0.7400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3238  | total loss: \u001b[1m\u001b[32m1.61243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3238 | loss: 1.61243 - acc: 0.6660 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3239  | total loss: \u001b[1m\u001b[32m1.47454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3239 | loss: 1.47454 - acc: 0.6994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3240  | total loss: \u001b[1m\u001b[32m1.35185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3240 | loss: 1.35185 - acc: 0.7294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3241  | total loss: \u001b[1m\u001b[32m1.24250\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3241 | loss: 1.24250 - acc: 0.7565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3242  | total loss: \u001b[1m\u001b[32m1.50033\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3242 | loss: 1.50033 - acc: 0.6880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3243  | total loss: \u001b[1m\u001b[32m1.37843\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3243 | loss: 1.37843 - acc: 0.7192 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3244  | total loss: \u001b[1m\u001b[32m1.64657\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3244 | loss: 1.64657 - acc: 0.6473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3245  | total loss: \u001b[1m\u001b[32m1.51346\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 3245 | loss: 1.51346 - acc: 0.6825 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3246  | total loss: \u001b[1m\u001b[32m1.71069\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3246 | loss: 1.71069 - acc: 0.6214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3247  | total loss: \u001b[1m\u001b[32m1.57574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3247 | loss: 1.57574 - acc: 0.6593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3248  | total loss: \u001b[1m\u001b[32m1.72951\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3248 | loss: 1.72951 - acc: 0.6148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3249  | total loss: \u001b[1m\u001b[32m1.59777\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3249 | loss: 1.59777 - acc: 0.6533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3250  | total loss: \u001b[1m\u001b[32m1.82055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3250 | loss: 1.82055 - acc: 0.5880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3251  | total loss: \u001b[1m\u001b[32m1.68510\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3251 | loss: 1.68510 - acc: 0.6292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3252  | total loss: \u001b[1m\u001b[32m1.83745\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3252 | loss: 1.83745 - acc: 0.5805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3253  | total loss: \u001b[1m\u001b[32m1.70587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3253 | loss: 1.70587 - acc: 0.6225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3254  | total loss: \u001b[1m\u001b[32m1.88104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3254 | loss: 1.88104 - acc: 0.5674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3255  | total loss: \u001b[1m\u001b[32m1.75023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3255 | loss: 1.75023 - acc: 0.6106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3256  | total loss: \u001b[1m\u001b[32m1.93138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3256 | loss: 1.93138 - acc: 0.5496 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3257  | total loss: \u001b[1m\u001b[32m1.80025\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3257 | loss: 1.80025 - acc: 0.5946 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3258  | total loss: \u001b[1m\u001b[32m1.95750\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3258 | loss: 1.95750 - acc: 0.5423 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3259  | total loss: \u001b[1m\u001b[32m1.82796\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3259 | loss: 1.82796 - acc: 0.5881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3260  | total loss: \u001b[1m\u001b[32m1.71270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3260 | loss: 1.71270 - acc: 0.6293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3261  | total loss: \u001b[1m\u001b[32m1.60917\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3261 | loss: 1.60917 - acc: 0.6663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3262  | total loss: \u001b[1m\u001b[32m1.80069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3262 | loss: 1.80069 - acc: 0.5997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3263  | total loss: \u001b[1m\u001b[32m1.68803\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3263 | loss: 1.68803 - acc: 0.6397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3264  | total loss: \u001b[1m\u001b[32m1.84635\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3264 | loss: 1.84635 - acc: 0.5758 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3265  | total loss: \u001b[1m\u001b[32m1.72906\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3265 | loss: 1.72906 - acc: 0.6182 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3266  | total loss: \u001b[1m\u001b[32m1.84625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3266 | loss: 1.84625 - acc: 0.5707 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3267  | total loss: \u001b[1m\u001b[32m1.72874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3267 | loss: 1.72874 - acc: 0.6136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3268  | total loss: \u001b[1m\u001b[32m1.83606\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3268 | loss: 1.83606 - acc: 0.5594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3269  | total loss: \u001b[1m\u001b[32m1.71911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3269 | loss: 1.71911 - acc: 0.6034 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3270  | total loss: \u001b[1m\u001b[32m1.61317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3270 | loss: 1.61317 - acc: 0.6431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3271  | total loss: \u001b[1m\u001b[32m1.51631\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3271 | loss: 1.51631 - acc: 0.6788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3272  | total loss: \u001b[1m\u001b[32m1.67077\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3272 | loss: 1.67077 - acc: 0.6252 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3273  | total loss: \u001b[1m\u001b[32m1.56467\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3273 | loss: 1.56467 - acc: 0.6627 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3274  | total loss: \u001b[1m\u001b[32m1.46724\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3274 | loss: 1.46724 - acc: 0.6964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3275  | total loss: \u001b[1m\u001b[32m1.37705\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3275 | loss: 1.37705 - acc: 0.7268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3276  | total loss: \u001b[1m\u001b[32m1.29294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3276 | loss: 1.29294 - acc: 0.7541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3277  | total loss: \u001b[1m\u001b[32m1.21398\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3277 | loss: 1.21398 - acc: 0.7787 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3278  | total loss: \u001b[1m\u001b[32m1.39118\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3278 | loss: 1.39118 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3279  | total loss: \u001b[1m\u001b[32m1.29664\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3279 | loss: 1.29664 - acc: 0.7500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3280  | total loss: \u001b[1m\u001b[32m1.54647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3280 | loss: 1.54647 - acc: 0.6750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3281  | total loss: \u001b[1m\u001b[32m1.43266\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3281 | loss: 1.43266 - acc: 0.7075 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3282  | total loss: \u001b[1m\u001b[32m1.32867\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3282 | loss: 1.32867 - acc: 0.7368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3283  | total loss: \u001b[1m\u001b[32m1.23326\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 3283 | loss: 1.23326 - acc: 0.7631 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3284  | total loss: \u001b[1m\u001b[32m1.47867\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3284 | loss: 1.47867 - acc: 0.6939 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3285  | total loss: \u001b[1m\u001b[32m1.36538\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3285 | loss: 1.36538 - acc: 0.7245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3286  | total loss: \u001b[1m\u001b[32m1.60742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3286 | loss: 1.60742 - acc: 0.6521 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3287  | total loss: \u001b[1m\u001b[32m1.48009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3287 | loss: 1.48009 - acc: 0.6869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3288  | total loss: \u001b[1m\u001b[32m1.67887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3288 | loss: 1.67887 - acc: 0.6325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3289  | total loss: \u001b[1m\u001b[32m1.54463\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3289 | loss: 1.54463 - acc: 0.6692 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3290  | total loss: \u001b[1m\u001b[32m1.75977\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3290 | loss: 1.75977 - acc: 0.6094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3291  | total loss: \u001b[1m\u001b[32m1.61886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3291 | loss: 1.61886 - acc: 0.6485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3292  | total loss: \u001b[1m\u001b[32m1.49277\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3292 | loss: 1.49277 - acc: 0.6836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3293  | total loss: \u001b[1m\u001b[32m1.37952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3293 | loss: 1.37952 - acc: 0.7153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3294  | total loss: \u001b[1m\u001b[32m1.27739\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3294 | loss: 1.27739 - acc: 0.7438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3295  | total loss: \u001b[1m\u001b[32m1.18485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3295 | loss: 1.18485 - acc: 0.7694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3296  | total loss: \u001b[1m\u001b[32m1.10058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3296 | loss: 1.10058 - acc: 0.7924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3297  | total loss: \u001b[1m\u001b[32m1.02345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3297 | loss: 1.02345 - acc: 0.8132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3298  | total loss: \u001b[1m\u001b[32m1.29274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3298 | loss: 1.29274 - acc: 0.7319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3299  | total loss: \u001b[1m\u001b[32m1.19459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3299 | loss: 1.19459 - acc: 0.7587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3300  | total loss: \u001b[1m\u001b[32m1.47435\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3300 | loss: 1.47435 - acc: 0.6828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3301  | total loss: \u001b[1m\u001b[32m1.35796\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3301 | loss: 1.35796 - acc: 0.7145 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3302  | total loss: \u001b[1m\u001b[32m1.58311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3302 | loss: 1.58311 - acc: 0.6574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3303  | total loss: \u001b[1m\u001b[32m1.45690\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3303 | loss: 1.45690 - acc: 0.6916 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3304  | total loss: \u001b[1m\u001b[32m1.34377\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3304 | loss: 1.34377 - acc: 0.7225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3305  | total loss: \u001b[1m\u001b[32m1.24200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3305 | loss: 1.24200 - acc: 0.7502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3306  | total loss: \u001b[1m\u001b[32m1.50522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3306 | loss: 1.50522 - acc: 0.6823 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3307  | total loss: \u001b[1m\u001b[32m1.38761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3307 | loss: 1.38761 - acc: 0.7141 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3308  | total loss: \u001b[1m\u001b[32m1.54196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3308 | loss: 1.54196 - acc: 0.6641 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3309  | total loss: \u001b[1m\u001b[32m1.42184\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3309 | loss: 1.42184 - acc: 0.6977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3310  | total loss: \u001b[1m\u001b[32m1.63584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3310 | loss: 1.63584 - acc: 0.6351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3311  | total loss: \u001b[1m\u001b[32m1.50827\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3311 | loss: 1.50827 - acc: 0.6716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3312  | total loss: \u001b[1m\u001b[32m1.73290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3312 | loss: 1.73290 - acc: 0.6116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3313  | total loss: \u001b[1m\u001b[32m1.59847\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3313 | loss: 1.59847 - acc: 0.6504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3314  | total loss: \u001b[1m\u001b[32m1.76177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3314 | loss: 1.76177 - acc: 0.6068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3315  | total loss: \u001b[1m\u001b[32m1.62775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3315 | loss: 1.62775 - acc: 0.6461 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3316  | total loss: \u001b[1m\u001b[32m1.86297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3316 | loss: 1.86297 - acc: 0.5815 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3317  | total loss: \u001b[1m\u001b[32m1.72252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3317 | loss: 1.72252 - acc: 0.6234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3318  | total loss: \u001b[1m\u001b[32m1.59770\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3318 | loss: 1.59770 - acc: 0.6610 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3319  | total loss: \u001b[1m\u001b[32m1.48618\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3319 | loss: 1.48618 - acc: 0.6949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3320  | total loss: \u001b[1m\u001b[32m1.38590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3320 | loss: 1.38590 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3321  | total loss: \u001b[1m\u001b[32m1.29507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3321 | loss: 1.29507 - acc: 0.7529 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3322  | total loss: \u001b[1m\u001b[32m1.52826\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3322 | loss: 1.52826 - acc: 0.6776 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3323  | total loss: \u001b[1m\u001b[32m1.42207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3323 | loss: 1.42207 - acc: 0.7098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3324  | total loss: \u001b[1m\u001b[32m1.62695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3324 | loss: 1.62695 - acc: 0.6460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3325  | total loss: \u001b[1m\u001b[32m1.51069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3325 | loss: 1.51069 - acc: 0.6814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3326  | total loss: \u001b[1m\u001b[32m1.40584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3326 | loss: 1.40584 - acc: 0.7133 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3327  | total loss: \u001b[1m\u001b[32m1.31067\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3327 | loss: 1.31067 - acc: 0.7419 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3328  | total loss: \u001b[1m\u001b[32m1.54494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3328 | loss: 1.54494 - acc: 0.6677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3329  | total loss: \u001b[1m\u001b[32m1.43456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3329 | loss: 1.43456 - acc: 0.7010 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3330  | total loss: \u001b[1m\u001b[32m1.64551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3330 | loss: 1.64551 - acc: 0.6380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3331  | total loss: \u001b[1m\u001b[32m1.52486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3331 | loss: 1.52486 - acc: 0.6742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3332  | total loss: \u001b[1m\u001b[32m1.41607\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3332 | loss: 1.41607 - acc: 0.7068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3333  | total loss: \u001b[1m\u001b[32m1.31742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3333 | loss: 1.31742 - acc: 0.7361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3334  | total loss: \u001b[1m\u001b[32m1.49132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3334 | loss: 1.49132 - acc: 0.6839 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3335  | total loss: \u001b[1m\u001b[32m1.38366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3335 | loss: 1.38366 - acc: 0.7155 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3336  | total loss: \u001b[1m\u001b[32m1.63370\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3336 | loss: 1.63370 - acc: 0.6440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3337  | total loss: \u001b[1m\u001b[32m1.51143\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3337 | loss: 1.51143 - acc: 0.6796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3338  | total loss: \u001b[1m\u001b[32m1.73537\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3338 | loss: 1.73537 - acc: 0.6116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3339  | total loss: \u001b[1m\u001b[32m1.60375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3339 | loss: 1.60375 - acc: 0.6505 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3340  | total loss: \u001b[1m\u001b[32m1.83551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3340 | loss: 1.83551 - acc: 0.5854 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3341  | total loss: \u001b[1m\u001b[32m1.69567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3341 | loss: 1.69567 - acc: 0.6269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3342  | total loss: \u001b[1m\u001b[32m1.87034\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3342 | loss: 1.87034 - acc: 0.5713 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3343  | total loss: \u001b[1m\u001b[32m1.72935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3343 | loss: 1.72935 - acc: 0.6142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3344  | total loss: \u001b[1m\u001b[32m1.88553\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3344 | loss: 1.88553 - acc: 0.5599 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3345  | total loss: \u001b[1m\u001b[32m1.74560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3345 | loss: 1.74560 - acc: 0.6039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3346  | total loss: \u001b[1m\u001b[32m1.62062\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3346 | loss: 1.62062 - acc: 0.6435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3347  | total loss: \u001b[1m\u001b[32m1.50836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3347 | loss: 1.50836 - acc: 0.6792 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3348  | total loss: \u001b[1m\u001b[32m1.70313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3348 | loss: 1.70313 - acc: 0.6184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3349  | total loss: \u001b[1m\u001b[32m1.58271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3349 | loss: 1.58271 - acc: 0.6566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3350  | total loss: \u001b[1m\u001b[32m1.47417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3350 | loss: 1.47417 - acc: 0.6909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3351  | total loss: \u001b[1m\u001b[32m1.37572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3351 | loss: 1.37572 - acc: 0.7218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3352  | total loss: \u001b[1m\u001b[32m1.53534\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3352 | loss: 1.53534 - acc: 0.6711 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3353  | total loss: \u001b[1m\u001b[32m1.42906\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3353 | loss: 1.42906 - acc: 0.7040 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3354  | total loss: \u001b[1m\u001b[32m1.33244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3354 | loss: 1.33244 - acc: 0.7336 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3355  | total loss: \u001b[1m\u001b[32m1.24407\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3355 | loss: 1.24407 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3356  | total loss: \u001b[1m\u001b[32m1.16273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3356 | loss: 1.16273 - acc: 0.7842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3357  | total loss: \u001b[1m\u001b[32m1.08744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3357 | loss: 1.08744 - acc: 0.8058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3358  | total loss: \u001b[1m\u001b[32m1.01735\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3358 | loss: 1.01735 - acc: 0.8252 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3359  | total loss: \u001b[1m\u001b[32m0.95181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3359 | loss: 0.95181 - acc: 0.8427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3360  | total loss: \u001b[1m\u001b[32m1.22969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3360 | loss: 1.22969 - acc: 0.7655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3361  | total loss: \u001b[1m\u001b[32m1.13915\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3361 | loss: 1.13915 - acc: 0.7890 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3362  | total loss: \u001b[1m\u001b[32m1.43225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3362 | loss: 1.43225 - acc: 0.7101 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3363  | total loss: \u001b[1m\u001b[32m1.31980\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3363 | loss: 1.31980 - acc: 0.7391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3364  | total loss: \u001b[1m\u001b[32m1.21806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3364 | loss: 1.21806 - acc: 0.7652 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3365  | total loss: \u001b[1m\u001b[32m1.12569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3365 | loss: 1.12569 - acc: 0.7887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3366  | total loss: \u001b[1m\u001b[32m1.04154\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3366 | loss: 1.04154 - acc: 0.8098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3367  | total loss: \u001b[1m\u001b[32m0.96459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3367 | loss: 0.96459 - acc: 0.8288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3368  | total loss: \u001b[1m\u001b[32m1.23350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3368 | loss: 1.23350 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3369  | total loss: \u001b[1m\u001b[32m1.13563\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3369 | loss: 1.13563 - acc: 0.7842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3370  | total loss: \u001b[1m\u001b[32m1.42555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3370 | loss: 1.42555 - acc: 0.7129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3371  | total loss: \u001b[1m\u001b[32m1.30828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3371 | loss: 1.30828 - acc: 0.7416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3372  | total loss: \u001b[1m\u001b[32m1.56448\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3372 | loss: 1.56448 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3373  | total loss: \u001b[1m\u001b[32m1.43452\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3373 | loss: 1.43452 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3374  | total loss: \u001b[1m\u001b[32m1.68415\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3374 | loss: 1.68415 - acc: 0.6436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3375  | total loss: \u001b[1m\u001b[32m1.54458\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3375 | loss: 1.54458 - acc: 0.6792 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3376  | total loss: \u001b[1m\u001b[32m1.77046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3376 | loss: 1.77046 - acc: 0.6184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3377  | total loss: \u001b[1m\u001b[32m1.62564\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3377 | loss: 1.62564 - acc: 0.6566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3378  | total loss: \u001b[1m\u001b[32m1.49695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3378 | loss: 1.49695 - acc: 0.6909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3379  | total loss: \u001b[1m\u001b[32m1.38225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3379 | loss: 1.38225 - acc: 0.7218 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3380  | total loss: \u001b[1m\u001b[32m1.64037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3380 | loss: 1.64037 - acc: 0.6497 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3381  | total loss: \u001b[1m\u001b[32m1.51347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3381 | loss: 1.51347 - acc: 0.6847 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3382  | total loss: \u001b[1m\u001b[32m1.40024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3382 | loss: 1.40024 - acc: 0.7162 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3383  | total loss: \u001b[1m\u001b[32m1.29875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3383 | loss: 1.29875 - acc: 0.7446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3384  | total loss: \u001b[1m\u001b[32m1.54762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3384 | loss: 1.54762 - acc: 0.6773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3385  | total loss: \u001b[1m\u001b[32m1.43217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3385 | loss: 1.43217 - acc: 0.7096 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3386  | total loss: \u001b[1m\u001b[32m1.32858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3386 | loss: 1.32858 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3387  | total loss: \u001b[1m\u001b[32m1.23515\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3387 | loss: 1.23515 - acc: 0.7647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3388  | total loss: \u001b[1m\u001b[32m1.15039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3388 | loss: 1.15039 - acc: 0.7883 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3389  | total loss: \u001b[1m\u001b[32m1.07304\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3389 | loss: 1.07304 - acc: 0.8094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3390  | total loss: \u001b[1m\u001b[32m1.28384\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3390 | loss: 1.28384 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3391  | total loss: \u001b[1m\u001b[32m1.19122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3391 | loss: 1.19122 - acc: 0.7749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3392  | total loss: \u001b[1m\u001b[32m1.10698\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3392 | loss: 1.10698 - acc: 0.7974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3393  | total loss: \u001b[1m\u001b[32m1.02998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3393 | loss: 1.02998 - acc: 0.8177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3394  | total loss: \u001b[1m\u001b[32m1.28811\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3394 | loss: 1.28811 - acc: 0.7431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3395  | total loss: \u001b[1m\u001b[32m1.19125\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3395 | loss: 1.19125 - acc: 0.7688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3396  | total loss: \u001b[1m\u001b[32m1.42101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3396 | loss: 1.42101 - acc: 0.7062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3397  | total loss: \u001b[1m\u001b[32m1.31043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3397 | loss: 1.31043 - acc: 0.7356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3398  | total loss: \u001b[1m\u001b[32m1.21075\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3398 | loss: 1.21075 - acc: 0.7620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3399  | total loss: \u001b[1m\u001b[32m1.12056\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3399 | loss: 1.12056 - acc: 0.7858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3400  | total loss: \u001b[1m\u001b[32m1.03861\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3400 | loss: 1.03861 - acc: 0.8072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3401  | total loss: \u001b[1m\u001b[32m0.96384\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3401 | loss: 0.96384 - acc: 0.8265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3402  | total loss: \u001b[1m\u001b[32m1.20523\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3402 | loss: 1.20523 - acc: 0.7653 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3403  | total loss: \u001b[1m\u001b[32m1.11227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3403 | loss: 1.11227 - acc: 0.7887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3404  | total loss: \u001b[1m\u001b[32m1.38586\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3404 | loss: 1.38586 - acc: 0.7170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3405  | total loss: \u001b[1m\u001b[32m1.27465\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3405 | loss: 1.27465 - acc: 0.7453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3406  | total loss: \u001b[1m\u001b[32m1.17466\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3406 | loss: 1.17466 - acc: 0.7708 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3407  | total loss: \u001b[1m\u001b[32m1.08446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3407 | loss: 1.08446 - acc: 0.7937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3408  | total loss: \u001b[1m\u001b[32m1.41678\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3408 | loss: 1.41678 - acc: 0.7143 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3409  | total loss: \u001b[1m\u001b[32m1.30259\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3409 | loss: 1.30259 - acc: 0.7429 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3410  | total loss: \u001b[1m\u001b[32m1.52919\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3410 | loss: 1.52919 - acc: 0.6829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3411  | total loss: \u001b[1m\u001b[32m1.40524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3411 | loss: 1.40524 - acc: 0.7146 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3412  | total loss: \u001b[1m\u001b[32m1.29444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3412 | loss: 1.29444 - acc: 0.7431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3413  | total loss: \u001b[1m\u001b[32m1.19510\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3413 | loss: 1.19510 - acc: 0.7688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3414  | total loss: \u001b[1m\u001b[32m1.10568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3414 | loss: 1.10568 - acc: 0.7919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3415  | total loss: \u001b[1m\u001b[32m1.02486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3415 | loss: 1.02486 - acc: 0.8128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3416  | total loss: \u001b[1m\u001b[32m1.30615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3416 | loss: 1.30615 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3417  | total loss: \u001b[1m\u001b[32m1.20502\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3417 | loss: 1.20502 - acc: 0.7583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3418  | total loss: \u001b[1m\u001b[32m1.11402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3418 | loss: 1.11402 - acc: 0.7825 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3419  | total loss: \u001b[1m\u001b[32m1.03180\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3419 | loss: 1.03180 - acc: 0.8042 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3420  | total loss: \u001b[1m\u001b[32m1.31245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3420 | loss: 1.31245 - acc: 0.7310 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3421  | total loss: \u001b[1m\u001b[32m1.21016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3421 | loss: 1.21016 - acc: 0.7579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3422  | total loss: \u001b[1m\u001b[32m1.47492\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3422 | loss: 1.47492 - acc: 0.6892 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3423  | total loss: \u001b[1m\u001b[32m1.35741\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3423 | loss: 1.35741 - acc: 0.7203 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3424  | total loss: \u001b[1m\u001b[32m1.25223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3424 | loss: 1.25223 - acc: 0.7483 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3425  | total loss: \u001b[1m\u001b[32m1.15775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3425 | loss: 1.15775 - acc: 0.7734 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3426  | total loss: \u001b[1m\u001b[32m1.41576\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3426 | loss: 1.41576 - acc: 0.7104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3427  | total loss: \u001b[1m\u001b[32m1.30547\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3427 | loss: 1.30547 - acc: 0.7393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3428  | total loss: \u001b[1m\u001b[32m1.56647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3428 | loss: 1.56647 - acc: 0.6654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3429  | total loss: \u001b[1m\u001b[32m1.44284\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3429 | loss: 1.44284 - acc: 0.6989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3430  | total loss: \u001b[1m\u001b[32m1.65627\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3430 | loss: 1.65627 - acc: 0.6361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3431  | total loss: \u001b[1m\u001b[32m1.52650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3431 | loss: 1.52650 - acc: 0.6725 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3432  | total loss: \u001b[1m\u001b[32m1.41107\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3432 | loss: 1.41107 - acc: 0.7053 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3433  | total loss: \u001b[1m\u001b[32m1.30798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3433 | loss: 1.30798 - acc: 0.7347 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3434  | total loss: \u001b[1m\u001b[32m1.51879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3434 | loss: 1.51879 - acc: 0.6755 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3435  | total loss: \u001b[1m\u001b[32m1.40626\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3435 | loss: 1.40626 - acc: 0.7080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3436  | total loss: \u001b[1m\u001b[32m1.62950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3436 | loss: 1.62950 - acc: 0.6372 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3437  | total loss: \u001b[1m\u001b[32m1.50801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3437 | loss: 1.50801 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3438  | total loss: \u001b[1m\u001b[32m1.73138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3438 | loss: 1.73138 - acc: 0.6061 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3439  | total loss: \u001b[1m\u001b[32m1.60258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3439 | loss: 1.60258 - acc: 0.6455 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3440  | total loss: \u001b[1m\u001b[32m1.72285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3440 | loss: 1.72285 - acc: 0.6095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3441  | total loss: \u001b[1m\u001b[32m1.59777\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3441 | loss: 1.59777 - acc: 0.6486 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3442  | total loss: \u001b[1m\u001b[32m1.48612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3442 | loss: 1.48612 - acc: 0.6837 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3443  | total loss: \u001b[1m\u001b[32m1.38580\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3443 | loss: 1.38580 - acc: 0.7154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3444  | total loss: \u001b[1m\u001b[32m1.29503\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3444 | loss: 1.29503 - acc: 0.7438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3445  | total loss: \u001b[1m\u001b[32m1.21226\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3445 | loss: 1.21226 - acc: 0.7694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3446  | total loss: \u001b[1m\u001b[32m1.47868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3446 | loss: 1.47868 - acc: 0.6925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3447  | total loss: \u001b[1m\u001b[32m1.37576\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3447 | loss: 1.37576 - acc: 0.7232 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3448  | total loss: \u001b[1m\u001b[32m1.58893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3448 | loss: 1.58893 - acc: 0.6581 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3449  | total loss: \u001b[1m\u001b[32m1.47454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3449 | loss: 1.47454 - acc: 0.6923 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3450  | total loss: \u001b[1m\u001b[32m1.68008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3450 | loss: 1.68008 - acc: 0.6230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3451  | total loss: \u001b[1m\u001b[32m1.55710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3451 | loss: 1.55710 - acc: 0.6607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3452  | total loss: \u001b[1m\u001b[32m1.44654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3452 | loss: 1.44654 - acc: 0.6947 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3453  | total loss: \u001b[1m\u001b[32m1.34657\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3453 | loss: 1.34657 - acc: 0.7252 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3454  | total loss: \u001b[1m\u001b[32m1.54718\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3454 | loss: 1.54718 - acc: 0.6598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3455  | total loss: \u001b[1m\u001b[32m1.43622\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3455 | loss: 1.43622 - acc: 0.6938 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3456  | total loss: \u001b[1m\u001b[32m1.33584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3456 | loss: 1.33584 - acc: 0.7244 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3457  | total loss: \u001b[1m\u001b[32m1.24449\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3457 | loss: 1.24449 - acc: 0.7520 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3458  | total loss: \u001b[1m\u001b[32m1.16084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3458 | loss: 1.16084 - acc: 0.7768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3459  | total loss: \u001b[1m\u001b[32m1.08374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3459 | loss: 1.08374 - acc: 0.7991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3460  | total loss: \u001b[1m\u001b[32m1.30086\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3460 | loss: 1.30086 - acc: 0.7264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3461  | total loss: \u001b[1m\u001b[32m1.20686\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3461 | loss: 1.20686 - acc: 0.7537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3462  | total loss: \u001b[1m\u001b[32m1.12107\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3462 | loss: 1.12107 - acc: 0.7783 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3463  | total loss: \u001b[1m\u001b[32m1.04239\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3463 | loss: 1.04239 - acc: 0.8005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3464  | total loss: \u001b[1m\u001b[32m1.32499\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3464 | loss: 1.32499 - acc: 0.7205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3465  | total loss: \u001b[1m\u001b[32m1.22382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3465 | loss: 1.22382 - acc: 0.7484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3466  | total loss: \u001b[1m\u001b[32m1.47056\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3466 | loss: 1.47056 - acc: 0.6807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3467  | total loss: \u001b[1m\u001b[32m1.35448\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3467 | loss: 1.35448 - acc: 0.7126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3468  | total loss: \u001b[1m\u001b[32m1.58487\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3468 | loss: 1.58487 - acc: 0.6485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3469  | total loss: \u001b[1m\u001b[32m1.45834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3469 | loss: 1.45834 - acc: 0.6837 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3470  | total loss: \u001b[1m\u001b[32m1.63378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3470 | loss: 1.63378 - acc: 0.6296 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3471  | total loss: \u001b[1m\u001b[32m1.50426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3471 | loss: 1.50426 - acc: 0.6666 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3472  | total loss: \u001b[1m\u001b[32m1.71935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3472 | loss: 1.71935 - acc: 0.6000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3473  | total loss: \u001b[1m\u001b[32m1.58404\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3473 | loss: 1.58404 - acc: 0.6400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3474  | total loss: \u001b[1m\u001b[32m1.79236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3474 | loss: 1.79236 - acc: 0.5831 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3475  | total loss: \u001b[1m\u001b[32m1.65335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3475 | loss: 1.65335 - acc: 0.6248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3476  | total loss: \u001b[1m\u001b[32m1.52982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3476 | loss: 1.52982 - acc: 0.6623 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3477  | total loss: \u001b[1m\u001b[32m1.41949\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3477 | loss: 1.41949 - acc: 0.6961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3478  | total loss: \u001b[1m\u001b[32m1.32038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3478 | loss: 1.32038 - acc: 0.7265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3479  | total loss: \u001b[1m\u001b[32m1.23075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3479 | loss: 1.23075 - acc: 0.7538 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3480  | total loss: \u001b[1m\u001b[32m1.38408\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3480 | loss: 1.38408 - acc: 0.7142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3481  | total loss: \u001b[1m\u001b[32m1.28678\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3481 | loss: 1.28678 - acc: 0.7427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3482  | total loss: \u001b[1m\u001b[32m1.19838\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3482 | loss: 1.19838 - acc: 0.7685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3483  | total loss: \u001b[1m\u001b[32m1.11754\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3483 | loss: 1.11754 - acc: 0.7916 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3484  | total loss: \u001b[1m\u001b[32m1.41250\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3484 | loss: 1.41250 - acc: 0.7125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3485  | total loss: \u001b[1m\u001b[32m1.30822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3485 | loss: 1.30822 - acc: 0.7412 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3486  | total loss: \u001b[1m\u001b[32m1.21355\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3486 | loss: 1.21355 - acc: 0.7671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3487  | total loss: \u001b[1m\u001b[32m1.12717\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3487 | loss: 1.12717 - acc: 0.7904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3488  | total loss: \u001b[1m\u001b[32m1.40312\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3488 | loss: 1.40312 - acc: 0.7185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3489  | total loss: \u001b[1m\u001b[32m1.29597\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3489 | loss: 1.29597 - acc: 0.7466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3490  | total loss: \u001b[1m\u001b[32m1.57712\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3490 | loss: 1.57712 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3491  | total loss: \u001b[1m\u001b[32m1.45245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3491 | loss: 1.45245 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3492  | total loss: \u001b[1m\u001b[32m1.69465\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3492 | loss: 1.69465 - acc: 0.6414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3493  | total loss: \u001b[1m\u001b[32m1.55951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3493 | loss: 1.55951 - acc: 0.6773 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3494  | total loss: \u001b[1m\u001b[32m1.76485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3494 | loss: 1.76485 - acc: 0.6096 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3495  | total loss: \u001b[1m\u001b[32m1.62504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3495 | loss: 1.62504 - acc: 0.6486 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3496  | total loss: \u001b[1m\u001b[32m1.87650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3496 | loss: 1.87650 - acc: 0.5838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3497  | total loss: \u001b[1m\u001b[32m1.72879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3497 | loss: 1.72879 - acc: 0.6254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3498  | total loss: \u001b[1m\u001b[32m1.89210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3498 | loss: 1.89210 - acc: 0.5771 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3499  | total loss: \u001b[1m\u001b[32m1.74656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3499 | loss: 1.74656 - acc: 0.6194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3500  | total loss: \u001b[1m\u001b[32m1.61710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3500 | loss: 1.61710 - acc: 0.6575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3501  | total loss: \u001b[1m\u001b[32m1.50139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3501 | loss: 1.50139 - acc: 0.6917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3502  | total loss: \u001b[1m\u001b[32m1.39736\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3502 | loss: 1.39736 - acc: 0.7226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3503  | total loss: \u001b[1m\u001b[32m1.30324\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3503 | loss: 1.30324 - acc: 0.7503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3504  | total loss: \u001b[1m\u001b[32m1.21749\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3504 | loss: 1.21749 - acc: 0.7753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3505  | total loss: \u001b[1m\u001b[32m1.13882\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3505 | loss: 1.13882 - acc: 0.7977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3506  | total loss: \u001b[1m\u001b[32m1.38300\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3506 | loss: 1.38300 - acc: 0.7251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3507  | total loss: \u001b[1m\u001b[32m1.28528\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3507 | loss: 1.28528 - acc: 0.7526 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3508  | total loss: \u001b[1m\u001b[32m1.19629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3508 | loss: 1.19629 - acc: 0.7773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3509  | total loss: \u001b[1m\u001b[32m1.11477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3509 | loss: 1.11477 - acc: 0.7996 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3510  | total loss: \u001b[1m\u001b[32m1.03969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3510 | loss: 1.03969 - acc: 0.8196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3511  | total loss: \u001b[1m\u001b[32m0.97019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3511 | loss: 0.97019 - acc: 0.8377 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3512  | total loss: \u001b[1m\u001b[32m1.28152\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3512 | loss: 1.28152 - acc: 0.7539 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3513  | total loss: \u001b[1m\u001b[32m1.18499\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3513 | loss: 1.18499 - acc: 0.7785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3514  | total loss: \u001b[1m\u001b[32m1.40889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3514 | loss: 1.40889 - acc: 0.7150 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3515  | total loss: \u001b[1m\u001b[32m1.29850\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3515 | loss: 1.29850 - acc: 0.7435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3516  | total loss: \u001b[1m\u001b[32m1.19876\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3516 | loss: 1.19876 - acc: 0.7691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3517  | total loss: \u001b[1m\u001b[32m1.10832\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3517 | loss: 1.10832 - acc: 0.7922 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3518  | total loss: \u001b[1m\u001b[32m1.02600\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3518 | loss: 1.02600 - acc: 0.8130 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3519  | total loss: \u001b[1m\u001b[32m0.95080\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3519 | loss: 0.95080 - acc: 0.8317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3520  | total loss: \u001b[1m\u001b[32m1.26389\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3520 | loss: 1.26389 - acc: 0.7485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3521  | total loss: \u001b[1m\u001b[32m1.16351\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3521 | loss: 1.16351 - acc: 0.7737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3522  | total loss: \u001b[1m\u001b[32m1.07277\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3522 | loss: 1.07277 - acc: 0.7963 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3523  | total loss: \u001b[1m\u001b[32m0.99048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3523 | loss: 0.99048 - acc: 0.8167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3524  | total loss: \u001b[1m\u001b[32m1.30265\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3524 | loss: 1.30265 - acc: 0.7350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3525  | total loss: \u001b[1m\u001b[32m1.19691\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3525 | loss: 1.19691 - acc: 0.7615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3526  | total loss: \u001b[1m\u001b[32m1.10180\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3526 | loss: 1.10180 - acc: 0.7854 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3527  | total loss: \u001b[1m\u001b[32m1.01598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3527 | loss: 1.01598 - acc: 0.8068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3528  | total loss: \u001b[1m\u001b[32m1.32687\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3528 | loss: 1.32687 - acc: 0.7333 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3529  | total loss: \u001b[1m\u001b[32m1.21862\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3529 | loss: 1.21862 - acc: 0.7599 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3530  | total loss: \u001b[1m\u001b[32m1.51647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3530 | loss: 1.51647 - acc: 0.6840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3531  | total loss: \u001b[1m\u001b[32m1.39069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3531 | loss: 1.39069 - acc: 0.7156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3532  | total loss: \u001b[1m\u001b[32m1.27832\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 3532 | loss: 1.27832 - acc: 0.7440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3533  | total loss: \u001b[1m\u001b[32m1.17765\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3533 | loss: 1.17765 - acc: 0.7696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3534  | total loss: \u001b[1m\u001b[32m1.08716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3534 | loss: 1.08716 - acc: 0.7926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3535  | total loss: \u001b[1m\u001b[32m1.00552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3535 | loss: 1.00552 - acc: 0.8134 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3536  | total loss: \u001b[1m\u001b[32m1.28619\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3536 | loss: 1.28619 - acc: 0.7392 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3537  | total loss: \u001b[1m\u001b[32m1.18462\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3537 | loss: 1.18462 - acc: 0.7653 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3538  | total loss: \u001b[1m\u001b[32m1.44103\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3538 | loss: 1.44103 - acc: 0.6959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3539  | total loss: \u001b[1m\u001b[32m1.32525\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3539 | loss: 1.32525 - acc: 0.7263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3540  | total loss: \u001b[1m\u001b[32m1.57390\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3540 | loss: 1.57390 - acc: 0.6608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3541  | total loss: \u001b[1m\u001b[32m1.44720\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3541 | loss: 1.44720 - acc: 0.6947 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3542  | total loss: \u001b[1m\u001b[32m1.33433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3542 | loss: 1.33433 - acc: 0.7253 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3543  | total loss: \u001b[1m\u001b[32m1.23345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3543 | loss: 1.23345 - acc: 0.7527 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3544  | total loss: \u001b[1m\u001b[32m1.14288\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3544 | loss: 1.14288 - acc: 0.7775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3545  | total loss: \u001b[1m\u001b[32m1.06117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3545 | loss: 1.06117 - acc: 0.7997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3546  | total loss: \u001b[1m\u001b[32m1.34283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3546 | loss: 1.34283 - acc: 0.7269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3547  | total loss: \u001b[1m\u001b[32m1.24094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3547 | loss: 1.24094 - acc: 0.7542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3548  | total loss: \u001b[1m\u001b[32m1.14922\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3548 | loss: 1.14922 - acc: 0.7788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3549  | total loss: \u001b[1m\u001b[32m1.06625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3549 | loss: 1.06625 - acc: 0.8009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3550  | total loss: \u001b[1m\u001b[32m1.37782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3550 | loss: 1.37782 - acc: 0.7208 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3551  | total loss: \u001b[1m\u001b[32m1.27161\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3551 | loss: 1.27161 - acc: 0.7487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3552  | total loss: \u001b[1m\u001b[32m1.17598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3552 | loss: 1.17598 - acc: 0.7739 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3553  | total loss: \u001b[1m\u001b[32m1.08951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3553 | loss: 1.08951 - acc: 0.7965 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3554  | total loss: \u001b[1m\u001b[32m1.35845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3554 | loss: 1.35845 - acc: 0.7240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3555  | total loss: \u001b[1m\u001b[32m1.25334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3555 | loss: 1.25334 - acc: 0.7516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3556  | total loss: \u001b[1m\u001b[32m1.51636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3556 | loss: 1.51636 - acc: 0.6764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3557  | total loss: \u001b[1m\u001b[32m1.39642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3557 | loss: 1.39642 - acc: 0.7088 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3558  | total loss: \u001b[1m\u001b[32m1.28904\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3558 | loss: 1.28904 - acc: 0.7379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3559  | total loss: \u001b[1m\u001b[32m1.19252\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3559 | loss: 1.19252 - acc: 0.7641 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3560  | total loss: \u001b[1m\u001b[32m1.10538\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3560 | loss: 1.10538 - acc: 0.7877 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3561  | total loss: \u001b[1m\u001b[32m1.02632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3561 | loss: 1.02632 - acc: 0.8089 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3562  | total loss: \u001b[1m\u001b[32m0.95424\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3562 | loss: 0.95424 - acc: 0.8280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3563  | total loss: \u001b[1m\u001b[32m0.88820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3563 | loss: 0.88820 - acc: 0.8452 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3564  | total loss: \u001b[1m\u001b[32m1.22566\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3564 | loss: 1.22566 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3565  | total loss: \u001b[1m\u001b[32m1.13101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3565 | loss: 1.13101 - acc: 0.7846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3566  | total loss: \u001b[1m\u001b[32m1.04543\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3566 | loss: 1.04543 - acc: 0.8062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3567  | total loss: \u001b[1m\u001b[32m0.96774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3567 | loss: 0.96774 - acc: 0.8256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3568  | total loss: \u001b[1m\u001b[32m1.27215\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3568 | loss: 1.27215 - acc: 0.7501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3569  | total loss: \u001b[1m\u001b[32m1.17108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3569 | loss: 1.17108 - acc: 0.7751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3570  | total loss: \u001b[1m\u001b[32m1.43315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3570 | loss: 1.43315 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3571  | total loss: \u001b[1m\u001b[32m1.31668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3571 | loss: 1.31668 - acc: 0.7343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3572  | total loss: \u001b[1m\u001b[32m1.59503\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3572 | loss: 1.59503 - acc: 0.6609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3573  | total loss: \u001b[1m\u001b[32m1.46436\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3573 | loss: 1.46436 - acc: 0.6948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3574  | total loss: \u001b[1m\u001b[32m1.69968\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3574 | loss: 1.69968 - acc: 0.6324 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3575  | total loss: \u001b[1m\u001b[32m1.56168\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3575 | loss: 1.56168 - acc: 0.6692 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3576  | total loss: \u001b[1m\u001b[32m1.43901\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3576 | loss: 1.43901 - acc: 0.7023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3577  | total loss: \u001b[1m\u001b[32m1.32960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3577 | loss: 1.32960 - acc: 0.7320 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3578  | total loss: \u001b[1m\u001b[32m1.55680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3578 | loss: 1.55680 - acc: 0.6660 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3579  | total loss: \u001b[1m\u001b[32m1.43742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3579 | loss: 1.43742 - acc: 0.6994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3580  | total loss: \u001b[1m\u001b[32m1.33074\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3580 | loss: 1.33074 - acc: 0.7294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3581  | total loss: \u001b[1m\u001b[32m1.23493\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3581 | loss: 1.23493 - acc: 0.7565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3582  | total loss: \u001b[1m\u001b[32m1.44487\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3582 | loss: 1.44487 - acc: 0.6951 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3583  | total loss: \u001b[1m\u001b[32m1.33798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3583 | loss: 1.33798 - acc: 0.7256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3584  | total loss: \u001b[1m\u001b[32m1.24187\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3584 | loss: 1.24187 - acc: 0.7531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3585  | total loss: \u001b[1m\u001b[32m1.15496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3585 | loss: 1.15496 - acc: 0.7778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3586  | total loss: \u001b[1m\u001b[32m1.07592\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3586 | loss: 1.07592 - acc: 0.8000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3587  | total loss: \u001b[1m\u001b[32m1.00358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3587 | loss: 1.00358 - acc: 0.8200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3588  | total loss: \u001b[1m\u001b[32m1.28444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3588 | loss: 1.28444 - acc: 0.7451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3589  | total loss: \u001b[1m\u001b[32m1.18946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3589 | loss: 1.18946 - acc: 0.7706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3590  | total loss: \u001b[1m\u001b[32m1.45794\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3590 | loss: 1.45794 - acc: 0.7007 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3591  | total loss: \u001b[1m\u001b[32m1.34535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3591 | loss: 1.34535 - acc: 0.7306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3592  | total loss: \u001b[1m\u001b[32m1.54116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3592 | loss: 1.54116 - acc: 0.6718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3593  | total loss: \u001b[1m\u001b[32m1.42107\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3593 | loss: 1.42107 - acc: 0.7047 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3594  | total loss: \u001b[1m\u001b[32m1.61447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3594 | loss: 1.61447 - acc: 0.6485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3595  | total loss: \u001b[1m\u001b[32m1.48860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3595 | loss: 1.48860 - acc: 0.6836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3596  | total loss: \u001b[1m\u001b[32m1.37594\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3596 | loss: 1.37594 - acc: 0.7153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3597  | total loss: \u001b[1m\u001b[32m1.27470\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3597 | loss: 1.27470 - acc: 0.7437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3598  | total loss: \u001b[1m\u001b[32m1.18325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3598 | loss: 1.18325 - acc: 0.7694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3599  | total loss: \u001b[1m\u001b[32m1.10023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3599 | loss: 1.10023 - acc: 0.7924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3600  | total loss: \u001b[1m\u001b[32m1.36187\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3600 | loss: 1.36187 - acc: 0.7132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3601  | total loss: \u001b[1m\u001b[32m1.26009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3601 | loss: 1.26009 - acc: 0.7419 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3602  | total loss: \u001b[1m\u001b[32m1.16824\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3602 | loss: 1.16824 - acc: 0.7677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3603  | total loss: \u001b[1m\u001b[32m1.08495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3603 | loss: 1.08495 - acc: 0.7909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3604  | total loss: \u001b[1m\u001b[32m1.35891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3604 | loss: 1.35891 - acc: 0.7118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3605  | total loss: \u001b[1m\u001b[32m1.25575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3605 | loss: 1.25575 - acc: 0.7406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3606  | total loss: \u001b[1m\u001b[32m1.16267\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3606 | loss: 1.16267 - acc: 0.7666 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3607  | total loss: \u001b[1m\u001b[32m1.07829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3607 | loss: 1.07829 - acc: 0.7899 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3608  | total loss: \u001b[1m\u001b[32m1.00144\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3608 | loss: 1.00144 - acc: 0.8109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3609  | total loss: \u001b[1m\u001b[32m0.93111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3609 | loss: 0.93111 - acc: 0.8298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3610  | total loss: \u001b[1m\u001b[32m1.25004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3610 | loss: 1.25004 - acc: 0.7469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3611  | total loss: \u001b[1m\u001b[32m1.15335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3611 | loss: 1.15335 - acc: 0.7722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3612  | total loss: \u001b[1m\u001b[32m1.06588\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3612 | loss: 1.06588 - acc: 0.7949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3613  | total loss: \u001b[1m\u001b[32m0.98646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3613 | loss: 0.98646 - acc: 0.8155 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3614  | total loss: \u001b[1m\u001b[32m1.27366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3614 | loss: 1.27366 - acc: 0.7411 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3615  | total loss: \u001b[1m\u001b[32m1.17260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3615 | loss: 1.17260 - acc: 0.7669 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3616  | total loss: \u001b[1m\u001b[32m1.08142\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3616 | loss: 1.08142 - acc: 0.7903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3617  | total loss: \u001b[1m\u001b[32m0.99888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3617 | loss: 0.99888 - acc: 0.8112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3618  | total loss: \u001b[1m\u001b[32m0.92388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3618 | loss: 0.92388 - acc: 0.8301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3619  | total loss: \u001b[1m\u001b[32m0.85550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3619 | loss: 0.85550 - acc: 0.8471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3620  | total loss: \u001b[1m\u001b[32m1.21401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3620 | loss: 1.21401 - acc: 0.7624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3621  | total loss: \u001b[1m\u001b[32m1.11563\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3621 | loss: 1.11563 - acc: 0.7861 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3622  | total loss: \u001b[1m\u001b[32m1.41909\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3622 | loss: 1.41909 - acc: 0.7075 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3623  | total loss: \u001b[1m\u001b[32m1.30082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3623 | loss: 1.30082 - acc: 0.7368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3624  | total loss: \u001b[1m\u001b[32m1.19486\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3624 | loss: 1.19486 - acc: 0.7631 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3625  | total loss: \u001b[1m\u001b[32m1.09969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3625 | loss: 1.09969 - acc: 0.7868 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3626  | total loss: \u001b[1m\u001b[32m1.39343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3626 | loss: 1.39343 - acc: 0.7153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3627  | total loss: \u001b[1m\u001b[32m1.27925\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3627 | loss: 1.27925 - acc: 0.7437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3628  | total loss: \u001b[1m\u001b[32m1.17708\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3628 | loss: 1.17708 - acc: 0.7694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3629  | total loss: \u001b[1m\u001b[32m1.08540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3629 | loss: 1.08540 - acc: 0.7924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3630  | total loss: \u001b[1m\u001b[32m1.00284\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3630 | loss: 1.00284 - acc: 0.8132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3631  | total loss: \u001b[1m\u001b[32m0.92821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3631 | loss: 0.92821 - acc: 0.8319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3632  | total loss: \u001b[1m\u001b[32m1.20786\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3632 | loss: 1.20786 - acc: 0.7558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3633  | total loss: \u001b[1m\u001b[32m1.11247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3633 | loss: 1.11247 - acc: 0.7802 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3634  | total loss: \u001b[1m\u001b[32m1.38982\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3634 | loss: 1.38982 - acc: 0.7094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3635  | total loss: \u001b[1m\u001b[32m1.27714\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3635 | loss: 1.27714 - acc: 0.7384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3636  | total loss: \u001b[1m\u001b[32m1.55670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3636 | loss: 1.55670 - acc: 0.6717 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3637  | total loss: \u001b[1m\u001b[32m1.42936\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3637 | loss: 1.42936 - acc: 0.7045 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3638  | total loss: \u001b[1m\u001b[32m1.31580\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3638 | loss: 1.31580 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3639  | total loss: \u001b[1m\u001b[32m1.21422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3639 | loss: 1.21422 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3640  | total loss: \u001b[1m\u001b[32m1.12300\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3640 | loss: 1.12300 - acc: 0.7846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3641  | total loss: \u001b[1m\u001b[32m1.04072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3641 | loss: 1.04072 - acc: 0.8062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3642  | total loss: \u001b[1m\u001b[32m1.30948\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3642 | loss: 1.30948 - acc: 0.7255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3643  | total loss: \u001b[1m\u001b[32m1.20859\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3643 | loss: 1.20859 - acc: 0.7530 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3644  | total loss: \u001b[1m\u001b[32m1.11795\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3644 | loss: 1.11795 - acc: 0.7777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3645  | total loss: \u001b[1m\u001b[32m1.03615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3645 | loss: 1.03615 - acc: 0.7999 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3646  | total loss: \u001b[1m\u001b[32m0.96200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3646 | loss: 0.96200 - acc: 0.8199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3647  | total loss: \u001b[1m\u001b[32m0.89445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3647 | loss: 0.89445 - acc: 0.8379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3648  | total loss: \u001b[1m\u001b[32m0.83260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3648 | loss: 0.83260 - acc: 0.8541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3649  | total loss: \u001b[1m\u001b[32m0.77573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3649 | loss: 0.77573 - acc: 0.8687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3650  | total loss: \u001b[1m\u001b[32m0.72318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3650 | loss: 0.72318 - acc: 0.8819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3651  | total loss: \u001b[1m\u001b[32m0.67446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3651 | loss: 0.67446 - acc: 0.8937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3652  | total loss: \u001b[1m\u001b[32m0.62913\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3652 | loss: 0.62913 - acc: 0.9043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3653  | total loss: \u001b[1m\u001b[32m0.58684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3653 | loss: 0.58684 - acc: 0.9139 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3654  | total loss: \u001b[1m\u001b[32m0.54730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3654 | loss: 0.54730 - acc: 0.9225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3655  | total loss: \u001b[1m\u001b[32m0.51029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3655 | loss: 0.51029 - acc: 0.9302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3656  | total loss: \u001b[1m\u001b[32m0.88735\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3656 | loss: 0.88735 - acc: 0.8515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3657  | total loss: \u001b[1m\u001b[32m0.81448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3657 | loss: 0.81448 - acc: 0.8663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3658  | total loss: \u001b[1m\u001b[32m0.74836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3658 | loss: 0.74836 - acc: 0.8797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3659  | total loss: \u001b[1m\u001b[32m0.68826\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3659 | loss: 0.68826 - acc: 0.8917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3660  | total loss: \u001b[1m\u001b[32m0.63353\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3660 | loss: 0.63353 - acc: 0.9026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3661  | total loss: \u001b[1m\u001b[32m0.58362\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3661 | loss: 0.58362 - acc: 0.9123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3662  | total loss: \u001b[1m\u001b[32m0.93873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3662 | loss: 0.93873 - acc: 0.8425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3663  | total loss: \u001b[1m\u001b[32m0.85762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3663 | loss: 0.85762 - acc: 0.8583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3664  | total loss: \u001b[1m\u001b[32m1.21214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3664 | loss: 1.21214 - acc: 0.7796 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3665  | total loss: \u001b[1m\u001b[32m1.10417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3665 | loss: 1.10417 - acc: 0.8016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3666  | total loss: \u001b[1m\u001b[32m1.00744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3666 | loss: 1.00744 - acc: 0.8215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3667  | total loss: \u001b[1m\u001b[32m0.92071\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3667 | loss: 0.92071 - acc: 0.8393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3668  | total loss: \u001b[1m\u001b[32m1.30548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3668 | loss: 1.30548 - acc: 0.7554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3669  | total loss: \u001b[1m\u001b[32m1.19000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3669 | loss: 1.19000 - acc: 0.7798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3670  | total loss: \u001b[1m\u001b[32m1.08677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3670 | loss: 1.08677 - acc: 0.8019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3671  | total loss: \u001b[1m\u001b[32m0.99437\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3671 | loss: 0.99437 - acc: 0.8217 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3672  | total loss: \u001b[1m\u001b[32m1.31598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3672 | loss: 1.31598 - acc: 0.7466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3673  | total loss: \u001b[1m\u001b[32m1.20206\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3673 | loss: 1.20206 - acc: 0.7720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3674  | total loss: \u001b[1m\u001b[32m1.10037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3674 | loss: 1.10037 - acc: 0.7948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3675  | total loss: \u001b[1m\u001b[32m1.00946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3675 | loss: 1.00946 - acc: 0.8153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3676  | total loss: \u001b[1m\u001b[32m1.31826\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3676 | loss: 1.31826 - acc: 0.7409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3677  | total loss: \u001b[1m\u001b[32m1.20713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3677 | loss: 1.20713 - acc: 0.7668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3678  | total loss: \u001b[1m\u001b[32m1.48488\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3678 | loss: 1.48488 - acc: 0.6973 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3679  | total loss: \u001b[1m\u001b[32m1.35976\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3679 | loss: 1.35976 - acc: 0.7276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3680  | total loss: \u001b[1m\u001b[32m1.60490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3680 | loss: 1.60490 - acc: 0.6619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3681  | total loss: \u001b[1m\u001b[32m1.47157\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3681 | loss: 1.47157 - acc: 0.6958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3682  | total loss: \u001b[1m\u001b[32m1.69137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3682 | loss: 1.69137 - acc: 0.6405 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3683  | total loss: \u001b[1m\u001b[32m1.55412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3683 | loss: 1.55412 - acc: 0.6764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3684  | total loss: \u001b[1m\u001b[32m1.80087\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3684 | loss: 1.80087 - acc: 0.6088 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3685  | total loss: \u001b[1m\u001b[32m1.65819\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3685 | loss: 1.65819 - acc: 0.6479 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3686  | total loss: \u001b[1m\u001b[32m1.53236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3686 | loss: 1.53236 - acc: 0.6831 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3687  | total loss: \u001b[1m\u001b[32m1.42097\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3687 | loss: 1.42097 - acc: 0.7148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3688  | total loss: \u001b[1m\u001b[32m1.64174\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3688 | loss: 1.64174 - acc: 0.6433 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3689  | total loss: \u001b[1m\u001b[32m1.52271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3689 | loss: 1.52271 - acc: 0.6790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3690  | total loss: \u001b[1m\u001b[32m1.72802\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3690 | loss: 1.72802 - acc: 0.6111 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3691  | total loss: \u001b[1m\u001b[32m1.60416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3691 | loss: 1.60416 - acc: 0.6500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3692  | total loss: \u001b[1m\u001b[32m1.49424\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3692 | loss: 1.49424 - acc: 0.6850 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3693  | total loss: \u001b[1m\u001b[32m1.39603\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3693 | loss: 1.39603 - acc: 0.7165 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3694  | total loss: \u001b[1m\u001b[32m1.30760\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3694 | loss: 1.30760 - acc: 0.7448 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3695  | total loss: \u001b[1m\u001b[32m1.22726\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3695 | loss: 1.22726 - acc: 0.7704 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3696  | total loss: \u001b[1m\u001b[32m1.42945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3696 | loss: 1.42945 - acc: 0.7005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3697  | total loss: \u001b[1m\u001b[32m1.33535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3697 | loss: 1.33535 - acc: 0.7304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3698  | total loss: \u001b[1m\u001b[32m1.54877\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3698 | loss: 1.54877 - acc: 0.6645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3699  | total loss: \u001b[1m\u001b[32m1.44220\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3699 | loss: 1.44220 - acc: 0.6981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3700  | total loss: \u001b[1m\u001b[32m1.68570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3700 | loss: 1.68570 - acc: 0.6283 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3701  | total loss: \u001b[1m\u001b[32m1.56592\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3701 | loss: 1.56592 - acc: 0.6654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3702  | total loss: \u001b[1m\u001b[32m1.72507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3702 | loss: 1.72507 - acc: 0.6132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3703  | total loss: \u001b[1m\u001b[32m1.60236\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3703 | loss: 1.60236 - acc: 0.6519 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3704  | total loss: \u001b[1m\u001b[32m1.79189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3704 | loss: 1.79189 - acc: 0.5867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3705  | total loss: \u001b[1m\u001b[32m1.66390\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3705 | loss: 1.66390 - acc: 0.6280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3706  | total loss: \u001b[1m\u001b[32m1.81064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3706 | loss: 1.81064 - acc: 0.5723 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3707  | total loss: \u001b[1m\u001b[32m1.68268\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3707 | loss: 1.68268 - acc: 0.6151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3708  | total loss: \u001b[1m\u001b[32m1.56814\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3708 | loss: 1.56814 - acc: 0.6536 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3709  | total loss: \u001b[1m\u001b[32m1.46491\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3709 | loss: 1.46491 - acc: 0.6882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3710  | total loss: \u001b[1m\u001b[32m1.70765\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3710 | loss: 1.70765 - acc: 0.6194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3711  | total loss: \u001b[1m\u001b[32m1.58992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3711 | loss: 1.58992 - acc: 0.6575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3712  | total loss: \u001b[1m\u001b[32m1.48352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3712 | loss: 1.48352 - acc: 0.6917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3713  | total loss: \u001b[1m\u001b[32m1.38665\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3713 | loss: 1.38665 - acc: 0.7226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3714  | total loss: \u001b[1m\u001b[32m1.29780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3714 | loss: 1.29780 - acc: 0.7503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3715  | total loss: \u001b[1m\u001b[32m1.21571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3715 | loss: 1.21571 - acc: 0.7753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3716  | total loss: \u001b[1m\u001b[32m1.48299\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3716 | loss: 1.48299 - acc: 0.6977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3717  | total loss: \u001b[1m\u001b[32m1.37879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3717 | loss: 1.37879 - acc: 0.7280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3718  | total loss: \u001b[1m\u001b[32m1.28348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3718 | loss: 1.28348 - acc: 0.7552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3719  | total loss: \u001b[1m\u001b[32m1.19582\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3719 | loss: 1.19582 - acc: 0.7797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3720  | total loss: \u001b[1m\u001b[32m1.44266\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3720 | loss: 1.44266 - acc: 0.7088 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3721  | total loss: \u001b[1m\u001b[32m1.33599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3721 | loss: 1.33599 - acc: 0.7379 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3722  | total loss: \u001b[1m\u001b[32m1.57937\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3722 | loss: 1.57937 - acc: 0.6642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3723  | total loss: \u001b[1m\u001b[32m1.45769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3723 | loss: 1.45769 - acc: 0.6977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3724  | total loss: \u001b[1m\u001b[32m1.68502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3724 | loss: 1.68502 - acc: 0.6351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3725  | total loss: \u001b[1m\u001b[32m1.55292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3725 | loss: 1.55292 - acc: 0.6716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3726  | total loss: \u001b[1m\u001b[32m1.74777\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3726 | loss: 1.74777 - acc: 0.6116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3727  | total loss: \u001b[1m\u001b[32m1.61054\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3727 | loss: 1.61054 - acc: 0.6504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3728  | total loss: \u001b[1m\u001b[32m1.77427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3728 | loss: 1.77427 - acc: 0.5997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3729  | total loss: \u001b[1m\u001b[32m1.63608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3729 | loss: 1.63608 - acc: 0.6397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3730  | total loss: \u001b[1m\u001b[32m1.51233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3730 | loss: 1.51233 - acc: 0.6757 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3731  | total loss: \u001b[1m\u001b[32m1.40105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3731 | loss: 1.40105 - acc: 0.7082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3732  | total loss: \u001b[1m\u001b[32m1.61686\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3732 | loss: 1.61686 - acc: 0.6445 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3733  | total loss: \u001b[1m\u001b[32m1.49534\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3733 | loss: 1.49534 - acc: 0.6800 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3734  | total loss: \u001b[1m\u001b[32m1.71371\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3734 | loss: 1.71371 - acc: 0.6120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3735  | total loss: \u001b[1m\u001b[32m1.58366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3735 | loss: 1.58366 - acc: 0.6508 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3736  | total loss: \u001b[1m\u001b[32m1.79111\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3736 | loss: 1.79111 - acc: 0.5929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3737  | total loss: \u001b[1m\u001b[32m1.65528\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3737 | loss: 1.65528 - acc: 0.6336 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3738  | total loss: \u001b[1m\u001b[32m1.86788\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3738 | loss: 1.86788 - acc: 0.5702 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3739  | total loss: \u001b[1m\u001b[32m1.72691\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3739 | loss: 1.72691 - acc: 0.6132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3740  | total loss: \u001b[1m\u001b[32m1.91779\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3740 | loss: 1.91779 - acc: 0.5519 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3741  | total loss: \u001b[1m\u001b[32m1.77480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3741 | loss: 1.77480 - acc: 0.5967 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3742  | total loss: \u001b[1m\u001b[32m1.93149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3742 | loss: 1.93149 - acc: 0.5442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3743  | total loss: \u001b[1m\u001b[32m1.79032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3743 | loss: 1.79032 - acc: 0.5898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3744  | total loss: \u001b[1m\u001b[32m1.93216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3744 | loss: 1.93216 - acc: 0.5379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3745  | total loss: \u001b[1m\u001b[32m1.79405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3745 | loss: 1.79405 - acc: 0.5841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3746  | total loss: \u001b[1m\u001b[32m1.94656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3746 | loss: 1.94656 - acc: 0.5257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3747  | total loss: \u001b[1m\u001b[32m1.81007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3747 | loss: 1.81007 - acc: 0.5731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3748  | total loss: \u001b[1m\u001b[32m1.95139\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3748 | loss: 1.95139 - acc: 0.5230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3749  | total loss: \u001b[1m\u001b[32m1.81742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3749 | loss: 1.81742 - acc: 0.5707 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3750  | total loss: \u001b[1m\u001b[32m1.69784\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3750 | loss: 1.69784 - acc: 0.6136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3751  | total loss: \u001b[1m\u001b[32m1.59031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3751 | loss: 1.59031 - acc: 0.6522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3752  | total loss: \u001b[1m\u001b[32m1.76238\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3752 | loss: 1.76238 - acc: 0.5870 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3753  | total loss: \u001b[1m\u001b[32m1.64789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3753 | loss: 1.64789 - acc: 0.6283 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3754  | total loss: \u001b[1m\u001b[32m1.82756\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3754 | loss: 1.82756 - acc: 0.5726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3755  | total loss: \u001b[1m\u001b[32m1.70633\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3755 | loss: 1.70633 - acc: 0.6154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3756  | total loss: \u001b[1m\u001b[32m1.82661\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3756 | loss: 1.82661 - acc: 0.5753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3757  | total loss: \u001b[1m\u001b[32m1.70534\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3757 | loss: 1.70534 - acc: 0.6177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3758  | total loss: \u001b[1m\u001b[32m1.59567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3758 | loss: 1.59567 - acc: 0.6560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3759  | total loss: \u001b[1m\u001b[32m1.49573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3759 | loss: 1.49573 - acc: 0.6904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3760  | total loss: \u001b[1m\u001b[32m1.63673\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3760 | loss: 1.63673 - acc: 0.6428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3761  | total loss: \u001b[1m\u001b[32m1.52983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3761 | loss: 1.52983 - acc: 0.6785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3762  | total loss: \u001b[1m\u001b[32m1.69401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3762 | loss: 1.69401 - acc: 0.6178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3763  | total loss: \u001b[1m\u001b[32m1.57922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3763 | loss: 1.57922 - acc: 0.6560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3764  | total loss: \u001b[1m\u001b[32m1.47474\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3764 | loss: 1.47474 - acc: 0.6904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3765  | total loss: \u001b[1m\u001b[32m1.37900\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3765 | loss: 1.37900 - acc: 0.7214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3766  | total loss: \u001b[1m\u001b[32m1.29070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3766 | loss: 1.29070 - acc: 0.7492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3767  | total loss: \u001b[1m\u001b[32m1.20874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3767 | loss: 1.20874 - acc: 0.7743 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3768  | total loss: \u001b[1m\u001b[32m1.13224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3768 | loss: 1.13224 - acc: 0.7969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3769  | total loss: \u001b[1m\u001b[32m1.06047\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3769 | loss: 1.06047 - acc: 0.8172 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3770  | total loss: \u001b[1m\u001b[32m1.27348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3770 | loss: 1.27348 - acc: 0.7498 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3771  | total loss: \u001b[1m\u001b[32m1.18271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3771 | loss: 1.18271 - acc: 0.7748 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3772  | total loss: \u001b[1m\u001b[32m1.09898\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3772 | loss: 1.09898 - acc: 0.7973 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3773  | total loss: \u001b[1m\u001b[32m1.02146\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3773 | loss: 1.02146 - acc: 0.8176 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3774  | total loss: \u001b[1m\u001b[32m1.31904\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3774 | loss: 1.31904 - acc: 0.7358 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3775  | total loss: \u001b[1m\u001b[32m1.21643\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3775 | loss: 1.21643 - acc: 0.7622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3776  | total loss: \u001b[1m\u001b[32m1.50073\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3776 | loss: 1.50073 - acc: 0.6932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3777  | total loss: \u001b[1m\u001b[32m1.37887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3777 | loss: 1.37887 - acc: 0.7238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3778  | total loss: \u001b[1m\u001b[32m1.26892\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3778 | loss: 1.26892 - acc: 0.7515 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3779  | total loss: \u001b[1m\u001b[32m1.16943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3779 | loss: 1.16943 - acc: 0.7763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3780  | total loss: \u001b[1m\u001b[32m1.44177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3780 | loss: 1.44177 - acc: 0.6987 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3781  | total loss: \u001b[1m\u001b[32m1.32454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3781 | loss: 1.32454 - acc: 0.7288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3782  | total loss: \u001b[1m\u001b[32m1.21905\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3782 | loss: 1.21905 - acc: 0.7559 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3783  | total loss: \u001b[1m\u001b[32m1.12383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3783 | loss: 1.12383 - acc: 0.7803 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3784  | total loss: \u001b[1m\u001b[32m1.03762\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3784 | loss: 1.03762 - acc: 0.8023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3785  | total loss: \u001b[1m\u001b[32m0.95930\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3785 | loss: 0.95930 - acc: 0.8221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3786  | total loss: \u001b[1m\u001b[32m0.88791\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3786 | loss: 0.88791 - acc: 0.8399 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3787  | total loss: \u001b[1m\u001b[32m0.82261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3787 | loss: 0.82261 - acc: 0.8559 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3788  | total loss: \u001b[1m\u001b[32m0.76268\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3788 | loss: 0.76268 - acc: 0.8703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3789  | total loss: \u001b[1m\u001b[32m0.70754\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3789 | loss: 0.70754 - acc: 0.8833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3790  | total loss: \u001b[1m\u001b[32m1.04558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3790 | loss: 1.04558 - acc: 0.8021 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3791  | total loss: \u001b[1m\u001b[32m0.96061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3791 | loss: 0.96061 - acc: 0.8219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3792  | total loss: \u001b[1m\u001b[32m1.25447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3792 | loss: 1.25447 - acc: 0.7540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3793  | total loss: \u001b[1m\u001b[32m1.14851\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3793 | loss: 1.14851 - acc: 0.7786 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3794  | total loss: \u001b[1m\u001b[32m1.05328\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3794 | loss: 1.05328 - acc: 0.8007 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3795  | total loss: \u001b[1m\u001b[32m0.96752\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3795 | loss: 0.96752 - acc: 0.8206 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3796  | total loss: \u001b[1m\u001b[32m1.32752\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3796 | loss: 1.32752 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3797  | total loss: \u001b[1m\u001b[32m1.21480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3797 | loss: 1.21480 - acc: 0.7647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3798  | total loss: \u001b[1m\u001b[32m1.11382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3798 | loss: 1.11382 - acc: 0.7882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3799  | total loss: \u001b[1m\u001b[32m1.02316\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3799 | loss: 1.02316 - acc: 0.8094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3800  | total loss: \u001b[1m\u001b[32m0.94156\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3800 | loss: 0.94156 - acc: 0.8285 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3801  | total loss: \u001b[1m\u001b[32m0.86792\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3801 | loss: 0.86792 - acc: 0.8456 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3802  | total loss: \u001b[1m\u001b[32m0.80126\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3802 | loss: 0.80126 - acc: 0.8611 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3803  | total loss: \u001b[1m\u001b[32m0.74073\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3803 | loss: 0.74073 - acc: 0.8750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3804  | total loss: \u001b[1m\u001b[32m1.11782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3804 | loss: 1.11782 - acc: 0.7875 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3805  | total loss: \u001b[1m\u001b[32m1.02523\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3805 | loss: 1.02523 - acc: 0.8087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3806  | total loss: \u001b[1m\u001b[32m1.37555\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3806 | loss: 1.37555 - acc: 0.7278 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3807  | total loss: \u001b[1m\u001b[32m1.25821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3807 | loss: 1.25821 - acc: 0.7551 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3808  | total loss: \u001b[1m\u001b[32m1.53425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3808 | loss: 1.53425 - acc: 0.6867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3809  | total loss: \u001b[1m\u001b[32m1.40336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3809 | loss: 1.40336 - acc: 0.7180 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3810  | total loss: \u001b[1m\u001b[32m1.65390\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3810 | loss: 1.65390 - acc: 0.6534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3811  | total loss: \u001b[1m\u001b[32m1.51446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3811 | loss: 1.51446 - acc: 0.6880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3812  | total loss: \u001b[1m\u001b[32m1.39067\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3812 | loss: 1.39067 - acc: 0.7192 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3813  | total loss: \u001b[1m\u001b[32m1.28055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3813 | loss: 1.28055 - acc: 0.7473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3814  | total loss: \u001b[1m\u001b[32m1.18227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3814 | loss: 1.18227 - acc: 0.7726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3815  | total loss: \u001b[1m\u001b[32m1.09423\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3815 | loss: 1.09423 - acc: 0.7953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3816  | total loss: \u001b[1m\u001b[32m1.34618\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3816 | loss: 1.34618 - acc: 0.7229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3817  | total loss: \u001b[1m\u001b[32m1.24272\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3817 | loss: 1.24272 - acc: 0.7506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3818  | total loss: \u001b[1m\u001b[32m1.50809\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3818 | loss: 1.50809 - acc: 0.6756 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3819  | total loss: \u001b[1m\u001b[32m1.39048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3819 | loss: 1.39048 - acc: 0.7080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3820  | total loss: \u001b[1m\u001b[32m1.59602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3820 | loss: 1.59602 - acc: 0.6515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3821  | total loss: \u001b[1m\u001b[32m1.47236\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3821 | loss: 1.47236 - acc: 0.6863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3822  | total loss: \u001b[1m\u001b[32m1.69192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3822 | loss: 1.69192 - acc: 0.6249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3823  | total loss: \u001b[1m\u001b[32m1.56200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3823 | loss: 1.56200 - acc: 0.6624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3824  | total loss: \u001b[1m\u001b[32m1.74899\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3824 | loss: 1.74899 - acc: 0.6033 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3825  | total loss: \u001b[1m\u001b[32m1.61727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3825 | loss: 1.61727 - acc: 0.6429 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3826  | total loss: \u001b[1m\u001b[32m1.50035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3826 | loss: 1.50035 - acc: 0.6787 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3827  | total loss: \u001b[1m\u001b[32m1.39602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3827 | loss: 1.39602 - acc: 0.7108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3828  | total loss: \u001b[1m\u001b[32m1.30231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3828 | loss: 1.30231 - acc: 0.7397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3829  | total loss: \u001b[1m\u001b[32m1.21751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3829 | loss: 1.21751 - acc: 0.7657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3830  | total loss: \u001b[1m\u001b[32m1.14016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3830 | loss: 1.14016 - acc: 0.7892 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3831  | total loss: \u001b[1m\u001b[32m1.06906\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3831 | loss: 1.06906 - acc: 0.8102 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3832  | total loss: \u001b[1m\u001b[32m1.00318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3832 | loss: 1.00318 - acc: 0.8292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3833  | total loss: \u001b[1m\u001b[32m0.94171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3833 | loss: 0.94171 - acc: 0.8463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3834  | total loss: \u001b[1m\u001b[32m0.88401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3834 | loss: 0.88401 - acc: 0.8617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3835  | total loss: \u001b[1m\u001b[32m0.82959\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3835 | loss: 0.82959 - acc: 0.8755 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3836  | total loss: \u001b[1m\u001b[32m1.15022\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3836 | loss: 1.15022 - acc: 0.7880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3837  | total loss: \u001b[1m\u001b[32m1.06544\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3837 | loss: 1.06544 - acc: 0.8092 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3838  | total loss: \u001b[1m\u001b[32m1.32988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3838 | loss: 1.32988 - acc: 0.7354 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3839  | total loss: \u001b[1m\u001b[32m1.22550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3839 | loss: 1.22550 - acc: 0.7618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3840  | total loss: \u001b[1m\u001b[32m1.41748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3840 | loss: 1.41748 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3841  | total loss: \u001b[1m\u001b[32m1.30411\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3841 | loss: 1.30411 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3842  | total loss: \u001b[1m\u001b[32m1.52664\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3842 | loss: 1.52664 - acc: 0.6770 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3843  | total loss: \u001b[1m\u001b[32m1.40317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3843 | loss: 1.40317 - acc: 0.7093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3844  | total loss: \u001b[1m\u001b[32m1.64229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3844 | loss: 1.64229 - acc: 0.6384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3845  | total loss: \u001b[1m\u001b[32m1.50923\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3845 | loss: 1.50923 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3846  | total loss: \u001b[1m\u001b[32m1.39054\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3846 | loss: 1.39054 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3847  | total loss: \u001b[1m\u001b[32m1.28431\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3847 | loss: 1.28431 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3848  | total loss: \u001b[1m\u001b[32m1.52268\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3848 | loss: 1.52268 - acc: 0.6699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3849  | total loss: \u001b[1m\u001b[32m1.40446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3849 | loss: 1.40446 - acc: 0.7029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3850  | total loss: \u001b[1m\u001b[32m1.62318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3850 | loss: 1.62318 - acc: 0.6398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3851  | total loss: \u001b[1m\u001b[32m1.49696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3851 | loss: 1.49696 - acc: 0.6758 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3852  | total loss: \u001b[1m\u001b[32m1.38428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3852 | loss: 1.38428 - acc: 0.7082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3853  | total loss: \u001b[1m\u001b[32m1.28321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3853 | loss: 1.28321 - acc: 0.7374 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3854  | total loss: \u001b[1m\u001b[32m1.46786\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3854 | loss: 1.46786 - acc: 0.6851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3855  | total loss: \u001b[1m\u001b[32m1.35895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3855 | loss: 1.35895 - acc: 0.7166 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3856  | total loss: \u001b[1m\u001b[32m1.26108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3856 | loss: 1.26108 - acc: 0.7449 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3857  | total loss: \u001b[1m\u001b[32m1.17263\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3857 | loss: 1.17263 - acc: 0.7704 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3858  | total loss: \u001b[1m\u001b[32m1.09223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3858 | loss: 1.09223 - acc: 0.7934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3859  | total loss: \u001b[1m\u001b[32m1.01870\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3859 | loss: 1.01870 - acc: 0.8140 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3860  | total loss: \u001b[1m\u001b[32m1.28009\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3860 | loss: 1.28009 - acc: 0.7398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3861  | total loss: \u001b[1m\u001b[32m1.18587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3861 | loss: 1.18587 - acc: 0.7658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3862  | total loss: \u001b[1m\u001b[32m1.41761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3862 | loss: 1.41761 - acc: 0.7035 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3863  | total loss: \u001b[1m\u001b[32m1.30897\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3863 | loss: 1.30897 - acc: 0.7332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3864  | total loss: \u001b[1m\u001b[32m1.52811\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3864 | loss: 1.52811 - acc: 0.6670 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3865  | total loss: \u001b[1m\u001b[32m1.40875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3865 | loss: 1.40875 - acc: 0.7003 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3866  | total loss: \u001b[1m\u001b[32m1.65655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3866 | loss: 1.65655 - acc: 0.6374 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3867  | total loss: \u001b[1m\u001b[32m1.52565\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3867 | loss: 1.52565 - acc: 0.6737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3868  | total loss: \u001b[1m\u001b[32m1.40848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3868 | loss: 1.40848 - acc: 0.7063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3869  | total loss: \u001b[1m\u001b[32m1.30318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3869 | loss: 1.30318 - acc: 0.7357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3870  | total loss: \u001b[1m\u001b[32m1.20813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3870 | loss: 1.20813 - acc: 0.7621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3871  | total loss: \u001b[1m\u001b[32m1.12193\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3871 | loss: 1.12193 - acc: 0.7859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3872  | total loss: \u001b[1m\u001b[32m1.41256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3872 | loss: 1.41256 - acc: 0.7073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3873  | total loss: \u001b[1m\u001b[32m1.30514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3873 | loss: 1.30514 - acc: 0.7366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3874  | total loss: \u001b[1m\u001b[32m1.20826\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3874 | loss: 1.20826 - acc: 0.7629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3875  | total loss: \u001b[1m\u001b[32m1.12050\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3875 | loss: 1.12050 - acc: 0.7866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3876  | total loss: \u001b[1m\u001b[32m1.39019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3876 | loss: 1.39019 - acc: 0.7080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3877  | total loss: \u001b[1m\u001b[32m1.28360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3877 | loss: 1.28360 - acc: 0.7372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3878  | total loss: \u001b[1m\u001b[32m1.54116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3878 | loss: 1.54116 - acc: 0.6706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3879  | total loss: \u001b[1m\u001b[32m1.42015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3879 | loss: 1.42015 - acc: 0.7035 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3880  | total loss: \u001b[1m\u001b[32m1.54550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3880 | loss: 1.54550 - acc: 0.6689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3881  | total loss: \u001b[1m\u001b[32m1.42538\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3881 | loss: 1.42538 - acc: 0.7020 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3882  | total loss: \u001b[1m\u001b[32m1.62088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3882 | loss: 1.62088 - acc: 0.6461 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3883  | total loss: \u001b[1m\u001b[32m1.49496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3883 | loss: 1.49496 - acc: 0.6815 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3884  | total loss: \u001b[1m\u001b[32m1.38238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3884 | loss: 1.38238 - acc: 0.7133 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3885  | total loss: \u001b[1m\u001b[32m1.28131\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3885 | loss: 1.28131 - acc: 0.7420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3886  | total loss: \u001b[1m\u001b[32m1.19011\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3886 | loss: 1.19011 - acc: 0.7678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3887  | total loss: \u001b[1m\u001b[32m1.10739\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3887 | loss: 1.10739 - acc: 0.7910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3888  | total loss: \u001b[1m\u001b[32m1.03193\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3888 | loss: 1.03193 - acc: 0.8119 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3889  | total loss: \u001b[1m\u001b[32m0.96270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3889 | loss: 0.96270 - acc: 0.8307 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3890  | total loss: \u001b[1m\u001b[32m0.89886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3890 | loss: 0.89886 - acc: 0.8477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3891  | total loss: \u001b[1m\u001b[32m0.83968\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3891 | loss: 0.83968 - acc: 0.8629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3892  | total loss: \u001b[1m\u001b[32m0.78458\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3892 | loss: 0.78458 - acc: 0.8766 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3893  | total loss: \u001b[1m\u001b[32m0.73309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3893 | loss: 0.73309 - acc: 0.8889 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3894  | total loss: \u001b[1m\u001b[32m0.68483\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3894 | loss: 0.68483 - acc: 0.9000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3895  | total loss: \u001b[1m\u001b[32m0.63951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3895 | loss: 0.63951 - acc: 0.9100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3896  | total loss: \u001b[1m\u001b[32m0.94594\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3896 | loss: 0.94594 - acc: 0.8333 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3897  | total loss: \u001b[1m\u001b[32m0.87190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3897 | loss: 0.87190 - acc: 0.8500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3898  | total loss: \u001b[1m\u001b[32m1.17315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3898 | loss: 1.17315 - acc: 0.7793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3899  | total loss: \u001b[1m\u001b[32m1.07550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3899 | loss: 1.07550 - acc: 0.8013 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3900  | total loss: \u001b[1m\u001b[32m1.34803\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3900 | loss: 1.34803 - acc: 0.7355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3901  | total loss: \u001b[1m\u001b[32m1.23330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3901 | loss: 1.23330 - acc: 0.7619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3902  | total loss: \u001b[1m\u001b[32m1.13042\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3902 | loss: 1.13042 - acc: 0.7858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3903  | total loss: \u001b[1m\u001b[32m1.03797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3903 | loss: 1.03797 - acc: 0.8072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3904  | total loss: \u001b[1m\u001b[32m1.27035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3904 | loss: 1.27035 - acc: 0.7550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3905  | total loss: \u001b[1m\u001b[32m1.16443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3905 | loss: 1.16443 - acc: 0.7795 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3906  | total loss: \u001b[1m\u001b[32m1.48412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3906 | loss: 1.48412 - acc: 0.7016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3907  | total loss: \u001b[1m\u001b[32m1.35841\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3907 | loss: 1.35841 - acc: 0.7314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3908  | total loss: \u001b[1m\u001b[32m1.24623\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3908 | loss: 1.24623 - acc: 0.7583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3909  | total loss: \u001b[1m\u001b[32m1.14591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3909 | loss: 1.14591 - acc: 0.7824 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3910  | total loss: \u001b[1m\u001b[32m1.46408\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3910 | loss: 1.46408 - acc: 0.7042 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3911  | total loss: \u001b[1m\u001b[32m1.34363\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3911 | loss: 1.34363 - acc: 0.7338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3912  | total loss: \u001b[1m\u001b[32m1.23617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3912 | loss: 1.23617 - acc: 0.7604 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3913  | total loss: \u001b[1m\u001b[32m1.14002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3913 | loss: 1.14002 - acc: 0.7844 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3914  | total loss: \u001b[1m\u001b[32m1.41341\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3914 | loss: 1.41341 - acc: 0.7131 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3915  | total loss: \u001b[1m\u001b[32m1.30085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3915 | loss: 1.30085 - acc: 0.7418 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3916  | total loss: \u001b[1m\u001b[32m1.20023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3916 | loss: 1.20023 - acc: 0.7676 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3917  | total loss: \u001b[1m\u001b[32m1.10997\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3917 | loss: 1.10997 - acc: 0.7908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3918  | total loss: \u001b[1m\u001b[32m1.38359\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3918 | loss: 1.38359 - acc: 0.7189 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3919  | total loss: \u001b[1m\u001b[32m1.27587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3919 | loss: 1.27587 - acc: 0.7470 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3920  | total loss: \u001b[1m\u001b[32m1.17943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3920 | loss: 1.17943 - acc: 0.7723 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3921  | total loss: \u001b[1m\u001b[32m1.09275\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3921 | loss: 1.09275 - acc: 0.7951 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3922  | total loss: \u001b[1m\u001b[32m1.37612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3922 | loss: 1.37612 - acc: 0.7227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3923  | total loss: \u001b[1m\u001b[32m1.27030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3923 | loss: 1.27030 - acc: 0.7504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3924  | total loss: \u001b[1m\u001b[32m1.54515\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3924 | loss: 1.54515 - acc: 0.6754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3925  | total loss: \u001b[1m\u001b[32m1.42421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3925 | loss: 1.42421 - acc: 0.7079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3926  | total loss: \u001b[1m\u001b[32m1.63201\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3926 | loss: 1.63201 - acc: 0.6442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3927  | total loss: \u001b[1m\u001b[32m1.50512\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3927 | loss: 1.50512 - acc: 0.6798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3928  | total loss: \u001b[1m\u001b[32m1.39218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3928 | loss: 1.39218 - acc: 0.7118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3929  | total loss: \u001b[1m\u001b[32m1.29122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3929 | loss: 1.29122 - acc: 0.7406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3930  | total loss: \u001b[1m\u001b[32m1.53847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3930 | loss: 1.53847 - acc: 0.6666 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3931  | total loss: \u001b[1m\u001b[32m1.42439\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3931 | loss: 1.42439 - acc: 0.6999 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3932  | total loss: \u001b[1m\u001b[32m1.65279\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3932 | loss: 1.65279 - acc: 0.6299 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3933  | total loss: \u001b[1m\u001b[32m1.52969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3933 | loss: 1.52969 - acc: 0.6669 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3934  | total loss: \u001b[1m\u001b[32m1.62994\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3934 | loss: 1.62994 - acc: 0.6288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3935  | total loss: \u001b[1m\u001b[32m1.51168\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3935 | loss: 1.51168 - acc: 0.6659 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3936  | total loss: \u001b[1m\u001b[32m1.70152\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3936 | loss: 1.70152 - acc: 0.6065 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3937  | total loss: \u001b[1m\u001b[32m1.57872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3937 | loss: 1.57872 - acc: 0.6458 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3938  | total loss: \u001b[1m\u001b[32m1.75366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3938 | loss: 1.75366 - acc: 0.5884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3939  | total loss: \u001b[1m\u001b[32m1.62862\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3939 | loss: 1.62862 - acc: 0.6295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3940  | total loss: \u001b[1m\u001b[32m1.81515\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3940 | loss: 1.81515 - acc: 0.5737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3941  | total loss: \u001b[1m\u001b[32m1.68707\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3941 | loss: 1.68707 - acc: 0.6164 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3942  | total loss: \u001b[1m\u001b[32m1.83617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3942 | loss: 1.83617 - acc: 0.5690 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3943  | total loss: \u001b[1m\u001b[32m1.70894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3943 | loss: 1.70894 - acc: 0.6121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3944  | total loss: \u001b[1m\u001b[32m1.89864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3944 | loss: 1.89864 - acc: 0.5509 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3945  | total loss: \u001b[1m\u001b[32m1.76803\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3945 | loss: 1.76803 - acc: 0.5958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3946  | total loss: \u001b[1m\u001b[32m1.94993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3946 | loss: 1.94993 - acc: 0.5362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3947  | total loss: \u001b[1m\u001b[32m1.81699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3947 | loss: 1.81699 - acc: 0.5826 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3948  | total loss: \u001b[1m\u001b[32m2.00729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3948 | loss: 2.00729 - acc: 0.5243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3949  | total loss: \u001b[1m\u001b[32m1.87126\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3949 | loss: 1.87126 - acc: 0.5719 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 3950  | total loss: \u001b[1m\u001b[32m1.74956\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3950 | loss: 1.74956 - acc: 0.6147 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3951  | total loss: \u001b[1m\u001b[32m1.63980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3951 | loss: 1.63980 - acc: 0.6532 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3952  | total loss: \u001b[1m\u001b[32m1.79599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3952 | loss: 1.79599 - acc: 0.6022 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3953  | total loss: \u001b[1m\u001b[32m1.68027\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3953 | loss: 1.68027 - acc: 0.6420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3954  | total loss: \u001b[1m\u001b[32m1.57507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3954 | loss: 1.57507 - acc: 0.6778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3955  | total loss: \u001b[1m\u001b[32m1.47862\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3955 | loss: 1.47862 - acc: 0.7100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3956  | total loss: \u001b[1m\u001b[32m1.69130\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3956 | loss: 1.69130 - acc: 0.6390 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3957  | total loss: \u001b[1m\u001b[32m1.57979\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3957 | loss: 1.57979 - acc: 0.6751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3958  | total loss: \u001b[1m\u001b[32m1.47774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3958 | loss: 1.47774 - acc: 0.7076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3959  | total loss: \u001b[1m\u001b[32m1.38366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3959 | loss: 1.38366 - acc: 0.7368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3960  | total loss: \u001b[1m\u001b[32m1.59645\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3960 | loss: 1.59645 - acc: 0.6632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3961  | total loss: \u001b[1m\u001b[32m1.48664\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3961 | loss: 1.48664 - acc: 0.6968 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3962  | total loss: \u001b[1m\u001b[32m1.38609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3962 | loss: 1.38609 - acc: 0.7272 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3963  | total loss: \u001b[1m\u001b[32m1.29350\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3963 | loss: 1.29350 - acc: 0.7544 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3964  | total loss: \u001b[1m\u001b[32m1.51241\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3964 | loss: 1.51241 - acc: 0.6861 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3965  | total loss: \u001b[1m\u001b[32m1.40364\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3965 | loss: 1.40364 - acc: 0.7175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3966  | total loss: \u001b[1m\u001b[32m1.30425\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3966 | loss: 1.30425 - acc: 0.7458 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3967  | total loss: \u001b[1m\u001b[32m1.21298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3967 | loss: 1.21298 - acc: 0.7712 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3968  | total loss: \u001b[1m\u001b[32m1.42427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3968 | loss: 1.42427 - acc: 0.7084 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3969  | total loss: \u001b[1m\u001b[32m1.31799\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3969 | loss: 1.31799 - acc: 0.7375 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3970  | total loss: \u001b[1m\u001b[32m1.22106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3970 | loss: 1.22106 - acc: 0.7638 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3971  | total loss: \u001b[1m\u001b[32m1.13232\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3971 | loss: 1.13232 - acc: 0.7874 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3972  | total loss: \u001b[1m\u001b[32m1.05075\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3972 | loss: 1.05075 - acc: 0.8087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3973  | total loss: \u001b[1m\u001b[32m0.97552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3973 | loss: 0.97552 - acc: 0.8278 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3974  | total loss: \u001b[1m\u001b[32m1.24456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3974 | loss: 1.24456 - acc: 0.7522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3975  | total loss: \u001b[1m\u001b[32m1.14725\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3975 | loss: 1.14725 - acc: 0.7769 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3976  | total loss: \u001b[1m\u001b[32m1.42755\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3976 | loss: 1.42755 - acc: 0.7064 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3977  | total loss: \u001b[1m\u001b[32m1.31098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3977 | loss: 1.31098 - acc: 0.7357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3978  | total loss: \u001b[1m\u001b[32m1.20582\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3978 | loss: 1.20582 - acc: 0.7622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3979  | total loss: \u001b[1m\u001b[32m1.11069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3979 | loss: 1.11069 - acc: 0.7860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3980  | total loss: \u001b[1m\u001b[32m1.36616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3980 | loss: 1.36616 - acc: 0.7216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3981  | total loss: \u001b[1m\u001b[32m1.25452\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 3981 | loss: 1.25452 - acc: 0.7495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3982  | total loss: \u001b[1m\u001b[32m1.56135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3982 | loss: 1.56135 - acc: 0.6745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3983  | total loss: \u001b[1m\u001b[32m1.43107\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3983 | loss: 1.43107 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3984  | total loss: \u001b[1m\u001b[32m1.69704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3984 | loss: 1.69704 - acc: 0.6364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3985  | total loss: \u001b[1m\u001b[32m1.55537\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3985 | loss: 1.55537 - acc: 0.6727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3986  | total loss: \u001b[1m\u001b[32m1.78607\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3986 | loss: 1.78607 - acc: 0.6126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3987  | total loss: \u001b[1m\u001b[32m1.63880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3987 | loss: 1.63880 - acc: 0.6513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3988  | total loss: \u001b[1m\u001b[32m1.89420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3988 | loss: 1.89420 - acc: 0.5862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3989  | total loss: \u001b[1m\u001b[32m1.74031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3989 | loss: 1.74031 - acc: 0.6276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3990  | total loss: \u001b[1m\u001b[32m1.60378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3990 | loss: 1.60378 - acc: 0.6648 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3991  | total loss: \u001b[1m\u001b[32m1.48225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3991 | loss: 1.48225 - acc: 0.6983 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3992  | total loss: \u001b[1m\u001b[32m1.66323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3992 | loss: 1.66323 - acc: 0.6428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3993  | total loss: \u001b[1m\u001b[32m1.53802\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3993 | loss: 1.53802 - acc: 0.6785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3994  | total loss: \u001b[1m\u001b[32m1.72677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3994 | loss: 1.72677 - acc: 0.6178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3995  | total loss: \u001b[1m\u001b[32m1.59784\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3995 | loss: 1.59784 - acc: 0.6560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3996  | total loss: \u001b[1m\u001b[32m1.80826\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3996 | loss: 1.80826 - acc: 0.5904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3997  | total loss: \u001b[1m\u001b[32m1.67429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3997 | loss: 1.67429 - acc: 0.6314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3998  | total loss: \u001b[1m\u001b[32m1.55502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3998 | loss: 1.55502 - acc: 0.6682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 3999  | total loss: \u001b[1m\u001b[32m1.44824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 3999 | loss: 1.44824 - acc: 0.7014 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4000  | total loss: \u001b[1m\u001b[32m1.64225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4000 | loss: 1.64225 - acc: 0.6384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4001  | total loss: \u001b[1m\u001b[32m1.52748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4001 | loss: 1.52748 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4002  | total loss: \u001b[1m\u001b[32m1.42433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4002 | loss: 1.42433 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4003  | total loss: \u001b[1m\u001b[32m1.33097\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4003 | loss: 1.33097 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4004  | total loss: \u001b[1m\u001b[32m1.54032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4004 | loss: 1.54032 - acc: 0.6699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4005  | total loss: \u001b[1m\u001b[32m1.43416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4005 | loss: 1.43416 - acc: 0.7029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4006  | total loss: \u001b[1m\u001b[32m1.33792\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4006 | loss: 1.33792 - acc: 0.7326 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4007  | total loss: \u001b[1m\u001b[32m1.25006\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4007 | loss: 1.25006 - acc: 0.7594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4008  | total loss: \u001b[1m\u001b[32m1.47772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4008 | loss: 1.47772 - acc: 0.6834 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4009  | total loss: \u001b[1m\u001b[32m1.37375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4009 | loss: 1.37375 - acc: 0.7151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4010  | total loss: \u001b[1m\u001b[32m1.27922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4010 | loss: 1.27922 - acc: 0.7436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4011  | total loss: \u001b[1m\u001b[32m1.19276\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4011 | loss: 1.19276 - acc: 0.7692 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4012  | total loss: \u001b[1m\u001b[32m1.42920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4012 | loss: 1.42920 - acc: 0.6994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4013  | total loss: \u001b[1m\u001b[32m1.32546\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4013 | loss: 1.32546 - acc: 0.7295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4014  | total loss: \u001b[1m\u001b[32m1.53020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4014 | loss: 1.53020 - acc: 0.6708 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4015  | total loss: \u001b[1m\u001b[32m1.41545\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4015 | loss: 1.41545 - acc: 0.7037 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4016  | total loss: \u001b[1m\u001b[32m1.64384\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4016 | loss: 1.64384 - acc: 0.6334 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4017  | total loss: \u001b[1m\u001b[32m1.51804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4017 | loss: 1.51804 - acc: 0.6700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4018  | total loss: \u001b[1m\u001b[32m1.69401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4018 | loss: 1.69401 - acc: 0.6173 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4019  | total loss: \u001b[1m\u001b[32m1.56439\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4019 | loss: 1.56439 - acc: 0.6556 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4020  | total loss: \u001b[1m\u001b[32m1.44815\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4020 | loss: 1.44815 - acc: 0.6900 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4021  | total loss: \u001b[1m\u001b[32m1.34345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4021 | loss: 1.34345 - acc: 0.7210 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4022  | total loss: \u001b[1m\u001b[32m1.57388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4022 | loss: 1.57388 - acc: 0.6561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4023  | total loss: \u001b[1m\u001b[32m1.45644\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4023 | loss: 1.45644 - acc: 0.6905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4024  | total loss: \u001b[1m\u001b[32m1.66831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4024 | loss: 1.66831 - acc: 0.6286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4025  | total loss: \u001b[1m\u001b[32m1.54224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4025 | loss: 1.54224 - acc: 0.6657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4026  | total loss: \u001b[1m\u001b[32m1.74282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4026 | loss: 1.74282 - acc: 0.6063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4027  | total loss: \u001b[1m\u001b[32m1.61091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4027 | loss: 1.61091 - acc: 0.6456 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4028  | total loss: \u001b[1m\u001b[32m1.77030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4028 | loss: 1.77030 - acc: 0.5954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4029  | total loss: \u001b[1m\u001b[32m1.63768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4029 | loss: 1.63768 - acc: 0.6358 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4030  | total loss: \u001b[1m\u001b[32m1.51907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4030 | loss: 1.51907 - acc: 0.6722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4031  | total loss: \u001b[1m\u001b[32m1.41244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4031 | loss: 1.41244 - acc: 0.7050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4032  | total loss: \u001b[1m\u001b[32m1.31602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4032 | loss: 1.31602 - acc: 0.7345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4033  | total loss: \u001b[1m\u001b[32m1.22830\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4033 | loss: 1.22830 - acc: 0.7611 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4034  | total loss: \u001b[1m\u001b[32m1.44773\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4034 | loss: 1.44773 - acc: 0.6921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4035  | total loss: \u001b[1m\u001b[32m1.34513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4035 | loss: 1.34513 - acc: 0.7229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4036  | total loss: \u001b[1m\u001b[32m1.57218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4036 | loss: 1.57218 - acc: 0.6506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4037  | total loss: \u001b[1m\u001b[32m1.45661\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4037 | loss: 1.45661 - acc: 0.6855 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4038  | total loss: \u001b[1m\u001b[32m1.35235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4038 | loss: 1.35235 - acc: 0.7170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4039  | total loss: \u001b[1m\u001b[32m1.25780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4039 | loss: 1.25780 - acc: 0.7453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4040  | total loss: \u001b[1m\u001b[32m1.17156\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4040 | loss: 1.17156 - acc: 0.7708 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4041  | total loss: \u001b[1m\u001b[32m1.09248\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4041 | loss: 1.09248 - acc: 0.7937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4042  | total loss: \u001b[1m\u001b[32m1.01956\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4042 | loss: 1.01956 - acc: 0.8143 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4043  | total loss: \u001b[1m\u001b[32m0.95199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4043 | loss: 0.95199 - acc: 0.8329 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4044  | total loss: \u001b[1m\u001b[32m0.88909\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4044 | loss: 0.88909 - acc: 0.8496 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4045  | total loss: \u001b[1m\u001b[32m0.83032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4045 | loss: 0.83032 - acc: 0.8646 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4046  | total loss: \u001b[1m\u001b[32m1.15422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4046 | loss: 1.15422 - acc: 0.7853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4047  | total loss: \u001b[1m\u001b[32m1.06579\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4047 | loss: 1.06579 - acc: 0.8068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4048  | total loss: \u001b[1m\u001b[32m0.98508\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4048 | loss: 0.98508 - acc: 0.8261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4049  | total loss: \u001b[1m\u001b[32m0.91120\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4049 | loss: 0.91120 - acc: 0.8435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4050  | total loss: \u001b[1m\u001b[32m0.84338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4050 | loss: 0.84338 - acc: 0.8591 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4051  | total loss: \u001b[1m\u001b[32m0.78098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4051 | loss: 0.78098 - acc: 0.8732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4052  | total loss: \u001b[1m\u001b[32m0.72344\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4052 | loss: 0.72344 - acc: 0.8859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4053  | total loss: \u001b[1m\u001b[32m0.67027\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4053 | loss: 0.67027 - acc: 0.8973 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4054  | total loss: \u001b[1m\u001b[32m0.98744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4054 | loss: 0.98744 - acc: 0.8219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4055  | total loss: \u001b[1m\u001b[32m0.90612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4055 | loss: 0.90612 - acc: 0.8397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4056  | total loss: \u001b[1m\u001b[32m1.22125\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4056 | loss: 1.22125 - acc: 0.7700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4057  | total loss: \u001b[1m\u001b[32m1.11632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4057 | loss: 1.11632 - acc: 0.7930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4058  | total loss: \u001b[1m\u001b[32m1.41721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4058 | loss: 1.41721 - acc: 0.7208 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4059  | total loss: \u001b[1m\u001b[32m1.29366\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4059 | loss: 1.29366 - acc: 0.7488 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4060  | total loss: \u001b[1m\u001b[32m1.58241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4060 | loss: 1.58241 - acc: 0.6810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4061  | total loss: \u001b[1m\u001b[32m1.44440\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4061 | loss: 1.44440 - acc: 0.7129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4062  | total loss: \u001b[1m\u001b[32m1.32136\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4062 | loss: 1.32136 - acc: 0.7416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4063  | total loss: \u001b[1m\u001b[32m1.21149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4063 | loss: 1.21149 - acc: 0.7675 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4064  | total loss: \u001b[1m\u001b[32m1.48513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4064 | loss: 1.48513 - acc: 0.6979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4065  | total loss: \u001b[1m\u001b[32m1.36094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4065 | loss: 1.36094 - acc: 0.7281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4066  | total loss: \u001b[1m\u001b[32m1.58629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4066 | loss: 1.58629 - acc: 0.6696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4067  | total loss: \u001b[1m\u001b[32m1.45495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4067 | loss: 1.45495 - acc: 0.7026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4068  | total loss: \u001b[1m\u001b[32m1.73287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4068 | loss: 1.73287 - acc: 0.6323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4069  | total loss: \u001b[1m\u001b[32m1.59065\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4069 | loss: 1.59065 - acc: 0.6691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4070  | total loss: \u001b[1m\u001b[32m1.83114\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4070 | loss: 1.83114 - acc: 0.6022 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4071  | total loss: \u001b[1m\u001b[32m1.68375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4071 | loss: 1.68375 - acc: 0.6420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4072  | total loss: \u001b[1m\u001b[32m1.55329\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4072 | loss: 1.55329 - acc: 0.6778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4073  | total loss: \u001b[1m\u001b[32m1.43740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4073 | loss: 1.43740 - acc: 0.7100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4074  | total loss: \u001b[1m\u001b[32m1.33400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4074 | loss: 1.33400 - acc: 0.7390 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4075  | total loss: \u001b[1m\u001b[32m1.24123\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4075 | loss: 1.24123 - acc: 0.7651 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4076  | total loss: \u001b[1m\u001b[32m1.15748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4076 | loss: 1.15748 - acc: 0.7886 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4077  | total loss: \u001b[1m\u001b[32m1.08136\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4077 | loss: 1.08136 - acc: 0.8097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4078  | total loss: \u001b[1m\u001b[32m1.01170\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4078 | loss: 1.01170 - acc: 0.8288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4079  | total loss: \u001b[1m\u001b[32m0.94751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4079 | loss: 0.94751 - acc: 0.8459 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4080  | total loss: \u001b[1m\u001b[32m1.23102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4080 | loss: 1.23102 - acc: 0.7613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4081  | total loss: \u001b[1m\u001b[32m1.14258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4081 | loss: 1.14258 - acc: 0.7852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4082  | total loss: \u001b[1m\u001b[32m1.06207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4082 | loss: 1.06207 - acc: 0.8066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4083  | total loss: \u001b[1m\u001b[32m0.98842\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4083 | loss: 0.98842 - acc: 0.8260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4084  | total loss: \u001b[1m\u001b[32m1.27136\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4084 | loss: 1.27136 - acc: 0.7434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4085  | total loss: \u001b[1m\u001b[32m1.17513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4085 | loss: 1.17513 - acc: 0.7690 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4086  | total loss: \u001b[1m\u001b[32m1.08797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4086 | loss: 1.08797 - acc: 0.7921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4087  | total loss: \u001b[1m\u001b[32m1.00870\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4087 | loss: 1.00870 - acc: 0.8129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4088  | total loss: \u001b[1m\u001b[32m0.93633\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4088 | loss: 0.93633 - acc: 0.8316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4089  | total loss: \u001b[1m\u001b[32m0.86998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4089 | loss: 0.86998 - acc: 0.8485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4090  | total loss: \u001b[1m\u001b[32m0.80893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4090 | loss: 0.80893 - acc: 0.8636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4091  | total loss: \u001b[1m\u001b[32m0.75257\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4091 | loss: 0.75257 - acc: 0.8773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4092  | total loss: \u001b[1m\u001b[32m1.08551\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4092 | loss: 1.08551 - acc: 0.7967 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4093  | total loss: \u001b[1m\u001b[32m0.99962\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4093 | loss: 0.99962 - acc: 0.8170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4094  | total loss: \u001b[1m\u001b[32m0.92175\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4094 | loss: 0.92175 - acc: 0.8353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4095  | total loss: \u001b[1m\u001b[32m0.85096\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4095 | loss: 0.85096 - acc: 0.8518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4096  | total loss: \u001b[1m\u001b[32m1.19282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4096 | loss: 1.19282 - acc: 0.7737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4097  | total loss: \u001b[1m\u001b[32m1.09419\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4097 | loss: 1.09419 - acc: 0.7964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4098  | total loss: \u001b[1m\u001b[32m1.00531\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4098 | loss: 1.00531 - acc: 0.8167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4099  | total loss: \u001b[1m\u001b[32m0.92504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4099 | loss: 0.92504 - acc: 0.8351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4100  | total loss: \u001b[1m\u001b[32m1.21709\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4100 | loss: 1.21709 - acc: 0.7658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4101  | total loss: \u001b[1m\u001b[32m1.11558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4101 | loss: 1.11558 - acc: 0.7893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4102  | total loss: \u001b[1m\u001b[32m1.33611\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4102 | loss: 1.33611 - acc: 0.7318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4103  | total loss: \u001b[1m\u001b[32m1.22366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4103 | loss: 1.22366 - acc: 0.7586 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4104  | total loss: \u001b[1m\u001b[32m1.52212\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4104 | loss: 1.52212 - acc: 0.6827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4105  | total loss: \u001b[1m\u001b[32m1.39303\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4105 | loss: 1.39303 - acc: 0.7145 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4106  | total loss: \u001b[1m\u001b[32m1.27797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4106 | loss: 1.27797 - acc: 0.7430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4107  | total loss: \u001b[1m\u001b[32m1.17519\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4107 | loss: 1.17519 - acc: 0.7687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4108  | total loss: \u001b[1m\u001b[32m1.50374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4108 | loss: 1.50374 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4109  | total loss: \u001b[1m\u001b[32m1.38032\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4109 | loss: 1.38032 - acc: 0.7227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4110  | total loss: \u001b[1m\u001b[32m1.61213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4110 | loss: 1.61213 - acc: 0.6647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4111  | total loss: \u001b[1m\u001b[32m1.48082\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4111 | loss: 1.48082 - acc: 0.6982 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4112  | total loss: \u001b[1m\u001b[32m1.70245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4112 | loss: 1.70245 - acc: 0.6355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4113  | total loss: \u001b[1m\u001b[32m1.56593\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4113 | loss: 1.56593 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4114  | total loss: \u001b[1m\u001b[32m1.72951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4114 | loss: 1.72951 - acc: 0.6191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4115  | total loss: \u001b[1m\u001b[32m1.59474\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4115 | loss: 1.59474 - acc: 0.6572 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4116  | total loss: \u001b[1m\u001b[32m1.47542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4116 | loss: 1.47542 - acc: 0.6914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4117  | total loss: \u001b[1m\u001b[32m1.36936\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4117 | loss: 1.36936 - acc: 0.7223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4118  | total loss: \u001b[1m\u001b[32m1.56804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4118 | loss: 1.56804 - acc: 0.6572 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4119  | total loss: \u001b[1m\u001b[32m1.45501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4119 | loss: 1.45501 - acc: 0.6915 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4120  | total loss: \u001b[1m\u001b[32m1.35420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4120 | loss: 1.35420 - acc: 0.7223 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4121  | total loss: \u001b[1m\u001b[32m1.26372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4121 | loss: 1.26372 - acc: 0.7501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4122  | total loss: \u001b[1m\u001b[32m1.18190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4122 | loss: 1.18190 - acc: 0.7751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4123  | total loss: \u001b[1m\u001b[32m1.10734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4123 | loss: 1.10734 - acc: 0.7976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4124  | total loss: \u001b[1m\u001b[32m1.35663\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4124 | loss: 1.35663 - acc: 0.7250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4125  | total loss: \u001b[1m\u001b[32m1.26297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4125 | loss: 1.26297 - acc: 0.7525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4126  | total loss: \u001b[1m\u001b[32m1.48055\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4126 | loss: 1.48055 - acc: 0.6915 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4127  | total loss: \u001b[1m\u001b[32m1.37402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4127 | loss: 1.37402 - acc: 0.7224 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4128  | total loss: \u001b[1m\u001b[32m1.62319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4128 | loss: 1.62319 - acc: 0.6501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4129  | total loss: \u001b[1m\u001b[32m1.50275\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4129 | loss: 1.50275 - acc: 0.6851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4130  | total loss: \u001b[1m\u001b[32m1.74238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4130 | loss: 1.74238 - acc: 0.6166 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4131  | total loss: \u001b[1m\u001b[32m1.61116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4131 | loss: 1.61116 - acc: 0.6549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4132  | total loss: \u001b[1m\u001b[32m1.81082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4132 | loss: 1.81082 - acc: 0.6037 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4133  | total loss: \u001b[1m\u001b[32m1.67450\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4133 | loss: 1.67450 - acc: 0.6434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4134  | total loss: \u001b[1m\u001b[32m1.82807\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4134 | loss: 1.82807 - acc: 0.5933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4135  | total loss: \u001b[1m\u001b[32m1.69212\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4135 | loss: 1.69212 - acc: 0.6340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4136  | total loss: \u001b[1m\u001b[32m1.57052\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4136 | loss: 1.57052 - acc: 0.6706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4137  | total loss: \u001b[1m\u001b[32m1.46117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4137 | loss: 1.46117 - acc: 0.7035 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4138  | total loss: \u001b[1m\u001b[32m1.66310\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4138 | loss: 1.66310 - acc: 0.6332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4139  | total loss: \u001b[1m\u001b[32m1.54446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4139 | loss: 1.54446 - acc: 0.6699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4140  | total loss: \u001b[1m\u001b[32m1.43754\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4140 | loss: 1.43754 - acc: 0.7029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4141  | total loss: \u001b[1m\u001b[32m1.34058\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4141 | loss: 1.34058 - acc: 0.7326 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4142  | total loss: \u001b[1m\u001b[32m1.57540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4142 | loss: 1.57540 - acc: 0.6593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4143  | total loss: \u001b[1m\u001b[32m1.46342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4143 | loss: 1.46342 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4144  | total loss: \u001b[1m\u001b[32m1.70705\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4144 | loss: 1.70705 - acc: 0.6241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4145  | total loss: \u001b[1m\u001b[32m1.58186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4145 | loss: 1.58186 - acc: 0.6616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4146  | total loss: \u001b[1m\u001b[32m1.46910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4146 | loss: 1.46910 - acc: 0.6955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4147  | total loss: \u001b[1m\u001b[32m1.36698\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4147 | loss: 1.36698 - acc: 0.7259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4148  | total loss: \u001b[1m\u001b[32m1.27393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4148 | loss: 1.27393 - acc: 0.7533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4149  | total loss: \u001b[1m\u001b[32m1.18865\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4149 | loss: 1.18865 - acc: 0.7780 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4150  | total loss: \u001b[1m\u001b[32m1.11003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4150 | loss: 1.11003 - acc: 0.8002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4151  | total loss: \u001b[1m\u001b[32m1.03716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4151 | loss: 1.03716 - acc: 0.8202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4152  | total loss: \u001b[1m\u001b[32m1.33132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4152 | loss: 1.33132 - acc: 0.7382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4153  | total loss: \u001b[1m\u001b[32m1.23302\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4153 | loss: 1.23302 - acc: 0.7643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4154  | total loss: \u001b[1m\u001b[32m1.47074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4154 | loss: 1.47074 - acc: 0.6951 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4155  | total loss: \u001b[1m\u001b[32m1.35697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4155 | loss: 1.35697 - acc: 0.7256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4156  | total loss: \u001b[1m\u001b[32m1.57643\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4156 | loss: 1.57643 - acc: 0.6601 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4157  | total loss: \u001b[1m\u001b[32m1.45193\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4157 | loss: 1.45193 - acc: 0.6941 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4158  | total loss: \u001b[1m\u001b[32m1.33990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4158 | loss: 1.33990 - acc: 0.7247 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4159  | total loss: \u001b[1m\u001b[32m1.23872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4159 | loss: 1.23872 - acc: 0.7522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4160  | total loss: \u001b[1m\u001b[32m1.14696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4160 | loss: 1.14696 - acc: 0.7770 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4161  | total loss: \u001b[1m\u001b[32m1.06341\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4161 | loss: 1.06341 - acc: 0.7993 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4162  | total loss: \u001b[1m\u001b[32m0.98703\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4162 | loss: 0.98703 - acc: 0.8194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4163  | total loss: \u001b[1m\u001b[32m0.91690\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4163 | loss: 0.91690 - acc: 0.8374 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4164  | total loss: \u001b[1m\u001b[32m1.23449\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4164 | loss: 1.23449 - acc: 0.7537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4165  | total loss: \u001b[1m\u001b[32m1.13778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4165 | loss: 1.13778 - acc: 0.7783 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4166  | total loss: \u001b[1m\u001b[32m1.05015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4166 | loss: 1.05015 - acc: 0.8005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4167  | total loss: \u001b[1m\u001b[32m0.97049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4167 | loss: 0.97049 - acc: 0.8204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4168  | total loss: \u001b[1m\u001b[32m0.89784\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4168 | loss: 0.89784 - acc: 0.8384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4169  | total loss: \u001b[1m\u001b[32m0.83138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4169 | loss: 0.83138 - acc: 0.8546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4170  | total loss: \u001b[1m\u001b[32m0.77039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4170 | loss: 0.77039 - acc: 0.8691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4171  | total loss: \u001b[1m\u001b[32m0.71428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4171 | loss: 0.71428 - acc: 0.8822 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4172  | total loss: \u001b[1m\u001b[32m0.66252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4172 | loss: 0.66252 - acc: 0.8940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4173  | total loss: \u001b[1m\u001b[32m0.61468\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4173 | loss: 0.61468 - acc: 0.9046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4174  | total loss: \u001b[1m\u001b[32m0.57038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4174 | loss: 0.57038 - acc: 0.9141 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4175  | total loss: \u001b[1m\u001b[32m0.52932\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4175 | loss: 0.52932 - acc: 0.9227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4176  | total loss: \u001b[1m\u001b[32m0.90007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4176 | loss: 0.90007 - acc: 0.8447 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4177  | total loss: \u001b[1m\u001b[32m0.82452\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4177 | loss: 0.82452 - acc: 0.8603 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4178  | total loss: \u001b[1m\u001b[32m0.75610\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4178 | loss: 0.75610 - acc: 0.8742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4179  | total loss: \u001b[1m\u001b[32m0.69406\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4179 | loss: 0.69406 - acc: 0.8868 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4180  | total loss: \u001b[1m\u001b[32m0.63771\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4180 | loss: 0.63771 - acc: 0.8981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4181  | total loss: \u001b[1m\u001b[32m0.58646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4181 | loss: 0.58646 - acc: 0.9083 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4182  | total loss: \u001b[1m\u001b[32m0.96640\u001b[0m\u001b[0m | time: 0.028s\n",
      "| Adam | epoch: 4182 | loss: 0.96640 - acc: 0.8246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4183  | total loss: \u001b[1m\u001b[32m0.88182\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 4183 | loss: 0.88182 - acc: 0.8422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4184  | total loss: \u001b[1m\u001b[32m0.80570\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 4184 | loss: 0.80570 - acc: 0.8579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4185  | total loss: \u001b[1m\u001b[32m0.73712\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4185 | loss: 0.73712 - acc: 0.8721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4186  | total loss: \u001b[1m\u001b[32m0.67524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4186 | loss: 0.67524 - acc: 0.8849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4187  | total loss: \u001b[1m\u001b[32m0.61935\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4187 | loss: 0.61935 - acc: 0.8964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4188  | total loss: \u001b[1m\u001b[32m0.56878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4188 | loss: 0.56878 - acc: 0.9068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4189  | total loss: \u001b[1m\u001b[32m0.52296\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4189 | loss: 0.52296 - acc: 0.9161 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4190  | total loss: \u001b[1m\u001b[32m0.95960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4190 | loss: 0.95960 - acc: 0.8316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4191  | total loss: \u001b[1m\u001b[32m0.87459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4191 | loss: 0.87459 - acc: 0.8485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4192  | total loss: \u001b[1m\u001b[32m0.79822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4192 | loss: 0.79822 - acc: 0.8636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4193  | total loss: \u001b[1m\u001b[32m0.72955\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4193 | loss: 0.72955 - acc: 0.8773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4194  | total loss: \u001b[1m\u001b[32m0.66772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4194 | loss: 0.66772 - acc: 0.8895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4195  | total loss: \u001b[1m\u001b[32m0.61198\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4195 | loss: 0.61198 - acc: 0.9006 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4196  | total loss: \u001b[1m\u001b[32m1.03161\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4196 | loss: 1.03161 - acc: 0.8177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4197  | total loss: \u001b[1m\u001b[32m0.93974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4197 | loss: 0.93974 - acc: 0.8359 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4198  | total loss: \u001b[1m\u001b[32m0.85737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4198 | loss: 0.85737 - acc: 0.8523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4199  | total loss: \u001b[1m\u001b[32m0.78344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4199 | loss: 0.78344 - acc: 0.8671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4200  | total loss: \u001b[1m\u001b[32m0.71702\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4200 | loss: 0.71702 - acc: 0.8804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4201  | total loss: \u001b[1m\u001b[32m0.65724\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4201 | loss: 0.65724 - acc: 0.8923 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4202  | total loss: \u001b[1m\u001b[32m0.60336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4202 | loss: 0.60336 - acc: 0.9031 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4203  | total loss: \u001b[1m\u001b[32m0.55470\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4203 | loss: 0.55470 - acc: 0.9128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4204  | total loss: \u001b[1m\u001b[32m0.98408\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4204 | loss: 0.98408 - acc: 0.8215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4205  | total loss: \u001b[1m\u001b[32m0.89755\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4205 | loss: 0.89755 - acc: 0.8394 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4206  | total loss: \u001b[1m\u001b[32m0.81998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4206 | loss: 0.81998 - acc: 0.8554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4207  | total loss: \u001b[1m\u001b[32m0.75036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4207 | loss: 0.75036 - acc: 0.8699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4208  | total loss: \u001b[1m\u001b[32m1.14533\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4208 | loss: 1.14533 - acc: 0.7829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4209  | total loss: \u001b[1m\u001b[32m1.04399\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4209 | loss: 1.04399 - acc: 0.8046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4210  | total loss: \u001b[1m\u001b[32m0.95337\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4210 | loss: 0.95337 - acc: 0.8241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4211  | total loss: \u001b[1m\u001b[32m0.87224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4211 | loss: 0.87224 - acc: 0.8417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4212  | total loss: \u001b[1m\u001b[32m1.17348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4212 | loss: 1.17348 - acc: 0.7790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4213  | total loss: \u001b[1m\u001b[32m1.07150\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4213 | loss: 1.07150 - acc: 0.8011 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4214  | total loss: \u001b[1m\u001b[32m0.98040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4214 | loss: 0.98040 - acc: 0.8210 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4215  | total loss: \u001b[1m\u001b[32m0.89891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4215 | loss: 0.89891 - acc: 0.8389 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4216  | total loss: \u001b[1m\u001b[32m0.82586\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4216 | loss: 0.82586 - acc: 0.8550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4217  | total loss: \u001b[1m\u001b[32m0.76024\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4217 | loss: 0.76024 - acc: 0.8695 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4218  | total loss: \u001b[1m\u001b[32m1.10636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4218 | loss: 1.10636 - acc: 0.7897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4219  | total loss: \u001b[1m\u001b[32m1.01334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4219 | loss: 1.01334 - acc: 0.8107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4220  | total loss: \u001b[1m\u001b[32m0.93011\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4220 | loss: 0.93011 - acc: 0.8296 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4221  | total loss: \u001b[1m\u001b[32m0.85549\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4221 | loss: 0.85549 - acc: 0.8467 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4222  | total loss: \u001b[1m\u001b[32m0.78840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4222 | loss: 0.78840 - acc: 0.8620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4223  | total loss: \u001b[1m\u001b[32m0.72790\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4223 | loss: 0.72790 - acc: 0.8758 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4224  | total loss: \u001b[1m\u001b[32m0.67318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4224 | loss: 0.67318 - acc: 0.8882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4225  | total loss: \u001b[1m\u001b[32m0.62351\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4225 | loss: 0.62351 - acc: 0.8994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4226  | total loss: \u001b[1m\u001b[32m0.94254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4226 | loss: 0.94254 - acc: 0.8309 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4227  | total loss: \u001b[1m\u001b[32m0.86559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4227 | loss: 0.86559 - acc: 0.8478 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4228  | total loss: \u001b[1m\u001b[32m1.23620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4228 | loss: 1.23620 - acc: 0.7630 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4229  | total loss: \u001b[1m\u001b[32m1.13078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4229 | loss: 1.13078 - acc: 0.7867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4230  | total loss: \u001b[1m\u001b[32m1.43010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4230 | loss: 1.43010 - acc: 0.7152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4231  | total loss: \u001b[1m\u001b[32m1.30733\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4231 | loss: 1.30733 - acc: 0.7437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4232  | total loss: \u001b[1m\u001b[32m1.57101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4232 | loss: 1.57101 - acc: 0.6764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4233  | total loss: \u001b[1m\u001b[32m1.43727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4233 | loss: 1.43727 - acc: 0.7088 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4234  | total loss: \u001b[1m\u001b[32m1.31852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4234 | loss: 1.31852 - acc: 0.7379 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4235  | total loss: \u001b[1m\u001b[32m1.21290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4235 | loss: 1.21290 - acc: 0.7641 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4236  | total loss: \u001b[1m\u001b[32m1.46839\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4236 | loss: 1.46839 - acc: 0.6949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4237  | total loss: \u001b[1m\u001b[32m1.35040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4237 | loss: 1.35040 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4238  | total loss: \u001b[1m\u001b[32m1.62379\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4238 | loss: 1.62379 - acc: 0.6528 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4239  | total loss: \u001b[1m\u001b[32m1.49391\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4239 | loss: 1.49391 - acc: 0.6876 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4240  | total loss: \u001b[1m\u001b[32m1.68268\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4240 | loss: 1.68268 - acc: 0.6402 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4241  | total loss: \u001b[1m\u001b[32m1.55110\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4241 | loss: 1.55110 - acc: 0.6762 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4242  | total loss: \u001b[1m\u001b[32m1.43446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4242 | loss: 1.43446 - acc: 0.7086 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4243  | total loss: \u001b[1m\u001b[32m1.33063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4243 | loss: 1.33063 - acc: 0.7377 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4244  | total loss: \u001b[1m\u001b[32m1.55439\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4244 | loss: 1.55439 - acc: 0.6640 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4245  | total loss: \u001b[1m\u001b[32m1.44067\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4245 | loss: 1.44067 - acc: 0.6976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4246  | total loss: \u001b[1m\u001b[32m1.65838\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4246 | loss: 1.65838 - acc: 0.6349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4247  | total loss: \u001b[1m\u001b[32m1.53692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4247 | loss: 1.53692 - acc: 0.6715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4248  | total loss: \u001b[1m\u001b[32m1.42864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4248 | loss: 1.42864 - acc: 0.7043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4249  | total loss: \u001b[1m\u001b[32m1.33151\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4249 | loss: 1.33151 - acc: 0.7339 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4250  | total loss: \u001b[1m\u001b[32m1.55690\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4250 | loss: 1.55690 - acc: 0.6676 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4251  | total loss: \u001b[1m\u001b[32m1.44729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4251 | loss: 1.44729 - acc: 0.7009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4252  | total loss: \u001b[1m\u001b[32m1.65226\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4252 | loss: 1.65226 - acc: 0.6379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4253  | total loss: \u001b[1m\u001b[32m1.53409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4253 | loss: 1.53409 - acc: 0.6741 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4254  | total loss: \u001b[1m\u001b[32m1.73920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4254 | loss: 1.73920 - acc: 0.6067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4255  | total loss: \u001b[1m\u001b[32m1.61403\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4255 | loss: 1.61403 - acc: 0.6460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4256  | total loss: \u001b[1m\u001b[32m1.50201\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4256 | loss: 1.50201 - acc: 0.6814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4257  | total loss: \u001b[1m\u001b[32m1.40114\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4257 | loss: 1.40114 - acc: 0.7133 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4258  | total loss: \u001b[1m\u001b[32m1.54318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4258 | loss: 1.54318 - acc: 0.6634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4259  | total loss: \u001b[1m\u001b[32m1.43759\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4259 | loss: 1.43759 - acc: 0.6971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4260  | total loss: \u001b[1m\u001b[32m1.62109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4260 | loss: 1.62109 - acc: 0.6345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4261  | total loss: \u001b[1m\u001b[32m1.50764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4261 | loss: 1.50764 - acc: 0.6710 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4262  | total loss: \u001b[1m\u001b[32m1.71629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4262 | loss: 1.71629 - acc: 0.6039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4263  | total loss: \u001b[1m\u001b[32m1.59396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4263 | loss: 1.59396 - acc: 0.6435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4264  | total loss: \u001b[1m\u001b[32m1.78616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4264 | loss: 1.78616 - acc: 0.5863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4265  | total loss: \u001b[1m\u001b[32m1.65811\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4265 | loss: 1.65811 - acc: 0.6277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4266  | total loss: \u001b[1m\u001b[32m1.54323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4266 | loss: 1.54323 - acc: 0.6649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4267  | total loss: \u001b[1m\u001b[32m1.43950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4267 | loss: 1.43950 - acc: 0.6984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4268  | total loss: \u001b[1m\u001b[32m1.34517\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4268 | loss: 1.34517 - acc: 0.7286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4269  | total loss: \u001b[1m\u001b[32m1.25879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4269 | loss: 1.25879 - acc: 0.7557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4270  | total loss: \u001b[1m\u001b[32m1.17912\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4270 | loss: 1.17912 - acc: 0.7802 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4271  | total loss: \u001b[1m\u001b[32m1.10513\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4271 | loss: 1.10513 - acc: 0.8021 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4272  | total loss: \u001b[1m\u001b[32m1.37801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4272 | loss: 1.37801 - acc: 0.7219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4273  | total loss: \u001b[1m\u001b[32m1.28050\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4273 | loss: 1.28050 - acc: 0.7497 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4274  | total loss: \u001b[1m\u001b[32m1.50563\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4274 | loss: 1.50563 - acc: 0.6819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4275  | total loss: \u001b[1m\u001b[32m1.39347\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4275 | loss: 1.39347 - acc: 0.7137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4276  | total loss: \u001b[1m\u001b[32m1.65311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4276 | loss: 1.65311 - acc: 0.6423 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4277  | total loss: \u001b[1m\u001b[32m1.52571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4277 | loss: 1.52571 - acc: 0.6781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4278  | total loss: \u001b[1m\u001b[32m1.76297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4278 | loss: 1.76297 - acc: 0.6103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4279  | total loss: \u001b[1m\u001b[32m1.62540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4279 | loss: 1.62540 - acc: 0.6493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4280  | total loss: \u001b[1m\u001b[32m1.50200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4280 | loss: 1.50200 - acc: 0.6843 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4281  | total loss: \u001b[1m\u001b[32m1.39087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4281 | loss: 1.39087 - acc: 0.7159 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4282  | total loss: \u001b[1m\u001b[32m1.29032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4282 | loss: 1.29032 - acc: 0.7443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4283  | total loss: \u001b[1m\u001b[32m1.19889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4283 | loss: 1.19889 - acc: 0.7699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4284  | total loss: \u001b[1m\u001b[32m1.45216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4284 | loss: 1.45216 - acc: 0.7000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4285  | total loss: \u001b[1m\u001b[32m1.34312\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4285 | loss: 1.34312 - acc: 0.7300 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4286  | total loss: \u001b[1m\u001b[32m1.24442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4286 | loss: 1.24442 - acc: 0.7570 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4287  | total loss: \u001b[1m\u001b[32m1.15468\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4287 | loss: 1.15468 - acc: 0.7813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4288  | total loss: \u001b[1m\u001b[32m1.35898\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4288 | loss: 1.35898 - acc: 0.7175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4289  | total loss: \u001b[1m\u001b[32m1.25634\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4289 | loss: 1.25634 - acc: 0.7457 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4290  | total loss: \u001b[1m\u001b[32m1.43333\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4290 | loss: 1.43333 - acc: 0.6926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4291  | total loss: \u001b[1m\u001b[32m1.32277\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4291 | loss: 1.32277 - acc: 0.7233 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4292  | total loss: \u001b[1m\u001b[32m1.56492\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4292 | loss: 1.56492 - acc: 0.6581 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4293  | total loss: \u001b[1m\u001b[32m1.44163\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4293 | loss: 1.44163 - acc: 0.6923 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4294  | total loss: \u001b[1m\u001b[32m1.67757\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4294 | loss: 1.67757 - acc: 0.6302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4295  | total loss: \u001b[1m\u001b[32m1.54446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4295 | loss: 1.54446 - acc: 0.6672 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4296  | total loss: \u001b[1m\u001b[32m1.42538\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4296 | loss: 1.42538 - acc: 0.7005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4297  | total loss: \u001b[1m\u001b[32m1.31846\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4297 | loss: 1.31846 - acc: 0.7304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4298  | total loss: \u001b[1m\u001b[32m1.56781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4298 | loss: 1.56781 - acc: 0.6574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4299  | total loss: \u001b[1m\u001b[32m1.44723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4299 | loss: 1.44723 - acc: 0.6917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4300  | total loss: \u001b[1m\u001b[32m1.63257\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4300 | loss: 1.63257 - acc: 0.6368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4301  | total loss: \u001b[1m\u001b[32m1.50692\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4301 | loss: 1.50692 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4302  | total loss: \u001b[1m\u001b[32m1.39443\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4302 | loss: 1.39443 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4303  | total loss: \u001b[1m\u001b[32m1.29330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4303 | loss: 1.29330 - acc: 0.7352 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4304  | total loss: \u001b[1m\u001b[32m1.54874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4304 | loss: 1.54874 - acc: 0.6617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4305  | total loss: \u001b[1m\u001b[32m1.43254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4305 | loss: 1.43254 - acc: 0.6955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4306  | total loss: \u001b[1m\u001b[32m1.62967\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4306 | loss: 1.62967 - acc: 0.6403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4307  | total loss: \u001b[1m\u001b[32m1.50659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4307 | loss: 1.50659 - acc: 0.6762 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4308  | total loss: \u001b[1m\u001b[32m1.39628\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 4308 | loss: 1.39628 - acc: 0.7086 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4309  | total loss: \u001b[1m\u001b[32m1.29694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4309 | loss: 1.29694 - acc: 0.7377 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4310  | total loss: \u001b[1m\u001b[32m1.53827\u001b[0m\u001b[0m | time: 0.024s\n",
      "| Adam | epoch: 4310 | loss: 1.53827 - acc: 0.6640 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4311  | total loss: \u001b[1m\u001b[32m1.42477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4311 | loss: 1.42477 - acc: 0.6976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4312  | total loss: \u001b[1m\u001b[32m1.32265\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4312 | loss: 1.32265 - acc: 0.7278 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4313  | total loss: \u001b[1m\u001b[32m1.23029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4313 | loss: 1.23029 - acc: 0.7550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4314  | total loss: \u001b[1m\u001b[32m1.14629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4314 | loss: 1.14629 - acc: 0.7795 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4315  | total loss: \u001b[1m\u001b[32m1.06943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4315 | loss: 1.06943 - acc: 0.8016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4316  | total loss: \u001b[1m\u001b[32m0.99872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4316 | loss: 0.99872 - acc: 0.8214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4317  | total loss: \u001b[1m\u001b[32m0.93331\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4317 | loss: 0.93331 - acc: 0.8393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4318  | total loss: \u001b[1m\u001b[32m0.87250\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4318 | loss: 0.87250 - acc: 0.8554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4319  | total loss: \u001b[1m\u001b[32m0.81572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4319 | loss: 0.81572 - acc: 0.8698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4320  | total loss: \u001b[1m\u001b[32m1.07053\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4320 | loss: 1.07053 - acc: 0.8043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4321  | total loss: \u001b[1m\u001b[32m0.99079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4321 | loss: 0.99079 - acc: 0.8238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4322  | total loss: \u001b[1m\u001b[32m0.91780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4322 | loss: 0.91780 - acc: 0.8415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4323  | total loss: \u001b[1m\u001b[32m0.85079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4323 | loss: 0.85079 - acc: 0.8573 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4324  | total loss: \u001b[1m\u001b[32m1.17569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4324 | loss: 1.17569 - acc: 0.7787 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4325  | total loss: \u001b[1m\u001b[32m1.08113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4325 | loss: 1.08113 - acc: 0.8008 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4326  | total loss: \u001b[1m\u001b[32m1.40426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4326 | loss: 1.40426 - acc: 0.7208 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4327  | total loss: \u001b[1m\u001b[32m1.28671\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4327 | loss: 1.28671 - acc: 0.7487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4328  | total loss: \u001b[1m\u001b[32m1.56077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4328 | loss: 1.56077 - acc: 0.6810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4329  | total loss: \u001b[1m\u001b[32m1.42880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4329 | loss: 1.42880 - acc: 0.7129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4330  | total loss: \u001b[1m\u001b[32m1.71855\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4330 | loss: 1.71855 - acc: 0.6416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4331  | total loss: \u001b[1m\u001b[32m1.57331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4331 | loss: 1.57331 - acc: 0.6774 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4332  | total loss: \u001b[1m\u001b[32m1.44396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4332 | loss: 1.44396 - acc: 0.7097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4333  | total loss: \u001b[1m\u001b[32m1.32850\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4333 | loss: 1.32850 - acc: 0.7387 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4334  | total loss: \u001b[1m\u001b[32m1.58324\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4334 | loss: 1.58324 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4335  | total loss: \u001b[1m\u001b[32m1.45590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4335 | loss: 1.45590 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4336  | total loss: \u001b[1m\u001b[32m1.34229\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4336 | loss: 1.34229 - acc: 0.7343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4337  | total loss: \u001b[1m\u001b[32m1.24061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4337 | loss: 1.24061 - acc: 0.7609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4338  | total loss: \u001b[1m\u001b[32m1.14922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4338 | loss: 1.14922 - acc: 0.7848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4339  | total loss: \u001b[1m\u001b[32m1.06670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4339 | loss: 1.06670 - acc: 0.8063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4340  | total loss: \u001b[1m\u001b[32m0.99183\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4340 | loss: 0.99183 - acc: 0.8257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4341  | total loss: \u001b[1m\u001b[32m0.92352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4341 | loss: 0.92352 - acc: 0.8431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4342  | total loss: \u001b[1m\u001b[32m1.22510\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4342 | loss: 1.22510 - acc: 0.7659 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4343  | total loss: \u001b[1m\u001b[32m1.13223\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4343 | loss: 1.13223 - acc: 0.7893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4344  | total loss: \u001b[1m\u001b[32m1.39184\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4344 | loss: 1.39184 - acc: 0.7247 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4345  | total loss: \u001b[1m\u001b[32m1.28240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4345 | loss: 1.28240 - acc: 0.7522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4346  | total loss: \u001b[1m\u001b[32m1.52515\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4346 | loss: 1.52515 - acc: 0.6841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4347  | total loss: \u001b[1m\u001b[32m1.40344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4347 | loss: 1.40344 - acc: 0.7157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4348  | total loss: \u001b[1m\u001b[32m1.29443\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4348 | loss: 1.29443 - acc: 0.7442 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4349  | total loss: \u001b[1m\u001b[32m1.19645\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4349 | loss: 1.19645 - acc: 0.7697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4350  | total loss: \u001b[1m\u001b[32m1.41788\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4350 | loss: 1.41788 - acc: 0.6999 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4351  | total loss: \u001b[1m\u001b[32m1.30806\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4351 | loss: 1.30806 - acc: 0.7299 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4352  | total loss: \u001b[1m\u001b[32m1.56023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4352 | loss: 1.56023 - acc: 0.6569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4353  | total loss: \u001b[1m\u001b[32m1.43775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4353 | loss: 1.43775 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4354  | total loss: \u001b[1m\u001b[32m1.67987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4354 | loss: 1.67987 - acc: 0.6221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4355  | total loss: \u001b[1m\u001b[32m1.54805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4355 | loss: 1.54805 - acc: 0.6599 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4356  | total loss: \u001b[1m\u001b[32m1.43071\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4356 | loss: 1.43071 - acc: 0.6939 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4357  | total loss: \u001b[1m\u001b[32m1.32585\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4357 | loss: 1.32585 - acc: 0.7245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4358  | total loss: \u001b[1m\u001b[32m1.57682\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4358 | loss: 1.57682 - acc: 0.6592 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4359  | total loss: \u001b[1m\u001b[32m1.45872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4359 | loss: 1.45872 - acc: 0.6933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4360  | total loss: \u001b[1m\u001b[32m1.69775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4360 | loss: 1.69775 - acc: 0.6240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4361  | total loss: \u001b[1m\u001b[32m1.56972\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4361 | loss: 1.56972 - acc: 0.6616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4362  | total loss: \u001b[1m\u001b[32m1.78965\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4362 | loss: 1.78965 - acc: 0.5954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4363  | total loss: \u001b[1m\u001b[32m1.65532\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4363 | loss: 1.65532 - acc: 0.6359 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4364  | total loss: \u001b[1m\u001b[32m1.82075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4364 | loss: 1.82075 - acc: 0.5866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4365  | total loss: \u001b[1m\u001b[32m1.68653\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4365 | loss: 1.68653 - acc: 0.6279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4366  | total loss: \u001b[1m\u001b[32m1.56696\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4366 | loss: 1.56696 - acc: 0.6651 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4367  | total loss: \u001b[1m\u001b[32m1.45985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4367 | loss: 1.45985 - acc: 0.6986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4368  | total loss: \u001b[1m\u001b[32m1.36325\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4368 | loss: 1.36325 - acc: 0.7287 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4369  | total loss: \u001b[1m\u001b[32m1.27552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4369 | loss: 1.27552 - acc: 0.7559 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4370  | total loss: \u001b[1m\u001b[32m1.44882\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4370 | loss: 1.44882 - acc: 0.7017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4371  | total loss: \u001b[1m\u001b[32m1.35070\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4371 | loss: 1.35070 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4372  | total loss: \u001b[1m\u001b[32m1.53376\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4372 | loss: 1.53376 - acc: 0.6727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4373  | total loss: \u001b[1m\u001b[32m1.42594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4373 | loss: 1.42594 - acc: 0.7054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4374  | total loss: \u001b[1m\u001b[32m1.32819\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4374 | loss: 1.32819 - acc: 0.7349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4375  | total loss: \u001b[1m\u001b[32m1.23906\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4375 | loss: 1.23906 - acc: 0.7614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4376  | total loss: \u001b[1m\u001b[32m1.15731\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4376 | loss: 1.15731 - acc: 0.7852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4377  | total loss: \u001b[1m\u001b[32m1.08188\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4377 | loss: 1.08188 - acc: 0.8067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4378  | total loss: \u001b[1m\u001b[32m1.34527\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4378 | loss: 1.34527 - acc: 0.7260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4379  | total loss: \u001b[1m\u001b[32m1.24820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4379 | loss: 1.24820 - acc: 0.7534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4380  | total loss: \u001b[1m\u001b[32m1.50418\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4380 | loss: 1.50418 - acc: 0.6852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4381  | total loss: \u001b[1m\u001b[32m1.39005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4381 | loss: 1.39005 - acc: 0.7167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4382  | total loss: \u001b[1m\u001b[32m1.28689\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4382 | loss: 1.28689 - acc: 0.7450 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4383  | total loss: \u001b[1m\u001b[32m1.19325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4383 | loss: 1.19325 - acc: 0.7705 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4384  | total loss: \u001b[1m\u001b[32m1.39834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4384 | loss: 1.39834 - acc: 0.7078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4385  | total loss: \u001b[1m\u001b[32m1.29223\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4385 | loss: 1.29223 - acc: 0.7370 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4386  | total loss: \u001b[1m\u001b[32m1.19618\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4386 | loss: 1.19618 - acc: 0.7633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4387  | total loss: \u001b[1m\u001b[32m1.10887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4387 | loss: 1.10887 - acc: 0.7870 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4388  | total loss: \u001b[1m\u001b[32m1.35231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4388 | loss: 1.35231 - acc: 0.7226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4389  | total loss: \u001b[1m\u001b[32m1.24817\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4389 | loss: 1.24817 - acc: 0.7503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4390  | total loss: \u001b[1m\u001b[32m1.49276\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4390 | loss: 1.49276 - acc: 0.6824 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4391  | total loss: \u001b[1m\u001b[32m1.37472\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4391 | loss: 1.37472 - acc: 0.7142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4392  | total loss: \u001b[1m\u001b[32m1.62783\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4392 | loss: 1.62783 - acc: 0.6499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4393  | total loss: \u001b[1m\u001b[32m1.49767\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4393 | loss: 1.49767 - acc: 0.6849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4394  | total loss: \u001b[1m\u001b[32m1.38124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4394 | loss: 1.38124 - acc: 0.7164 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4395  | total loss: \u001b[1m\u001b[32m1.27675\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4395 | loss: 1.27675 - acc: 0.7448 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4396  | total loss: \u001b[1m\u001b[32m1.18258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4396 | loss: 1.18258 - acc: 0.7703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4397  | total loss: \u001b[1m\u001b[32m1.09733\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4397 | loss: 1.09733 - acc: 0.7933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4398  | total loss: \u001b[1m\u001b[32m1.01978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4398 | loss: 1.01978 - acc: 0.8139 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4399  | total loss: \u001b[1m\u001b[32m0.94889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4399 | loss: 0.94889 - acc: 0.8325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4400  | total loss: \u001b[1m\u001b[32m0.88378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4400 | loss: 0.88378 - acc: 0.8493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4401  | total loss: \u001b[1m\u001b[32m0.82369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4401 | loss: 0.82369 - acc: 0.8644 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4402  | total loss: \u001b[1m\u001b[32m1.06852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4402 | loss: 1.06852 - acc: 0.7994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4403  | total loss: \u001b[1m\u001b[32m0.98761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4403 | loss: 0.98761 - acc: 0.8194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4404  | total loss: \u001b[1m\u001b[32m1.25572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4404 | loss: 1.25572 - acc: 0.7518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4405  | total loss: \u001b[1m\u001b[32m1.15510\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4405 | loss: 1.15510 - acc: 0.7766 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4406  | total loss: \u001b[1m\u001b[32m1.46284\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4406 | loss: 1.46284 - acc: 0.6989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4407  | total loss: \u001b[1m\u001b[32m1.34192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4407 | loss: 1.34192 - acc: 0.7290 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4408  | total loss: \u001b[1m\u001b[32m1.61985\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4408 | loss: 1.61985 - acc: 0.6561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4409  | total loss: \u001b[1m\u001b[32m1.48501\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4409 | loss: 1.48501 - acc: 0.6905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4410  | total loss: \u001b[1m\u001b[32m1.36465\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4410 | loss: 1.36465 - acc: 0.7215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4411  | total loss: \u001b[1m\u001b[32m1.25695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4411 | loss: 1.25695 - acc: 0.7493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4412  | total loss: \u001b[1m\u001b[32m1.53352\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4412 | loss: 1.53352 - acc: 0.6744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4413  | total loss: \u001b[1m\u001b[32m1.41051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4413 | loss: 1.41051 - acc: 0.7069 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4414  | total loss: \u001b[1m\u001b[32m1.30067\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4414 | loss: 1.30067 - acc: 0.7363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4415  | total loss: \u001b[1m\u001b[32m1.20226\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4415 | loss: 1.20226 - acc: 0.7626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4416  | total loss: \u001b[1m\u001b[32m1.11372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4416 | loss: 1.11372 - acc: 0.7864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4417  | total loss: \u001b[1m\u001b[32m1.03371\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4417 | loss: 1.03371 - acc: 0.8077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4418  | total loss: \u001b[1m\u001b[32m0.96106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4418 | loss: 0.96106 - acc: 0.8270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4419  | total loss: \u001b[1m\u001b[32m0.89474\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4419 | loss: 0.89474 - acc: 0.8443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4420  | total loss: \u001b[1m\u001b[32m1.12236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4420 | loss: 1.12236 - acc: 0.7813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4421  | total loss: \u001b[1m\u001b[32m1.03842\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4421 | loss: 1.03842 - acc: 0.8031 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4422  | total loss: \u001b[1m\u001b[32m0.96227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4422 | loss: 0.96227 - acc: 0.8228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4423  | total loss: \u001b[1m\u001b[32m0.89292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4423 | loss: 0.89292 - acc: 0.8405 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4424  | total loss: \u001b[1m\u001b[32m1.19421\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4424 | loss: 1.19421 - acc: 0.7565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4425  | total loss: \u001b[1m\u001b[32m1.10071\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4425 | loss: 1.10071 - acc: 0.7808 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4426  | total loss: \u001b[1m\u001b[32m1.01634\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4426 | loss: 1.01634 - acc: 0.8028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4427  | total loss: \u001b[1m\u001b[32m0.93996\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4427 | loss: 0.93996 - acc: 0.8225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4428  | total loss: \u001b[1m\u001b[32m0.87055\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4428 | loss: 0.87055 - acc: 0.8402 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4429  | total loss: \u001b[1m\u001b[32m0.80725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4429 | loss: 0.80725 - acc: 0.8562 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4430  | total loss: \u001b[1m\u001b[32m0.74930\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4430 | loss: 0.74930 - acc: 0.8706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4431  | total loss: \u001b[1m\u001b[32m0.69607\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4431 | loss: 0.69607 - acc: 0.8835 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4432  | total loss: \u001b[1m\u001b[32m0.64702\u001b[0m\u001b[0m | time: 0.024s\n",
      "| Adam | epoch: 4432 | loss: 0.64702 - acc: 0.8952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4433  | total loss: \u001b[1m\u001b[32m0.60169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4433 | loss: 0.60169 - acc: 0.9057 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4434  | total loss: \u001b[1m\u001b[32m0.95569\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4434 | loss: 0.95569 - acc: 0.8222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4435  | total loss: \u001b[1m\u001b[32m0.87805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4435 | loss: 0.87805 - acc: 0.8400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4436  | total loss: \u001b[1m\u001b[32m1.21341\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 4436 | loss: 1.21341 - acc: 0.7632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4437  | total loss: \u001b[1m\u001b[32m1.11004\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4437 | loss: 1.11004 - acc: 0.7868 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4438  | total loss: \u001b[1m\u001b[32m1.01724\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4438 | loss: 1.01724 - acc: 0.8082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4439  | total loss: \u001b[1m\u001b[32m0.93380\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4439 | loss: 0.93380 - acc: 0.8273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4440  | total loss: \u001b[1m\u001b[32m0.85859\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4440 | loss: 0.85859 - acc: 0.8446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4441  | total loss: \u001b[1m\u001b[32m0.79066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4441 | loss: 0.79066 - acc: 0.8601 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4442  | total loss: \u001b[1m\u001b[32m0.72914\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4442 | loss: 0.72914 - acc: 0.8741 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4443  | total loss: \u001b[1m\u001b[32m0.67327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4443 | loss: 0.67327 - acc: 0.8867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4444  | total loss: \u001b[1m\u001b[32m0.62241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4444 | loss: 0.62241 - acc: 0.8980 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4445  | total loss: \u001b[1m\u001b[32m0.57597\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4445 | loss: 0.57597 - acc: 0.9082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4446  | total loss: \u001b[1m\u001b[32m0.53348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4446 | loss: 0.53348 - acc: 0.9174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4447  | total loss: \u001b[1m\u001b[32m0.49449\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4447 | loss: 0.49449 - acc: 0.9257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4448  | total loss: \u001b[1m\u001b[32m0.88964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4448 | loss: 0.88964 - acc: 0.8403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4449  | total loss: \u001b[1m\u001b[32m0.81426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4449 | loss: 0.81426 - acc: 0.8562 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4450  | total loss: \u001b[1m\u001b[32m0.74629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4450 | loss: 0.74629 - acc: 0.8706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4451  | total loss: \u001b[1m\u001b[32m0.68492\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4451 | loss: 0.68492 - acc: 0.8835 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4452  | total loss: \u001b[1m\u001b[32m1.10854\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4452 | loss: 1.10854 - acc: 0.7952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4453  | total loss: \u001b[1m\u001b[32m1.01105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4453 | loss: 1.01105 - acc: 0.8157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4454  | total loss: \u001b[1m\u001b[32m1.38227\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4454 | loss: 1.38227 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4455  | total loss: \u001b[1m\u001b[32m1.25865\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4455 | loss: 1.25865 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4456  | total loss: \u001b[1m\u001b[32m1.14817\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4456 | loss: 1.14817 - acc: 0.7846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4457  | total loss: \u001b[1m\u001b[32m1.04935\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4457 | loss: 1.04935 - acc: 0.8062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4458  | total loss: \u001b[1m\u001b[32m1.34052\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4458 | loss: 1.34052 - acc: 0.7398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4459  | total loss: \u001b[1m\u001b[32m1.22400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4459 | loss: 1.22400 - acc: 0.7658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4460  | total loss: \u001b[1m\u001b[32m1.12003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4460 | loss: 1.12003 - acc: 0.7893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4461  | total loss: \u001b[1m\u001b[32m1.02711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4461 | loss: 1.02711 - acc: 0.8103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4462  | total loss: \u001b[1m\u001b[32m1.37352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4462 | loss: 1.37352 - acc: 0.7293 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4463  | total loss: \u001b[1m\u001b[32m1.25694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4463 | loss: 1.25694 - acc: 0.7564 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4464  | total loss: \u001b[1m\u001b[32m1.57637\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4464 | loss: 1.57637 - acc: 0.6807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4465  | total loss: \u001b[1m\u001b[32m1.44236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4465 | loss: 1.44236 - acc: 0.7127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4466  | total loss: \u001b[1m\u001b[32m1.32327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4466 | loss: 1.32327 - acc: 0.7414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4467  | total loss: \u001b[1m\u001b[32m1.21720\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4467 | loss: 1.21720 - acc: 0.7673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4468  | total loss: \u001b[1m\u001b[32m1.46532\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4468 | loss: 1.46532 - acc: 0.6977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4469  | total loss: \u001b[1m\u001b[32m1.34748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4469 | loss: 1.34748 - acc: 0.7279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4470  | total loss: \u001b[1m\u001b[32m1.24267\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4470 | loss: 1.24267 - acc: 0.7551 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4471  | total loss: \u001b[1m\u001b[32m1.14913\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4471 | loss: 1.14913 - acc: 0.7796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4472  | total loss: \u001b[1m\u001b[32m1.06527\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4472 | loss: 1.06527 - acc: 0.8016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4473  | total loss: \u001b[1m\u001b[32m0.98970\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4473 | loss: 0.98970 - acc: 0.8215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4474  | total loss: \u001b[1m\u001b[32m1.27184\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4474 | loss: 1.27184 - acc: 0.7465 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4475  | total loss: \u001b[1m\u001b[32m1.17569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4475 | loss: 1.17569 - acc: 0.7718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4476  | total loss: \u001b[1m\u001b[32m1.34492\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4476 | loss: 1.34492 - acc: 0.7304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4477  | total loss: \u001b[1m\u001b[32m1.24217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4477 | loss: 1.24217 - acc: 0.7573 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4478  | total loss: \u001b[1m\u001b[32m1.14988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4478 | loss: 1.14988 - acc: 0.7816 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4479  | total loss: \u001b[1m\u001b[32m1.06659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4479 | loss: 1.06659 - acc: 0.8034 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4480  | total loss: \u001b[1m\u001b[32m0.99107\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4480 | loss: 0.99107 - acc: 0.8231 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4481  | total loss: \u001b[1m\u001b[32m0.92224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4481 | loss: 0.92224 - acc: 0.8408 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4482  | total loss: \u001b[1m\u001b[32m1.11723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4482 | loss: 1.11723 - acc: 0.7853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4483  | total loss: \u001b[1m\u001b[32m1.03430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4483 | loss: 1.03430 - acc: 0.8067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4484  | total loss: \u001b[1m\u001b[32m1.31013\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4484 | loss: 1.31013 - acc: 0.7332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4485  | total loss: \u001b[1m\u001b[32m1.20760\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4485 | loss: 1.20760 - acc: 0.7599 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4486  | total loss: \u001b[1m\u001b[32m1.42335\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4486 | loss: 1.42335 - acc: 0.7053 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4487  | total loss: \u001b[1m\u001b[32m1.31025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4487 | loss: 1.31025 - acc: 0.7348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4488  | total loss: \u001b[1m\u001b[32m1.60167\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4488 | loss: 1.60167 - acc: 0.6613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4489  | total loss: \u001b[1m\u001b[32m1.47256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4489 | loss: 1.47256 - acc: 0.6952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4490  | total loss: \u001b[1m\u001b[32m1.35731\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4490 | loss: 1.35731 - acc: 0.7257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4491  | total loss: \u001b[1m\u001b[32m1.25410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4491 | loss: 1.25410 - acc: 0.7531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4492  | total loss: \u001b[1m\u001b[32m1.16129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4492 | loss: 1.16129 - acc: 0.7778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4493  | total loss: \u001b[1m\u001b[32m1.07745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4493 | loss: 1.07745 - acc: 0.8000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4494  | total loss: \u001b[1m\u001b[32m1.39097\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4494 | loss: 1.39097 - acc: 0.7200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4495  | total loss: \u001b[1m\u001b[32m1.28400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4495 | loss: 1.28400 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4496  | total loss: \u001b[1m\u001b[32m1.18781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4496 | loss: 1.18781 - acc: 0.7732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4497  | total loss: \u001b[1m\u001b[32m1.10094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4497 | loss: 1.10094 - acc: 0.7959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4498  | total loss: \u001b[1m\u001b[32m1.02213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4498 | loss: 1.02213 - acc: 0.8163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4499  | total loss: \u001b[1m\u001b[32m0.95028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4499 | loss: 0.95028 - acc: 0.8347 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4500  | total loss: \u001b[1m\u001b[32m1.28849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4500 | loss: 1.28849 - acc: 0.7512 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4501  | total loss: \u001b[1m\u001b[32m1.18888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4501 | loss: 1.18888 - acc: 0.7761 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4502  | total loss: \u001b[1m\u001b[32m1.46356\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4502 | loss: 1.46356 - acc: 0.7056 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4503  | total loss: \u001b[1m\u001b[32m1.34680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4503 | loss: 1.34680 - acc: 0.7351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4504  | total loss: \u001b[1m\u001b[32m1.60416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4504 | loss: 1.60416 - acc: 0.6615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4505  | total loss: \u001b[1m\u001b[32m1.47488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4505 | loss: 1.47488 - acc: 0.6954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4506  | total loss: \u001b[1m\u001b[32m1.35938\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4506 | loss: 1.35938 - acc: 0.7259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4507  | total loss: \u001b[1m\u001b[32m1.25583\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4507 | loss: 1.25583 - acc: 0.7533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4508  | total loss: \u001b[1m\u001b[32m1.16266\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4508 | loss: 1.16266 - acc: 0.7779 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4509  | total loss: \u001b[1m\u001b[32m1.07844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4509 | loss: 1.07844 - acc: 0.8001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4510  | total loss: \u001b[1m\u001b[32m1.34429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4510 | loss: 1.34429 - acc: 0.7273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4511  | total loss: \u001b[1m\u001b[32m1.24152\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4511 | loss: 1.24152 - acc: 0.7545 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4512  | total loss: \u001b[1m\u001b[32m1.49407\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4512 | loss: 1.49407 - acc: 0.6862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4513  | total loss: \u001b[1m\u001b[32m1.37715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4513 | loss: 1.37715 - acc: 0.7176 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4514  | total loss: \u001b[1m\u001b[32m1.27238\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4514 | loss: 1.27238 - acc: 0.7459 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4515  | total loss: \u001b[1m\u001b[32m1.17813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4515 | loss: 1.17813 - acc: 0.7713 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4516  | total loss: \u001b[1m\u001b[32m1.44342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4516 | loss: 1.44342 - acc: 0.7013 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4517  | total loss: \u001b[1m\u001b[32m1.33236\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4517 | loss: 1.33236 - acc: 0.7312 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4518  | total loss: \u001b[1m\u001b[32m1.23261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4518 | loss: 1.23261 - acc: 0.7580 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4519  | total loss: \u001b[1m\u001b[32m1.14264\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4519 | loss: 1.14264 - acc: 0.7822 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4520  | total loss: \u001b[1m\u001b[32m1.06110\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4520 | loss: 1.06110 - acc: 0.8040 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4521  | total loss: \u001b[1m\u001b[32m0.98684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4521 | loss: 0.98684 - acc: 0.8236 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4522  | total loss: \u001b[1m\u001b[32m1.27336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4522 | loss: 1.27336 - acc: 0.7484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4523  | total loss: \u001b[1m\u001b[32m1.17666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4523 | loss: 1.17666 - acc: 0.7736 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4524  | total loss: \u001b[1m\u001b[32m1.40339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4524 | loss: 1.40339 - acc: 0.7033 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4525  | total loss: \u001b[1m\u001b[32m1.29381\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4525 | loss: 1.29381 - acc: 0.7330 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4526  | total loss: \u001b[1m\u001b[32m1.52338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4526 | loss: 1.52338 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4527  | total loss: \u001b[1m\u001b[32m1.40305\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4527 | loss: 1.40305 - acc: 0.7002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4528  | total loss: \u001b[1m\u001b[32m1.60176\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4528 | loss: 1.60176 - acc: 0.6444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4529  | total loss: \u001b[1m\u001b[32m1.47572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4529 | loss: 1.47572 - acc: 0.6800 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4530  | total loss: \u001b[1m\u001b[32m1.61573\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4530 | loss: 1.61573 - acc: 0.6406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4531  | total loss: \u001b[1m\u001b[32m1.49095\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4531 | loss: 1.49095 - acc: 0.6765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4532  | total loss: \u001b[1m\u001b[32m1.73469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4532 | loss: 1.73469 - acc: 0.6089 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4533  | total loss: \u001b[1m\u001b[32m1.60125\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4533 | loss: 1.60125 - acc: 0.6480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4534  | total loss: \u001b[1m\u001b[32m1.82515\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4534 | loss: 1.82515 - acc: 0.5832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4535  | total loss: \u001b[1m\u001b[32m1.68658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4535 | loss: 1.68658 - acc: 0.6249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4536  | total loss: \u001b[1m\u001b[32m1.56354\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4536 | loss: 1.56354 - acc: 0.6624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4537  | total loss: \u001b[1m\u001b[32m1.45371\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4537 | loss: 1.45371 - acc: 0.6961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4538  | total loss: \u001b[1m\u001b[32m1.66935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4538 | loss: 1.66935 - acc: 0.6337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4539  | total loss: \u001b[1m\u001b[32m1.55028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4539 | loss: 1.55028 - acc: 0.6703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4540  | total loss: \u001b[1m\u001b[32m1.44351\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4540 | loss: 1.44351 - acc: 0.7033 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4541  | total loss: \u001b[1m\u001b[32m1.34712\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4541 | loss: 1.34712 - acc: 0.7329 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4542  | total loss: \u001b[1m\u001b[32m1.47429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4542 | loss: 1.47429 - acc: 0.6882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4543  | total loss: \u001b[1m\u001b[32m1.37375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4543 | loss: 1.37375 - acc: 0.7194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4544  | total loss: \u001b[1m\u001b[32m1.28251\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4544 | loss: 1.28251 - acc: 0.7475 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4545  | total loss: \u001b[1m\u001b[32m1.19912\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4545 | loss: 1.19912 - acc: 0.7727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4546  | total loss: \u001b[1m\u001b[32m1.46617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4546 | loss: 1.46617 - acc: 0.6954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4547  | total loss: \u001b[1m\u001b[32m1.36231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4547 | loss: 1.36231 - acc: 0.7259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4548  | total loss: \u001b[1m\u001b[32m1.57845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4548 | loss: 1.57845 - acc: 0.6604 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4549  | total loss: \u001b[1m\u001b[32m1.46259\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4549 | loss: 1.46259 - acc: 0.6944 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4550  | total loss: \u001b[1m\u001b[32m1.69522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4550 | loss: 1.69522 - acc: 0.6250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4551  | total loss: \u001b[1m\u001b[32m1.56801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4551 | loss: 1.56801 - acc: 0.6625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4552  | total loss: \u001b[1m\u001b[32m1.77624\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4552 | loss: 1.77624 - acc: 0.6034 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4553  | total loss: \u001b[1m\u001b[32m1.64210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4553 | loss: 1.64210 - acc: 0.6430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4554  | total loss: \u001b[1m\u001b[32m1.52180\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4554 | loss: 1.52180 - acc: 0.6787 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4555  | total loss: \u001b[1m\u001b[32m1.41334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4555 | loss: 1.41334 - acc: 0.7109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4556  | total loss: \u001b[1m\u001b[32m1.59123\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4556 | loss: 1.59123 - acc: 0.6541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4557  | total loss: \u001b[1m\u001b[32m1.47544\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4557 | loss: 1.47544 - acc: 0.6886 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4558  | total loss: \u001b[1m\u001b[32m1.68968\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4558 | loss: 1.68968 - acc: 0.6198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4559  | total loss: \u001b[1m\u001b[32m1.56473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4559 | loss: 1.56473 - acc: 0.6578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4560  | total loss: \u001b[1m\u001b[32m1.45258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4560 | loss: 1.45258 - acc: 0.6920 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4561  | total loss: \u001b[1m\u001b[32m1.35135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4561 | loss: 1.35135 - acc: 0.7228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4562  | total loss: \u001b[1m\u001b[32m1.54414\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4562 | loss: 1.54414 - acc: 0.6648 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4563  | total loss: \u001b[1m\u001b[32m1.43311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4563 | loss: 1.43311 - acc: 0.6983 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4564  | total loss: \u001b[1m\u001b[32m1.33280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4564 | loss: 1.33280 - acc: 0.7285 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4565  | total loss: \u001b[1m\u001b[32m1.24163\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4565 | loss: 1.24163 - acc: 0.7557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4566  | total loss: \u001b[1m\u001b[32m1.48863\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4566 | loss: 1.48863 - acc: 0.6801 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4567  | total loss: \u001b[1m\u001b[32m1.38047\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4567 | loss: 1.38047 - acc: 0.7121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4568  | total loss: \u001b[1m\u001b[32m1.51803\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4568 | loss: 1.51803 - acc: 0.6694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4569  | total loss: \u001b[1m\u001b[32m1.40636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4569 | loss: 1.40636 - acc: 0.7025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4570  | total loss: \u001b[1m\u001b[32m1.60910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4570 | loss: 1.60910 - acc: 0.6394 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4571  | total loss: \u001b[1m\u001b[32m1.48840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4571 | loss: 1.48840 - acc: 0.6755 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4572  | total loss: \u001b[1m\u001b[32m1.70613\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4572 | loss: 1.70613 - acc: 0.6151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4573  | total loss: \u001b[1m\u001b[32m1.57668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4573 | loss: 1.57668 - acc: 0.6535 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4574  | total loss: \u001b[1m\u001b[32m1.79694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4574 | loss: 1.79694 - acc: 0.5882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4575  | total loss: \u001b[1m\u001b[32m1.66020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4575 | loss: 1.66020 - acc: 0.6294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4576  | total loss: \u001b[1m\u001b[32m1.53791\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4576 | loss: 1.53791 - acc: 0.6664 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4577  | total loss: \u001b[1m\u001b[32m1.42798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4577 | loss: 1.42798 - acc: 0.6998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4578  | total loss: \u001b[1m\u001b[32m1.66376\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4578 | loss: 1.66376 - acc: 0.6298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4579  | total loss: \u001b[1m\u001b[32m1.54159\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4579 | loss: 1.54159 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4580  | total loss: \u001b[1m\u001b[32m1.69921\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4580 | loss: 1.69921 - acc: 0.6216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4581  | total loss: \u001b[1m\u001b[32m1.57449\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4581 | loss: 1.57449 - acc: 0.6594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4582  | total loss: \u001b[1m\u001b[32m1.71931\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4582 | loss: 1.71931 - acc: 0.6078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4583  | total loss: \u001b[1m\u001b[32m1.59374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4583 | loss: 1.59374 - acc: 0.6470 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4584  | total loss: \u001b[1m\u001b[32m1.75992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4584 | loss: 1.75992 - acc: 0.5966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4585  | total loss: \u001b[1m\u001b[32m1.63162\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4585 | loss: 1.63162 - acc: 0.6369 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4586  | total loss: \u001b[1m\u001b[32m1.81736\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4586 | loss: 1.81736 - acc: 0.5804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4587  | total loss: \u001b[1m\u001b[32m1.68482\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4587 | loss: 1.68482 - acc: 0.6223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4588  | total loss: \u001b[1m\u001b[32m1.85728\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4588 | loss: 1.85728 - acc: 0.5672 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4589  | total loss: \u001b[1m\u001b[32m1.72244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4589 | loss: 1.72244 - acc: 0.6105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4590  | total loss: \u001b[1m\u001b[32m1.89736\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4590 | loss: 1.89736 - acc: 0.5566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4591  | total loss: \u001b[1m\u001b[32m1.76046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4591 | loss: 1.76046 - acc: 0.6009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4592  | total loss: \u001b[1m\u001b[32m1.92004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4592 | loss: 1.92004 - acc: 0.5409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4593  | total loss: \u001b[1m\u001b[32m1.78314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4593 | loss: 1.78314 - acc: 0.5868 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4594  | total loss: \u001b[1m\u001b[32m1.89815\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4594 | loss: 1.89815 - acc: 0.5424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4595  | total loss: \u001b[1m\u001b[32m1.76556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4595 | loss: 1.76556 - acc: 0.5881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4596  | total loss: \u001b[1m\u001b[32m1.92469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4596 | loss: 1.92469 - acc: 0.5293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4597  | total loss: \u001b[1m\u001b[32m1.79135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4597 | loss: 1.79135 - acc: 0.5764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4598  | total loss: \u001b[1m\u001b[32m1.91034\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4598 | loss: 1.91034 - acc: 0.5330 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4599  | total loss: \u001b[1m\u001b[32m1.78013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4599 | loss: 1.78013 - acc: 0.5797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4600  | total loss: \u001b[1m\u001b[32m1.66322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4600 | loss: 1.66322 - acc: 0.6218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4601  | total loss: \u001b[1m\u001b[32m1.55748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4601 | loss: 1.55748 - acc: 0.6596 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4602  | total loss: \u001b[1m\u001b[32m1.75376\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 4602 | loss: 1.75376 - acc: 0.5936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4603  | total loss: \u001b[1m\u001b[32m1.63743\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4603 | loss: 1.63743 - acc: 0.6343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4604  | total loss: \u001b[1m\u001b[32m1.82342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4604 | loss: 1.82342 - acc: 0.5780 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4605  | total loss: \u001b[1m\u001b[32m1.69916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4605 | loss: 1.69916 - acc: 0.6202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4606  | total loss: \u001b[1m\u001b[32m1.88911\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4606 | loss: 1.88911 - acc: 0.5582 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4607  | total loss: \u001b[1m\u001b[32m1.75798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4607 | loss: 1.75798 - acc: 0.6023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4608  | total loss: \u001b[1m\u001b[32m1.63960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4608 | loss: 1.63960 - acc: 0.6421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4609  | total loss: \u001b[1m\u001b[32m1.53203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4609 | loss: 1.53203 - acc: 0.6779 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4610  | total loss: \u001b[1m\u001b[32m1.43361\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4610 | loss: 1.43361 - acc: 0.7101 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4611  | total loss: \u001b[1m\u001b[32m1.34295\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4611 | loss: 1.34295 - acc: 0.7391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4612  | total loss: \u001b[1m\u001b[32m1.25890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4612 | loss: 1.25890 - acc: 0.7652 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4613  | total loss: \u001b[1m\u001b[32m1.18049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4613 | loss: 1.18049 - acc: 0.7887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4614  | total loss: \u001b[1m\u001b[32m1.39575\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4614 | loss: 1.39575 - acc: 0.7169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4615  | total loss: \u001b[1m\u001b[32m1.29897\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4615 | loss: 1.29897 - acc: 0.7453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4616  | total loss: \u001b[1m\u001b[32m1.50758\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4616 | loss: 1.50758 - acc: 0.6779 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4617  | total loss: \u001b[1m\u001b[32m1.39676\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4617 | loss: 1.39676 - acc: 0.7101 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4618  | total loss: \u001b[1m\u001b[32m1.67059\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4618 | loss: 1.67059 - acc: 0.6391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4619  | total loss: \u001b[1m\u001b[32m1.54230\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4619 | loss: 1.54230 - acc: 0.6752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4620  | total loss: \u001b[1m\u001b[32m1.69424\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4620 | loss: 1.69424 - acc: 0.6291 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4621  | total loss: \u001b[1m\u001b[32m1.56363\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4621 | loss: 1.56363 - acc: 0.6662 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4622  | total loss: \u001b[1m\u001b[32m1.44605\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4622 | loss: 1.44605 - acc: 0.6996 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4623  | total loss: \u001b[1m\u001b[32m1.33976\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4623 | loss: 1.33976 - acc: 0.7296 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4624  | total loss: \u001b[1m\u001b[32m1.24327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4624 | loss: 1.24327 - acc: 0.7566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4625  | total loss: \u001b[1m\u001b[32m1.15526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4625 | loss: 1.15526 - acc: 0.7810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4626  | total loss: \u001b[1m\u001b[32m1.07462\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4626 | loss: 1.07462 - acc: 0.8029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4627  | total loss: \u001b[1m\u001b[32m1.00041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4627 | loss: 1.00041 - acc: 0.8226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4628  | total loss: \u001b[1m\u001b[32m1.30748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4628 | loss: 1.30748 - acc: 0.7403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4629  | total loss: \u001b[1m\u001b[32m1.20762\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4629 | loss: 1.20762 - acc: 0.7663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4630  | total loss: \u001b[1m\u001b[32m1.11689\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4630 | loss: 1.11689 - acc: 0.7897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4631  | total loss: \u001b[1m\u001b[32m1.03417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4631 | loss: 1.03417 - acc: 0.8107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4632  | total loss: \u001b[1m\u001b[32m1.25810\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4632 | loss: 1.25810 - acc: 0.7511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4633  | total loss: \u001b[1m\u001b[32m1.15964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4633 | loss: 1.15964 - acc: 0.7760 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4634  | total loss: \u001b[1m\u001b[32m1.07040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4634 | loss: 1.07040 - acc: 0.7984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4635  | total loss: \u001b[1m\u001b[32m0.98929\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4635 | loss: 0.98929 - acc: 0.8185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4636  | total loss: \u001b[1m\u001b[32m0.91531\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4636 | loss: 0.91531 - acc: 0.8367 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4637  | total loss: \u001b[1m\u001b[32m0.84763\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4637 | loss: 0.84763 - acc: 0.8530 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4638  | total loss: \u001b[1m\u001b[32m1.07616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4638 | loss: 1.07616 - acc: 0.7963 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4639  | total loss: \u001b[1m\u001b[32m0.99079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4639 | loss: 0.99079 - acc: 0.8166 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4640  | total loss: \u001b[1m\u001b[32m0.91337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4640 | loss: 0.91337 - acc: 0.8350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4641  | total loss: \u001b[1m\u001b[32m0.84299\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4641 | loss: 0.84299 - acc: 0.8515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4642  | total loss: \u001b[1m\u001b[32m0.77883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4642 | loss: 0.77883 - acc: 0.8663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4643  | total loss: \u001b[1m\u001b[32m0.72020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4643 | loss: 0.72020 - acc: 0.8797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4644  | total loss: \u001b[1m\u001b[32m1.09412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4644 | loss: 1.09412 - acc: 0.7917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4645  | total loss: \u001b[1m\u001b[32m1.00297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4645 | loss: 1.00297 - acc: 0.8126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4646  | total loss: \u001b[1m\u001b[32m1.30522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4646 | loss: 1.30522 - acc: 0.7384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4647  | total loss: \u001b[1m\u001b[32m1.19331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4647 | loss: 1.19331 - acc: 0.7646 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4648  | total loss: \u001b[1m\u001b[32m1.47171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4648 | loss: 1.47171 - acc: 0.6953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4649  | total loss: \u001b[1m\u001b[32m1.34458\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4649 | loss: 1.34458 - acc: 0.7258 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4650  | total loss: \u001b[1m\u001b[32m1.51765\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4650 | loss: 1.51765 - acc: 0.6818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4651  | total loss: \u001b[1m\u001b[32m1.38812\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4651 | loss: 1.38812 - acc: 0.7136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4652  | total loss: \u001b[1m\u001b[32m1.62898\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4652 | loss: 1.62898 - acc: 0.6565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4653  | total loss: \u001b[1m\u001b[32m1.49129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4653 | loss: 1.49129 - acc: 0.6909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4654  | total loss: \u001b[1m\u001b[32m1.69211\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4654 | loss: 1.69211 - acc: 0.6361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4655  | total loss: \u001b[1m\u001b[32m1.55195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4655 | loss: 1.55195 - acc: 0.6724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4656  | total loss: \u001b[1m\u001b[32m1.76558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4656 | loss: 1.76558 - acc: 0.6123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4657  | total loss: \u001b[1m\u001b[32m1.62266\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4657 | loss: 1.62266 - acc: 0.6511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4658  | total loss: \u001b[1m\u001b[32m1.49619\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4658 | loss: 1.49619 - acc: 0.6860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4659  | total loss: \u001b[1m\u001b[32m1.38397\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4659 | loss: 1.38397 - acc: 0.7174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4660  | total loss: \u001b[1m\u001b[32m1.61375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4660 | loss: 1.61375 - acc: 0.6528 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4661  | total loss: \u001b[1m\u001b[32m1.49263\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4661 | loss: 1.49263 - acc: 0.6875 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4662  | total loss: \u001b[1m\u001b[32m1.67229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4662 | loss: 1.67229 - acc: 0.6331 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4663  | total loss: \u001b[1m\u001b[32m1.54854\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4663 | loss: 1.54854 - acc: 0.6698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4664  | total loss: \u001b[1m\u001b[32m1.76327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4664 | loss: 1.76327 - acc: 0.6028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4665  | total loss: \u001b[1m\u001b[32m1.63409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4665 | loss: 1.63409 - acc: 0.6425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4666  | total loss: \u001b[1m\u001b[32m1.51939\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4666 | loss: 1.51939 - acc: 0.6782 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4667  | total loss: \u001b[1m\u001b[32m1.41695\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4667 | loss: 1.41695 - acc: 0.7104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4668  | total loss: \u001b[1m\u001b[32m1.65255\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4668 | loss: 1.65255 - acc: 0.6394 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4669  | total loss: \u001b[1m\u001b[32m1.53795\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4669 | loss: 1.53795 - acc: 0.6754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4670  | total loss: \u001b[1m\u001b[32m1.43514\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4670 | loss: 1.43514 - acc: 0.7079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4671  | total loss: \u001b[1m\u001b[32m1.34225\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4671 | loss: 1.34225 - acc: 0.7371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4672  | total loss: \u001b[1m\u001b[32m1.53658\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4672 | loss: 1.53658 - acc: 0.6777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4673  | total loss: \u001b[1m\u001b[32m1.43254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4673 | loss: 1.43254 - acc: 0.7099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4674  | total loss: \u001b[1m\u001b[32m1.59615\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4674 | loss: 1.59615 - acc: 0.6532 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4675  | total loss: \u001b[1m\u001b[32m1.48581\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4675 | loss: 1.48581 - acc: 0.6879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4676  | total loss: \u001b[1m\u001b[32m1.38615\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4676 | loss: 1.38615 - acc: 0.7191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4677  | total loss: \u001b[1m\u001b[32m1.29552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4677 | loss: 1.29552 - acc: 0.7472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4678  | total loss: \u001b[1m\u001b[32m1.21254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4678 | loss: 1.21254 - acc: 0.7725 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4679  | total loss: \u001b[1m\u001b[32m1.13603\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4679 | loss: 1.13603 - acc: 0.7952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4680  | total loss: \u001b[1m\u001b[32m1.31882\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4680 | loss: 1.31882 - acc: 0.7371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4681  | total loss: \u001b[1m\u001b[32m1.22834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4681 | loss: 1.22834 - acc: 0.7634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4682  | total loss: \u001b[1m\u001b[32m1.14538\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4682 | loss: 1.14538 - acc: 0.7871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4683  | total loss: \u001b[1m\u001b[32m1.06891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4683 | loss: 1.06891 - acc: 0.8084 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4684  | total loss: \u001b[1m\u001b[32m1.34595\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4684 | loss: 1.34595 - acc: 0.7347 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4685  | total loss: \u001b[1m\u001b[32m1.24655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4685 | loss: 1.24655 - acc: 0.7612 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4686  | total loss: \u001b[1m\u001b[32m1.47241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4686 | loss: 1.47241 - acc: 0.6994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4687  | total loss: \u001b[1m\u001b[32m1.35899\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4687 | loss: 1.35899 - acc: 0.7294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4688  | total loss: \u001b[1m\u001b[32m1.25634\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4688 | loss: 1.25634 - acc: 0.7565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4689  | total loss: \u001b[1m\u001b[32m1.16310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4689 | loss: 1.16310 - acc: 0.7808 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4690  | total loss: \u001b[1m\u001b[32m1.41907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4690 | loss: 1.41907 - acc: 0.7099 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4691  | total loss: \u001b[1m\u001b[32m1.30835\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4691 | loss: 1.30835 - acc: 0.7389 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4692  | total loss: \u001b[1m\u001b[32m1.20830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4692 | loss: 1.20830 - acc: 0.7650 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4693  | total loss: \u001b[1m\u001b[32m1.11757\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4693 | loss: 1.11757 - acc: 0.7885 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4694  | total loss: \u001b[1m\u001b[32m1.42631\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4694 | loss: 1.42631 - acc: 0.7097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4695  | total loss: \u001b[1m\u001b[32m1.31298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4695 | loss: 1.31298 - acc: 0.7387 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4696  | total loss: \u001b[1m\u001b[32m1.57196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4696 | loss: 1.57196 - acc: 0.6648 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4697  | total loss: \u001b[1m\u001b[32m1.44474\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4697 | loss: 1.44474 - acc: 0.6983 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4698  | total loss: \u001b[1m\u001b[32m1.68172\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4698 | loss: 1.68172 - acc: 0.6357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4699  | total loss: \u001b[1m\u001b[32m1.54527\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4699 | loss: 1.54527 - acc: 0.6721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4700  | total loss: \u001b[1m\u001b[32m1.42332\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4700 | loss: 1.42332 - acc: 0.7049 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4701  | total loss: \u001b[1m\u001b[32m1.31400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4701 | loss: 1.31400 - acc: 0.7344 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4702  | total loss: \u001b[1m\u001b[32m1.56464\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4702 | loss: 1.56464 - acc: 0.6681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4703  | total loss: \u001b[1m\u001b[32m1.44217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4703 | loss: 1.44217 - acc: 0.7013 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4704  | total loss: \u001b[1m\u001b[32m1.69580\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4704 | loss: 1.69580 - acc: 0.6312 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4705  | total loss: \u001b[1m\u001b[32m1.56225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4705 | loss: 1.56225 - acc: 0.6680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4706  | total loss: \u001b[1m\u001b[32m1.76820\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4706 | loss: 1.76820 - acc: 0.6084 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4707  | total loss: \u001b[1m\u001b[32m1.63028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4707 | loss: 1.63028 - acc: 0.6475 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4708  | total loss: \u001b[1m\u001b[32m1.83915\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4708 | loss: 1.83915 - acc: 0.5899 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4709  | total loss: \u001b[1m\u001b[32m1.69751\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4709 | loss: 1.69751 - acc: 0.6309 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4710  | total loss: \u001b[1m\u001b[32m1.57148\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4710 | loss: 1.57148 - acc: 0.6678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4711  | total loss: \u001b[1m\u001b[32m1.45883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4711 | loss: 1.45883 - acc: 0.7011 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4712  | total loss: \u001b[1m\u001b[32m1.66168\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4712 | loss: 1.66168 - acc: 0.6310 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4713  | total loss: \u001b[1m\u001b[32m1.54130\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4713 | loss: 1.54130 - acc: 0.6679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4714  | total loss: \u001b[1m\u001b[32m1.73659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4714 | loss: 1.73659 - acc: 0.6082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4715  | total loss: \u001b[1m\u001b[32m1.61052\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4715 | loss: 1.61052 - acc: 0.6474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4716  | total loss: \u001b[1m\u001b[32m1.49770\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4716 | loss: 1.49770 - acc: 0.6827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4717  | total loss: \u001b[1m\u001b[32m1.39614\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4717 | loss: 1.39614 - acc: 0.7144 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4718  | total loss: \u001b[1m\u001b[32m1.56050\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4718 | loss: 1.56050 - acc: 0.6572 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4719  | total loss: \u001b[1m\u001b[32m1.45226\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4719 | loss: 1.45226 - acc: 0.6915 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4720  | total loss: \u001b[1m\u001b[32m1.35445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4720 | loss: 1.35445 - acc: 0.7224 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4721  | total loss: \u001b[1m\u001b[32m1.26550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4721 | loss: 1.26550 - acc: 0.7501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4722  | total loss: \u001b[1m\u001b[32m1.18407\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4722 | loss: 1.18407 - acc: 0.7751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4723  | total loss: \u001b[1m\u001b[32m1.10904\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4723 | loss: 1.10904 - acc: 0.7976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4724  | total loss: \u001b[1m\u001b[32m1.03945\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4724 | loss: 1.03945 - acc: 0.8178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4725  | total loss: \u001b[1m\u001b[32m0.97455\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4725 | loss: 0.97455 - acc: 0.8361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4726  | total loss: \u001b[1m\u001b[32m1.27194\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4726 | loss: 1.27194 - acc: 0.7525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4727  | total loss: \u001b[1m\u001b[32m1.18030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4727 | loss: 1.18030 - acc: 0.7772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4728  | total loss: \u001b[1m\u001b[32m1.43524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4728 | loss: 1.43524 - acc: 0.7066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4729  | total loss: \u001b[1m\u001b[32m1.32563\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4729 | loss: 1.32563 - acc: 0.7360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4730  | total loss: \u001b[1m\u001b[32m1.54338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4730 | loss: 1.54338 - acc: 0.6767 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4731  | total loss: \u001b[1m\u001b[32m1.42255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4731 | loss: 1.42255 - acc: 0.7090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4732  | total loss: \u001b[1m\u001b[32m1.31364\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4732 | loss: 1.31364 - acc: 0.7381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4733  | total loss: \u001b[1m\u001b[32m1.21509\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4733 | loss: 1.21509 - acc: 0.7643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4734  | total loss: \u001b[1m\u001b[32m1.12558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4734 | loss: 1.12558 - acc: 0.7879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4735  | total loss: \u001b[1m\u001b[32m1.04394\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4735 | loss: 1.04394 - acc: 0.8091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4736  | total loss: \u001b[1m\u001b[32m1.29494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4736 | loss: 1.29494 - acc: 0.7424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4737  | total loss: \u001b[1m\u001b[32m1.19478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4737 | loss: 1.19478 - acc: 0.7682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4738  | total loss: \u001b[1m\u001b[32m1.10405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4738 | loss: 1.10405 - acc: 0.7914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4739  | total loss: \u001b[1m\u001b[32m1.02158\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4739 | loss: 1.02158 - acc: 0.8122 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4740  | total loss: \u001b[1m\u001b[32m0.94636\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4740 | loss: 0.94636 - acc: 0.8310 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4741  | total loss: \u001b[1m\u001b[32m0.87751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4741 | loss: 0.87751 - acc: 0.8479 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4742  | total loss: \u001b[1m\u001b[32m0.81429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4742 | loss: 0.81429 - acc: 0.8631 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4743  | total loss: \u001b[1m\u001b[32m0.75607\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4743 | loss: 0.75607 - acc: 0.8768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4744  | total loss: \u001b[1m\u001b[32m1.09675\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4744 | loss: 1.09675 - acc: 0.7963 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4745  | total loss: \u001b[1m\u001b[32m1.00852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4745 | loss: 1.00852 - acc: 0.8166 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4746  | total loss: \u001b[1m\u001b[32m1.36160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4746 | loss: 1.36160 - acc: 0.7350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4747  | total loss: \u001b[1m\u001b[32m1.24673\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4747 | loss: 1.24673 - acc: 0.7615 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4748  | total loss: \u001b[1m\u001b[32m1.44682\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4748 | loss: 1.44682 - acc: 0.7139 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4749  | total loss: \u001b[1m\u001b[32m1.32435\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4749 | loss: 1.32435 - acc: 0.7425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4750  | total loss: \u001b[1m\u001b[32m1.58433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4750 | loss: 1.58433 - acc: 0.6754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4751  | total loss: \u001b[1m\u001b[32m1.44992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4751 | loss: 1.44992 - acc: 0.7079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4752  | total loss: \u001b[1m\u001b[32m1.68060\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4752 | loss: 1.68060 - acc: 0.6514 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4753  | total loss: \u001b[1m\u001b[32m1.53932\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4753 | loss: 1.53932 - acc: 0.6862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4754  | total loss: \u001b[1m\u001b[32m1.79011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4754 | loss: 1.79011 - acc: 0.6176 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4755  | total loss: \u001b[1m\u001b[32m1.64158\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4755 | loss: 1.64158 - acc: 0.6558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4756  | total loss: \u001b[1m\u001b[32m1.50977\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4756 | loss: 1.50977 - acc: 0.6903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4757  | total loss: \u001b[1m\u001b[32m1.39252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4757 | loss: 1.39252 - acc: 0.7212 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4758  | total loss: \u001b[1m\u001b[32m1.60690\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4758 | loss: 1.60690 - acc: 0.6563 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4759  | total loss: \u001b[1m\u001b[32m1.48253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4759 | loss: 1.48253 - acc: 0.6906 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4760  | total loss: \u001b[1m\u001b[32m1.67952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4760 | loss: 1.67952 - acc: 0.6287 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4761  | total loss: \u001b[1m\u001b[32m1.55099\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4761 | loss: 1.55099 - acc: 0.6658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4762  | total loss: \u001b[1m\u001b[32m1.70454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4762 | loss: 1.70454 - acc: 0.6207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4763  | total loss: \u001b[1m\u001b[32m1.57677\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4763 | loss: 1.57677 - acc: 0.6586 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4764  | total loss: \u001b[1m\u001b[32m1.77360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4764 | loss: 1.77360 - acc: 0.5928 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4765  | total loss: \u001b[1m\u001b[32m1.64242\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4765 | loss: 1.64242 - acc: 0.6335 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4766  | total loss: \u001b[1m\u001b[32m1.79767\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4766 | loss: 1.79767 - acc: 0.5844 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4767  | total loss: \u001b[1m\u001b[32m1.66770\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4767 | loss: 1.66770 - acc: 0.6260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4768  | total loss: \u001b[1m\u001b[32m1.81110\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4768 | loss: 1.81110 - acc: 0.5777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4769  | total loss: \u001b[1m\u001b[32m1.68315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4769 | loss: 1.68315 - acc: 0.6199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4770  | total loss: \u001b[1m\u001b[32m1.83635\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4770 | loss: 1.83635 - acc: 0.5722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4771  | total loss: \u001b[1m\u001b[32m1.70894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4771 | loss: 1.70894 - acc: 0.6150 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4772  | total loss: \u001b[1m\u001b[32m1.84710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4772 | loss: 1.84710 - acc: 0.5606 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4773  | total loss: \u001b[1m\u001b[32m1.72137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4773 | loss: 1.72137 - acc: 0.6046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4774  | total loss: \u001b[1m\u001b[32m1.92753\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4774 | loss: 1.92753 - acc: 0.5441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4775  | total loss: \u001b[1m\u001b[32m1.79641\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4775 | loss: 1.79641 - acc: 0.5897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4776  | total loss: \u001b[1m\u001b[32m1.93112\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4776 | loss: 1.93112 - acc: 0.5379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4777  | total loss: \u001b[1m\u001b[32m1.80215\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4777 | loss: 1.80215 - acc: 0.5841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4778  | total loss: \u001b[1m\u001b[32m1.90238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4778 | loss: 1.90238 - acc: 0.5471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4779  | total loss: \u001b[1m\u001b[32m1.77809\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4779 | loss: 1.77809 - acc: 0.5924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4780  | total loss: \u001b[1m\u001b[32m1.94833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4780 | loss: 1.94833 - acc: 0.5403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4781  | total loss: \u001b[1m\u001b[32m1.82064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4781 | loss: 1.82064 - acc: 0.5863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4782  | total loss: \u001b[1m\u001b[32m1.98355\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4782 | loss: 1.98355 - acc: 0.5276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4783  | total loss: \u001b[1m\u001b[32m1.85338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4783 | loss: 1.85338 - acc: 0.5749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4784  | total loss: \u001b[1m\u001b[32m1.73628\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4784 | loss: 1.73628 - acc: 0.6174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4785  | total loss: \u001b[1m\u001b[32m1.63010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4785 | loss: 1.63010 - acc: 0.6556 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4786  | total loss: \u001b[1m\u001b[32m1.75871\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4786 | loss: 1.75871 - acc: 0.6115 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4787  | total loss: \u001b[1m\u001b[32m1.64795\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4787 | loss: 1.64795 - acc: 0.6504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4788  | total loss: \u001b[1m\u001b[32m1.54675\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4788 | loss: 1.54675 - acc: 0.6853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4789  | total loss: \u001b[1m\u001b[32m1.45359\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4789 | loss: 1.45359 - acc: 0.7168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4790  | total loss: \u001b[1m\u001b[32m1.65190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4790 | loss: 1.65190 - acc: 0.6451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4791  | total loss: \u001b[1m\u001b[32m1.54437\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4791 | loss: 1.54437 - acc: 0.6806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4792  | total loss: \u001b[1m\u001b[32m1.44578\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4792 | loss: 1.44578 - acc: 0.7125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4793  | total loss: \u001b[1m\u001b[32m1.35480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4793 | loss: 1.35480 - acc: 0.7413 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4794  | total loss: \u001b[1m\u001b[32m1.58759\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4794 | loss: 1.58759 - acc: 0.6672 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4795  | total loss: \u001b[1m\u001b[32m1.47852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4795 | loss: 1.47852 - acc: 0.7004 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4796  | total loss: \u001b[1m\u001b[32m1.66910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4796 | loss: 1.66910 - acc: 0.6375 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4797  | total loss: \u001b[1m\u001b[32m1.54947\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4797 | loss: 1.54947 - acc: 0.6738 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4798  | total loss: \u001b[1m\u001b[32m1.44066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4798 | loss: 1.44066 - acc: 0.7064 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4799  | total loss: \u001b[1m\u001b[32m1.34120\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4799 | loss: 1.34120 - acc: 0.7358 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4800  | total loss: \u001b[1m\u001b[32m1.51102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4800 | loss: 1.51102 - acc: 0.6836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4801  | total loss: \u001b[1m\u001b[32m1.40170\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4801 | loss: 1.40170 - acc: 0.7153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4802  | total loss: \u001b[1m\u001b[32m1.59118\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4802 | loss: 1.59118 - acc: 0.6580 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4803  | total loss: \u001b[1m\u001b[32m1.47204\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4803 | loss: 1.47204 - acc: 0.6922 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4804  | total loss: \u001b[1m\u001b[32m1.36396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4804 | loss: 1.36396 - acc: 0.7230 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4805  | total loss: \u001b[1m\u001b[32m1.26552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4805 | loss: 1.26552 - acc: 0.7507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4806  | total loss: \u001b[1m\u001b[32m1.17548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4806 | loss: 1.17548 - acc: 0.7756 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4807  | total loss: \u001b[1m\u001b[32m1.09281\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4807 | loss: 1.09281 - acc: 0.7981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4808  | total loss: \u001b[1m\u001b[32m1.01662\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4808 | loss: 1.01662 - acc: 0.8183 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4809  | total loss: \u001b[1m\u001b[32m0.94614\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4809 | loss: 0.94614 - acc: 0.8364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4810  | total loss: \u001b[1m\u001b[32m1.25757\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4810 | loss: 1.25757 - acc: 0.7528 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4811  | total loss: \u001b[1m\u001b[32m1.16027\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4811 | loss: 1.16027 - acc: 0.7775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4812  | total loss: \u001b[1m\u001b[32m1.46031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4812 | loss: 1.46031 - acc: 0.6998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4813  | total loss: \u001b[1m\u001b[32m1.34193\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4813 | loss: 1.34193 - acc: 0.7298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4814  | total loss: \u001b[1m\u001b[32m1.52764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4814 | loss: 1.52764 - acc: 0.6782 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4815  | total loss: \u001b[1m\u001b[32m1.40292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4815 | loss: 1.40292 - acc: 0.7104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4816  | total loss: \u001b[1m\u001b[32m1.66273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4816 | loss: 1.66273 - acc: 0.6394 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4817  | total loss: \u001b[1m\u001b[32m1.52587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4817 | loss: 1.52587 - acc: 0.6754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4818  | total loss: \u001b[1m\u001b[32m1.40346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4818 | loss: 1.40346 - acc: 0.7079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4819  | total loss: \u001b[1m\u001b[32m1.29369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4819 | loss: 1.29369 - acc: 0.7371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4820  | total loss: \u001b[1m\u001b[32m1.52887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4820 | loss: 1.52887 - acc: 0.6705 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4821  | total loss: \u001b[1m\u001b[32m1.40751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4821 | loss: 1.40751 - acc: 0.7035 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4822  | total loss: \u001b[1m\u001b[32m1.66197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4822 | loss: 1.66197 - acc: 0.6331 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4823  | total loss: \u001b[1m\u001b[32m1.52931\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4823 | loss: 1.52931 - acc: 0.6698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4824  | total loss: \u001b[1m\u001b[32m1.41094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4824 | loss: 1.41094 - acc: 0.7028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4825  | total loss: \u001b[1m\u001b[32m1.30497\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4825 | loss: 1.30497 - acc: 0.7326 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4826  | total loss: \u001b[1m\u001b[32m1.52214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4826 | loss: 1.52214 - acc: 0.6664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4827  | total loss: \u001b[1m\u001b[32m1.40623\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4827 | loss: 1.40623 - acc: 0.6998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4828  | total loss: \u001b[1m\u001b[32m1.64771\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4828 | loss: 1.64771 - acc: 0.6298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4829  | total loss: \u001b[1m\u001b[32m1.52135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4829 | loss: 1.52135 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4830  | total loss: \u001b[1m\u001b[32m1.40861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4830 | loss: 1.40861 - acc: 0.7002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4831  | total loss: \u001b[1m\u001b[32m1.30756\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4831 | loss: 1.30756 - acc: 0.7301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4832  | total loss: \u001b[1m\u001b[32m1.53840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4832 | loss: 1.53840 - acc: 0.6643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4833  | total loss: \u001b[1m\u001b[32m1.42511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4833 | loss: 1.42511 - acc: 0.6978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4834  | total loss: \u001b[1m\u001b[32m1.65306\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4834 | loss: 1.65306 - acc: 0.6281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4835  | total loss: \u001b[1m\u001b[32m1.52986\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4835 | loss: 1.52986 - acc: 0.6652 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4836  | total loss: \u001b[1m\u001b[32m1.75708\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4836 | loss: 1.75708 - acc: 0.5987 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4837  | total loss: \u001b[1m\u001b[32m1.62570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4837 | loss: 1.62570 - acc: 0.6389 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4838  | total loss: \u001b[1m\u001b[32m1.79922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4838 | loss: 1.79922 - acc: 0.5821 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4839  | total loss: \u001b[1m\u001b[32m1.66620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4839 | loss: 1.66620 - acc: 0.6239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4840  | total loss: \u001b[1m\u001b[32m1.87264\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4840 | loss: 1.87264 - acc: 0.5687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4841  | total loss: \u001b[1m\u001b[32m1.73505\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4841 | loss: 1.73505 - acc: 0.6118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4842  | total loss: \u001b[1m\u001b[32m1.90029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4842 | loss: 1.90029 - acc: 0.5578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4843  | total loss: \u001b[1m\u001b[32m1.76289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4843 | loss: 1.76289 - acc: 0.6020 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4844  | total loss: \u001b[1m\u001b[32m1.64032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4844 | loss: 1.64032 - acc: 0.6418 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4845  | total loss: \u001b[1m\u001b[32m1.53030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4845 | loss: 1.53030 - acc: 0.6776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4846  | total loss: \u001b[1m\u001b[32m1.70916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4846 | loss: 1.70916 - acc: 0.6170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4847  | total loss: \u001b[1m\u001b[32m1.59233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4847 | loss: 1.59233 - acc: 0.6553 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4848  | total loss: \u001b[1m\u001b[32m1.74627\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4848 | loss: 1.74627 - acc: 0.5969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4849  | total loss: \u001b[1m\u001b[32m1.62607\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4849 | loss: 1.62607 - acc: 0.6372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4850  | total loss: \u001b[1m\u001b[32m1.51774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4850 | loss: 1.51774 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4851  | total loss: \u001b[1m\u001b[32m1.41944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4851 | loss: 1.41944 - acc: 0.7061 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4852  | total loss: \u001b[1m\u001b[32m1.63292\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4852 | loss: 1.63292 - acc: 0.6355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4853  | total loss: \u001b[1m\u001b[32m1.52146\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4853 | loss: 1.52146 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4854  | total loss: \u001b[1m\u001b[32m1.73164\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4854 | loss: 1.73164 - acc: 0.6048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4855  | total loss: \u001b[1m\u001b[32m1.60959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4855 | loss: 1.60959 - acc: 0.6443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4856  | total loss: \u001b[1m\u001b[32m1.81806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4856 | loss: 1.81806 - acc: 0.5799 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4857  | total loss: \u001b[1m\u001b[32m1.68735\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4857 | loss: 1.68735 - acc: 0.6219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4858  | total loss: \u001b[1m\u001b[32m1.80869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4858 | loss: 1.80869 - acc: 0.5811 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4859  | total loss: \u001b[1m\u001b[32m1.67927\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4859 | loss: 1.67927 - acc: 0.6230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4860  | total loss: \u001b[1m\u001b[32m1.85581\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4860 | loss: 1.85581 - acc: 0.5679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4861  | total loss: \u001b[1m\u001b[32m1.72234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4861 | loss: 1.72234 - acc: 0.6111 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4862  | total loss: \u001b[1m\u001b[32m1.89734\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4862 | loss: 1.89734 - acc: 0.5500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4863  | total loss: \u001b[1m\u001b[32m1.76076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4863 | loss: 1.76076 - acc: 0.5950 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4864  | total loss: \u001b[1m\u001b[32m1.87627\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4864 | loss: 1.87627 - acc: 0.5569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4865  | total loss: \u001b[1m\u001b[32m1.74293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4865 | loss: 1.74293 - acc: 0.6012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4866  | total loss: \u001b[1m\u001b[32m1.91058\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4866 | loss: 1.91058 - acc: 0.5482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4867  | total loss: \u001b[1m\u001b[32m1.77498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4867 | loss: 1.77498 - acc: 0.5934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4868  | total loss: \u001b[1m\u001b[32m1.90947\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4868 | loss: 1.90947 - acc: 0.5484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4869  | total loss: \u001b[1m\u001b[32m1.77518\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4869 | loss: 1.77518 - acc: 0.5935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4870  | total loss: \u001b[1m\u001b[32m1.93558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4870 | loss: 1.93558 - acc: 0.5413 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4871  | total loss: \u001b[1m\u001b[32m1.79984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4871 | loss: 1.79984 - acc: 0.5872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4872  | total loss: \u001b[1m\u001b[32m1.94117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4872 | loss: 1.94117 - acc: 0.5427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4873  | total loss: \u001b[1m\u001b[32m1.80610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4873 | loss: 1.80610 - acc: 0.5885 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4874  | total loss: \u001b[1m\u001b[32m1.95689\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4874 | loss: 1.95689 - acc: 0.5296 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4875  | total loss: \u001b[1m\u001b[32m1.82158\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4875 | loss: 1.82158 - acc: 0.5767 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4876  | total loss: \u001b[1m\u001b[32m2.01004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4876 | loss: 2.01004 - acc: 0.5190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4877  | total loss: \u001b[1m\u001b[32m1.87084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4877 | loss: 1.87084 - acc: 0.5671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4878  | total loss: \u001b[1m\u001b[32m1.99967\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4878 | loss: 1.99967 - acc: 0.5175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4879  | total loss: \u001b[1m\u001b[32m1.86292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4879 | loss: 1.86292 - acc: 0.5658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4880  | total loss: \u001b[1m\u001b[32m2.01021\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4880 | loss: 2.01021 - acc: 0.5092 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4881  | total loss: \u001b[1m\u001b[32m1.87385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4881 | loss: 1.87385 - acc: 0.5583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4882  | total loss: \u001b[1m\u001b[32m1.98982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4882 | loss: 1.98982 - acc: 0.5167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4883  | total loss: \u001b[1m\u001b[32m1.85682\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4883 | loss: 1.85682 - acc: 0.5651 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4884  | total loss: \u001b[1m\u001b[32m1.97301\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4884 | loss: 1.97301 - acc: 0.5157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4885  | total loss: \u001b[1m\u001b[32m1.84272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4885 | loss: 1.84272 - acc: 0.5641 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4886  | total loss: \u001b[1m\u001b[32m1.96938\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4886 | loss: 1.96938 - acc: 0.5220 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4887  | total loss: \u001b[1m\u001b[32m1.84016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4887 | loss: 1.84016 - acc: 0.5698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4888  | total loss: \u001b[1m\u001b[32m1.72373\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4888 | loss: 1.72373 - acc: 0.6128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4889  | total loss: \u001b[1m\u001b[32m1.61805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4889 | loss: 1.61805 - acc: 0.6515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4890  | total loss: \u001b[1m\u001b[32m1.52137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4890 | loss: 1.52137 - acc: 0.6864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4891  | total loss: \u001b[1m\u001b[32m1.43223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4891 | loss: 1.43223 - acc: 0.7177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4892  | total loss: \u001b[1m\u001b[32m1.34940\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4892 | loss: 1.34940 - acc: 0.7460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4893  | total loss: \u001b[1m\u001b[32m1.27185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4893 | loss: 1.27185 - acc: 0.7714 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4894  | total loss: \u001b[1m\u001b[32m1.47852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4894 | loss: 1.47852 - acc: 0.7014 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4895  | total loss: \u001b[1m\u001b[32m1.38268\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4895 | loss: 1.38268 - acc: 0.7312 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4896  | total loss: \u001b[1m\u001b[32m1.60674\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4896 | loss: 1.60674 - acc: 0.6581 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4897  | total loss: \u001b[1m\u001b[32m1.49442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4897 | loss: 1.49442 - acc: 0.6923 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4898  | total loss: \u001b[1m\u001b[32m1.39170\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4898 | loss: 1.39170 - acc: 0.7231 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4899  | total loss: \u001b[1m\u001b[32m1.29732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4899 | loss: 1.29732 - acc: 0.7508 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4900  | total loss: \u001b[1m\u001b[32m1.52230\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4900 | loss: 1.52230 - acc: 0.6828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4901  | total loss: \u001b[1m\u001b[32m1.41160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4901 | loss: 1.41160 - acc: 0.7146 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4902  | total loss: \u001b[1m\u001b[32m1.31058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4902 | loss: 1.31058 - acc: 0.7431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4903  | total loss: \u001b[1m\u001b[32m1.21801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4903 | loss: 1.21801 - acc: 0.7688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4904  | total loss: \u001b[1m\u001b[32m1.46365\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4904 | loss: 1.46365 - acc: 0.6919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4905  | total loss: \u001b[1m\u001b[32m1.35318\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4905 | loss: 1.35318 - acc: 0.7227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4906  | total loss: \u001b[1m\u001b[32m1.25274\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4906 | loss: 1.25274 - acc: 0.7504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4907  | total loss: \u001b[1m\u001b[32m1.16108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4907 | loss: 1.16108 - acc: 0.7754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4908  | total loss: \u001b[1m\u001b[32m1.43419\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4908 | loss: 1.43419 - acc: 0.6979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4909  | total loss: \u001b[1m\u001b[32m1.32258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4909 | loss: 1.32258 - acc: 0.7281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4910  | total loss: \u001b[1m\u001b[32m1.59304\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4910 | loss: 1.59304 - acc: 0.6553 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4911  | total loss: \u001b[1m\u001b[32m1.46529\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4911 | loss: 1.46529 - acc: 0.6897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4912  | total loss: \u001b[1m\u001b[32m1.35035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4912 | loss: 1.35035 - acc: 0.7208 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4913  | total loss: \u001b[1m\u001b[32m1.24659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4913 | loss: 1.24659 - acc: 0.7487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4914  | total loss: \u001b[1m\u001b[32m1.50654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4914 | loss: 1.50654 - acc: 0.6738 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4915  | total loss: \u001b[1m\u001b[32m1.38696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4915 | loss: 1.38696 - acc: 0.7064 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4916  | total loss: \u001b[1m\u001b[32m1.59322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4916 | loss: 1.59322 - acc: 0.6501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4917  | total loss: \u001b[1m\u001b[32m1.46582\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4917 | loss: 1.46582 - acc: 0.6851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4918  | total loss: \u001b[1m\u001b[32m1.35159\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4918 | loss: 1.35159 - acc: 0.7166 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4919  | total loss: \u001b[1m\u001b[32m1.24882\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4919 | loss: 1.24882 - acc: 0.7449 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4920  | total loss: \u001b[1m\u001b[32m1.15602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4920 | loss: 1.15602 - acc: 0.7704 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4921  | total loss: \u001b[1m\u001b[32m1.07188\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4921 | loss: 1.07188 - acc: 0.7934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4922  | total loss: \u001b[1m\u001b[32m1.37708\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4922 | loss: 1.37708 - acc: 0.7140 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4923  | total loss: \u001b[1m\u001b[32m1.27013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4923 | loss: 1.27013 - acc: 0.7426 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4924  | total loss: \u001b[1m\u001b[32m1.50231\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4924 | loss: 1.50231 - acc: 0.6827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4925  | total loss: \u001b[1m\u001b[32m1.38329\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4925 | loss: 1.38329 - acc: 0.7144 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4926  | total loss: \u001b[1m\u001b[32m1.59158\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4926 | loss: 1.59158 - acc: 0.6501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4927  | total loss: \u001b[1m\u001b[32m1.46493\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4927 | loss: 1.46493 - acc: 0.6851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4928  | total loss: \u001b[1m\u001b[32m1.64765\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4928 | loss: 1.64765 - acc: 0.6309 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4929  | total loss: \u001b[1m\u001b[32m1.51740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4929 | loss: 1.51740 - acc: 0.6678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4930  | total loss: \u001b[1m\u001b[32m1.40107\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4930 | loss: 1.40107 - acc: 0.7010 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4931  | total loss: \u001b[1m\u001b[32m1.29681\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4931 | loss: 1.29681 - acc: 0.7309 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4932  | total loss: \u001b[1m\u001b[32m1.20298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4932 | loss: 1.20298 - acc: 0.7578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4933  | total loss: \u001b[1m\u001b[32m1.11815\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4933 | loss: 1.11815 - acc: 0.7820 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4934  | total loss: \u001b[1m\u001b[32m1.04105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4934 | loss: 1.04105 - acc: 0.8038 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4935  | total loss: \u001b[1m\u001b[32m0.97062\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4935 | loss: 0.97062 - acc: 0.8234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4936  | total loss: \u001b[1m\u001b[32m1.28443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4936 | loss: 1.28443 - acc: 0.7411 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4937  | total loss: \u001b[1m\u001b[32m1.18830\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4937 | loss: 1.18830 - acc: 0.7670 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4938  | total loss: \u001b[1m\u001b[32m1.41464\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4938 | loss: 1.41464 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4939  | total loss: \u001b[1m\u001b[32m1.30557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4939 | loss: 1.30557 - acc: 0.7277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4940  | total loss: \u001b[1m\u001b[32m1.20752\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4940 | loss: 1.20752 - acc: 0.7549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4941  | total loss: \u001b[1m\u001b[32m1.11902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4941 | loss: 1.11902 - acc: 0.7794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4942  | total loss: \u001b[1m\u001b[32m1.03879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4942 | loss: 1.03879 - acc: 0.8015 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4943  | total loss: \u001b[1m\u001b[32m0.96571\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4943 | loss: 0.96571 - acc: 0.8213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4944  | total loss: \u001b[1m\u001b[32m1.22638\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4944 | loss: 1.22638 - acc: 0.7463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4945  | total loss: \u001b[1m\u001b[32m1.13339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4945 | loss: 1.13339 - acc: 0.7717 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4946  | total loss: \u001b[1m\u001b[32m1.04935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4946 | loss: 1.04935 - acc: 0.7945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4947  | total loss: \u001b[1m\u001b[32m0.97308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4947 | loss: 0.97308 - acc: 0.8151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4948  | total loss: \u001b[1m\u001b[32m1.29224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4948 | loss: 1.29224 - acc: 0.7336 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4949  | total loss: \u001b[1m\u001b[32m1.19105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4949 | loss: 1.19105 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4950  | total loss: \u001b[1m\u001b[32m1.09988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4950 | loss: 1.09988 - acc: 0.7842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4951  | total loss: \u001b[1m\u001b[32m1.01745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4951 | loss: 1.01745 - acc: 0.8058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4952  | total loss: \u001b[1m\u001b[32m1.31441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4952 | loss: 1.31441 - acc: 0.7252 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4953  | total loss: \u001b[1m\u001b[32m1.21019\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4953 | loss: 1.21019 - acc: 0.7527 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4954  | total loss: \u001b[1m\u001b[32m1.43875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4954 | loss: 1.43875 - acc: 0.6988 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4955  | total loss: \u001b[1m\u001b[32m1.32287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4955 | loss: 1.32287 - acc: 0.7290 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4956  | total loss: \u001b[1m\u001b[32m1.61308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4956 | loss: 1.61308 - acc: 0.6561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4957  | total loss: \u001b[1m\u001b[32m1.48161\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4957 | loss: 1.48161 - acc: 0.6905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4958  | total loss: \u001b[1m\u001b[32m1.73036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4958 | loss: 1.73036 - acc: 0.6214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4959  | total loss: \u001b[1m\u001b[32m1.59006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4959 | loss: 1.59006 - acc: 0.6593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4960  | total loss: \u001b[1m\u001b[32m1.46521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4960 | loss: 1.46521 - acc: 0.6933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4961  | total loss: \u001b[1m\u001b[32m1.35375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4961 | loss: 1.35375 - acc: 0.7240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4962  | total loss: \u001b[1m\u001b[32m1.25384\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4962 | loss: 1.25384 - acc: 0.7516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4963  | total loss: \u001b[1m\u001b[32m1.16387\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4963 | loss: 1.16387 - acc: 0.7764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4964  | total loss: \u001b[1m\u001b[32m1.41489\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4964 | loss: 1.41489 - acc: 0.7059 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4965  | total loss: \u001b[1m\u001b[32m1.30885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4965 | loss: 1.30885 - acc: 0.7353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4966  | total loss: \u001b[1m\u001b[32m1.21346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4966 | loss: 1.21346 - acc: 0.7618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4967  | total loss: \u001b[1m\u001b[32m1.12725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4967 | loss: 1.12725 - acc: 0.7856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4968  | total loss: \u001b[1m\u001b[32m1.04893\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4968 | loss: 1.04893 - acc: 0.8071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4969  | total loss: \u001b[1m\u001b[32m0.97741\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4969 | loss: 0.97741 - acc: 0.8264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4970  | total loss: \u001b[1m\u001b[32m1.22902\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4970 | loss: 1.22902 - acc: 0.7580 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4971  | total loss: \u001b[1m\u001b[32m1.13789\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4971 | loss: 1.13789 - acc: 0.7822 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4972  | total loss: \u001b[1m\u001b[32m1.41264\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4972 | loss: 1.41264 - acc: 0.7111 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4973  | total loss: \u001b[1m\u001b[32m1.30291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4973 | loss: 1.30291 - acc: 0.7400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4974  | total loss: \u001b[1m\u001b[32m1.51705\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4974 | loss: 1.51705 - acc: 0.6803 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4975  | total loss: \u001b[1m\u001b[32m1.39777\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4975 | loss: 1.39777 - acc: 0.7123 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 4976  | total loss: \u001b[1m\u001b[32m1.65529\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4976 | loss: 1.65529 - acc: 0.6410 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4977  | total loss: \u001b[1m\u001b[32m1.52402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4977 | loss: 1.52402 - acc: 0.6769 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4978  | total loss: \u001b[1m\u001b[32m1.75892\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4978 | loss: 1.75892 - acc: 0.6164 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4979  | total loss: \u001b[1m\u001b[32m1.61991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4979 | loss: 1.61991 - acc: 0.6548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4980  | total loss: \u001b[1m\u001b[32m1.79624\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4980 | loss: 1.79624 - acc: 0.5964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4981  | total loss: \u001b[1m\u001b[32m1.65661\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4981 | loss: 1.65661 - acc: 0.6368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4982  | total loss: \u001b[1m\u001b[32m1.53229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4982 | loss: 1.53229 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4983  | total loss: \u001b[1m\u001b[32m1.42116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4983 | loss: 1.42116 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4984  | total loss: \u001b[1m\u001b[32m1.60536\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4984 | loss: 1.60536 - acc: 0.6566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4985  | total loss: \u001b[1m\u001b[32m1.48796\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4985 | loss: 1.48796 - acc: 0.6910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4986  | total loss: \u001b[1m\u001b[32m1.65368\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4986 | loss: 1.65368 - acc: 0.6290 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4987  | total loss: \u001b[1m\u001b[32m1.53284\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4987 | loss: 1.53284 - acc: 0.6661 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4988  | total loss: \u001b[1m\u001b[32m1.71595\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4988 | loss: 1.71595 - acc: 0.6066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4989  | total loss: \u001b[1m\u001b[32m1.59076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4989 | loss: 1.59076 - acc: 0.6460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4990  | total loss: \u001b[1m\u001b[32m1.78887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4990 | loss: 1.78887 - acc: 0.5814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4991  | total loss: \u001b[1m\u001b[32m1.65890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4991 | loss: 1.65890 - acc: 0.6232 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4992  | total loss: \u001b[1m\u001b[32m1.54297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4992 | loss: 1.54297 - acc: 0.6609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4993  | total loss: \u001b[1m\u001b[32m1.43898\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4993 | loss: 1.43898 - acc: 0.6948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4994  | total loss: \u001b[1m\u001b[32m1.61960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4994 | loss: 1.61960 - acc: 0.6325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4995  | total loss: \u001b[1m\u001b[32m1.50831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4995 | loss: 1.50831 - acc: 0.6692 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4996  | total loss: \u001b[1m\u001b[32m1.71916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4996 | loss: 1.71916 - acc: 0.6023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4997  | total loss: \u001b[1m\u001b[32m1.59881\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 4997 | loss: 1.59881 - acc: 0.6421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4998  | total loss: \u001b[1m\u001b[32m1.77561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4998 | loss: 1.77561 - acc: 0.5850 -- iter: 14/14\n",
      "--\n",
      "Training Step: 4999  | total loss: \u001b[1m\u001b[32m1.65087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 4999 | loss: 1.65087 - acc: 0.6265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5000  | total loss: \u001b[1m\u001b[32m1.79210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5000 | loss: 1.79210 - acc: 0.5853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5001  | total loss: \u001b[1m\u001b[32m1.66691\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5001 | loss: 1.66691 - acc: 0.6268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5002  | total loss: \u001b[1m\u001b[32m1.55437\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5002 | loss: 1.55437 - acc: 0.6641 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5003  | total loss: \u001b[1m\u001b[32m1.45255\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5003 | loss: 1.45255 - acc: 0.6977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5004  | total loss: \u001b[1m\u001b[32m1.62413\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5004 | loss: 1.62413 - acc: 0.6351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5005  | total loss: \u001b[1m\u001b[32m1.51409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5005 | loss: 1.51409 - acc: 0.6715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5006  | total loss: \u001b[1m\u001b[32m1.41433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5006 | loss: 1.41433 - acc: 0.7044 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5007  | total loss: \u001b[1m\u001b[32m1.32329\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5007 | loss: 1.32329 - acc: 0.7340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5008  | total loss: \u001b[1m\u001b[32m1.55526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5008 | loss: 1.55526 - acc: 0.6606 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5009  | total loss: \u001b[1m\u001b[32m1.44782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5009 | loss: 1.44782 - acc: 0.6945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5010  | total loss: \u001b[1m\u001b[32m1.35004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5010 | loss: 1.35004 - acc: 0.7251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5011  | total loss: \u001b[1m\u001b[32m1.26051\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 5011 | loss: 1.26051 - acc: 0.7525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5012  | total loss: \u001b[1m\u001b[32m1.48211\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5012 | loss: 1.48211 - acc: 0.6844 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5013  | total loss: \u001b[1m\u001b[32m1.37675\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5013 | loss: 1.37675 - acc: 0.7160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5014  | total loss: \u001b[1m\u001b[32m1.28074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5014 | loss: 1.28074 - acc: 0.7444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5015  | total loss: \u001b[1m\u001b[32m1.19282\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 5015 | loss: 1.19282 - acc: 0.7700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5016  | total loss: \u001b[1m\u001b[32m1.39280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5016 | loss: 1.39280 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5017  | total loss: \u001b[1m\u001b[32m1.29111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5017 | loss: 1.29111 - acc: 0.7365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5018  | total loss: \u001b[1m\u001b[32m1.19850\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5018 | loss: 1.19850 - acc: 0.7629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5019  | total loss: \u001b[1m\u001b[32m1.11377\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 5019 | loss: 1.11377 - acc: 0.7866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5020  | total loss: \u001b[1m\u001b[32m1.36283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5020 | loss: 1.36283 - acc: 0.7079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5021  | total loss: \u001b[1m\u001b[32m1.25971\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5021 | loss: 1.25971 - acc: 0.7371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5022  | total loss: \u001b[1m\u001b[32m1.16621\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5022 | loss: 1.16621 - acc: 0.7634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5023  | total loss: \u001b[1m\u001b[32m1.08111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5023 | loss: 1.08111 - acc: 0.7871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5024  | total loss: \u001b[1m\u001b[32m1.00334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5024 | loss: 1.00334 - acc: 0.8084 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5025  | total loss: \u001b[1m\u001b[32m0.93199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5025 | loss: 0.93199 - acc: 0.8275 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5026  | total loss: \u001b[1m\u001b[32m1.24308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5026 | loss: 1.24308 - acc: 0.7448 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5027  | total loss: \u001b[1m\u001b[32m1.14589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5027 | loss: 1.14589 - acc: 0.7703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5028  | total loss: \u001b[1m\u001b[32m1.34396\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 5028 | loss: 1.34396 - acc: 0.7218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5029  | total loss: \u001b[1m\u001b[32m1.23608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5029 | loss: 1.23608 - acc: 0.7497 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5030  | total loss: \u001b[1m\u001b[32m1.55161\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5030 | loss: 1.55161 - acc: 0.6747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5031  | total loss: \u001b[1m\u001b[32m1.42346\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 5031 | loss: 1.42346 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5032  | total loss: \u001b[1m\u001b[32m1.59999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5032 | loss: 1.59999 - acc: 0.6579 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5033  | total loss: \u001b[1m\u001b[32m1.46854\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5033 | loss: 1.46854 - acc: 0.6921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5034  | total loss: \u001b[1m\u001b[32m1.35099\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5034 | loss: 1.35099 - acc: 0.7229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5035  | total loss: \u001b[1m\u001b[32m1.24558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5035 | loss: 1.24558 - acc: 0.7506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5036  | total loss: \u001b[1m\u001b[32m1.46109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5036 | loss: 1.46109 - acc: 0.6970 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5037  | total loss: \u001b[1m\u001b[32m1.34551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5037 | loss: 1.34551 - acc: 0.7273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5038  | total loss: \u001b[1m\u001b[32m1.24190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5038 | loss: 1.24190 - acc: 0.7546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5039  | total loss: \u001b[1m\u001b[32m1.14870\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5039 | loss: 1.14870 - acc: 0.7791 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5040  | total loss: \u001b[1m\u001b[32m1.06453\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5040 | loss: 1.06453 - acc: 0.8012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5041  | total loss: \u001b[1m\u001b[32m0.98818\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5041 | loss: 0.98818 - acc: 0.8211 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5042  | total loss: \u001b[1m\u001b[32m1.23097\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5042 | loss: 1.23097 - acc: 0.7533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5043  | total loss: \u001b[1m\u001b[32m1.13721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5043 | loss: 1.13721 - acc: 0.7779 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5044  | total loss: \u001b[1m\u001b[32m1.45026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5044 | loss: 1.45026 - acc: 0.7001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5045  | total loss: \u001b[1m\u001b[32m1.33517\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5045 | loss: 1.33517 - acc: 0.7301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5046  | total loss: \u001b[1m\u001b[32m1.23203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5046 | loss: 1.23203 - acc: 0.7571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5047  | total loss: \u001b[1m\u001b[32m1.13926\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5047 | loss: 1.13926 - acc: 0.7814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5048  | total loss: \u001b[1m\u001b[32m1.05548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5048 | loss: 1.05548 - acc: 0.8033 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5049  | total loss: \u001b[1m\u001b[32m0.97950\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5049 | loss: 0.97950 - acc: 0.8229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5050  | total loss: \u001b[1m\u001b[32m1.31594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5050 | loss: 1.31594 - acc: 0.7406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5051  | total loss: \u001b[1m\u001b[32m1.21333\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5051 | loss: 1.21333 - acc: 0.7666 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5052  | total loss: \u001b[1m\u001b[32m1.48805\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5052 | loss: 1.48805 - acc: 0.6899 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5053  | total loss: \u001b[1m\u001b[32m1.36902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5053 | loss: 1.36902 - acc: 0.7209 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5054  | total loss: \u001b[1m\u001b[32m1.26240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5054 | loss: 1.26240 - acc: 0.7488 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5055  | total loss: \u001b[1m\u001b[32m1.16655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5055 | loss: 1.16655 - acc: 0.7740 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5056  | total loss: \u001b[1m\u001b[32m1.41631\u001b[0m\u001b[0m | time: 0.028s\n",
      "| Adam | epoch: 5056 | loss: 1.41631 - acc: 0.7037 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5057  | total loss: \u001b[1m\u001b[32m1.30548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5057 | loss: 1.30548 - acc: 0.7333 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5058  | total loss: \u001b[1m\u001b[32m1.20598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5058 | loss: 1.20598 - acc: 0.7600 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5059  | total loss: \u001b[1m\u001b[32m1.11632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5059 | loss: 1.11632 - acc: 0.7840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5060  | total loss: \u001b[1m\u001b[32m1.35739\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5060 | loss: 1.35739 - acc: 0.7199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5061  | total loss: \u001b[1m\u001b[32m1.25258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5061 | loss: 1.25258 - acc: 0.7479 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5062  | total loss: \u001b[1m\u001b[32m1.15829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5062 | loss: 1.15829 - acc: 0.7731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5063  | total loss: \u001b[1m\u001b[32m1.07314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5063 | loss: 1.07314 - acc: 0.7958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5064  | total loss: \u001b[1m\u001b[32m0.99591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5064 | loss: 0.99591 - acc: 0.8162 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5065  | total loss: \u001b[1m\u001b[32m0.92555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5065 | loss: 0.92555 - acc: 0.8346 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5066  | total loss: \u001b[1m\u001b[32m1.24501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5066 | loss: 1.24501 - acc: 0.7511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5067  | total loss: \u001b[1m\u001b[32m1.14868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5067 | loss: 1.14868 - acc: 0.7760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5068  | total loss: \u001b[1m\u001b[32m1.41699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5068 | loss: 1.41699 - acc: 0.7056 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5069  | total loss: \u001b[1m\u001b[32m1.30380\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5069 | loss: 1.30380 - acc: 0.7350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5070  | total loss: \u001b[1m\u001b[32m1.54327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5070 | loss: 1.54327 - acc: 0.6686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5071  | total loss: \u001b[1m\u001b[32m1.41896\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5071 | loss: 1.41896 - acc: 0.7018 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5072  | total loss: \u001b[1m\u001b[32m1.67430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5072 | loss: 1.67430 - acc: 0.6316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5073  | total loss: \u001b[1m\u001b[32m1.53936\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5073 | loss: 1.53936 - acc: 0.6684 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5074  | total loss: \u001b[1m\u001b[32m1.41910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5074 | loss: 1.41910 - acc: 0.7016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5075  | total loss: \u001b[1m\u001b[32m1.31157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5075 | loss: 1.31157 - acc: 0.7314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5076  | total loss: \u001b[1m\u001b[32m1.58178\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5076 | loss: 1.58178 - acc: 0.6583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5077  | total loss: \u001b[1m\u001b[32m1.45951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5077 | loss: 1.45951 - acc: 0.6925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5078  | total loss: \u001b[1m\u001b[32m1.59853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5078 | loss: 1.59853 - acc: 0.6518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5079  | total loss: \u001b[1m\u001b[32m1.47665\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5079 | loss: 1.47665 - acc: 0.6866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5080  | total loss: \u001b[1m\u001b[32m1.67890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5080 | loss: 1.67890 - acc: 0.6251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5081  | total loss: \u001b[1m\u001b[32m1.55141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5081 | loss: 1.55141 - acc: 0.6626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5082  | total loss: \u001b[1m\u001b[32m1.77108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5082 | loss: 1.77108 - acc: 0.5963 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5083  | total loss: \u001b[1m\u001b[32m1.63737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5083 | loss: 1.63737 - acc: 0.6367 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5084  | total loss: \u001b[1m\u001b[32m1.82839\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5084 | loss: 1.82839 - acc: 0.5802 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5085  | total loss: \u001b[1m\u001b[32m1.69215\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5085 | loss: 1.69215 - acc: 0.6222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5086  | total loss: \u001b[1m\u001b[32m1.57072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5086 | loss: 1.57072 - acc: 0.6599 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5087  | total loss: \u001b[1m\u001b[32m1.46190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5087 | loss: 1.46190 - acc: 0.6939 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5088  | total loss: \u001b[1m\u001b[32m1.36379\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5088 | loss: 1.36379 - acc: 0.7245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5089  | total loss: \u001b[1m\u001b[32m1.27473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5089 | loss: 1.27473 - acc: 0.7521 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5090  | total loss: \u001b[1m\u001b[32m1.53829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5090 | loss: 1.53829 - acc: 0.6769 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5091  | total loss: \u001b[1m\u001b[32m1.43050\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5091 | loss: 1.43050 - acc: 0.7092 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5092  | total loss: \u001b[1m\u001b[32m1.65661\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5092 | loss: 1.65661 - acc: 0.6383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5093  | total loss: \u001b[1m\u001b[32m1.53687\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5093 | loss: 1.53687 - acc: 0.6744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5094  | total loss: \u001b[1m\u001b[32m1.68946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5094 | loss: 1.68946 - acc: 0.6284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5095  | total loss: \u001b[1m\u001b[32m1.56696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5095 | loss: 1.56696 - acc: 0.6656 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5096  | total loss: \u001b[1m\u001b[32m1.78382\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5096 | loss: 1.78382 - acc: 0.5990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5097  | total loss: \u001b[1m\u001b[32m1.65292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5097 | loss: 1.65292 - acc: 0.6391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5098  | total loss: \u001b[1m\u001b[32m1.78892\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5098 | loss: 1.78892 - acc: 0.5966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5099  | total loss: \u001b[1m\u001b[32m1.65888\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5099 | loss: 1.65888 - acc: 0.6370 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5100  | total loss: \u001b[1m\u001b[32m1.81176\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5100 | loss: 1.81176 - acc: 0.5876 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5101  | total loss: \u001b[1m\u001b[32m1.68091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5101 | loss: 1.68091 - acc: 0.6288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5102  | total loss: \u001b[1m\u001b[32m1.88794\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5102 | loss: 1.88794 - acc: 0.5659 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5103  | total loss: \u001b[1m\u001b[32m1.75116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5103 | loss: 1.75116 - acc: 0.6093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5104  | total loss: \u001b[1m\u001b[32m1.88442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5104 | loss: 1.88442 - acc: 0.5698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5105  | total loss: \u001b[1m\u001b[32m1.74973\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5105 | loss: 1.74973 - acc: 0.6128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5106  | total loss: \u001b[1m\u001b[32m1.62895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5106 | loss: 1.62895 - acc: 0.6516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5107  | total loss: \u001b[1m\u001b[32m1.52002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5107 | loss: 1.52002 - acc: 0.6864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5108  | total loss: \u001b[1m\u001b[32m1.42115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5108 | loss: 1.42115 - acc: 0.7178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5109  | total loss: \u001b[1m\u001b[32m1.33079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5109 | loss: 1.33079 - acc: 0.7460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5110  | total loss: \u001b[1m\u001b[32m1.53640\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5110 | loss: 1.53640 - acc: 0.6785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5111  | total loss: \u001b[1m\u001b[32m1.43197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5111 | loss: 1.43197 - acc: 0.7107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5112  | total loss: \u001b[1m\u001b[32m1.58287\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5112 | loss: 1.58287 - acc: 0.6539 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5113  | total loss: \u001b[1m\u001b[32m1.47223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5113 | loss: 1.47223 - acc: 0.6885 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5114  | total loss: \u001b[1m\u001b[32m1.68573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5114 | loss: 1.68573 - acc: 0.6197 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5115  | total loss: \u001b[1m\u001b[32m1.56415\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5115 | loss: 1.56415 - acc: 0.6577 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5116  | total loss: \u001b[1m\u001b[32m1.66315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5116 | loss: 1.66315 - acc: 0.6205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5117  | total loss: \u001b[1m\u001b[32m1.54355\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5117 | loss: 1.54355 - acc: 0.6584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5118  | total loss: \u001b[1m\u001b[32m1.71668\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5118 | loss: 1.71668 - acc: 0.6069 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5119  | total loss: \u001b[1m\u001b[32m1.59169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5119 | loss: 1.59169 - acc: 0.6462 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5120  | total loss: \u001b[1m\u001b[32m1.47904\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5120 | loss: 1.47904 - acc: 0.6816 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5121  | total loss: \u001b[1m\u001b[32m1.37700\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5121 | loss: 1.37700 - acc: 0.7134 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5122  | total loss: \u001b[1m\u001b[32m1.58305\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5122 | loss: 1.58305 - acc: 0.6492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5123  | total loss: \u001b[1m\u001b[32m1.46937\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5123 | loss: 1.46937 - acc: 0.6843 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5124  | total loss: \u001b[1m\u001b[32m1.63588\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5124 | loss: 1.63588 - acc: 0.6302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5125  | total loss: \u001b[1m\u001b[32m1.51638\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5125 | loss: 1.51638 - acc: 0.6671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5126  | total loss: \u001b[1m\u001b[32m1.72813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5126 | loss: 1.72813 - acc: 0.6004 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5127  | total loss: \u001b[1m\u001b[32m1.59954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5127 | loss: 1.59954 - acc: 0.6404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5128  | total loss: \u001b[1m\u001b[32m1.78349\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5128 | loss: 1.78349 - acc: 0.5763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5129  | total loss: \u001b[1m\u001b[32m1.65032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5129 | loss: 1.65032 - acc: 0.6187 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5130  | total loss: \u001b[1m\u001b[32m1.85745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5130 | loss: 1.85745 - acc: 0.5568 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5131  | total loss: \u001b[1m\u001b[32m1.71860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5131 | loss: 1.71860 - acc: 0.6012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5132  | total loss: \u001b[1m\u001b[32m1.59434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5132 | loss: 1.59434 - acc: 0.6410 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5133  | total loss: \u001b[1m\u001b[32m1.48260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5133 | loss: 1.48260 - acc: 0.6769 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5134  | total loss: \u001b[1m\u001b[32m1.38156\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5134 | loss: 1.38156 - acc: 0.7092 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5135  | total loss: \u001b[1m\u001b[32m1.28964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5135 | loss: 1.28964 - acc: 0.7383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5136  | total loss: \u001b[1m\u001b[32m1.20550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5136 | loss: 1.20550 - acc: 0.7645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5137  | total loss: \u001b[1m\u001b[32m1.12801\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5137 | loss: 1.12801 - acc: 0.7880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5138  | total loss: \u001b[1m\u001b[32m1.33851\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5138 | loss: 1.33851 - acc: 0.7235 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5139  | total loss: \u001b[1m\u001b[32m1.24467\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5139 | loss: 1.24467 - acc: 0.7512 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5140  | total loss: \u001b[1m\u001b[32m1.43079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5140 | loss: 1.43079 - acc: 0.6903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5141  | total loss: \u001b[1m\u001b[32m1.32589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5141 | loss: 1.32589 - acc: 0.7213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5142  | total loss: \u001b[1m\u001b[32m1.55577\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5142 | loss: 1.55577 - acc: 0.6563 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5143  | total loss: \u001b[1m\u001b[32m1.43766\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5143 | loss: 1.43766 - acc: 0.6907 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5144  | total loss: \u001b[1m\u001b[32m1.33108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5144 | loss: 1.33108 - acc: 0.7216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5145  | total loss: \u001b[1m\u001b[32m1.23450\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5145 | loss: 1.23450 - acc: 0.7495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5146  | total loss: \u001b[1m\u001b[32m1.47392\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5146 | loss: 1.47392 - acc: 0.6817 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5147  | total loss: \u001b[1m\u001b[32m1.36207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5147 | loss: 1.36207 - acc: 0.7135 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5148  | total loss: \u001b[1m\u001b[32m1.26102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5148 | loss: 1.26102 - acc: 0.7421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5149  | total loss: \u001b[1m\u001b[32m1.16935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5149 | loss: 1.16935 - acc: 0.7679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5150  | total loss: \u001b[1m\u001b[32m1.41592\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5150 | loss: 1.41592 - acc: 0.6983 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5151  | total loss: \u001b[1m\u001b[32m1.30774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5151 | loss: 1.30774 - acc: 0.7284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5152  | total loss: \u001b[1m\u001b[32m1.57319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5152 | loss: 1.57319 - acc: 0.6556 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5153  | total loss: \u001b[1m\u001b[32m1.44959\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5153 | loss: 1.44959 - acc: 0.6900 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5154  | total loss: \u001b[1m\u001b[32m1.67100\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5154 | loss: 1.67100 - acc: 0.6210 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5155  | total loss: \u001b[1m\u001b[32m1.53900\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5155 | loss: 1.53900 - acc: 0.6589 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5156  | total loss: \u001b[1m\u001b[32m1.42089\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5156 | loss: 1.42089 - acc: 0.6930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5157  | total loss: \u001b[1m\u001b[32m1.31479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5157 | loss: 1.31479 - acc: 0.7237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5158  | total loss: \u001b[1m\u001b[32m1.56138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5158 | loss: 1.56138 - acc: 0.6585 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5159  | total loss: \u001b[1m\u001b[32m1.44169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5159 | loss: 1.44169 - acc: 0.6927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5160  | total loss: \u001b[1m\u001b[32m1.66603\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5160 | loss: 1.66603 - acc: 0.6234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5161  | total loss: \u001b[1m\u001b[32m1.53721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5161 | loss: 1.53721 - acc: 0.6611 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5162  | total loss: \u001b[1m\u001b[32m1.75277\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5162 | loss: 1.75277 - acc: 0.6021 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5163  | total loss: \u001b[1m\u001b[32m1.61735\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5163 | loss: 1.61735 - acc: 0.6419 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5164  | total loss: \u001b[1m\u001b[32m1.49636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5164 | loss: 1.49636 - acc: 0.6777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5165  | total loss: \u001b[1m\u001b[32m1.38782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5165 | loss: 1.38782 - acc: 0.7099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5166  | total loss: \u001b[1m\u001b[32m1.56789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5166 | loss: 1.56789 - acc: 0.6604 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5167  | total loss: \u001b[1m\u001b[32m1.45249\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5167 | loss: 1.45249 - acc: 0.6943 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5168  | total loss: \u001b[1m\u001b[32m1.63560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5168 | loss: 1.63560 - acc: 0.6392 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5169  | total loss: \u001b[1m\u001b[32m1.51412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5169 | loss: 1.51412 - acc: 0.6753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5170  | total loss: \u001b[1m\u001b[32m1.40499\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5170 | loss: 1.40499 - acc: 0.7077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5171  | total loss: \u001b[1m\u001b[32m1.30650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5171 | loss: 1.30650 - acc: 0.7370 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5172  | total loss: \u001b[1m\u001b[32m1.51614\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5172 | loss: 1.51614 - acc: 0.6775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5173  | total loss: \u001b[1m\u001b[32m1.40599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5173 | loss: 1.40599 - acc: 0.7098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5174  | total loss: \u001b[1m\u001b[32m1.61642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5174 | loss: 1.61642 - acc: 0.6460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5175  | total loss: \u001b[1m\u001b[32m1.49647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5175 | loss: 1.49647 - acc: 0.6814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5176  | total loss: \u001b[1m\u001b[32m1.68732\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5176 | loss: 1.68732 - acc: 0.6204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5177  | total loss: \u001b[1m\u001b[32m1.56105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5177 | loss: 1.56105 - acc: 0.6583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5178  | total loss: \u001b[1m\u001b[32m1.44761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5178 | loss: 1.44761 - acc: 0.6925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5179  | total loss: \u001b[1m\u001b[32m1.34524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5179 | loss: 1.34524 - acc: 0.7232 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5180  | total loss: \u001b[1m\u001b[32m1.56751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5180 | loss: 1.56751 - acc: 0.6509 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5181  | total loss: \u001b[1m\u001b[32m1.45274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5181 | loss: 1.45274 - acc: 0.6858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5182  | total loss: \u001b[1m\u001b[32m1.34926\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5182 | loss: 1.34926 - acc: 0.7172 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5183  | total loss: \u001b[1m\u001b[32m1.25550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5183 | loss: 1.25550 - acc: 0.7455 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5184  | total loss: \u001b[1m\u001b[32m1.46522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5184 | loss: 1.46522 - acc: 0.6853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5185  | total loss: \u001b[1m\u001b[32m1.35877\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5185 | loss: 1.35877 - acc: 0.7167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5186  | total loss: \u001b[1m\u001b[32m1.26247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5186 | loss: 1.26247 - acc: 0.7451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5187  | total loss: \u001b[1m\u001b[32m1.17491\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5187 | loss: 1.17491 - acc: 0.7706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5188  | total loss: \u001b[1m\u001b[32m1.09491\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5188 | loss: 1.09491 - acc: 0.7935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5189  | total loss: \u001b[1m\u001b[32m1.02145\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5189 | loss: 1.02145 - acc: 0.8141 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5190  | total loss: \u001b[1m\u001b[32m0.95366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5190 | loss: 0.95366 - acc: 0.8327 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5191  | total loss: \u001b[1m\u001b[32m0.89084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5191 | loss: 0.89084 - acc: 0.8495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5192  | total loss: \u001b[1m\u001b[32m0.83238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5192 | loss: 0.83238 - acc: 0.8645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5193  | total loss: \u001b[1m\u001b[32m0.77781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5193 | loss: 0.77781 - acc: 0.8781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5194  | total loss: \u001b[1m\u001b[32m0.72672\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5194 | loss: 0.72672 - acc: 0.8903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5195  | total loss: \u001b[1m\u001b[32m0.67880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5195 | loss: 0.67880 - acc: 0.9012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5196  | total loss: \u001b[1m\u001b[32m1.03848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5196 | loss: 1.03848 - acc: 0.8111 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5197  | total loss: \u001b[1m\u001b[32m0.95668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5197 | loss: 0.95668 - acc: 0.8300 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5198  | total loss: \u001b[1m\u001b[32m0.88217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5198 | loss: 0.88217 - acc: 0.8470 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5199  | total loss: \u001b[1m\u001b[32m0.81414\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5199 | loss: 0.81414 - acc: 0.8623 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5200  | total loss: \u001b[1m\u001b[32m1.12326\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5200 | loss: 1.12326 - acc: 0.7832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5201  | total loss: \u001b[1m\u001b[32m1.02996\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5201 | loss: 1.02996 - acc: 0.8049 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5202  | total loss: \u001b[1m\u001b[32m1.34532\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5202 | loss: 1.34532 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5203  | total loss: \u001b[1m\u001b[32m1.22999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5203 | loss: 1.22999 - acc: 0.7584 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5204  | total loss: \u001b[1m\u001b[32m1.53450\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5204 | loss: 1.53450 - acc: 0.6897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5205  | total loss: \u001b[1m\u001b[32m1.40159\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5205 | loss: 1.40159 - acc: 0.7207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5206  | total loss: \u001b[1m\u001b[32m1.61963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5206 | loss: 1.61963 - acc: 0.6629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5207  | total loss: \u001b[1m\u001b[32m1.48049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5207 | loss: 1.48049 - acc: 0.6966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5208  | total loss: \u001b[1m\u001b[32m1.70425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5208 | loss: 1.70425 - acc: 0.6341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5209  | total loss: \u001b[1m\u001b[32m1.55977\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5209 | loss: 1.55977 - acc: 0.6707 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5210  | total loss: \u001b[1m\u001b[32m1.81531\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5210 | loss: 1.81531 - acc: 0.6036 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5211  | total loss: \u001b[1m\u001b[32m1.66379\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5211 | loss: 1.66379 - acc: 0.6433 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5212  | total loss: \u001b[1m\u001b[32m1.86440\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5212 | loss: 1.86440 - acc: 0.5861 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5213  | total loss: \u001b[1m\u001b[32m1.71282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5213 | loss: 1.71282 - acc: 0.6275 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5214  | total loss: \u001b[1m\u001b[32m1.85888\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5214 | loss: 1.85888 - acc: 0.5790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5215  | total loss: \u001b[1m\u001b[32m1.71301\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5215 | loss: 1.71301 - acc: 0.6211 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5216  | total loss: \u001b[1m\u001b[32m1.91242\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5216 | loss: 1.91242 - acc: 0.5590 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5217  | total loss: \u001b[1m\u001b[32m1.76658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5217 | loss: 1.76658 - acc: 0.6031 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5218  | total loss: \u001b[1m\u001b[32m1.63769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5218 | loss: 1.63769 - acc: 0.6428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5219  | total loss: \u001b[1m\u001b[32m1.52330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5219 | loss: 1.52330 - acc: 0.6785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5220  | total loss: \u001b[1m\u001b[32m1.73263\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5220 | loss: 1.73263 - acc: 0.6107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5221  | total loss: \u001b[1m\u001b[32m1.61145\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5221 | loss: 1.61145 - acc: 0.6496 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5222  | total loss: \u001b[1m\u001b[32m1.74232\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5222 | loss: 1.74232 - acc: 0.5989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5223  | total loss: \u001b[1m\u001b[32m1.62290\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5223 | loss: 1.62290 - acc: 0.6390 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5224  | total loss: \u001b[1m\u001b[32m1.79130\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5224 | loss: 1.79130 - acc: 0.5823 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5225  | total loss: \u001b[1m\u001b[32m1.66949\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5225 | loss: 1.66949 - acc: 0.6240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5226  | total loss: \u001b[1m\u001b[32m1.56064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5226 | loss: 1.56064 - acc: 0.6616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5227  | total loss: \u001b[1m\u001b[32m1.46267\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5227 | loss: 1.46267 - acc: 0.6955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5228  | total loss: \u001b[1m\u001b[32m1.64909\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5228 | loss: 1.64909 - acc: 0.6331 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5229  | total loss: \u001b[1m\u001b[32m1.54185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5229 | loss: 1.54185 - acc: 0.6698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5230  | total loss: \u001b[1m\u001b[32m1.44491\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5230 | loss: 1.44491 - acc: 0.7028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5231  | total loss: \u001b[1m\u001b[32m1.35658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5231 | loss: 1.35658 - acc: 0.7325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5232  | total loss: \u001b[1m\u001b[32m1.27543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5232 | loss: 1.27543 - acc: 0.7593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5233  | total loss: \u001b[1m\u001b[32m1.20028\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5233 | loss: 1.20028 - acc: 0.7833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5234  | total loss: \u001b[1m\u001b[32m1.13013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5234 | loss: 1.13013 - acc: 0.8050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5235  | total loss: \u001b[1m\u001b[32m1.06422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5235 | loss: 1.06422 - acc: 0.8245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5236  | total loss: \u001b[1m\u001b[32m1.00192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5236 | loss: 1.00192 - acc: 0.8420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5237  | total loss: \u001b[1m\u001b[32m0.94277\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5237 | loss: 0.94277 - acc: 0.8578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5238  | total loss: \u001b[1m\u001b[32m1.19560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5238 | loss: 1.19560 - acc: 0.7863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5239  | total loss: \u001b[1m\u001b[32m1.11211\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5239 | loss: 1.11211 - acc: 0.8077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5240  | total loss: \u001b[1m\u001b[32m1.03497\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5240 | loss: 1.03497 - acc: 0.8269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5241  | total loss: \u001b[1m\u001b[32m0.96345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5241 | loss: 0.96345 - acc: 0.8442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5242  | total loss: \u001b[1m\u001b[32m0.89696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5242 | loss: 0.89696 - acc: 0.8598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5243  | total loss: \u001b[1m\u001b[32m0.83500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5243 | loss: 0.83500 - acc: 0.8738 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5244  | total loss: \u001b[1m\u001b[32m0.77716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5244 | loss: 0.77716 - acc: 0.8865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5245  | total loss: \u001b[1m\u001b[32m0.72309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5245 | loss: 0.72309 - acc: 0.8978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5246  | total loss: \u001b[1m\u001b[32m1.05477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5246 | loss: 1.05477 - acc: 0.8152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5247  | total loss: \u001b[1m\u001b[32m0.97019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5247 | loss: 0.97019 - acc: 0.8337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5248  | total loss: \u001b[1m\u001b[32m1.27382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5248 | loss: 1.27382 - acc: 0.7574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5249  | total loss: \u001b[1m\u001b[32m1.16644\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5249 | loss: 1.16644 - acc: 0.7817 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5250  | total loss: \u001b[1m\u001b[32m1.06965\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5250 | loss: 1.06965 - acc: 0.8035 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5251  | total loss: \u001b[1m\u001b[32m0.98225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5251 | loss: 0.98225 - acc: 0.8232 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5252  | total loss: \u001b[1m\u001b[32m0.90317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5252 | loss: 0.90317 - acc: 0.8409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5253  | total loss: \u001b[1m\u001b[32m0.83147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5253 | loss: 0.83147 - acc: 0.8568 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5254  | total loss: \u001b[1m\u001b[32m1.22029\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5254 | loss: 1.22029 - acc: 0.7711 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5255  | total loss: \u001b[1m\u001b[32m1.11646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5255 | loss: 1.11646 - acc: 0.7940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5256  | total loss: \u001b[1m\u001b[32m1.44302\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5256 | loss: 1.44302 - acc: 0.7217 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5257  | total loss: \u001b[1m\u001b[32m1.31771\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5257 | loss: 1.31771 - acc: 0.7496 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5258  | total loss: \u001b[1m\u001b[32m1.55404\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5258 | loss: 1.55404 - acc: 0.6889 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5259  | total loss: \u001b[1m\u001b[32m1.41939\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5259 | loss: 1.41939 - acc: 0.7200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5260  | total loss: \u001b[1m\u001b[32m1.69279\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5260 | loss: 1.69279 - acc: 0.6551 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5261  | total loss: \u001b[1m\u001b[32m1.54702\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5261 | loss: 1.54702 - acc: 0.6896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5262  | total loss: \u001b[1m\u001b[32m1.41730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5262 | loss: 1.41730 - acc: 0.7207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5263  | total loss: \u001b[1m\u001b[32m1.30167\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5263 | loss: 1.30167 - acc: 0.7486 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5264  | total loss: \u001b[1m\u001b[32m1.55939\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5264 | loss: 1.55939 - acc: 0.6809 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5265  | total loss: \u001b[1m\u001b[32m1.43184\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5265 | loss: 1.43184 - acc: 0.7128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5266  | total loss: \u001b[1m\u001b[32m1.69933\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5266 | loss: 1.69933 - acc: 0.6415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5267  | total loss: \u001b[1m\u001b[32m1.56092\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5267 | loss: 1.56092 - acc: 0.6774 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5268  | total loss: \u001b[1m\u001b[32m1.77646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5268 | loss: 1.77646 - acc: 0.6168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5269  | total loss: \u001b[1m\u001b[32m1.63424\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5269 | loss: 1.63424 - acc: 0.6551 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5270  | total loss: \u001b[1m\u001b[32m1.50805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5270 | loss: 1.50805 - acc: 0.6896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5271  | total loss: \u001b[1m\u001b[32m1.39569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5271 | loss: 1.39569 - acc: 0.7206 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5272  | total loss: \u001b[1m\u001b[32m1.60421\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5272 | loss: 1.60421 - acc: 0.6628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5273  | total loss: \u001b[1m\u001b[32m1.48428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5273 | loss: 1.48428 - acc: 0.6966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5274  | total loss: \u001b[1m\u001b[32m1.37713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5274 | loss: 1.37713 - acc: 0.7269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5275  | total loss: \u001b[1m\u001b[32m1.28092\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5275 | loss: 1.28092 - acc: 0.7542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5276  | total loss: \u001b[1m\u001b[32m1.51670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5276 | loss: 1.51670 - acc: 0.6788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5277  | total loss: \u001b[1m\u001b[32m1.40693\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5277 | loss: 1.40693 - acc: 0.7109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5278  | total loss: \u001b[1m\u001b[32m1.59910\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5278 | loss: 1.59910 - acc: 0.6541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5279  | total loss: \u001b[1m\u001b[32m1.48206\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5279 | loss: 1.48206 - acc: 0.6887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5280  | total loss: \u001b[1m\u001b[32m1.67833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5280 | loss: 1.67833 - acc: 0.6270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5281  | total loss: \u001b[1m\u001b[32m1.55477\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5281 | loss: 1.55477 - acc: 0.6643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5282  | total loss: \u001b[1m\u001b[32m1.73892\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5282 | loss: 1.73892 - acc: 0.5978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5283  | total loss: \u001b[1m\u001b[32m1.61124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5283 | loss: 1.61124 - acc: 0.6381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5284  | total loss: \u001b[1m\u001b[32m1.79561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5284 | loss: 1.79561 - acc: 0.5814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5285  | total loss: \u001b[1m\u001b[32m1.66464\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5285 | loss: 1.66464 - acc: 0.6233 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5286  | total loss: \u001b[1m\u001b[32m1.82040\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5286 | loss: 1.82040 - acc: 0.5681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5287  | total loss: \u001b[1m\u001b[32m1.68950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5287 | loss: 1.68950 - acc: 0.6113 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5288  | total loss: \u001b[1m\u001b[32m1.57261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5288 | loss: 1.57261 - acc: 0.6501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5289  | total loss: \u001b[1m\u001b[32m1.46763\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5289 | loss: 1.46763 - acc: 0.6851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5290  | total loss: \u001b[1m\u001b[32m1.64984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5290 | loss: 1.64984 - acc: 0.6238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5291  | total loss: \u001b[1m\u001b[32m1.53718\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5291 | loss: 1.53718 - acc: 0.6614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5292  | total loss: \u001b[1m\u001b[32m1.71579\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5292 | loss: 1.71579 - acc: 0.6024 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5293  | total loss: \u001b[1m\u001b[32m1.59703\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5293 | loss: 1.59703 - acc: 0.6421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5294  | total loss: \u001b[1m\u001b[32m1.49015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5294 | loss: 1.49015 - acc: 0.6779 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5295  | total loss: \u001b[1m\u001b[32m1.39335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5295 | loss: 1.39335 - acc: 0.7101 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5296  | total loss: \u001b[1m\u001b[32m1.61139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5296 | loss: 1.61139 - acc: 0.6391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5297  | total loss: \u001b[1m\u001b[32m1.50126\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5297 | loss: 1.50126 - acc: 0.6752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5298  | total loss: \u001b[1m\u001b[32m1.40150\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5298 | loss: 1.40150 - acc: 0.7077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5299  | total loss: \u001b[1m\u001b[32m1.31057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5299 | loss: 1.31057 - acc: 0.7369 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5300  | total loss: \u001b[1m\u001b[32m1.49927\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5300 | loss: 1.49927 - acc: 0.6775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5301  | total loss: \u001b[1m\u001b[32m1.39627\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5301 | loss: 1.39627 - acc: 0.7098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5302  | total loss: \u001b[1m\u001b[32m1.60958\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5302 | loss: 1.60958 - acc: 0.6459 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5303  | total loss: \u001b[1m\u001b[32m1.49430\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5303 | loss: 1.49430 - acc: 0.6813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5304  | total loss: \u001b[1m\u001b[32m1.65113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5304 | loss: 1.65113 - acc: 0.6346 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5305  | total loss: \u001b[1m\u001b[32m1.53128\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5305 | loss: 1.53128 - acc: 0.6712 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5306  | total loss: \u001b[1m\u001b[32m1.71790\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5306 | loss: 1.71790 - acc: 0.6112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5307  | total loss: \u001b[1m\u001b[32m1.59156\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5307 | loss: 1.59156 - acc: 0.6501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5308  | total loss: \u001b[1m\u001b[32m1.47782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5308 | loss: 1.47782 - acc: 0.6851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5309  | total loss: \u001b[1m\u001b[32m1.37490\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5309 | loss: 1.37490 - acc: 0.7166 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5310  | total loss: \u001b[1m\u001b[32m1.61123\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5310 | loss: 1.61123 - acc: 0.6449 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5311  | total loss: \u001b[1m\u001b[32m1.49402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5311 | loss: 1.49402 - acc: 0.6804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5312  | total loss: \u001b[1m\u001b[32m1.73033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5312 | loss: 1.73033 - acc: 0.6124 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5313  | total loss: \u001b[1m\u001b[32m1.60122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5313 | loss: 1.60122 - acc: 0.6511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5314  | total loss: \u001b[1m\u001b[32m1.77725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5314 | loss: 1.77725 - acc: 0.5932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5315  | total loss: \u001b[1m\u001b[32m1.64421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5315 | loss: 1.64421 - acc: 0.6338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5316  | total loss: \u001b[1m\u001b[32m1.52475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5316 | loss: 1.52475 - acc: 0.6705 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5317  | total loss: \u001b[1m\u001b[32m1.41695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5317 | loss: 1.41695 - acc: 0.7034 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5318  | total loss: \u001b[1m\u001b[32m1.31918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5318 | loss: 1.31918 - acc: 0.7331 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5319  | total loss: \u001b[1m\u001b[32m1.23002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5319 | loss: 1.23002 - acc: 0.7598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5320  | total loss: \u001b[1m\u001b[32m1.43272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5320 | loss: 1.43272 - acc: 0.6981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5321  | total loss: \u001b[1m\u001b[32m1.33013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5321 | loss: 1.33013 - acc: 0.7283 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5322  | total loss: \u001b[1m\u001b[32m1.54466\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5322 | loss: 1.54466 - acc: 0.6697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5323  | total loss: \u001b[1m\u001b[32m1.42995\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5323 | loss: 1.42995 - acc: 0.7028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5324  | total loss: \u001b[1m\u001b[32m1.64463\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5324 | loss: 1.64463 - acc: 0.6325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5325  | total loss: \u001b[1m\u001b[32m1.52004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5325 | loss: 1.52004 - acc: 0.6692 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5326  | total loss: \u001b[1m\u001b[32m1.40797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5326 | loss: 1.40797 - acc: 0.7023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5327  | total loss: \u001b[1m\u001b[32m1.30670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5327 | loss: 1.30670 - acc: 0.7321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5328  | total loss: \u001b[1m\u001b[32m1.21477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5328 | loss: 1.21477 - acc: 0.7589 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5329  | total loss: \u001b[1m\u001b[32m1.13090\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5329 | loss: 1.13090 - acc: 0.7830 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5330  | total loss: \u001b[1m\u001b[32m1.41069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5330 | loss: 1.41069 - acc: 0.7047 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5331  | total loss: \u001b[1m\u001b[32m1.30543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5331 | loss: 1.30543 - acc: 0.7342 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5332  | total loss: \u001b[1m\u001b[32m1.48808\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5332 | loss: 1.48808 - acc: 0.6751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5333  | total loss: \u001b[1m\u001b[32m1.37445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5333 | loss: 1.37445 - acc: 0.7076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5334  | total loss: \u001b[1m\u001b[32m1.27190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5334 | loss: 1.27190 - acc: 0.7368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5335  | total loss: \u001b[1m\u001b[32m1.17901\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5335 | loss: 1.17901 - acc: 0.7631 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5336  | total loss: \u001b[1m\u001b[32m1.43292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5336 | loss: 1.43292 - acc: 0.6940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5337  | total loss: \u001b[1m\u001b[32m1.32311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5337 | loss: 1.32311 - acc: 0.7246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5338  | total loss: \u001b[1m\u001b[32m1.59006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5338 | loss: 1.59006 - acc: 0.6521 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5339  | total loss: \u001b[1m\u001b[32m1.46497\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5339 | loss: 1.46497 - acc: 0.6869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5340  | total loss: \u001b[1m\u001b[32m1.35267\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5340 | loss: 1.35267 - acc: 0.7182 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5341  | total loss: \u001b[1m\u001b[32m1.25152\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5341 | loss: 1.25152 - acc: 0.7464 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5342  | total loss: \u001b[1m\u001b[32m1.53134\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5342 | loss: 1.53134 - acc: 0.6717 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5343  | total loss: \u001b[1m\u001b[32m1.41249\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5343 | loss: 1.41249 - acc: 0.7046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5344  | total loss: \u001b[1m\u001b[32m1.30573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5344 | loss: 1.30573 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5345  | total loss: \u001b[1m\u001b[32m1.20946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5345 | loss: 1.20946 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5346  | total loss: \u001b[1m\u001b[32m1.46784\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5346 | loss: 1.46784 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5347  | total loss: \u001b[1m\u001b[32m1.35520\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5347 | loss: 1.35520 - acc: 0.7226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5348  | total loss: \u001b[1m\u001b[32m1.56286\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5348 | loss: 1.56286 - acc: 0.6575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5349  | total loss: \u001b[1m\u001b[32m1.44149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5349 | loss: 1.44149 - acc: 0.6917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5350  | total loss: \u001b[1m\u001b[32m1.33261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5350 | loss: 1.33261 - acc: 0.7226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5351  | total loss: \u001b[1m\u001b[32m1.23457\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5351 | loss: 1.23457 - acc: 0.7503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5352  | total loss: \u001b[1m\u001b[32m1.48060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5352 | loss: 1.48060 - acc: 0.6824 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5353  | total loss: \u001b[1m\u001b[32m1.36789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5353 | loss: 1.36789 - acc: 0.7142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5354  | total loss: \u001b[1m\u001b[32m1.26657\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5354 | loss: 1.26657 - acc: 0.7428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5355  | total loss: \u001b[1m\u001b[32m1.17513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5355 | loss: 1.17513 - acc: 0.7685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5356  | total loss: \u001b[1m\u001b[32m1.09222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5356 | loss: 1.09222 - acc: 0.7916 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5357  | total loss: \u001b[1m\u001b[32m1.01669\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5357 | loss: 1.01669 - acc: 0.8125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5358  | total loss: \u001b[1m\u001b[32m1.31869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5358 | loss: 1.31869 - acc: 0.7312 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5359  | total loss: \u001b[1m\u001b[32m1.21931\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5359 | loss: 1.21931 - acc: 0.7581 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5360  | total loss: \u001b[1m\u001b[32m1.12947\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5360 | loss: 1.12947 - acc: 0.7823 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5361  | total loss: \u001b[1m\u001b[32m1.04795\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5361 | loss: 1.04795 - acc: 0.8041 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5362  | total loss: \u001b[1m\u001b[32m1.31208\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5362 | loss: 1.31208 - acc: 0.7308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5363  | total loss: \u001b[1m\u001b[32m1.21140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5363 | loss: 1.21140 - acc: 0.7577 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5364  | total loss: \u001b[1m\u001b[32m1.47873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5364 | loss: 1.47873 - acc: 0.6891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5365  | total loss: \u001b[1m\u001b[32m1.36177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5365 | loss: 1.36177 - acc: 0.7202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5366  | total loss: \u001b[1m\u001b[32m1.62591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5366 | loss: 1.62591 - acc: 0.6482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5367  | total loss: \u001b[1m\u001b[32m1.49567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5367 | loss: 1.49567 - acc: 0.6833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5368  | total loss: \u001b[1m\u001b[32m1.66052\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5368 | loss: 1.66052 - acc: 0.6364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5369  | total loss: \u001b[1m\u001b[32m1.52884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5369 | loss: 1.52884 - acc: 0.6728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5370  | total loss: \u001b[1m\u001b[32m1.73303\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5370 | loss: 1.73303 - acc: 0.6198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5371  | total loss: \u001b[1m\u001b[32m1.59650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5371 | loss: 1.59650 - acc: 0.6578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5372  | total loss: \u001b[1m\u001b[32m1.79676\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5372 | loss: 1.79676 - acc: 0.5992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5373  | total loss: \u001b[1m\u001b[32m1.65672\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5373 | loss: 1.65672 - acc: 0.6393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5374  | total loss: \u001b[1m\u001b[32m1.87436\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5374 | loss: 1.87436 - acc: 0.5753 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5375  | total loss: \u001b[1m\u001b[32m1.72990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5375 | loss: 1.72990 - acc: 0.6178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5376  | total loss: \u001b[1m\u001b[32m1.84848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5376 | loss: 1.84848 - acc: 0.5775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5377  | total loss: \u001b[1m\u001b[32m1.71004\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5377 | loss: 1.71004 - acc: 0.6197 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5378  | total loss: \u001b[1m\u001b[32m1.85423\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5378 | loss: 1.85423 - acc: 0.5720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5379  | total loss: \u001b[1m\u001b[32m1.71840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5379 | loss: 1.71840 - acc: 0.6148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5380  | total loss: \u001b[1m\u001b[32m1.92001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5380 | loss: 1.92001 - acc: 0.5533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5381  | total loss: \u001b[1m\u001b[32m1.78088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5381 | loss: 1.78088 - acc: 0.5980 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5382  | total loss: \u001b[1m\u001b[32m1.92343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5382 | loss: 1.92343 - acc: 0.5453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5383  | total loss: \u001b[1m\u001b[32m1.78723\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5383 | loss: 1.78723 - acc: 0.5908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5384  | total loss: \u001b[1m\u001b[32m1.89182\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5384 | loss: 1.89182 - acc: 0.5532 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5385  | total loss: \u001b[1m\u001b[32m1.76155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5385 | loss: 1.76155 - acc: 0.5978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5386  | total loss: \u001b[1m\u001b[32m1.88725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5386 | loss: 1.88725 - acc: 0.5523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5387  | total loss: \u001b[1m\u001b[32m1.75966\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5387 | loss: 1.75966 - acc: 0.5971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5388  | total loss: \u001b[1m\u001b[32m1.64540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5388 | loss: 1.64540 - acc: 0.6374 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5389  | total loss: \u001b[1m\u001b[32m1.54238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5389 | loss: 1.54238 - acc: 0.6737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5390  | total loss: \u001b[1m\u001b[32m1.44877\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5390 | loss: 1.44877 - acc: 0.7063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5391  | total loss: \u001b[1m\u001b[32m1.36303\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5391 | loss: 1.36303 - acc: 0.7357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5392  | total loss: \u001b[1m\u001b[32m1.56275\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5392 | loss: 1.56275 - acc: 0.6621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5393  | total loss: \u001b[1m\u001b[32m1.46266\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5393 | loss: 1.46266 - acc: 0.6959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5394  | total loss: \u001b[1m\u001b[32m1.64132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5394 | loss: 1.64132 - acc: 0.6334 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5395  | total loss: \u001b[1m\u001b[32m1.53142\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5395 | loss: 1.53142 - acc: 0.6701 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5396  | total loss: \u001b[1m\u001b[32m1.70514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5396 | loss: 1.70514 - acc: 0.6031 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5397  | total loss: \u001b[1m\u001b[32m1.58782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5397 | loss: 1.58782 - acc: 0.6428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5398  | total loss: \u001b[1m\u001b[32m1.78503\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5398 | loss: 1.78503 - acc: 0.5785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5399  | total loss: \u001b[1m\u001b[32m1.65950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5399 | loss: 1.65950 - acc: 0.6207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5400  | total loss: \u001b[1m\u001b[32m1.81238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5400 | loss: 1.81238 - acc: 0.5657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5401  | total loss: \u001b[1m\u001b[32m1.68453\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5401 | loss: 1.68453 - acc: 0.6092 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5402  | total loss: \u001b[1m\u001b[32m1.56944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5402 | loss: 1.56944 - acc: 0.6482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5403  | total loss: \u001b[1m\u001b[32m1.46522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5403 | loss: 1.46522 - acc: 0.6834 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5404  | total loss: \u001b[1m\u001b[32m1.63669\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 5404 | loss: 1.63669 - acc: 0.6294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5405  | total loss: \u001b[1m\u001b[32m1.52427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5405 | loss: 1.52427 - acc: 0.6664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5406  | total loss: \u001b[1m\u001b[32m1.72180\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5406 | loss: 1.72180 - acc: 0.6069 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5407  | total loss: \u001b[1m\u001b[32m1.60010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5407 | loss: 1.60010 - acc: 0.6462 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5408  | total loss: \u001b[1m\u001b[32m1.76149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5408 | loss: 1.76149 - acc: 0.5959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5409  | total loss: \u001b[1m\u001b[32m1.63567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5409 | loss: 1.63567 - acc: 0.6363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5410  | total loss: \u001b[1m\u001b[32m1.52218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5410 | loss: 1.52218 - acc: 0.6727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5411  | total loss: \u001b[1m\u001b[32m1.41923\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5411 | loss: 1.41923 - acc: 0.7054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5412  | total loss: \u001b[1m\u001b[32m1.60420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5412 | loss: 1.60420 - acc: 0.6492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5413  | total loss: \u001b[1m\u001b[32m1.49143\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5413 | loss: 1.49143 - acc: 0.6842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5414  | total loss: \u001b[1m\u001b[32m1.67794\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5414 | loss: 1.67794 - acc: 0.6230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5415  | total loss: \u001b[1m\u001b[32m1.55701\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5415 | loss: 1.55701 - acc: 0.6607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5416  | total loss: \u001b[1m\u001b[32m1.44774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5416 | loss: 1.44774 - acc: 0.6946 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5417  | total loss: \u001b[1m\u001b[32m1.34847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5417 | loss: 1.34847 - acc: 0.7251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5418  | total loss: \u001b[1m\u001b[32m1.56272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5418 | loss: 1.56272 - acc: 0.6598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5419  | total loss: \u001b[1m\u001b[32m1.45038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5419 | loss: 1.45038 - acc: 0.6938 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5420  | total loss: \u001b[1m\u001b[32m1.68774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5420 | loss: 1.68774 - acc: 0.6244 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5421  | total loss: \u001b[1m\u001b[32m1.56255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5421 | loss: 1.56255 - acc: 0.6620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5422  | total loss: \u001b[1m\u001b[32m1.76246\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5422 | loss: 1.76246 - acc: 0.5958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5423  | total loss: \u001b[1m\u001b[32m1.63046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5423 | loss: 1.63046 - acc: 0.6362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5424  | total loss: \u001b[1m\u001b[32m1.85182\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5424 | loss: 1.85182 - acc: 0.5726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5425  | total loss: \u001b[1m\u001b[32m1.71246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5425 | loss: 1.71246 - acc: 0.6153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5426  | total loss: \u001b[1m\u001b[32m1.58771\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5426 | loss: 1.58771 - acc: 0.6538 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5427  | total loss: \u001b[1m\u001b[32m1.47552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5427 | loss: 1.47552 - acc: 0.6884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5428  | total loss: \u001b[1m\u001b[32m1.64388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5428 | loss: 1.64388 - acc: 0.6339 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5429  | total loss: \u001b[1m\u001b[32m1.52602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5429 | loss: 1.52602 - acc: 0.6705 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5430  | total loss: \u001b[1m\u001b[32m1.69246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5430 | loss: 1.69246 - acc: 0.6106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5431  | total loss: \u001b[1m\u001b[32m1.57032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5431 | loss: 1.57032 - acc: 0.6495 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5432  | total loss: \u001b[1m\u001b[32m1.78367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5432 | loss: 1.78367 - acc: 0.5846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5433  | total loss: \u001b[1m\u001b[32m1.65361\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5433 | loss: 1.65361 - acc: 0.6261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5434  | total loss: \u001b[1m\u001b[32m1.79676\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5434 | loss: 1.79676 - acc: 0.5849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5435  | total loss: \u001b[1m\u001b[32m1.66684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5435 | loss: 1.66684 - acc: 0.6264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5436  | total loss: \u001b[1m\u001b[32m1.55026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5436 | loss: 1.55026 - acc: 0.6638 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5437  | total loss: \u001b[1m\u001b[32m1.44505\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5437 | loss: 1.44505 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5438  | total loss: \u001b[1m\u001b[32m1.34951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5438 | loss: 1.34951 - acc: 0.7277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5439  | total loss: \u001b[1m\u001b[32m1.26219\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5439 | loss: 1.26219 - acc: 0.7549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5440  | total loss: \u001b[1m\u001b[32m1.18184\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5440 | loss: 1.18184 - acc: 0.7794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5441  | total loss: \u001b[1m\u001b[32m1.10746\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5441 | loss: 1.10746 - acc: 0.8015 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5442  | total loss: \u001b[1m\u001b[32m1.37646\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5442 | loss: 1.37646 - acc: 0.7213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5443  | total loss: \u001b[1m\u001b[32m1.27919\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5443 | loss: 1.27919 - acc: 0.7492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5444  | total loss: \u001b[1m\u001b[32m1.50647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5444 | loss: 1.50647 - acc: 0.6814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5445  | total loss: \u001b[1m\u001b[32m1.39440\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5445 | loss: 1.39440 - acc: 0.7133 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5446  | total loss: \u001b[1m\u001b[32m1.29278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5446 | loss: 1.29278 - acc: 0.7419 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5447  | total loss: \u001b[1m\u001b[32m1.20023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5447 | loss: 1.20023 - acc: 0.7678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5448  | total loss: \u001b[1m\u001b[32m1.47523\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5448 | loss: 1.47523 - acc: 0.6910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5449  | total loss: \u001b[1m\u001b[32m1.36279\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5449 | loss: 1.36279 - acc: 0.7219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5450  | total loss: \u001b[1m\u001b[32m1.56190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5450 | loss: 1.56190 - acc: 0.6640 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5451  | total loss: \u001b[1m\u001b[32m1.44040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5451 | loss: 1.44040 - acc: 0.6976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5452  | total loss: \u001b[1m\u001b[32m1.68243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5452 | loss: 1.68243 - acc: 0.6278 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5453  | total loss: \u001b[1m\u001b[32m1.54959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5453 | loss: 1.54959 - acc: 0.6650 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5454  | total loss: \u001b[1m\u001b[32m1.78707\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5454 | loss: 1.78707 - acc: 0.5985 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5455  | total loss: \u001b[1m\u001b[32m1.64553\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5455 | loss: 1.64553 - acc: 0.6387 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5456  | total loss: \u001b[1m\u001b[32m1.84285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5456 | loss: 1.84285 - acc: 0.5820 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5457  | total loss: \u001b[1m\u001b[32m1.69819\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5457 | loss: 1.69819 - acc: 0.6238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5458  | total loss: \u001b[1m\u001b[32m1.56906\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5458 | loss: 1.56906 - acc: 0.6614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5459  | total loss: \u001b[1m\u001b[32m1.45337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5459 | loss: 1.45337 - acc: 0.6952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5460  | total loss: \u001b[1m\u001b[32m1.63479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5460 | loss: 1.63479 - acc: 0.6400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5461  | total loss: \u001b[1m\u001b[32m1.51328\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5461 | loss: 1.51328 - acc: 0.6760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5462  | total loss: \u001b[1m\u001b[32m1.40413\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5462 | loss: 1.40413 - acc: 0.7084 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5463  | total loss: \u001b[1m\u001b[32m1.30560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5463 | loss: 1.30560 - acc: 0.7376 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5464  | total loss: \u001b[1m\u001b[32m1.21618\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5464 | loss: 1.21618 - acc: 0.7638 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5465  | total loss: \u001b[1m\u001b[32m1.13457\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5465 | loss: 1.13457 - acc: 0.7874 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5466  | total loss: \u001b[1m\u001b[32m1.05968\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5466 | loss: 1.05968 - acc: 0.8087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5467  | total loss: \u001b[1m\u001b[32m0.99058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5467 | loss: 0.99058 - acc: 0.8278 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5468  | total loss: \u001b[1m\u001b[32m1.28803\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5468 | loss: 1.28803 - acc: 0.7450 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5469  | total loss: \u001b[1m\u001b[32m1.19354\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5469 | loss: 1.19354 - acc: 0.7705 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5470  | total loss: \u001b[1m\u001b[32m1.44331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5470 | loss: 1.44331 - acc: 0.7006 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5471  | total loss: \u001b[1m\u001b[32m1.33237\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5471 | loss: 1.33237 - acc: 0.7306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5472  | total loss: \u001b[1m\u001b[32m1.59732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5472 | loss: 1.59732 - acc: 0.6575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5473  | total loss: \u001b[1m\u001b[32m1.47131\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5473 | loss: 1.47131 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5474  | total loss: \u001b[1m\u001b[32m1.71917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5474 | loss: 1.71917 - acc: 0.6226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5475  | total loss: \u001b[1m\u001b[32m1.58237\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5475 | loss: 1.58237 - acc: 0.6603 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5476  | total loss: \u001b[1m\u001b[32m1.45994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5476 | loss: 1.45994 - acc: 0.6943 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5477  | total loss: \u001b[1m\u001b[32m1.34998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5477 | loss: 1.34998 - acc: 0.7249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5478  | total loss: \u001b[1m\u001b[32m1.61749\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5478 | loss: 1.61749 - acc: 0.6524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5479  | total loss: \u001b[1m\u001b[32m1.49244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5479 | loss: 1.49244 - acc: 0.6871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5480  | total loss: \u001b[1m\u001b[32m1.67844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5480 | loss: 1.67844 - acc: 0.6327 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5481  | total loss: \u001b[1m\u001b[32m1.54869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5481 | loss: 1.54869 - acc: 0.6694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5482  | total loss: \u001b[1m\u001b[32m1.78001\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5482 | loss: 1.78001 - acc: 0.6025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5483  | total loss: \u001b[1m\u001b[32m1.64205\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5483 | loss: 1.64205 - acc: 0.6422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5484  | total loss: \u001b[1m\u001b[32m1.82318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5484 | loss: 1.82318 - acc: 0.5852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5485  | total loss: \u001b[1m\u001b[32m1.68342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5485 | loss: 1.68342 - acc: 0.6266 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5486  | total loss: \u001b[1m\u001b[32m1.88319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5486 | loss: 1.88319 - acc: 0.5640 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5487  | total loss: \u001b[1m\u001b[32m1.74039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5487 | loss: 1.74039 - acc: 0.6076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5488  | total loss: \u001b[1m\u001b[32m1.89858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5488 | loss: 1.89858 - acc: 0.5540 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5489  | total loss: \u001b[1m\u001b[32m1.75751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5489 | loss: 1.75751 - acc: 0.5986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5490  | total loss: \u001b[1m\u001b[32m1.63185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5490 | loss: 1.63185 - acc: 0.6387 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5491  | total loss: \u001b[1m\u001b[32m1.51935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5491 | loss: 1.51935 - acc: 0.6748 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5492  | total loss: \u001b[1m\u001b[32m1.41804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5492 | loss: 1.41804 - acc: 0.7074 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5493  | total loss: \u001b[1m\u001b[32m1.32623\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5493 | loss: 1.32623 - acc: 0.7366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5494  | total loss: \u001b[1m\u001b[32m1.24244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5494 | loss: 1.24244 - acc: 0.7630 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5495  | total loss: \u001b[1m\u001b[32m1.16545\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5495 | loss: 1.16545 - acc: 0.7867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5496  | total loss: \u001b[1m\u001b[32m1.09422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5496 | loss: 1.09422 - acc: 0.8080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5497  | total loss: \u001b[1m\u001b[32m1.02790\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5497 | loss: 1.02790 - acc: 0.8272 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5498  | total loss: \u001b[1m\u001b[32m1.28848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5498 | loss: 1.28848 - acc: 0.7516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5499  | total loss: \u001b[1m\u001b[32m1.19902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5499 | loss: 1.19902 - acc: 0.7765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5500  | total loss: \u001b[1m\u001b[32m1.36978\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5500 | loss: 1.36978 - acc: 0.7274 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5501  | total loss: \u001b[1m\u001b[32m1.26982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5501 | loss: 1.26982 - acc: 0.7546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5502  | total loss: \u001b[1m\u001b[32m1.45058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5502 | loss: 1.45058 - acc: 0.7006 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5503  | total loss: \u001b[1m\u001b[32m1.34114\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5503 | loss: 1.34114 - acc: 0.7305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5504  | total loss: \u001b[1m\u001b[32m1.53274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5504 | loss: 1.53274 - acc: 0.6718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5505  | total loss: \u001b[1m\u001b[32m1.41462\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5505 | loss: 1.41462 - acc: 0.7046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5506  | total loss: \u001b[1m\u001b[32m1.63340\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5506 | loss: 1.63340 - acc: 0.6413 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5507  | total loss: \u001b[1m\u001b[32m1.50572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5507 | loss: 1.50572 - acc: 0.6772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5508  | total loss: \u001b[1m\u001b[32m1.73353\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5508 | loss: 1.73353 - acc: 0.6094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5509  | total loss: \u001b[1m\u001b[32m1.59722\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5509 | loss: 1.59722 - acc: 0.6485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5510  | total loss: \u001b[1m\u001b[32m1.78824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5510 | loss: 1.78824 - acc: 0.5979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5511  | total loss: \u001b[1m\u001b[32m1.64837\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5511 | loss: 1.64837 - acc: 0.6381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5512  | total loss: \u001b[1m\u001b[32m1.52326\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5512 | loss: 1.52326 - acc: 0.6743 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5513  | total loss: \u001b[1m\u001b[32m1.41093\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5513 | loss: 1.41093 - acc: 0.7069 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5514  | total loss: \u001b[1m\u001b[32m1.64190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5514 | loss: 1.64190 - acc: 0.6362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5515  | total loss: \u001b[1m\u001b[32m1.51825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5515 | loss: 1.51825 - acc: 0.6726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5516  | total loss: \u001b[1m\u001b[32m1.40720\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5516 | loss: 1.40720 - acc: 0.7053 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5517  | total loss: \u001b[1m\u001b[32m1.30704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5517 | loss: 1.30704 - acc: 0.7348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5518  | total loss: \u001b[1m\u001b[32m1.50879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5518 | loss: 1.50879 - acc: 0.6756 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5519  | total loss: \u001b[1m\u001b[32m1.39797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5519 | loss: 1.39797 - acc: 0.7080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5520  | total loss: \u001b[1m\u001b[32m1.63818\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5520 | loss: 1.63818 - acc: 0.6372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5521  | total loss: \u001b[1m\u001b[32m1.51476\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5521 | loss: 1.51476 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5522  | total loss: \u001b[1m\u001b[32m1.40382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5522 | loss: 1.40382 - acc: 0.7062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5523  | total loss: \u001b[1m\u001b[32m1.30367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5523 | loss: 1.30367 - acc: 0.7355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5524  | total loss: \u001b[1m\u001b[32m1.52051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5524 | loss: 1.52051 - acc: 0.6691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5525  | total loss: \u001b[1m\u001b[32m1.40821\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5525 | loss: 1.40821 - acc: 0.7022 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5526  | total loss: \u001b[1m\u001b[32m1.56641\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5526 | loss: 1.56641 - acc: 0.6534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5527  | total loss: \u001b[1m\u001b[32m1.44975\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5527 | loss: 1.44975 - acc: 0.6881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5528  | total loss: \u001b[1m\u001b[32m1.65831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5528 | loss: 1.65831 - acc: 0.6264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5529  | total loss: \u001b[1m\u001b[32m1.53337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5529 | loss: 1.53337 - acc: 0.6638 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5530  | total loss: \u001b[1m\u001b[32m1.42131\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5530 | loss: 1.42131 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5531  | total loss: \u001b[1m\u001b[32m1.32037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5531 | loss: 1.32037 - acc: 0.7277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5532  | total loss: \u001b[1m\u001b[32m1.22902\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5532 | loss: 1.22902 - acc: 0.7549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5533  | total loss: \u001b[1m\u001b[32m1.14591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5533 | loss: 1.14591 - acc: 0.7794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5534  | total loss: \u001b[1m\u001b[32m1.06990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5534 | loss: 1.06990 - acc: 0.8015 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5535  | total loss: \u001b[1m\u001b[32m1.00001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5535 | loss: 1.00001 - acc: 0.8213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5536  | total loss: \u001b[1m\u001b[32m1.31975\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5536 | loss: 1.31975 - acc: 0.7392 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5537  | total loss: \u001b[1m\u001b[32m1.22262\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5537 | loss: 1.22262 - acc: 0.7653 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5538  | total loss: \u001b[1m\u001b[32m1.47571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5538 | loss: 1.47571 - acc: 0.6959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5539  | total loss: \u001b[1m\u001b[32m1.36216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5539 | loss: 1.36216 - acc: 0.7263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5540  | total loss: \u001b[1m\u001b[32m1.58963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5540 | loss: 1.58963 - acc: 0.6608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5541  | total loss: \u001b[1m\u001b[32m1.46491\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5541 | loss: 1.46491 - acc: 0.6947 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5542  | total loss: \u001b[1m\u001b[32m1.72270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5542 | loss: 1.72270 - acc: 0.6253 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5543  | total loss: \u001b[1m\u001b[32m1.58586\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5543 | loss: 1.58586 - acc: 0.6627 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5544  | total loss: \u001b[1m\u001b[32m1.81154\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5544 | loss: 1.81154 - acc: 0.5965 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5545  | total loss: \u001b[1m\u001b[32m1.66789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5545 | loss: 1.66789 - acc: 0.6368 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5546  | total loss: \u001b[1m\u001b[32m1.87296\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5546 | loss: 1.87296 - acc: 0.5803 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5547  | total loss: \u001b[1m\u001b[32m1.72591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5547 | loss: 1.72591 - acc: 0.6222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5548  | total loss: \u001b[1m\u001b[32m1.59478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5548 | loss: 1.59478 - acc: 0.6600 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5549  | total loss: \u001b[1m\u001b[32m1.47742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5549 | loss: 1.47742 - acc: 0.6940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5550  | total loss: \u001b[1m\u001b[32m1.69507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5550 | loss: 1.69507 - acc: 0.6246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5551  | total loss: \u001b[1m\u001b[32m1.56886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5551 | loss: 1.56886 - acc: 0.6622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5552  | total loss: \u001b[1m\u001b[32m1.45575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5552 | loss: 1.45575 - acc: 0.6959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5553  | total loss: \u001b[1m\u001b[32m1.35390\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5553 | loss: 1.35390 - acc: 0.7263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5554  | total loss: \u001b[1m\u001b[32m1.54536\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5554 | loss: 1.54536 - acc: 0.6680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5555  | total loss: \u001b[1m\u001b[32m1.43434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5555 | loss: 1.43434 - acc: 0.7012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5556  | total loss: \u001b[1m\u001b[32m1.61729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5556 | loss: 1.61729 - acc: 0.6454 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5557  | total loss: \u001b[1m\u001b[32m1.49947\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5557 | loss: 1.49947 - acc: 0.6808 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5558  | total loss: \u001b[1m\u001b[32m1.39349\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5558 | loss: 1.39349 - acc: 0.7127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5559  | total loss: \u001b[1m\u001b[32m1.29770\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5559 | loss: 1.29770 - acc: 0.7415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5560  | total loss: \u001b[1m\u001b[32m1.21064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5560 | loss: 1.21064 - acc: 0.7673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5561  | total loss: \u001b[1m\u001b[32m1.13108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5561 | loss: 1.13108 - acc: 0.7906 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5562  | total loss: \u001b[1m\u001b[32m1.05797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5562 | loss: 1.05797 - acc: 0.8115 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5563  | total loss: \u001b[1m\u001b[32m0.99041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5563 | loss: 0.99041 - acc: 0.8304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5564  | total loss: \u001b[1m\u001b[32m0.92766\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5564 | loss: 0.92766 - acc: 0.8473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5565  | total loss: \u001b[1m\u001b[32m0.86912\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5565 | loss: 0.86912 - acc: 0.8626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5566  | total loss: \u001b[1m\u001b[32m0.81429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5566 | loss: 0.81429 - acc: 0.8763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5567  | total loss: \u001b[1m\u001b[32m0.76278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5567 | loss: 0.76278 - acc: 0.8887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5568  | total loss: \u001b[1m\u001b[32m0.71427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5568 | loss: 0.71427 - acc: 0.8998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5569  | total loss: \u001b[1m\u001b[32m0.66851\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5569 | loss: 0.66851 - acc: 0.9099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5570  | total loss: \u001b[1m\u001b[32m0.99713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5570 | loss: 0.99713 - acc: 0.8260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5571  | total loss: \u001b[1m\u001b[32m0.92010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5571 | loss: 0.92010 - acc: 0.8434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5572  | total loss: \u001b[1m\u001b[32m1.22622\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5572 | loss: 1.22622 - acc: 0.7662 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5573  | total loss: \u001b[1m\u001b[32m1.12504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5573 | loss: 1.12504 - acc: 0.7896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5574  | total loss: \u001b[1m\u001b[32m1.39618\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5574 | loss: 1.39618 - acc: 0.7178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5575  | total loss: \u001b[1m\u001b[32m1.27807\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5575 | loss: 1.27807 - acc: 0.7460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5576  | total loss: \u001b[1m\u001b[32m1.17199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5576 | loss: 1.17199 - acc: 0.7714 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5577  | total loss: \u001b[1m\u001b[32m1.07654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5577 | loss: 1.07654 - acc: 0.7943 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5578  | total loss: \u001b[1m\u001b[32m1.36119\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5578 | loss: 1.36119 - acc: 0.7220 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5579  | total loss: \u001b[1m\u001b[32m1.24725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5579 | loss: 1.24725 - acc: 0.7498 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5580  | total loss: \u001b[1m\u001b[32m1.50969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5580 | loss: 1.50969 - acc: 0.6891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5581  | total loss: \u001b[1m\u001b[32m1.38231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5581 | loss: 1.38231 - acc: 0.7202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5582  | total loss: \u001b[1m\u001b[32m1.63501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5582 | loss: 1.63501 - acc: 0.6553 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5583  | total loss: \u001b[1m\u001b[32m1.49739\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5583 | loss: 1.49739 - acc: 0.6898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5584  | total loss: \u001b[1m\u001b[32m1.71427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5584 | loss: 1.71427 - acc: 0.6351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5585  | total loss: \u001b[1m\u001b[32m1.57185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5585 | loss: 1.57185 - acc: 0.6716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5586  | total loss: \u001b[1m\u001b[32m1.44518\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5586 | loss: 1.44518 - acc: 0.7044 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5587  | total loss: \u001b[1m\u001b[32m1.33227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5587 | loss: 1.33227 - acc: 0.7340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5588  | total loss: \u001b[1m\u001b[32m1.53547\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5588 | loss: 1.53547 - acc: 0.6749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5589  | total loss: \u001b[1m\u001b[32m1.41547\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5589 | loss: 1.41547 - acc: 0.7074 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5590  | total loss: \u001b[1m\u001b[32m1.66557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5590 | loss: 1.66557 - acc: 0.6366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5591  | total loss: \u001b[1m\u001b[32m1.53506\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5591 | loss: 1.53506 - acc: 0.6730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5592  | total loss: \u001b[1m\u001b[32m1.77808\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5592 | loss: 1.77808 - acc: 0.6057 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5593  | total loss: \u001b[1m\u001b[32m1.63960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5593 | loss: 1.63960 - acc: 0.6451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5594  | total loss: \u001b[1m\u001b[32m1.51650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5594 | loss: 1.51650 - acc: 0.6806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5595  | total loss: \u001b[1m\u001b[32m1.40666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5595 | loss: 1.40666 - acc: 0.7125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5596  | total loss: \u001b[1m\u001b[32m1.30822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5596 | loss: 1.30822 - acc: 0.7413 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5597  | total loss: \u001b[1m\u001b[32m1.21952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5597 | loss: 1.21952 - acc: 0.7672 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5598  | total loss: \u001b[1m\u001b[32m1.13914\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5598 | loss: 1.13914 - acc: 0.7904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5599  | total loss: \u001b[1m\u001b[32m1.06584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5599 | loss: 1.06584 - acc: 0.8114 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5600  | total loss: \u001b[1m\u001b[32m0.99860\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5600 | loss: 0.99860 - acc: 0.8303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5601  | total loss: \u001b[1m\u001b[32m0.93652\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5601 | loss: 0.93652 - acc: 0.8472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5602  | total loss: \u001b[1m\u001b[32m0.87889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5602 | loss: 0.87889 - acc: 0.8625 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5603  | total loss: \u001b[1m\u001b[32m0.82510\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5603 | loss: 0.82510 - acc: 0.8763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5604  | total loss: \u001b[1m\u001b[32m1.15139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5604 | loss: 1.15139 - acc: 0.7886 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5605  | total loss: \u001b[1m\u001b[32m1.06748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5605 | loss: 1.06748 - acc: 0.8098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5606  | total loss: \u001b[1m\u001b[32m1.29425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5606 | loss: 1.29425 - acc: 0.7502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5607  | total loss: \u001b[1m\u001b[32m1.19473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5607 | loss: 1.19473 - acc: 0.7752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5608  | total loss: \u001b[1m\u001b[32m1.43852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5608 | loss: 1.43852 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5609  | total loss: \u001b[1m\u001b[32m1.32434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5609 | loss: 1.32434 - acc: 0.7343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5610  | total loss: \u001b[1m\u001b[32m1.58812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5610 | loss: 1.58812 - acc: 0.6680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5611  | total loss: \u001b[1m\u001b[32m1.45976\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5611 | loss: 1.45976 - acc: 0.7012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5612  | total loss: \u001b[1m\u001b[32m1.68422\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5612 | loss: 1.68422 - acc: 0.6383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5613  | total loss: \u001b[1m\u001b[32m1.54796\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5613 | loss: 1.54796 - acc: 0.6744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5614  | total loss: \u001b[1m\u001b[32m1.42616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5614 | loss: 1.42616 - acc: 0.7070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5615  | total loss: \u001b[1m\u001b[32m1.31696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5615 | loss: 1.31696 - acc: 0.7363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5616  | total loss: \u001b[1m\u001b[32m1.21873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5616 | loss: 1.21873 - acc: 0.7627 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5617  | total loss: \u001b[1m\u001b[32m1.13002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5617 | loss: 1.13002 - acc: 0.7864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5618  | total loss: \u001b[1m\u001b[32m1.04957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5618 | loss: 1.04957 - acc: 0.8078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5619  | total loss: \u001b[1m\u001b[32m0.97630\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5619 | loss: 0.97630 - acc: 0.8270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5620  | total loss: \u001b[1m\u001b[32m0.90926\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5620 | loss: 0.90926 - acc: 0.8443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5621  | total loss: \u001b[1m\u001b[32m0.84766\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5621 | loss: 0.84766 - acc: 0.8599 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5622  | total loss: \u001b[1m\u001b[32m1.17306\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5622 | loss: 1.17306 - acc: 0.7810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5623  | total loss: \u001b[1m\u001b[32m1.08331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5623 | loss: 1.08331 - acc: 0.8029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5624  | total loss: \u001b[1m\u001b[32m1.00194\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5624 | loss: 1.00194 - acc: 0.8226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5625  | total loss: \u001b[1m\u001b[32m0.92793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5625 | loss: 0.92793 - acc: 0.8404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5626  | total loss: \u001b[1m\u001b[32m1.26725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5626 | loss: 1.26725 - acc: 0.7563 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5627  | total loss: \u001b[1m\u001b[32m1.16581\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5627 | loss: 1.16581 - acc: 0.7807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5628  | total loss: \u001b[1m\u001b[32m1.41776\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5628 | loss: 1.41776 - acc: 0.7169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5629  | total loss: \u001b[1m\u001b[32m1.30160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5629 | loss: 1.30160 - acc: 0.7452 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5630  | total loss: \u001b[1m\u001b[32m1.19731\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5630 | loss: 1.19731 - acc: 0.7707 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5631  | total loss: \u001b[1m\u001b[32m1.10344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5631 | loss: 1.10344 - acc: 0.7936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5632  | total loss: \u001b[1m\u001b[32m1.37533\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5632 | loss: 1.37533 - acc: 0.7214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5633  | total loss: \u001b[1m\u001b[32m1.26401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5633 | loss: 1.26401 - acc: 0.7493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5634  | total loss: \u001b[1m\u001b[32m1.52082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5634 | loss: 1.52082 - acc: 0.6815 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5635  | total loss: \u001b[1m\u001b[32m1.39636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5635 | loss: 1.39636 - acc: 0.7133 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5636  | total loss: \u001b[1m\u001b[32m1.62003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5636 | loss: 1.62003 - acc: 0.6563 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5637  | total loss: \u001b[1m\u001b[32m1.48790\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5637 | loss: 1.48790 - acc: 0.6907 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5638  | total loss: \u001b[1m\u001b[32m1.37011\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5638 | loss: 1.37011 - acc: 0.7216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5639  | total loss: \u001b[1m\u001b[32m1.26482\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5639 | loss: 1.26482 - acc: 0.7494 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5640  | total loss: \u001b[1m\u001b[32m1.49749\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5640 | loss: 1.49749 - acc: 0.6816 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5641  | total loss: \u001b[1m\u001b[32m1.38085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5641 | loss: 1.38085 - acc: 0.7135 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5642  | total loss: \u001b[1m\u001b[32m1.27650\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5642 | loss: 1.27650 - acc: 0.7421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5643  | total loss: \u001b[1m\u001b[32m1.18281\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5643 | loss: 1.18281 - acc: 0.7679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5644  | total loss: \u001b[1m\u001b[32m1.09833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5644 | loss: 1.09833 - acc: 0.7911 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5645  | total loss: \u001b[1m\u001b[32m1.02181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5645 | loss: 1.02181 - acc: 0.8120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5646  | total loss: \u001b[1m\u001b[32m1.27865\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5646 | loss: 1.27865 - acc: 0.7379 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5647  | total loss: \u001b[1m\u001b[32m1.18346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5647 | loss: 1.18346 - acc: 0.7642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5648  | total loss: \u001b[1m\u001b[32m1.09757\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5648 | loss: 1.09757 - acc: 0.7877 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5649  | total loss: \u001b[1m\u001b[32m1.01976\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5649 | loss: 1.01976 - acc: 0.8090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5650  | total loss: \u001b[1m\u001b[32m0.94893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5650 | loss: 0.94893 - acc: 0.8281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5651  | total loss: \u001b[1m\u001b[32m0.88419\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5651 | loss: 0.88419 - acc: 0.8453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5652  | total loss: \u001b[1m\u001b[32m0.82473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5652 | loss: 0.82473 - acc: 0.8607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5653  | total loss: \u001b[1m\u001b[32m0.76989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5653 | loss: 0.76989 - acc: 0.8747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5654  | total loss: \u001b[1m\u001b[32m0.71911\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5654 | loss: 0.71911 - acc: 0.8872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5655  | total loss: \u001b[1m\u001b[32m0.67194\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5655 | loss: 0.67194 - acc: 0.8985 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5656  | total loss: \u001b[1m\u001b[32m0.62797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5656 | loss: 0.62797 - acc: 0.9086 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5657  | total loss: \u001b[1m\u001b[32m0.58691\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5657 | loss: 0.58691 - acc: 0.9178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5658  | total loss: \u001b[1m\u001b[32m0.54847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5658 | loss: 0.54847 - acc: 0.9260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5659  | total loss: \u001b[1m\u001b[32m0.51245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5659 | loss: 0.51245 - acc: 0.9334 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5660  | total loss: \u001b[1m\u001b[32m0.87911\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5660 | loss: 0.87911 - acc: 0.8472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5661  | total loss: \u001b[1m\u001b[32m0.80812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5661 | loss: 0.80812 - acc: 0.8625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5662  | total loss: \u001b[1m\u001b[32m1.11336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5662 | loss: 1.11336 - acc: 0.7905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5663  | total loss: \u001b[1m\u001b[32m1.01844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5663 | loss: 1.01844 - acc: 0.8115 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5664  | total loss: \u001b[1m\u001b[32m0.93298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5664 | loss: 0.93298 - acc: 0.8303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5665  | total loss: \u001b[1m\u001b[32m0.85591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5665 | loss: 0.85591 - acc: 0.8473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5666  | total loss: \u001b[1m\u001b[32m0.78629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5666 | loss: 0.78629 - acc: 0.8626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5667  | total loss: \u001b[1m\u001b[32m0.72329\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5667 | loss: 0.72329 - acc: 0.8763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5668  | total loss: \u001b[1m\u001b[32m0.66617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5668 | loss: 0.66617 - acc: 0.8887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5669  | total loss: \u001b[1m\u001b[32m0.61428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5669 | loss: 0.61428 - acc: 0.8998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5670  | total loss: \u001b[1m\u001b[32m0.56706\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5670 | loss: 0.56706 - acc: 0.9098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5671  | total loss: \u001b[1m\u001b[32m0.52400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5671 | loss: 0.52400 - acc: 0.9188 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5672  | total loss: \u001b[1m\u001b[32m0.92119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5672 | loss: 0.92119 - acc: 0.8341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5673  | total loss: \u001b[1m\u001b[32m0.84218\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5673 | loss: 0.84218 - acc: 0.8507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5674  | total loss: \u001b[1m\u001b[32m0.77104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5674 | loss: 0.77104 - acc: 0.8656 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5675  | total loss: \u001b[1m\u001b[32m0.70689\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5675 | loss: 0.70689 - acc: 0.8791 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5676  | total loss: \u001b[1m\u001b[32m0.64897\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5676 | loss: 0.64897 - acc: 0.8912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5677  | total loss: \u001b[1m\u001b[32m0.59657\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5677 | loss: 0.59657 - acc: 0.9020 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5678  | total loss: \u001b[1m\u001b[32m0.54911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5678 | loss: 0.54911 - acc: 0.9118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5679  | total loss: \u001b[1m\u001b[32m0.50604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5679 | loss: 0.50604 - acc: 0.9207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5680  | total loss: \u001b[1m\u001b[32m0.95594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5680 | loss: 0.95594 - acc: 0.8286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5681  | total loss: \u001b[1m\u001b[32m0.87199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5681 | loss: 0.87199 - acc: 0.8457 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5682  | total loss: \u001b[1m\u001b[32m0.79653\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5682 | loss: 0.79653 - acc: 0.8612 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5683  | total loss: \u001b[1m\u001b[32m0.72864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5683 | loss: 0.72864 - acc: 0.8750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5684  | total loss: \u001b[1m\u001b[32m0.66748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5684 | loss: 0.66748 - acc: 0.8875 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5685  | total loss: \u001b[1m\u001b[32m0.61231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5685 | loss: 0.61231 - acc: 0.8988 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5686  | total loss: \u001b[1m\u001b[32m0.56247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5686 | loss: 0.56247 - acc: 0.9089 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5687  | total loss: \u001b[1m\u001b[32m0.51737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5687 | loss: 0.51737 - acc: 0.9180 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5688  | total loss: \u001b[1m\u001b[32m0.93485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5688 | loss: 0.93485 - acc: 0.8334 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5689  | total loss: \u001b[1m\u001b[32m0.85248\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5689 | loss: 0.85248 - acc: 0.8500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5690  | total loss: \u001b[1m\u001b[32m1.15320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5690 | loss: 1.15320 - acc: 0.7864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5691  | total loss: \u001b[1m\u001b[32m1.04979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5691 | loss: 1.04979 - acc: 0.8078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5692  | total loss: \u001b[1m\u001b[32m1.43394\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5692 | loss: 1.43394 - acc: 0.7270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5693  | total loss: \u001b[1m\u001b[32m1.30405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5693 | loss: 1.30405 - acc: 0.7543 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5694  | total loss: \u001b[1m\u001b[32m1.63395\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5694 | loss: 1.63395 - acc: 0.6860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5695  | total loss: \u001b[1m\u001b[32m1.48656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5695 | loss: 1.48656 - acc: 0.7174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5696  | total loss: \u001b[1m\u001b[32m1.79185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5696 | loss: 1.79185 - acc: 0.6528 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5697  | total loss: \u001b[1m\u001b[32m1.63209\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5697 | loss: 1.63209 - acc: 0.6875 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5698  | total loss: \u001b[1m\u001b[32m1.49011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5698 | loss: 1.49011 - acc: 0.7188 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5699  | total loss: \u001b[1m\u001b[32m1.36385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5699 | loss: 1.36385 - acc: 0.7469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5700  | total loss: \u001b[1m\u001b[32m1.60785\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5700 | loss: 1.60785 - acc: 0.6794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5701  | total loss: \u001b[1m\u001b[32m1.47297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5701 | loss: 1.47297 - acc: 0.7114 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5702  | total loss: \u001b[1m\u001b[32m1.72124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5702 | loss: 1.72124 - acc: 0.6474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5703  | total loss: \u001b[1m\u001b[32m1.57896\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5703 | loss: 1.57896 - acc: 0.6827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5704  | total loss: \u001b[1m\u001b[32m1.45282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5704 | loss: 1.45282 - acc: 0.7144 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5705  | total loss: \u001b[1m\u001b[32m1.34072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5705 | loss: 1.34072 - acc: 0.7430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5706  | total loss: \u001b[1m\u001b[32m1.59156\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5706 | loss: 1.59156 - acc: 0.6687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5707  | total loss: \u001b[1m\u001b[32m1.46839\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5707 | loss: 1.46839 - acc: 0.7018 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5708  | total loss: \u001b[1m\u001b[32m1.35885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5708 | loss: 1.35885 - acc: 0.7316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5709  | total loss: \u001b[1m\u001b[32m1.26104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5709 | loss: 1.26104 - acc: 0.7585 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5710  | total loss: \u001b[1m\u001b[32m1.52495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5710 | loss: 1.52495 - acc: 0.6826 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5711  | total loss: \u001b[1m\u001b[32m1.41205\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5711 | loss: 1.41205 - acc: 0.7144 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5712  | total loss: \u001b[1m\u001b[32m1.64039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5712 | loss: 1.64039 - acc: 0.6429 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5713  | total loss: \u001b[1m\u001b[32m1.51820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5713 | loss: 1.51820 - acc: 0.6786 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5714  | total loss: \u001b[1m\u001b[32m1.70992\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5714 | loss: 1.70992 - acc: 0.6179 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5715  | total loss: \u001b[1m\u001b[32m1.58349\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5715 | loss: 1.58349 - acc: 0.6561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5716  | total loss: \u001b[1m\u001b[32m1.78701\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5716 | loss: 1.78701 - acc: 0.5905 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5717  | total loss: \u001b[1m\u001b[32m1.65594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5717 | loss: 1.65594 - acc: 0.6315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5718  | total loss: \u001b[1m\u001b[32m1.53924\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5718 | loss: 1.53924 - acc: 0.6683 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5719  | total loss: \u001b[1m\u001b[32m1.43479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5719 | loss: 1.43479 - acc: 0.7015 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5720  | total loss: \u001b[1m\u001b[32m1.58597\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5720 | loss: 1.58597 - acc: 0.6528 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5721  | total loss: \u001b[1m\u001b[32m1.47738\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5721 | loss: 1.47738 - acc: 0.6875 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5722  | total loss: \u001b[1m\u001b[32m1.67571\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5722 | loss: 1.67571 - acc: 0.6330 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5723  | total loss: \u001b[1m\u001b[32m1.55881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5723 | loss: 1.55881 - acc: 0.6697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5724  | total loss: \u001b[1m\u001b[32m1.45365\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5724 | loss: 1.45365 - acc: 0.7027 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5725  | total loss: \u001b[1m\u001b[32m1.35845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5725 | loss: 1.35845 - acc: 0.7325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5726  | total loss: \u001b[1m\u001b[32m1.27170\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5726 | loss: 1.27170 - acc: 0.7592 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5727  | total loss: \u001b[1m\u001b[32m1.19211\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5727 | loss: 1.19211 - acc: 0.7833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5728  | total loss: \u001b[1m\u001b[32m1.11859\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5728 | loss: 1.11859 - acc: 0.8050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5729  | total loss: \u001b[1m\u001b[32m1.05025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5729 | loss: 1.05025 - acc: 0.8245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5730  | total loss: \u001b[1m\u001b[32m1.28596\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5730 | loss: 1.28596 - acc: 0.7492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5731  | total loss: \u001b[1m\u001b[32m1.19719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5731 | loss: 1.19719 - acc: 0.7743 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5732  | total loss: \u001b[1m\u001b[32m1.43815\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5732 | loss: 1.43815 - acc: 0.7040 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5733  | total loss: \u001b[1m\u001b[32m1.33199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5733 | loss: 1.33199 - acc: 0.7336 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5734  | total loss: \u001b[1m\u001b[32m1.58599\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5734 | loss: 1.58599 - acc: 0.6602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5735  | total loss: \u001b[1m\u001b[32m1.46426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5735 | loss: 1.46426 - acc: 0.6942 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5736  | total loss: \u001b[1m\u001b[32m1.67530\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5736 | loss: 1.67530 - acc: 0.6248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5737  | total loss: \u001b[1m\u001b[32m1.54509\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5737 | loss: 1.54509 - acc: 0.6623 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5738  | total loss: \u001b[1m\u001b[32m1.76481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5738 | loss: 1.76481 - acc: 0.5961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5739  | total loss: \u001b[1m\u001b[32m1.62711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5739 | loss: 1.62711 - acc: 0.6365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5740  | total loss: \u001b[1m\u001b[32m1.50385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5740 | loss: 1.50385 - acc: 0.6728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5741  | total loss: \u001b[1m\u001b[32m1.39310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5741 | loss: 1.39310 - acc: 0.7055 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5742  | total loss: \u001b[1m\u001b[32m1.60847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5742 | loss: 1.60847 - acc: 0.6350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5743  | total loss: \u001b[1m\u001b[32m1.48769\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5743 | loss: 1.48769 - acc: 0.6715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5744  | total loss: \u001b[1m\u001b[32m1.67135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5744 | loss: 1.67135 - acc: 0.6186 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5745  | total loss: \u001b[1m\u001b[32m1.54544\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5745 | loss: 1.54544 - acc: 0.6568 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5746  | total loss: \u001b[1m\u001b[32m1.76088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5746 | loss: 1.76088 - acc: 0.5911 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5747  | total loss: \u001b[1m\u001b[32m1.62774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5747 | loss: 1.62774 - acc: 0.6320 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5748  | total loss: \u001b[1m\u001b[32m1.50860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5748 | loss: 1.50860 - acc: 0.6688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5749  | total loss: \u001b[1m\u001b[32m1.40149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5749 | loss: 1.40149 - acc: 0.7019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5750  | total loss: \u001b[1m\u001b[32m1.63714\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5750 | loss: 1.63714 - acc: 0.6317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5751  | total loss: \u001b[1m\u001b[32m1.51734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5751 | loss: 1.51734 - acc: 0.6685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5752  | total loss: \u001b[1m\u001b[32m1.72472\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5752 | loss: 1.72472 - acc: 0.6017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5753  | total loss: \u001b[1m\u001b[32m1.59711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5753 | loss: 1.59711 - acc: 0.6415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5754  | total loss: \u001b[1m\u001b[32m1.81828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5754 | loss: 1.81828 - acc: 0.5774 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5755  | total loss: \u001b[1m\u001b[32m1.68295\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5755 | loss: 1.68295 - acc: 0.6196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5756  | total loss: \u001b[1m\u001b[32m1.87012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5756 | loss: 1.87012 - acc: 0.5577 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5757  | total loss: \u001b[1m\u001b[32m1.73178\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5757 | loss: 1.73178 - acc: 0.6019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5758  | total loss: \u001b[1m\u001b[32m1.60811\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5758 | loss: 1.60811 - acc: 0.6417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5759  | total loss: \u001b[1m\u001b[32m1.49699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5759 | loss: 1.49699 - acc: 0.6775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5760  | total loss: \u001b[1m\u001b[32m1.70004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5760 | loss: 1.70004 - acc: 0.6169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5761  | total loss: \u001b[1m\u001b[32m1.57978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5761 | loss: 1.57978 - acc: 0.6552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5762  | total loss: \u001b[1m\u001b[32m1.47138\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5762 | loss: 1.47138 - acc: 0.6897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5763  | total loss: \u001b[1m\u001b[32m1.37311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5763 | loss: 1.37311 - acc: 0.7207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5764  | total loss: \u001b[1m\u001b[32m1.59432\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5764 | loss: 1.59432 - acc: 0.6487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5765  | total loss: \u001b[1m\u001b[32m1.48239\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5765 | loss: 1.48239 - acc: 0.6838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5766  | total loss: \u001b[1m\u001b[32m1.38098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5766 | loss: 1.38098 - acc: 0.7154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5767  | total loss: \u001b[1m\u001b[32m1.28857\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5767 | loss: 1.28857 - acc: 0.7439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5768  | total loss: \u001b[1m\u001b[32m1.20388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5768 | loss: 1.20388 - acc: 0.7695 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5769  | total loss: \u001b[1m\u001b[32m1.12581\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5769 | loss: 1.12581 - acc: 0.7925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5770  | total loss: \u001b[1m\u001b[32m1.33258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5770 | loss: 1.33258 - acc: 0.7347 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5771  | total loss: \u001b[1m\u001b[32m1.23831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5771 | loss: 1.23831 - acc: 0.7612 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5772  | total loss: \u001b[1m\u001b[32m1.15195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5772 | loss: 1.15195 - acc: 0.7851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5773  | total loss: \u001b[1m\u001b[32m1.07250\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5773 | loss: 1.07250 - acc: 0.8066 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5774  | total loss: \u001b[1m\u001b[32m1.35327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5774 | loss: 1.35327 - acc: 0.7259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5775  | total loss: \u001b[1m\u001b[32m1.25111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5775 | loss: 1.25111 - acc: 0.7534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5776  | total loss: \u001b[1m\u001b[32m1.15822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5776 | loss: 1.15822 - acc: 0.7780 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5777  | total loss: \u001b[1m\u001b[32m1.07347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5777 | loss: 1.07347 - acc: 0.8002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5778  | total loss: \u001b[1m\u001b[32m1.35469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5778 | loss: 1.35469 - acc: 0.7273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5779  | total loss: \u001b[1m\u001b[32m1.24863\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5779 | loss: 1.24863 - acc: 0.7546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5780  | total loss: \u001b[1m\u001b[32m1.15258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5780 | loss: 1.15258 - acc: 0.7791 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5781  | total loss: \u001b[1m\u001b[32m1.06536\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5781 | loss: 1.06536 - acc: 0.8012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5782  | total loss: \u001b[1m\u001b[32m1.38467\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5782 | loss: 1.38467 - acc: 0.7211 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5783  | total loss: \u001b[1m\u001b[32m1.27329\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5783 | loss: 1.27329 - acc: 0.7490 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5784  | total loss: \u001b[1m\u001b[32m1.17281\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5784 | loss: 1.17281 - acc: 0.7741 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5785  | total loss: \u001b[1m\u001b[32m1.08192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5785 | loss: 1.08192 - acc: 0.7967 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5786  | total loss: \u001b[1m\u001b[32m0.99946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5786 | loss: 0.99946 - acc: 0.8170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5787  | total loss: \u001b[1m\u001b[32m0.92443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5787 | loss: 0.92443 - acc: 0.8353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5788  | total loss: \u001b[1m\u001b[32m1.26184\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5788 | loss: 1.26184 - acc: 0.7518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5789  | total loss: \u001b[1m\u001b[32m1.15963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5789 | loss: 1.15963 - acc: 0.7766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5790  | total loss: \u001b[1m\u001b[32m1.45169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5790 | loss: 1.45169 - acc: 0.7061 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5791  | total loss: \u001b[1m\u001b[32m1.33092\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5791 | loss: 1.33092 - acc: 0.7355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5792  | total loss: \u001b[1m\u001b[32m1.22260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5792 | loss: 1.22260 - acc: 0.7619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5793  | total loss: \u001b[1m\u001b[32m1.12523\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5793 | loss: 1.12523 - acc: 0.7857 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5794  | total loss: \u001b[1m\u001b[32m1.03747\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5794 | loss: 1.03747 - acc: 0.8072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5795  | total loss: \u001b[1m\u001b[32m0.95816\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5795 | loss: 0.95816 - acc: 0.8264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5796  | total loss: \u001b[1m\u001b[32m1.28189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5796 | loss: 1.28189 - acc: 0.7438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5797  | total loss: \u001b[1m\u001b[32m1.17798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5797 | loss: 1.17798 - acc: 0.7694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5798  | total loss: \u001b[1m\u001b[32m1.44648\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5798 | loss: 1.44648 - acc: 0.6996 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5799  | total loss: \u001b[1m\u001b[32m1.32713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5799 | loss: 1.32713 - acc: 0.7297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5800  | total loss: \u001b[1m\u001b[32m1.61412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5800 | loss: 1.61412 - acc: 0.6567 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5801  | total loss: \u001b[1m\u001b[32m1.48008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5801 | loss: 1.48008 - acc: 0.6910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5802  | total loss: \u001b[1m\u001b[32m1.74500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5802 | loss: 1.74500 - acc: 0.6219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5803  | total loss: \u001b[1m\u001b[32m1.60097\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5803 | loss: 1.60097 - acc: 0.6597 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5804  | total loss: \u001b[1m\u001b[32m1.76645\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5804 | loss: 1.76645 - acc: 0.6080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5805  | total loss: \u001b[1m\u001b[32m1.62393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5805 | loss: 1.62393 - acc: 0.6472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5806  | total loss: \u001b[1m\u001b[32m1.83591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5806 | loss: 1.83591 - acc: 0.5897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5807  | total loss: \u001b[1m\u001b[32m1.69048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5807 | loss: 1.69048 - acc: 0.6307 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5808  | total loss: \u001b[1m\u001b[32m1.88757\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5808 | loss: 1.88757 - acc: 0.5676 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5809  | total loss: \u001b[1m\u001b[32m1.74139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5809 | loss: 1.74139 - acc: 0.6109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5810  | total loss: \u001b[1m\u001b[32m1.91600\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5810 | loss: 1.91600 - acc: 0.5498 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5811  | total loss: \u001b[1m\u001b[32m1.77155\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5811 | loss: 1.77155 - acc: 0.5948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5812  | total loss: \u001b[1m\u001b[32m1.64348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5812 | loss: 1.64348 - acc: 0.6353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5813  | total loss: \u001b[1m\u001b[32m1.52941\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5813 | loss: 1.52941 - acc: 0.6718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5814  | total loss: \u001b[1m\u001b[32m1.42727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5814 | loss: 1.42727 - acc: 0.7046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5815  | total loss: \u001b[1m\u001b[32m1.33524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5815 | loss: 1.33524 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5816  | total loss: \u001b[1m\u001b[32m1.25174\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5816 | loss: 1.25174 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5817  | total loss: \u001b[1m\u001b[32m1.17542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5817 | loss: 1.17542 - acc: 0.7847 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5818  | total loss: \u001b[1m\u001b[32m1.10516\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5818 | loss: 1.10516 - acc: 0.8062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5819  | total loss: \u001b[1m\u001b[32m1.04001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5819 | loss: 1.04001 - acc: 0.8256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5820  | total loss: \u001b[1m\u001b[32m1.27944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5820 | loss: 1.27944 - acc: 0.7502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5821  | total loss: \u001b[1m\u001b[32m1.19359\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5821 | loss: 1.19359 - acc: 0.7751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5822  | total loss: \u001b[1m\u001b[32m1.11490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5822 | loss: 1.11490 - acc: 0.7976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5823  | total loss: \u001b[1m\u001b[32m1.04241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5823 | loss: 1.04241 - acc: 0.8179 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5824  | total loss: \u001b[1m\u001b[32m0.97529\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5824 | loss: 0.97529 - acc: 0.8361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5825  | total loss: \u001b[1m\u001b[32m0.91287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5825 | loss: 0.91287 - acc: 0.8525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5826  | total loss: \u001b[1m\u001b[32m0.85458\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5826 | loss: 0.85458 - acc: 0.8672 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5827  | total loss: \u001b[1m\u001b[32m0.79999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5827 | loss: 0.79999 - acc: 0.8805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5828  | total loss: \u001b[1m\u001b[32m1.10330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5828 | loss: 1.10330 - acc: 0.7996 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5829  | total loss: \u001b[1m\u001b[32m1.02063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5829 | loss: 1.02063 - acc: 0.8196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5830  | total loss: \u001b[1m\u001b[32m1.31499\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5830 | loss: 1.31499 - acc: 0.7448 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5831  | total loss: \u001b[1m\u001b[32m1.20974\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5831 | loss: 1.20974 - acc: 0.7703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5832  | total loss: \u001b[1m\u001b[32m1.49090\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5832 | loss: 1.49090 - acc: 0.6933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5833  | total loss: \u001b[1m\u001b[32m1.36805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5833 | loss: 1.36805 - acc: 0.7240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5834  | total loss: \u001b[1m\u001b[32m1.25764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5834 | loss: 1.25764 - acc: 0.7516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5835  | total loss: \u001b[1m\u001b[32m1.15818\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5835 | loss: 1.15818 - acc: 0.7764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5836  | total loss: \u001b[1m\u001b[32m1.46468\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5836 | loss: 1.46468 - acc: 0.6988 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5837  | total loss: \u001b[1m\u001b[32m1.34478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5837 | loss: 1.34478 - acc: 0.7289 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5838  | total loss: \u001b[1m\u001b[32m1.23716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5838 | loss: 1.23716 - acc: 0.7560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5839  | total loss: \u001b[1m\u001b[32m1.14033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5839 | loss: 1.14033 - acc: 0.7804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5840  | total loss: \u001b[1m\u001b[32m1.05295\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5840 | loss: 1.05295 - acc: 0.8024 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5841  | total loss: \u001b[1m\u001b[32m0.97386\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5841 | loss: 0.97386 - acc: 0.8221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5842  | total loss: \u001b[1m\u001b[32m1.25907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5842 | loss: 1.25907 - acc: 0.7471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5843  | total loss: \u001b[1m\u001b[32m1.15895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5843 | loss: 1.15895 - acc: 0.7724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5844  | total loss: \u001b[1m\u001b[32m1.42983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5844 | loss: 1.42983 - acc: 0.7023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5845  | total loss: \u001b[1m\u001b[32m1.31345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5845 | loss: 1.31345 - acc: 0.7320 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5846  | total loss: \u001b[1m\u001b[32m1.58988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5846 | loss: 1.58988 - acc: 0.6588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5847  | total loss: \u001b[1m\u001b[32m1.45938\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5847 | loss: 1.45938 - acc: 0.6929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5848  | total loss: \u001b[1m\u001b[32m1.70043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5848 | loss: 1.70043 - acc: 0.6308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5849  | total loss: \u001b[1m\u001b[32m1.56163\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5849 | loss: 1.56163 - acc: 0.6677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5850  | total loss: \u001b[1m\u001b[32m1.43805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5850 | loss: 1.43805 - acc: 0.7009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5851  | total loss: \u001b[1m\u001b[32m1.32775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5851 | loss: 1.32775 - acc: 0.7309 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5852  | total loss: \u001b[1m\u001b[32m1.22897\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5852 | loss: 1.22897 - acc: 0.7578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5853  | total loss: \u001b[1m\u001b[32m1.14016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5853 | loss: 1.14016 - acc: 0.7820 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5854  | total loss: \u001b[1m\u001b[32m1.40345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5854 | loss: 1.40345 - acc: 0.7109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5855  | total loss: \u001b[1m\u001b[32m1.29753\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5855 | loss: 1.29753 - acc: 0.7398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5856  | total loss: \u001b[1m\u001b[32m1.20241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5856 | loss: 1.20241 - acc: 0.7659 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5857  | total loss: \u001b[1m\u001b[32m1.11662\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5857 | loss: 1.11662 - acc: 0.7893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5858  | total loss: \u001b[1m\u001b[32m1.34632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5858 | loss: 1.34632 - acc: 0.7246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5859  | total loss: \u001b[1m\u001b[32m1.24590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5859 | loss: 1.24590 - acc: 0.7522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5860  | total loss: \u001b[1m\u001b[32m1.46165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5860 | loss: 1.46165 - acc: 0.6841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5861  | total loss: \u001b[1m\u001b[32m1.35034\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5861 | loss: 1.35034 - acc: 0.7157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5862  | total loss: \u001b[1m\u001b[32m1.25047\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5862 | loss: 1.25047 - acc: 0.7441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5863  | total loss: \u001b[1m\u001b[32m1.16051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5863 | loss: 1.16051 - acc: 0.7697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5864  | total loss: \u001b[1m\u001b[32m1.44055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5864 | loss: 1.44055 - acc: 0.6927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5865  | total loss: \u001b[1m\u001b[32m1.33169\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5865 | loss: 1.33169 - acc: 0.7235 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5866  | total loss: \u001b[1m\u001b[32m1.23385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5866 | loss: 1.23385 - acc: 0.7511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5867  | total loss: \u001b[1m\u001b[32m1.14555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5867 | loss: 1.14555 - acc: 0.7760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5868  | total loss: \u001b[1m\u001b[32m1.45371\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5868 | loss: 1.45371 - acc: 0.6984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5869  | total loss: \u001b[1m\u001b[32m1.34323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5869 | loss: 1.34323 - acc: 0.7286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5870  | total loss: \u001b[1m\u001b[32m1.24380\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5870 | loss: 1.24380 - acc: 0.7557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5871  | total loss: \u001b[1m\u001b[32m1.15394\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5871 | loss: 1.15394 - acc: 0.7801 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5872  | total loss: \u001b[1m\u001b[32m1.39571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5872 | loss: 1.39571 - acc: 0.7093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5873  | total loss: \u001b[1m\u001b[32m1.29015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5873 | loss: 1.29015 - acc: 0.7383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5874  | total loss: \u001b[1m\u001b[32m1.19496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5874 | loss: 1.19496 - acc: 0.7645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5875  | total loss: \u001b[1m\u001b[32m1.10878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5875 | loss: 1.10878 - acc: 0.7881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5876  | total loss: \u001b[1m\u001b[32m1.36017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5876 | loss: 1.36017 - acc: 0.7164 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5877  | total loss: \u001b[1m\u001b[32m1.25674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5877 | loss: 1.25674 - acc: 0.7448 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5878  | total loss: \u001b[1m\u001b[32m1.16341\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5878 | loss: 1.16341 - acc: 0.7703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5879  | total loss: \u001b[1m\u001b[32m1.07885\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5879 | loss: 1.07885 - acc: 0.7932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5880  | total loss: \u001b[1m\u001b[32m1.00195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5880 | loss: 1.00195 - acc: 0.8139 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5881  | total loss: \u001b[1m\u001b[32m0.93171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5881 | loss: 0.93171 - acc: 0.8325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5882  | total loss: \u001b[1m\u001b[32m1.20523\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5882 | loss: 1.20523 - acc: 0.7564 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5883  | total loss: \u001b[1m\u001b[32m1.11321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5883 | loss: 1.11321 - acc: 0.7808 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5884  | total loss: \u001b[1m\u001b[32m1.02989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5884 | loss: 1.02989 - acc: 0.8027 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5885  | total loss: \u001b[1m\u001b[32m0.95418\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5885 | loss: 0.95418 - acc: 0.8224 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5886  | total loss: \u001b[1m\u001b[32m1.20691\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5886 | loss: 1.20691 - acc: 0.7616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5887  | total loss: \u001b[1m\u001b[32m1.11246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5887 | loss: 1.11246 - acc: 0.7855 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5888  | total loss: \u001b[1m\u001b[32m1.41647\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5888 | loss: 1.41647 - acc: 0.7069 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5889  | total loss: \u001b[1m\u001b[32m1.30126\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5889 | loss: 1.30126 - acc: 0.7362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5890  | total loss: \u001b[1m\u001b[32m1.19783\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5890 | loss: 1.19783 - acc: 0.7626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5891  | total loss: \u001b[1m\u001b[32m1.10473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5891 | loss: 1.10473 - acc: 0.7863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5892  | total loss: \u001b[1m\u001b[32m1.37734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5892 | loss: 1.37734 - acc: 0.7148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5893  | total loss: \u001b[1m\u001b[32m1.26657\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5893 | loss: 1.26657 - acc: 0.7434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5894  | total loss: \u001b[1m\u001b[32m1.54519\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5894 | loss: 1.54519 - acc: 0.6690 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5895  | total loss: \u001b[1m\u001b[32m1.41895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5895 | loss: 1.41895 - acc: 0.7021 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5896  | total loss: \u001b[1m\u001b[32m1.30604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5896 | loss: 1.30604 - acc: 0.7319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5897  | total loss: \u001b[1m\u001b[32m1.20478\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5897 | loss: 1.20478 - acc: 0.7587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5898  | total loss: \u001b[1m\u001b[32m1.11369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5898 | loss: 1.11369 - acc: 0.7828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5899  | total loss: \u001b[1m\u001b[32m1.03144\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5899 | loss: 1.03144 - acc: 0.8046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5900  | total loss: \u001b[1m\u001b[32m1.32884\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5900 | loss: 1.32884 - acc: 0.7241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5901  | total loss: \u001b[1m\u001b[32m1.22495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5901 | loss: 1.22495 - acc: 0.7517 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5902  | total loss: \u001b[1m\u001b[32m1.48149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5902 | loss: 1.48149 - acc: 0.6837 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5903  | total loss: \u001b[1m\u001b[32m1.36330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5903 | loss: 1.36330 - acc: 0.7153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5904  | total loss: \u001b[1m\u001b[32m1.55442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5904 | loss: 1.55442 - acc: 0.6581 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5905  | total loss: \u001b[1m\u001b[32m1.43065\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5905 | loss: 1.43065 - acc: 0.6923 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5906  | total loss: \u001b[1m\u001b[32m1.60978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5906 | loss: 1.60978 - acc: 0.6445 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5907  | total loss: \u001b[1m\u001b[32m1.48246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5907 | loss: 1.48246 - acc: 0.6800 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5908  | total loss: \u001b[1m\u001b[32m1.69611\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5908 | loss: 1.69611 - acc: 0.6192 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5909  | total loss: \u001b[1m\u001b[32m1.56248\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5909 | loss: 1.56248 - acc: 0.6572 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5910  | total loss: \u001b[1m\u001b[32m1.44328\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5910 | loss: 1.44328 - acc: 0.6915 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5911  | total loss: \u001b[1m\u001b[32m1.33658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5911 | loss: 1.33658 - acc: 0.7224 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5912  | total loss: \u001b[1m\u001b[32m1.24068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5912 | loss: 1.24068 - acc: 0.7501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5913  | total loss: \u001b[1m\u001b[32m1.15410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5913 | loss: 1.15410 - acc: 0.7751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5914  | total loss: \u001b[1m\u001b[32m1.07553\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5914 | loss: 1.07553 - acc: 0.7976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5915  | total loss: \u001b[1m\u001b[32m1.00386\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5915 | loss: 1.00386 - acc: 0.8178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5916  | total loss: \u001b[1m\u001b[32m1.28196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5916 | loss: 1.28196 - acc: 0.7432 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5917  | total loss: \u001b[1m\u001b[32m1.18823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5917 | loss: 1.18823 - acc: 0.7689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5918  | total loss: \u001b[1m\u001b[32m1.42533\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5918 | loss: 1.42533 - acc: 0.6991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5919  | total loss: \u001b[1m\u001b[32m1.31706\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5919 | loss: 1.31706 - acc: 0.7292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5920  | total loss: \u001b[1m\u001b[32m1.52955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5920 | loss: 1.52955 - acc: 0.6634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5921  | total loss: \u001b[1m\u001b[32m1.41151\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5921 | loss: 1.41151 - acc: 0.6971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5922  | total loss: \u001b[1m\u001b[32m1.60722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5922 | loss: 1.60722 - acc: 0.6417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5923  | total loss: \u001b[1m\u001b[32m1.48276\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5923 | loss: 1.48276 - acc: 0.6775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5924  | total loss: \u001b[1m\u001b[32m1.37135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5924 | loss: 1.37135 - acc: 0.7098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5925  | total loss: \u001b[1m\u001b[32m1.27125\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5925 | loss: 1.27125 - acc: 0.7388 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5926  | total loss: \u001b[1m\u001b[32m1.52468\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5926 | loss: 1.52468 - acc: 0.6649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5927  | total loss: \u001b[1m\u001b[32m1.40975\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5927 | loss: 1.40975 - acc: 0.6984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5928  | total loss: \u001b[1m\u001b[32m1.64992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5928 | loss: 1.64992 - acc: 0.6286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5929  | total loss: \u001b[1m\u001b[32m1.52396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5929 | loss: 1.52396 - acc: 0.6657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5930  | total loss: \u001b[1m\u001b[32m1.73035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5930 | loss: 1.73035 - acc: 0.6063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5931  | total loss: \u001b[1m\u001b[32m1.59860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5931 | loss: 1.59860 - acc: 0.6457 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5932  | total loss: \u001b[1m\u001b[32m1.81856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5932 | loss: 1.81856 - acc: 0.5811 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5933  | total loss: \u001b[1m\u001b[32m1.68070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5933 | loss: 1.68070 - acc: 0.6230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5934  | total loss: \u001b[1m\u001b[32m1.88557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5934 | loss: 1.88557 - acc: 0.5607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5935  | total loss: \u001b[1m\u001b[32m1.74413\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5935 | loss: 1.74413 - acc: 0.6046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5936  | total loss: \u001b[1m\u001b[32m1.91832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5936 | loss: 1.91832 - acc: 0.5513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5937  | total loss: \u001b[1m\u001b[32m1.77698\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5937 | loss: 1.77698 - acc: 0.5962 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5938  | total loss: \u001b[1m\u001b[32m1.93834\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5938 | loss: 1.93834 - acc: 0.5366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5939  | total loss: \u001b[1m\u001b[32m1.79845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5939 | loss: 1.79845 - acc: 0.5829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5940  | total loss: \u001b[1m\u001b[32m1.97478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5940 | loss: 1.97478 - acc: 0.5246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5941  | total loss: \u001b[1m\u001b[32m1.83473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5941 | loss: 1.83473 - acc: 0.5721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5942  | total loss: \u001b[1m\u001b[32m1.99853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5942 | loss: 1.99853 - acc: 0.5149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5943  | total loss: \u001b[1m\u001b[32m1.85954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5943 | loss: 1.85954 - acc: 0.5634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5944  | total loss: \u001b[1m\u001b[32m2.00673\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5944 | loss: 2.00673 - acc: 0.5142 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 5945  | total loss: \u001b[1m\u001b[32m1.87013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5945 | loss: 1.87013 - acc: 0.5628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5946  | total loss: \u001b[1m\u001b[32m1.74825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5946 | loss: 1.74825 - acc: 0.6065 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5947  | total loss: \u001b[1m\u001b[32m1.63875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5947 | loss: 1.63875 - acc: 0.6459 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5948  | total loss: \u001b[1m\u001b[32m1.80747\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5948 | loss: 1.80747 - acc: 0.5884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5949  | total loss: \u001b[1m\u001b[32m1.69166\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5949 | loss: 1.69166 - acc: 0.6296 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5950  | total loss: \u001b[1m\u001b[32m1.84189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5950 | loss: 1.84189 - acc: 0.5738 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5951  | total loss: \u001b[1m\u001b[32m1.72229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5951 | loss: 1.72229 - acc: 0.6164 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5952  | total loss: \u001b[1m\u001b[32m1.61410\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5952 | loss: 1.61410 - acc: 0.6548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5953  | total loss: \u001b[1m\u001b[32m1.51550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5953 | loss: 1.51550 - acc: 0.6893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5954  | total loss: \u001b[1m\u001b[32m1.42496\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5954 | loss: 1.42496 - acc: 0.7204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5955  | total loss: \u001b[1m\u001b[32m1.34117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5955 | loss: 1.34117 - acc: 0.7483 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5956  | total loss: \u001b[1m\u001b[32m1.26309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5956 | loss: 1.26309 - acc: 0.7735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5957  | total loss: \u001b[1m\u001b[32m1.18983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5957 | loss: 1.18983 - acc: 0.7961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5958  | total loss: \u001b[1m\u001b[32m1.12071\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5958 | loss: 1.12071 - acc: 0.8165 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5959  | total loss: \u001b[1m\u001b[32m1.05520\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5959 | loss: 1.05520 - acc: 0.8349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5960  | total loss: \u001b[1m\u001b[32m1.30994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5960 | loss: 1.30994 - acc: 0.7514 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5961  | total loss: \u001b[1m\u001b[32m1.22014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5961 | loss: 1.22014 - acc: 0.7762 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5962  | total loss: \u001b[1m\u001b[32m1.49553\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5962 | loss: 1.49553 - acc: 0.6986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5963  | total loss: \u001b[1m\u001b[32m1.38408\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5963 | loss: 1.38408 - acc: 0.7288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5964  | total loss: \u001b[1m\u001b[32m1.59977\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5964 | loss: 1.59977 - acc: 0.6702 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5965  | total loss: \u001b[1m\u001b[32m1.47638\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5965 | loss: 1.47638 - acc: 0.7032 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5966  | total loss: \u001b[1m\u001b[32m1.36469\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5966 | loss: 1.36469 - acc: 0.7328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5967  | total loss: \u001b[1m\u001b[32m1.26323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5967 | loss: 1.26323 - acc: 0.7596 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5968  | total loss: \u001b[1m\u001b[32m1.17074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5968 | loss: 1.17074 - acc: 0.7836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5969  | total loss: \u001b[1m\u001b[32m1.08612\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5969 | loss: 1.08612 - acc: 0.8052 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5970  | total loss: \u001b[1m\u001b[32m1.36051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5970 | loss: 1.36051 - acc: 0.7247 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5971  | total loss: \u001b[1m\u001b[32m1.25495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5971 | loss: 1.25495 - acc: 0.7522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5972  | total loss: \u001b[1m\u001b[32m1.51916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5972 | loss: 1.51916 - acc: 0.6842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5973  | total loss: \u001b[1m\u001b[32m1.39726\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5973 | loss: 1.39726 - acc: 0.7157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5974  | total loss: \u001b[1m\u001b[32m1.58391\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5974 | loss: 1.58391 - acc: 0.6656 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5975  | total loss: \u001b[1m\u001b[32m1.45606\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5975 | loss: 1.45606 - acc: 0.6990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5976  | total loss: \u001b[1m\u001b[32m1.59950\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5976 | loss: 1.59950 - acc: 0.6577 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5977  | total loss: \u001b[1m\u001b[32m1.47122\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5977 | loss: 1.47122 - acc: 0.6919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5978  | total loss: \u001b[1m\u001b[32m1.73844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5978 | loss: 1.73844 - acc: 0.6227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5979  | total loss: \u001b[1m\u001b[32m1.59812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5979 | loss: 1.59812 - acc: 0.6605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5980  | total loss: \u001b[1m\u001b[32m1.81626\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5980 | loss: 1.81626 - acc: 0.6016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5981  | total loss: \u001b[1m\u001b[32m1.67078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5981 | loss: 1.67078 - acc: 0.6414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5982  | total loss: \u001b[1m\u001b[32m1.90432\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5982 | loss: 1.90432 - acc: 0.5773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5983  | total loss: \u001b[1m\u001b[32m1.75319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5983 | loss: 1.75319 - acc: 0.6195 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5984  | total loss: \u001b[1m\u001b[32m1.61856\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5984 | loss: 1.61856 - acc: 0.6576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5985  | total loss: \u001b[1m\u001b[32m1.49822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5985 | loss: 1.49822 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5986  | total loss: \u001b[1m\u001b[32m1.67062\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5986 | loss: 1.67062 - acc: 0.6369 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5987  | total loss: \u001b[1m\u001b[32m1.54630\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5987 | loss: 1.54630 - acc: 0.6732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5988  | total loss: \u001b[1m\u001b[32m1.70260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5988 | loss: 1.70260 - acc: 0.6273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5989  | total loss: \u001b[1m\u001b[32m1.57642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5989 | loss: 1.57642 - acc: 0.6646 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5990  | total loss: \u001b[1m\u001b[32m1.71460\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5990 | loss: 1.71460 - acc: 0.6196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5991  | total loss: \u001b[1m\u001b[32m1.58855\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5991 | loss: 1.58855 - acc: 0.6576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5992  | total loss: \u001b[1m\u001b[32m1.81278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5992 | loss: 1.81278 - acc: 0.5919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5993  | total loss: \u001b[1m\u001b[32m1.67851\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5993 | loss: 1.67851 - acc: 0.6327 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5994  | total loss: \u001b[1m\u001b[32m1.55829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5994 | loss: 1.55829 - acc: 0.6694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5995  | total loss: \u001b[1m\u001b[32m1.45015\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5995 | loss: 1.45015 - acc: 0.7025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5996  | total loss: \u001b[1m\u001b[32m1.59836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5996 | loss: 1.59836 - acc: 0.6536 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5997  | total loss: \u001b[1m\u001b[32m1.48596\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5997 | loss: 1.48596 - acc: 0.6883 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5998  | total loss: \u001b[1m\u001b[32m1.38445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 5998 | loss: 1.38445 - acc: 0.7195 -- iter: 14/14\n",
      "--\n",
      "Training Step: 5999  | total loss: \u001b[1m\u001b[32m1.29230\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 5999 | loss: 1.29230 - acc: 0.7475 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6000  | total loss: \u001b[1m\u001b[32m1.52387\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6000 | loss: 1.52387 - acc: 0.6728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6001  | total loss: \u001b[1m\u001b[32m1.41635\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6001 | loss: 1.41635 - acc: 0.7055 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6002  | total loss: \u001b[1m\u001b[32m1.31890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6002 | loss: 1.31890 - acc: 0.7349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6003  | total loss: \u001b[1m\u001b[32m1.23014\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6003 | loss: 1.23014 - acc: 0.7614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6004  | total loss: \u001b[1m\u001b[32m1.14887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6004 | loss: 1.14887 - acc: 0.7853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6005  | total loss: \u001b[1m\u001b[32m1.07408\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6005 | loss: 1.07408 - acc: 0.8068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6006  | total loss: \u001b[1m\u001b[32m1.00490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6006 | loss: 1.00490 - acc: 0.8261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6007  | total loss: \u001b[1m\u001b[32m0.94063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6007 | loss: 0.94063 - acc: 0.8435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6008  | total loss: \u001b[1m\u001b[32m0.88068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6008 | loss: 0.88068 - acc: 0.8591 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6009  | total loss: \u001b[1m\u001b[32m0.82456\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6009 | loss: 0.82456 - acc: 0.8732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6010  | total loss: \u001b[1m\u001b[32m0.77187\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6010 | loss: 0.77187 - acc: 0.8859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6011  | total loss: \u001b[1m\u001b[32m0.72231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6011 | loss: 0.72231 - acc: 0.8973 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6012  | total loss: \u001b[1m\u001b[32m1.04928\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6012 | loss: 1.04928 - acc: 0.8147 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6013  | total loss: \u001b[1m\u001b[32m0.96891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6013 | loss: 0.96891 - acc: 0.8332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6014  | total loss: \u001b[1m\u001b[32m1.29026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6014 | loss: 1.29026 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6015  | total loss: \u001b[1m\u001b[32m1.18460\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6015 | loss: 1.18460 - acc: 0.7749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6016  | total loss: \u001b[1m\u001b[32m1.08919\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6016 | loss: 1.08919 - acc: 0.7974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6017  | total loss: \u001b[1m\u001b[32m1.00285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6017 | loss: 1.00285 - acc: 0.8177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6018  | total loss: \u001b[1m\u001b[32m1.25346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6018 | loss: 1.25346 - acc: 0.7502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6019  | total loss: \u001b[1m\u001b[32m1.15017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6019 | loss: 1.15017 - acc: 0.7752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6020  | total loss: \u001b[1m\u001b[32m1.46102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6020 | loss: 1.46102 - acc: 0.6977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6021  | total loss: \u001b[1m\u001b[32m1.33759\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6021 | loss: 1.33759 - acc: 0.7279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6022  | total loss: \u001b[1m\u001b[32m1.57214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6022 | loss: 1.57214 - acc: 0.6694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6023  | total loss: \u001b[1m\u001b[32m1.43916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6023 | loss: 1.43916 - acc: 0.7025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6024  | total loss: \u001b[1m\u001b[32m1.68771\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6024 | loss: 1.68771 - acc: 0.6394 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6025  | total loss: \u001b[1m\u001b[32m1.54552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6025 | loss: 1.54552 - acc: 0.6754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6026  | total loss: \u001b[1m\u001b[32m1.74958\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6026 | loss: 1.74958 - acc: 0.6150 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6027  | total loss: \u001b[1m\u001b[32m1.60430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6027 | loss: 1.60430 - acc: 0.6535 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6028  | total loss: \u001b[1m\u001b[32m1.83706\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6028 | loss: 1.83706 - acc: 0.5882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6029  | total loss: \u001b[1m\u001b[32m1.68680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6029 | loss: 1.68680 - acc: 0.6294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6030  | total loss: \u001b[1m\u001b[32m1.55335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6030 | loss: 1.55335 - acc: 0.6664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6031  | total loss: \u001b[1m\u001b[32m1.43453\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6031 | loss: 1.43453 - acc: 0.6998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6032  | total loss: \u001b[1m\u001b[32m1.63705\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6032 | loss: 1.63705 - acc: 0.6441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6033  | total loss: \u001b[1m\u001b[32m1.51213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6033 | loss: 1.51213 - acc: 0.6797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6034  | total loss: \u001b[1m\u001b[32m1.70074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6034 | loss: 1.70074 - acc: 0.6260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6035  | total loss: \u001b[1m\u001b[32m1.57202\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6035 | loss: 1.57202 - acc: 0.6634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6036  | total loss: \u001b[1m\u001b[32m1.45722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6036 | loss: 1.45722 - acc: 0.6971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6037  | total loss: \u001b[1m\u001b[32m1.35439\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6037 | loss: 1.35439 - acc: 0.7273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6038  | total loss: \u001b[1m\u001b[32m1.54668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6038 | loss: 1.54668 - acc: 0.6689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6039  | total loss: \u001b[1m\u001b[32m1.43564\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6039 | loss: 1.43564 - acc: 0.7020 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6040  | total loss: \u001b[1m\u001b[32m1.66674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6040 | loss: 1.66674 - acc: 0.6318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6041  | total loss: \u001b[1m\u001b[32m1.54496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6041 | loss: 1.54496 - acc: 0.6686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6042  | total loss: \u001b[1m\u001b[32m1.70409\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6042 | loss: 1.70409 - acc: 0.6161 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6043  | total loss: \u001b[1m\u001b[32m1.58019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6043 | loss: 1.58019 - acc: 0.6544 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6044  | total loss: \u001b[1m\u001b[32m1.80584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6044 | loss: 1.80584 - acc: 0.5890 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6045  | total loss: \u001b[1m\u001b[32m1.67376\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6045 | loss: 1.67376 - acc: 0.6301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6046  | total loss: \u001b[1m\u001b[32m1.87035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6046 | loss: 1.87035 - acc: 0.5671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6047  | total loss: \u001b[1m\u001b[32m1.73424\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 6047 | loss: 1.73424 - acc: 0.6104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6048  | total loss: \u001b[1m\u001b[32m1.93787\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6048 | loss: 1.93787 - acc: 0.5493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6049  | total loss: \u001b[1m\u001b[32m1.79771\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6049 | loss: 1.79771 - acc: 0.5944 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6050  | total loss: \u001b[1m\u001b[32m1.89509\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6050 | loss: 1.89509 - acc: 0.5564 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6051  | total loss: \u001b[1m\u001b[32m1.76176\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6051 | loss: 1.76176 - acc: 0.6008 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6052  | total loss: \u001b[1m\u001b[32m1.91375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6052 | loss: 1.91375 - acc: 0.5478 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6053  | total loss: \u001b[1m\u001b[32m1.78088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6053 | loss: 1.78088 - acc: 0.5930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6054  | total loss: \u001b[1m\u001b[32m1.93545\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6054 | loss: 1.93545 - acc: 0.5337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6055  | total loss: \u001b[1m\u001b[32m1.80278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6055 | loss: 1.80278 - acc: 0.5804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6056  | total loss: \u001b[1m\u001b[32m1.68415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6056 | loss: 1.68415 - acc: 0.6223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6057  | total loss: \u001b[1m\u001b[32m1.57740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6057 | loss: 1.57740 - acc: 0.6601 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6058  | total loss: \u001b[1m\u001b[32m1.74096\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6058 | loss: 1.74096 - acc: 0.6012 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6059  | total loss: \u001b[1m\u001b[32m1.62796\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6059 | loss: 1.62796 - acc: 0.6411 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6060  | total loss: \u001b[1m\u001b[32m1.81583\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6060 | loss: 1.81583 - acc: 0.5770 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6061  | total loss: \u001b[1m\u001b[32m1.69506\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6061 | loss: 1.69506 - acc: 0.6193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6062  | total loss: \u001b[1m\u001b[32m1.83454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6062 | loss: 1.83454 - acc: 0.5645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6063  | total loss: \u001b[1m\u001b[32m1.71180\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6063 | loss: 1.71180 - acc: 0.6081 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6064  | total loss: \u001b[1m\u001b[32m1.60094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6064 | loss: 1.60094 - acc: 0.6473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6065  | total loss: \u001b[1m\u001b[32m1.50016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6065 | loss: 1.50016 - acc: 0.6825 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6066  | total loss: \u001b[1m\u001b[32m1.40789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6066 | loss: 1.40789 - acc: 0.7143 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6067  | total loss: \u001b[1m\u001b[32m1.32283\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6067 | loss: 1.32283 - acc: 0.7428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6068  | total loss: \u001b[1m\u001b[32m1.24388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6068 | loss: 1.24388 - acc: 0.7686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6069  | total loss: \u001b[1m\u001b[32m1.17014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6069 | loss: 1.17014 - acc: 0.7917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6070  | total loss: \u001b[1m\u001b[32m1.42066\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6070 | loss: 1.42066 - acc: 0.7125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6071  | total loss: \u001b[1m\u001b[32m1.32473\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6071 | loss: 1.32473 - acc: 0.7413 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6072  | total loss: \u001b[1m\u001b[32m1.23647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6072 | loss: 1.23647 - acc: 0.7672 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6073  | total loss: \u001b[1m\u001b[32m1.15490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6073 | loss: 1.15490 - acc: 0.7904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6074  | total loss: \u001b[1m\u001b[32m1.07918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6074 | loss: 1.07918 - acc: 0.8114 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6075  | total loss: \u001b[1m\u001b[32m1.00863\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6075 | loss: 1.00863 - acc: 0.8303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6076  | total loss: \u001b[1m\u001b[32m0.94268\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6076 | loss: 0.94268 - acc: 0.8472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6077  | total loss: \u001b[1m\u001b[32m0.88087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6077 | loss: 0.88087 - acc: 0.8625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6078  | total loss: \u001b[1m\u001b[32m1.15495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6078 | loss: 1.15495 - acc: 0.7834 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6079  | total loss: \u001b[1m\u001b[32m1.06819\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6079 | loss: 1.06819 - acc: 0.8051 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6080  | total loss: \u001b[1m\u001b[32m0.98869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6080 | loss: 0.98869 - acc: 0.8246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6081  | total loss: \u001b[1m\u001b[32m0.91567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6081 | loss: 0.91567 - acc: 0.8421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6082  | total loss: \u001b[1m\u001b[32m0.84845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6082 | loss: 0.84845 - acc: 0.8579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6083  | total loss: \u001b[1m\u001b[32m0.78645\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6083 | loss: 0.78645 - acc: 0.8721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6084  | total loss: \u001b[1m\u001b[32m1.09648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6084 | loss: 1.09648 - acc: 0.7992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6085  | total loss: \u001b[1m\u001b[32m1.00764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6085 | loss: 1.00764 - acc: 0.8193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6086  | total loss: \u001b[1m\u001b[32m1.29289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6086 | loss: 1.29289 - acc: 0.7445 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6087  | total loss: \u001b[1m\u001b[32m1.18383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6087 | loss: 1.18383 - acc: 0.7700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6088  | total loss: \u001b[1m\u001b[32m1.08560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6088 | loss: 1.08560 - acc: 0.7930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6089  | total loss: \u001b[1m\u001b[32m0.99697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6089 | loss: 0.99697 - acc: 0.8137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6090  | total loss: \u001b[1m\u001b[32m1.28337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6090 | loss: 1.28337 - acc: 0.7466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6091  | total loss: \u001b[1m\u001b[32m1.17494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6091 | loss: 1.17494 - acc: 0.7720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6092  | total loss: \u001b[1m\u001b[32m1.07751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6092 | loss: 1.07751 - acc: 0.7948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6093  | total loss: \u001b[1m\u001b[32m0.98980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6093 | loss: 0.98980 - acc: 0.8153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6094  | total loss: \u001b[1m\u001b[32m1.31275\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6094 | loss: 1.31275 - acc: 0.7338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6095  | total loss: \u001b[1m\u001b[32m1.20192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6095 | loss: 1.20192 - acc: 0.7604 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6096  | total loss: \u001b[1m\u001b[32m1.49584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6096 | loss: 1.49584 - acc: 0.6844 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6097  | total loss: \u001b[1m\u001b[32m1.36820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6097 | loss: 1.36820 - acc: 0.7159 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6098  | total loss: \u001b[1m\u001b[32m1.25421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6098 | loss: 1.25421 - acc: 0.7443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6099  | total loss: \u001b[1m\u001b[32m1.15224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6099 | loss: 1.15224 - acc: 0.7699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6100  | total loss: \u001b[1m\u001b[32m1.45543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6100 | loss: 1.45543 - acc: 0.6929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6101  | total loss: \u001b[1m\u001b[32m1.33482\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6101 | loss: 1.33482 - acc: 0.7236 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6102  | total loss: \u001b[1m\u001b[32m1.56561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6102 | loss: 1.56561 - acc: 0.6655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6103  | total loss: \u001b[1m\u001b[32m1.43629\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6103 | loss: 1.43629 - acc: 0.6990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6104  | total loss: \u001b[1m\u001b[32m1.32104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6104 | loss: 1.32104 - acc: 0.7291 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6105  | total loss: \u001b[1m\u001b[32m1.21810\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6105 | loss: 1.21810 - acc: 0.7562 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6106  | total loss: \u001b[1m\u001b[32m1.50207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6106 | loss: 1.50207 - acc: 0.6806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6107  | total loss: \u001b[1m\u001b[32m1.38270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6107 | loss: 1.38270 - acc: 0.7125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6108  | total loss: \u001b[1m\u001b[32m1.49902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6108 | loss: 1.49902 - acc: 0.6698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6109  | total loss: \u001b[1m\u001b[32m1.38217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6109 | loss: 1.38217 - acc: 0.7028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6110  | total loss: \u001b[1m\u001b[32m1.63055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6110 | loss: 1.63055 - acc: 0.6326 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6111  | total loss: \u001b[1m\u001b[32m1.50326\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6111 | loss: 1.50326 - acc: 0.6693 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6112  | total loss: \u001b[1m\u001b[32m1.73352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6112 | loss: 1.73352 - acc: 0.6095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6113  | total loss: \u001b[1m\u001b[32m1.59927\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6113 | loss: 1.59927 - acc: 0.6486 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6114  | total loss: \u001b[1m\u001b[32m1.81878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6114 | loss: 1.81878 - acc: 0.5837 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6115  | total loss: \u001b[1m\u001b[32m1.67982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6115 | loss: 1.67982 - acc: 0.6253 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6116  | total loss: \u001b[1m\u001b[32m1.55643\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6116 | loss: 1.55643 - acc: 0.6628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6117  | total loss: \u001b[1m\u001b[32m1.44639\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6117 | loss: 1.44639 - acc: 0.6965 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6118  | total loss: \u001b[1m\u001b[32m1.65842\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6118 | loss: 1.65842 - acc: 0.6340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6119  | total loss: \u001b[1m\u001b[32m1.53978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6119 | loss: 1.53978 - acc: 0.6706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6120  | total loss: \u001b[1m\u001b[32m1.67150\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6120 | loss: 1.67150 - acc: 0.6250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6121  | total loss: \u001b[1m\u001b[32m1.55325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6121 | loss: 1.55325 - acc: 0.6625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6122  | total loss: \u001b[1m\u001b[32m1.75127\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6122 | loss: 1.75127 - acc: 0.6034 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6123  | total loss: \u001b[1m\u001b[32m1.62679\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6123 | loss: 1.62679 - acc: 0.6430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6124  | total loss: \u001b[1m\u001b[32m1.51535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6124 | loss: 1.51535 - acc: 0.6787 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6125  | total loss: \u001b[1m\u001b[32m1.41500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6125 | loss: 1.41500 - acc: 0.7109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6126  | total loss: \u001b[1m\u001b[32m1.59303\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6126 | loss: 1.59303 - acc: 0.6541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6127  | total loss: \u001b[1m\u001b[32m1.48446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6127 | loss: 1.48446 - acc: 0.6887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6128  | total loss: \u001b[1m\u001b[32m1.70399\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6128 | loss: 1.70399 - acc: 0.6198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6129  | total loss: \u001b[1m\u001b[32m1.58457\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6129 | loss: 1.58457 - acc: 0.6578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6130  | total loss: \u001b[1m\u001b[32m1.47712\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6130 | loss: 1.47712 - acc: 0.6920 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6131  | total loss: \u001b[1m\u001b[32m1.37987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6131 | loss: 1.37987 - acc: 0.7228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6132  | total loss: \u001b[1m\u001b[32m1.55578\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6132 | loss: 1.55578 - acc: 0.6648 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6133  | total loss: \u001b[1m\u001b[32m1.44944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6133 | loss: 1.44944 - acc: 0.6983 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6134  | total loss: \u001b[1m\u001b[32m1.65516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6134 | loss: 1.65516 - acc: 0.6285 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6135  | total loss: \u001b[1m\u001b[32m1.53839\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6135 | loss: 1.53839 - acc: 0.6657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6136  | total loss: \u001b[1m\u001b[32m1.71302\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6136 | loss: 1.71302 - acc: 0.6062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6137  | total loss: \u001b[1m\u001b[32m1.59054\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6137 | loss: 1.59054 - acc: 0.6456 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6138  | total loss: \u001b[1m\u001b[32m1.76826\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6138 | loss: 1.76826 - acc: 0.5953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6139  | total loss: \u001b[1m\u001b[32m1.64075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6139 | loss: 1.64075 - acc: 0.6358 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6140  | total loss: \u001b[1m\u001b[32m1.52603\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6140 | loss: 1.52603 - acc: 0.6722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6141  | total loss: \u001b[1m\u001b[32m1.42229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6141 | loss: 1.42229 - acc: 0.7050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6142  | total loss: \u001b[1m\u001b[32m1.32794\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6142 | loss: 1.32794 - acc: 0.7345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6143  | total loss: \u001b[1m\u001b[32m1.24163\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6143 | loss: 1.24163 - acc: 0.7611 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6144  | total loss: \u001b[1m\u001b[32m1.46828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6144 | loss: 1.46828 - acc: 0.6921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6145  | total loss: \u001b[1m\u001b[32m1.36554\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6145 | loss: 1.36554 - acc: 0.7229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6146  | total loss: \u001b[1m\u001b[32m1.27202\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6146 | loss: 1.27202 - acc: 0.7506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6147  | total loss: \u001b[1m\u001b[32m1.18644\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6147 | loss: 1.18644 - acc: 0.7755 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6148  | total loss: \u001b[1m\u001b[32m1.42699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6148 | loss: 1.42699 - acc: 0.7051 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6149  | total loss: \u001b[1m\u001b[32m1.32350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6149 | loss: 1.32350 - acc: 0.7346 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6150  | total loss: \u001b[1m\u001b[32m1.58323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6150 | loss: 1.58323 - acc: 0.6611 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6151  | total loss: \u001b[1m\u001b[32m1.46298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6151 | loss: 1.46298 - acc: 0.6950 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6152  | total loss: \u001b[1m\u001b[32m1.68234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6152 | loss: 1.68234 - acc: 0.6327 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6153  | total loss: \u001b[1m\u001b[32m1.55215\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6153 | loss: 1.55215 - acc: 0.6694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6154  | total loss: \u001b[1m\u001b[32m1.77998\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6154 | loss: 1.77998 - acc: 0.6025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6155  | total loss: \u001b[1m\u001b[32m1.64099\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6155 | loss: 1.64099 - acc: 0.6422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6156  | total loss: \u001b[1m\u001b[32m1.82048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6156 | loss: 1.82048 - acc: 0.5851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6157  | total loss: \u001b[1m\u001b[32m1.67922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6157 | loss: 1.67922 - acc: 0.6266 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6158  | total loss: \u001b[1m\u001b[32m1.90561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6158 | loss: 1.90561 - acc: 0.5640 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6159  | total loss: \u001b[1m\u001b[32m1.75823\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6159 | loss: 1.75823 - acc: 0.6076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6160  | total loss: \u001b[1m\u001b[32m1.92324\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6160 | loss: 1.92324 - acc: 0.5540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6161  | total loss: \u001b[1m\u001b[32m1.77692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6161 | loss: 1.77692 - acc: 0.5986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6162  | total loss: \u001b[1m\u001b[32m1.97056\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6162 | loss: 1.97056 - acc: 0.5458 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6163  | total loss: \u001b[1m\u001b[32m1.82257\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6163 | loss: 1.82257 - acc: 0.5913 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6164  | total loss: \u001b[1m\u001b[32m1.97212\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6164 | loss: 1.97212 - acc: 0.5393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6165  | total loss: \u001b[1m\u001b[32m1.82708\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6165 | loss: 1.82708 - acc: 0.5853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6166  | total loss: \u001b[1m\u001b[32m1.69768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6166 | loss: 1.69768 - acc: 0.6268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6167  | total loss: \u001b[1m\u001b[32m1.58167\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6167 | loss: 1.58167 - acc: 0.6641 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6168  | total loss: \u001b[1m\u001b[32m1.47705\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6168 | loss: 1.47705 - acc: 0.6977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6169  | total loss: \u001b[1m\u001b[32m1.38213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6169 | loss: 1.38213 - acc: 0.7279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6170  | total loss: \u001b[1m\u001b[32m1.29543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6170 | loss: 1.29543 - acc: 0.7552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6171  | total loss: \u001b[1m\u001b[32m1.21571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6171 | loss: 1.21571 - acc: 0.7796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6172  | total loss: \u001b[1m\u001b[32m1.39813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6172 | loss: 1.39813 - acc: 0.7231 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6173  | total loss: \u001b[1m\u001b[32m1.30494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6173 | loss: 1.30494 - acc: 0.7508 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6174  | total loss: \u001b[1m\u001b[32m1.50672\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6174 | loss: 1.50672 - acc: 0.6829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6175  | total loss: \u001b[1m\u001b[32m1.40055\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6175 | loss: 1.40055 - acc: 0.7146 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6176  | total loss: \u001b[1m\u001b[32m1.30403\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6176 | loss: 1.30403 - acc: 0.7431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6177  | total loss: \u001b[1m\u001b[32m1.21583\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6177 | loss: 1.21583 - acc: 0.7688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6178  | total loss: \u001b[1m\u001b[32m1.13486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6178 | loss: 1.13486 - acc: 0.7919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6179  | total loss: \u001b[1m\u001b[32m1.06017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6179 | loss: 1.06017 - acc: 0.8127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6180  | total loss: \u001b[1m\u001b[32m1.31905\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6180 | loss: 1.31905 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6181  | total loss: \u001b[1m\u001b[32m1.22313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6181 | loss: 1.22313 - acc: 0.7583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6182  | total loss: \u001b[1m\u001b[32m1.49421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6182 | loss: 1.49421 - acc: 0.6825 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6183  | total loss: \u001b[1m\u001b[32m1.37963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6183 | loss: 1.37963 - acc: 0.7142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6184  | total loss: \u001b[1m\u001b[32m1.27610\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6184 | loss: 1.27610 - acc: 0.7428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6185  | total loss: \u001b[1m\u001b[32m1.18223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6185 | loss: 1.18223 - acc: 0.7685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6186  | total loss: \u001b[1m\u001b[32m1.42653\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6186 | loss: 1.42653 - acc: 0.6988 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6187  | total loss: \u001b[1m\u001b[32m1.31666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6187 | loss: 1.31666 - acc: 0.7289 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6188  | total loss: \u001b[1m\u001b[32m1.57313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6188 | loss: 1.57313 - acc: 0.6560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6189  | total loss: \u001b[1m\u001b[32m1.44887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6189 | loss: 1.44887 - acc: 0.6904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6190  | total loss: \u001b[1m\u001b[32m1.33723\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6190 | loss: 1.33723 - acc: 0.7214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6191  | total loss: \u001b[1m\u001b[32m1.23661\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6191 | loss: 1.23661 - acc: 0.7493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6192  | total loss: \u001b[1m\u001b[32m1.47165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6192 | loss: 1.47165 - acc: 0.6886 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6193  | total loss: \u001b[1m\u001b[32m1.35746\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6193 | loss: 1.35746 - acc: 0.7198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6194  | total loss: \u001b[1m\u001b[32m1.25467\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6194 | loss: 1.25467 - acc: 0.7478 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6195  | total loss: \u001b[1m\u001b[32m1.16182\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6195 | loss: 1.16182 - acc: 0.7730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6196  | total loss: \u001b[1m\u001b[32m1.42586\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6196 | loss: 1.42586 - acc: 0.6957 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6197  | total loss: \u001b[1m\u001b[32m1.31551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6197 | loss: 1.31551 - acc: 0.7261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6198  | total loss: \u001b[1m\u001b[32m1.55624\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6198 | loss: 1.55624 - acc: 0.6607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6199  | total loss: \u001b[1m\u001b[32m1.43350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6199 | loss: 1.43350 - acc: 0.6946 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6200  | total loss: \u001b[1m\u001b[32m1.32336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6200 | loss: 1.32336 - acc: 0.7251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6201  | total loss: \u001b[1m\u001b[32m1.22421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6201 | loss: 1.22421 - acc: 0.7526 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6202  | total loss: \u001b[1m\u001b[32m1.48928\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6202 | loss: 1.48928 - acc: 0.6845 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6203  | total loss: \u001b[1m\u001b[32m1.37373\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6203 | loss: 1.37373 - acc: 0.7161 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6204  | total loss: \u001b[1m\u001b[32m1.26991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6204 | loss: 1.26991 - acc: 0.7444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6205  | total loss: \u001b[1m\u001b[32m1.17629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6205 | loss: 1.17629 - acc: 0.7700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6206  | total loss: \u001b[1m\u001b[32m1.45435\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6206 | loss: 1.45435 - acc: 0.6930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6207  | total loss: \u001b[1m\u001b[32m1.34224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6207 | loss: 1.34224 - acc: 0.7237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6208  | total loss: \u001b[1m\u001b[32m1.58609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6208 | loss: 1.58609 - acc: 0.6513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6209  | total loss: \u001b[1m\u001b[32m1.46191\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6209 | loss: 1.46191 - acc: 0.6862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6210  | total loss: \u001b[1m\u001b[32m1.66993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6210 | loss: 1.66993 - acc: 0.6247 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6211  | total loss: \u001b[1m\u001b[32m1.53932\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6211 | loss: 1.53932 - acc: 0.6622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6212  | total loss: \u001b[1m\u001b[32m1.72306\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6212 | loss: 1.72306 - acc: 0.6103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6213  | total loss: \u001b[1m\u001b[32m1.58952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6213 | loss: 1.58952 - acc: 0.6493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6214  | total loss: \u001b[1m\u001b[32m1.78524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6214 | loss: 1.78524 - acc: 0.5915 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6215  | total loss: \u001b[1m\u001b[32m1.64819\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6215 | loss: 1.64819 - acc: 0.6323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6216  | total loss: \u001b[1m\u001b[32m1.52603\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6216 | loss: 1.52603 - acc: 0.6691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6217  | total loss: \u001b[1m\u001b[32m1.41668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6217 | loss: 1.41668 - acc: 0.7022 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6218  | total loss: \u001b[1m\u001b[32m1.60788\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6218 | loss: 1.60788 - acc: 0.6391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6219  | total loss: \u001b[1m\u001b[32m1.49130\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6219 | loss: 1.49130 - acc: 0.6752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6220  | total loss: \u001b[1m\u001b[32m1.68401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6220 | loss: 1.68401 - acc: 0.6148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6221  | total loss: \u001b[1m\u001b[32m1.56124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6221 | loss: 1.56124 - acc: 0.6533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6222  | total loss: \u001b[1m\u001b[32m1.73711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6222 | loss: 1.73711 - acc: 0.5952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6223  | total loss: \u001b[1m\u001b[32m1.61078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6223 | loss: 1.61078 - acc: 0.6356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6224  | total loss: \u001b[1m\u001b[32m1.78753\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6224 | loss: 1.78753 - acc: 0.5792 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6225  | total loss: \u001b[1m\u001b[32m1.65816\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6225 | loss: 1.65816 - acc: 0.6213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6226  | total loss: \u001b[1m\u001b[32m1.82456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6226 | loss: 1.82456 - acc: 0.5663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6227  | total loss: \u001b[1m\u001b[32m1.69372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6227 | loss: 1.69372 - acc: 0.6097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6228  | total loss: \u001b[1m\u001b[32m1.81412\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6228 | loss: 1.81412 - acc: 0.5701 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6229  | total loss: \u001b[1m\u001b[32m1.68642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6229 | loss: 1.68642 - acc: 0.6131 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6230  | total loss: \u001b[1m\u001b[32m1.82057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6230 | loss: 1.82057 - acc: 0.5661 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6231  | total loss: \u001b[1m\u001b[32m1.69400\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6231 | loss: 1.69400 - acc: 0.6095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6232  | total loss: \u001b[1m\u001b[32m1.88063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6232 | loss: 1.88063 - acc: 0.5485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6233  | total loss: \u001b[1m\u001b[32m1.74985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6233 | loss: 1.74985 - acc: 0.5937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6234  | total loss: \u001b[1m\u001b[32m1.63271\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6234 | loss: 1.63271 - acc: 0.6343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6235  | total loss: \u001b[1m\u001b[32m1.52713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6235 | loss: 1.52713 - acc: 0.6709 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6236  | total loss: \u001b[1m\u001b[32m1.73014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6236 | loss: 1.73014 - acc: 0.6038 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6237  | total loss: \u001b[1m\u001b[32m1.61422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6237 | loss: 1.61422 - acc: 0.6434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6238  | total loss: \u001b[1m\u001b[32m1.77669\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6238 | loss: 1.77669 - acc: 0.5934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6239  | total loss: \u001b[1m\u001b[32m1.65587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6239 | loss: 1.65587 - acc: 0.6340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6240  | total loss: \u001b[1m\u001b[32m1.79294\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6240 | loss: 1.79294 - acc: 0.5921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6241  | total loss: \u001b[1m\u001b[32m1.67030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6241 | loss: 1.67030 - acc: 0.6328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6242  | total loss: \u001b[1m\u001b[32m1.80790\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6242 | loss: 1.80790 - acc: 0.5838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6243  | total loss: \u001b[1m\u001b[32m1.68366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6243 | loss: 1.68366 - acc: 0.6255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6244  | total loss: \u001b[1m\u001b[32m1.57151\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6244 | loss: 1.57151 - acc: 0.6629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6245  | total loss: \u001b[1m\u001b[32m1.46964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6245 | loss: 1.46964 - acc: 0.6966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6246  | total loss: \u001b[1m\u001b[32m1.37651\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6246 | loss: 1.37651 - acc: 0.7270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6247  | total loss: \u001b[1m\u001b[32m1.29080\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6247 | loss: 1.29080 - acc: 0.7543 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6248  | total loss: \u001b[1m\u001b[32m1.48725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6248 | loss: 1.48725 - acc: 0.6931 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6249  | total loss: \u001b[1m\u001b[32m1.38692\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6249 | loss: 1.38692 - acc: 0.7238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6250  | total loss: \u001b[1m\u001b[32m1.29492\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6250 | loss: 1.29492 - acc: 0.7514 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6251  | total loss: \u001b[1m\u001b[32m1.21013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6251 | loss: 1.21013 - acc: 0.7763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6252  | total loss: \u001b[1m\u001b[32m1.13160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6252 | loss: 1.13160 - acc: 0.7987 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6253  | total loss: \u001b[1m\u001b[32m1.05853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6253 | loss: 1.05853 - acc: 0.8188 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6254  | total loss: \u001b[1m\u001b[32m1.33416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6254 | loss: 1.33416 - acc: 0.7369 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6255  | total loss: \u001b[1m\u001b[32m1.23709\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6255 | loss: 1.23709 - acc: 0.7632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6256  | total loss: \u001b[1m\u001b[32m1.14826\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6256 | loss: 1.14826 - acc: 0.7869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6257  | total loss: \u001b[1m\u001b[32m1.06668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6257 | loss: 1.06668 - acc: 0.8082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6258  | total loss: \u001b[1m\u001b[32m1.38013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6258 | loss: 1.38013 - acc: 0.7274 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6259  | total loss: \u001b[1m\u001b[32m1.27302\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6259 | loss: 1.27302 - acc: 0.7547 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6260  | total loss: \u001b[1m\u001b[32m1.48150\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6260 | loss: 1.48150 - acc: 0.6935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6261  | total loss: \u001b[1m\u001b[32m1.36345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6261 | loss: 1.36345 - acc: 0.7241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6262  | total loss: \u001b[1m\u001b[32m1.52699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6262 | loss: 1.52699 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6263  | total loss: \u001b[1m\u001b[32m1.40450\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6263 | loss: 1.40450 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6264  | total loss: \u001b[1m\u001b[32m1.64574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6264 | loss: 1.64574 - acc: 0.6424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6265  | total loss: \u001b[1m\u001b[32m1.51240\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6265 | loss: 1.51240 - acc: 0.6781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6266  | total loss: \u001b[1m\u001b[32m1.39298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6266 | loss: 1.39298 - acc: 0.7103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6267  | total loss: \u001b[1m\u001b[32m1.28571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6267 | loss: 1.28571 - acc: 0.7393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6268  | total loss: \u001b[1m\u001b[32m1.18905\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6268 | loss: 1.18905 - acc: 0.7654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6269  | total loss: \u001b[1m\u001b[32m1.10164\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6269 | loss: 1.10164 - acc: 0.7888 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6270  | total loss: \u001b[1m\u001b[32m1.02228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6270 | loss: 1.02228 - acc: 0.8099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6271  | total loss: \u001b[1m\u001b[32m0.94994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6271 | loss: 0.94994 - acc: 0.8290 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6272  | total loss: \u001b[1m\u001b[32m0.88373\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6272 | loss: 0.88373 - acc: 0.8461 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6273  | total loss: \u001b[1m\u001b[32m0.82289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6273 | loss: 0.82289 - acc: 0.8615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6274  | total loss: \u001b[1m\u001b[32m1.10815\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6274 | loss: 1.10815 - acc: 0.7896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6275  | total loss: \u001b[1m\u001b[32m1.02296\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6275 | loss: 1.02296 - acc: 0.8106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6276  | total loss: \u001b[1m\u001b[32m0.94557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6276 | loss: 0.94557 - acc: 0.8296 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6277  | total loss: \u001b[1m\u001b[32m0.87506\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6277 | loss: 0.87506 - acc: 0.8466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6278  | total loss: \u001b[1m\u001b[32m1.09811\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6278 | loss: 1.09811 - acc: 0.7834 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6279  | total loss: \u001b[1m\u001b[32m1.01113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6279 | loss: 1.01113 - acc: 0.8050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6280  | total loss: \u001b[1m\u001b[32m0.93243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6280 | loss: 0.93243 - acc: 0.8245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6281  | total loss: \u001b[1m\u001b[32m0.86103\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6281 | loss: 0.86103 - acc: 0.8421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6282  | total loss: \u001b[1m\u001b[32m0.79610\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6282 | loss: 0.79610 - acc: 0.8579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6283  | total loss: \u001b[1m\u001b[32m0.73688\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6283 | loss: 0.73688 - acc: 0.8721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6284  | total loss: \u001b[1m\u001b[32m0.68273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6284 | loss: 0.68273 - acc: 0.8849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6285  | total loss: \u001b[1m\u001b[32m0.63310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6285 | loss: 0.63310 - acc: 0.8964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6286  | total loss: \u001b[1m\u001b[32m0.58751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6286 | loss: 0.58751 - acc: 0.9068 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6287  | total loss: \u001b[1m\u001b[32m0.54554\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6287 | loss: 0.54554 - acc: 0.9161 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6288  | total loss: \u001b[1m\u001b[32m0.94840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6288 | loss: 0.94840 - acc: 0.8245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6289  | total loss: \u001b[1m\u001b[32m0.86921\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6289 | loss: 0.86921 - acc: 0.8420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6290  | total loss: \u001b[1m\u001b[32m0.79765\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6290 | loss: 0.79765 - acc: 0.8578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6291  | total loss: \u001b[1m\u001b[32m0.73290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6291 | loss: 0.73290 - acc: 0.8720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6292  | total loss: \u001b[1m\u001b[32m0.67420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6292 | loss: 0.67420 - acc: 0.8848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6293  | total loss: \u001b[1m\u001b[32m0.62089\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6293 | loss: 0.62089 - acc: 0.8964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6294  | total loss: \u001b[1m\u001b[32m0.57242\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6294 | loss: 0.57242 - acc: 0.9067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6295  | total loss: \u001b[1m\u001b[32m0.52825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6295 | loss: 0.52825 - acc: 0.9160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6296  | total loss: \u001b[1m\u001b[32m0.97850\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6296 | loss: 0.97850 - acc: 0.8244 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6297  | total loss: \u001b[1m\u001b[32m0.89325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6297 | loss: 0.89325 - acc: 0.8420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6298  | total loss: \u001b[1m\u001b[32m1.22594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6298 | loss: 1.22594 - acc: 0.7721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6299  | total loss: \u001b[1m\u001b[32m1.11640\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6299 | loss: 1.11640 - acc: 0.7949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6300  | total loss: \u001b[1m\u001b[32m1.45144\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6300 | loss: 1.45144 - acc: 0.7225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6301  | total loss: \u001b[1m\u001b[32m1.32064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6301 | loss: 1.32064 - acc: 0.7503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6302  | total loss: \u001b[1m\u001b[32m1.20369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6302 | loss: 1.20369 - acc: 0.7752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6303  | total loss: \u001b[1m\u001b[32m1.09904\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6303 | loss: 1.09904 - acc: 0.7977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6304  | total loss: \u001b[1m\u001b[32m1.43800\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6304 | loss: 1.43800 - acc: 0.7251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6305  | total loss: \u001b[1m\u001b[32m1.31146\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6305 | loss: 1.31146 - acc: 0.7526 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6306  | total loss: \u001b[1m\u001b[32m1.61357\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6306 | loss: 1.61357 - acc: 0.6773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6307  | total loss: \u001b[1m\u001b[32m1.47192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6307 | loss: 1.47192 - acc: 0.7096 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6308  | total loss: \u001b[1m\u001b[32m1.76486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6308 | loss: 1.76486 - acc: 0.6386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6309  | total loss: \u001b[1m\u001b[32m1.61148\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6309 | loss: 1.61148 - acc: 0.6748 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6310  | total loss: \u001b[1m\u001b[32m1.81670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6310 | loss: 1.81670 - acc: 0.6216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6311  | total loss: \u001b[1m\u001b[32m1.66238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6311 | loss: 1.66238 - acc: 0.6594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6312  | total loss: \u001b[1m\u001b[32m1.91849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6312 | loss: 1.91849 - acc: 0.5935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6313  | total loss: \u001b[1m\u001b[32m1.75901\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6313 | loss: 1.75901 - acc: 0.6341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6314  | total loss: \u001b[1m\u001b[32m1.86195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6314 | loss: 1.86195 - acc: 0.5993 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6315  | total loss: \u001b[1m\u001b[32m1.71335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6315 | loss: 1.71335 - acc: 0.6394 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6316  | total loss: \u001b[1m\u001b[32m1.89051\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6316 | loss: 1.89051 - acc: 0.5826 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6317  | total loss: \u001b[1m\u001b[32m1.74413\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6317 | loss: 1.74413 - acc: 0.6243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6318  | total loss: \u001b[1m\u001b[32m1.86285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6318 | loss: 1.86285 - acc: 0.5833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6319  | total loss: \u001b[1m\u001b[32m1.72412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6319 | loss: 1.72412 - acc: 0.6250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6320  | total loss: \u001b[1m\u001b[32m1.85416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6320 | loss: 1.85416 - acc: 0.5768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6321  | total loss: \u001b[1m\u001b[32m1.72073\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6321 | loss: 1.72073 - acc: 0.6191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6322  | total loss: \u001b[1m\u001b[32m1.83568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6322 | loss: 1.83568 - acc: 0.5786 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6323  | total loss: \u001b[1m\u001b[32m1.70784\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6323 | loss: 1.70784 - acc: 0.6207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6324  | total loss: \u001b[1m\u001b[32m1.59403\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6324 | loss: 1.59403 - acc: 0.6587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6325  | total loss: \u001b[1m\u001b[32m1.49208\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6325 | loss: 1.49208 - acc: 0.6928 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6326  | total loss: \u001b[1m\u001b[32m1.40012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6326 | loss: 1.40012 - acc: 0.7235 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6327  | total loss: \u001b[1m\u001b[32m1.31654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6327 | loss: 1.31654 - acc: 0.7512 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6328  | total loss: \u001b[1m\u001b[32m1.23996\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6328 | loss: 1.23996 - acc: 0.7761 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6329  | total loss: \u001b[1m\u001b[32m1.16923\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6329 | loss: 1.16923 - acc: 0.7984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6330  | total loss: \u001b[1m\u001b[32m1.36913\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6330 | loss: 1.36913 - acc: 0.7329 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6331  | total loss: \u001b[1m\u001b[32m1.28199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6331 | loss: 1.28199 - acc: 0.7596 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6332  | total loss: \u001b[1m\u001b[32m1.48262\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6332 | loss: 1.48262 - acc: 0.6979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6333  | total loss: \u001b[1m\u001b[32m1.38166\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6333 | loss: 1.38166 - acc: 0.7281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6334  | total loss: \u001b[1m\u001b[32m1.61159\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6334 | loss: 1.61159 - acc: 0.6553 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6335  | total loss: \u001b[1m\u001b[32m1.49644\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 6335 | loss: 1.49644 - acc: 0.6898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6336  | total loss: \u001b[1m\u001b[32m1.66433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6336 | loss: 1.66433 - acc: 0.6351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6337  | total loss: \u001b[1m\u001b[32m1.54349\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6337 | loss: 1.54349 - acc: 0.6716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6338  | total loss: \u001b[1m\u001b[32m1.67885\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6338 | loss: 1.67885 - acc: 0.6259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6339  | total loss: \u001b[1m\u001b[32m1.55655\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6339 | loss: 1.55655 - acc: 0.6633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6340  | total loss: \u001b[1m\u001b[32m1.75953\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 6340 | loss: 1.75953 - acc: 0.5969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6341  | total loss: \u001b[1m\u001b[32m1.62965\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 6341 | loss: 1.62965 - acc: 0.6372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6342  | total loss: \u001b[1m\u001b[32m1.51293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6342 | loss: 1.51293 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6343  | total loss: \u001b[1m\u001b[32m1.40755\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6343 | loss: 1.40755 - acc: 0.7062 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6344  | total loss: \u001b[1m\u001b[32m1.62630\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6344 | loss: 1.62630 - acc: 0.6356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6345  | total loss: \u001b[1m\u001b[32m1.50902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6345 | loss: 1.50902 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6346  | total loss: \u001b[1m\u001b[32m1.70946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6346 | loss: 1.70946 - acc: 0.6119 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6347  | total loss: \u001b[1m\u001b[32m1.58412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6347 | loss: 1.58412 - acc: 0.6507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6348  | total loss: \u001b[1m\u001b[32m1.76242\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6348 | loss: 1.76242 - acc: 0.5928 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6349  | total loss: \u001b[1m\u001b[32m1.63265\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6349 | loss: 1.63265 - acc: 0.6335 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6350  | total loss: \u001b[1m\u001b[32m1.77113\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6350 | loss: 1.77113 - acc: 0.5916 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6351  | total loss: \u001b[1m\u001b[32m1.64158\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6351 | loss: 1.64158 - acc: 0.6324 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6352  | total loss: \u001b[1m\u001b[32m1.52521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6352 | loss: 1.52521 - acc: 0.6692 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6353  | total loss: \u001b[1m\u001b[32m1.42018\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6353 | loss: 1.42018 - acc: 0.7023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6354  | total loss: \u001b[1m\u001b[32m1.60987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6354 | loss: 1.60987 - acc: 0.6392 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6355  | total loss: \u001b[1m\u001b[32m1.49572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6355 | loss: 1.49572 - acc: 0.6753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6356  | total loss: \u001b[1m\u001b[32m1.39260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6356 | loss: 1.39260 - acc: 0.7078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6357  | total loss: \u001b[1m\u001b[32m1.29894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6357 | loss: 1.29894 - acc: 0.7370 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6358  | total loss: \u001b[1m\u001b[32m1.21342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6358 | loss: 1.21342 - acc: 0.7633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6359  | total loss: \u001b[1m\u001b[32m1.13489\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6359 | loss: 1.13489 - acc: 0.7869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6360  | total loss: \u001b[1m\u001b[32m1.35464\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6360 | loss: 1.35464 - acc: 0.7154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6361  | total loss: \u001b[1m\u001b[32m1.25939\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6361 | loss: 1.25939 - acc: 0.7439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6362  | total loss: \u001b[1m\u001b[32m1.46027\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6362 | loss: 1.46027 - acc: 0.6838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6363  | total loss: \u001b[1m\u001b[32m1.35317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6363 | loss: 1.35317 - acc: 0.7154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6364  | total loss: \u001b[1m\u001b[32m1.57672\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6364 | loss: 1.57672 - acc: 0.6510 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6365  | total loss: \u001b[1m\u001b[32m1.45768\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6365 | loss: 1.45768 - acc: 0.6859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6366  | total loss: \u001b[1m\u001b[32m1.35038\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6366 | loss: 1.35038 - acc: 0.7173 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6367  | total loss: \u001b[1m\u001b[32m1.25327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6367 | loss: 1.25327 - acc: 0.7456 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6368  | total loss: \u001b[1m\u001b[32m1.16500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6368 | loss: 1.16500 - acc: 0.7710 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6369  | total loss: \u001b[1m\u001b[32m1.08439\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6369 | loss: 1.08439 - acc: 0.7939 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6370  | total loss: \u001b[1m\u001b[32m1.28417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6370 | loss: 1.28417 - acc: 0.7288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6371  | total loss: \u001b[1m\u001b[32m1.18970\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6371 | loss: 1.18970 - acc: 0.7559 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6372  | total loss: \u001b[1m\u001b[32m1.45037\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6372 | loss: 1.45037 - acc: 0.6803 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6373  | total loss: \u001b[1m\u001b[32m1.33858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6373 | loss: 1.33858 - acc: 0.7123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6374  | total loss: \u001b[1m\u001b[32m1.59571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6374 | loss: 1.59571 - acc: 0.6411 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6375  | total loss: \u001b[1m\u001b[32m1.46994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6375 | loss: 1.46994 - acc: 0.6770 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6376  | total loss: \u001b[1m\u001b[32m1.35711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6376 | loss: 1.35711 - acc: 0.7093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6377  | total loss: \u001b[1m\u001b[32m1.25553\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6377 | loss: 1.25553 - acc: 0.7383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6378  | total loss: \u001b[1m\u001b[32m1.47749\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6378 | loss: 1.47749 - acc: 0.6788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6379  | total loss: \u001b[1m\u001b[32m1.36394\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6379 | loss: 1.36394 - acc: 0.7109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6380  | total loss: \u001b[1m\u001b[32m1.60732\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6380 | loss: 1.60732 - acc: 0.6398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6381  | total loss: \u001b[1m\u001b[32m1.48175\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6381 | loss: 1.48175 - acc: 0.6758 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6382  | total loss: \u001b[1m\u001b[32m1.74099\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6382 | loss: 1.74099 - acc: 0.6083 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6383  | total loss: \u001b[1m\u001b[32m1.60391\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 6383 | loss: 1.60391 - acc: 0.6474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6384  | total loss: \u001b[1m\u001b[32m1.48140\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6384 | loss: 1.48140 - acc: 0.6827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6385  | total loss: \u001b[1m\u001b[32m1.37151\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6385 | loss: 1.37151 - acc: 0.7144 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6386  | total loss: \u001b[1m\u001b[32m1.27255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6386 | loss: 1.27255 - acc: 0.7430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6387  | total loss: \u001b[1m\u001b[32m1.18301\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6387 | loss: 1.18301 - acc: 0.7687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6388  | total loss: \u001b[1m\u001b[32m1.10160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6388 | loss: 1.10160 - acc: 0.7918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6389  | total loss: \u001b[1m\u001b[32m1.02723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6389 | loss: 1.02723 - acc: 0.8126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6390  | total loss: \u001b[1m\u001b[32m1.28226\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6390 | loss: 1.28226 - acc: 0.7385 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6391  | total loss: \u001b[1m\u001b[32m1.18812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6391 | loss: 1.18812 - acc: 0.7647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6392  | total loss: \u001b[1m\u001b[32m1.45112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6392 | loss: 1.45112 - acc: 0.6953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6393  | total loss: \u001b[1m\u001b[32m1.33962\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6393 | loss: 1.33962 - acc: 0.7258 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6394  | total loss: \u001b[1m\u001b[32m1.60644\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6394 | loss: 1.60644 - acc: 0.6532 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6395  | total loss: \u001b[1m\u001b[32m1.48008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6395 | loss: 1.48008 - acc: 0.6879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6396  | total loss: \u001b[1m\u001b[32m1.71600\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6396 | loss: 1.71600 - acc: 0.6191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6397  | total loss: \u001b[1m\u001b[32m1.58040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6397 | loss: 1.58040 - acc: 0.6572 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6398  | total loss: \u001b[1m\u001b[32m1.45918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6398 | loss: 1.45918 - acc: 0.6915 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6399  | total loss: \u001b[1m\u001b[32m1.35044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6399 | loss: 1.35044 - acc: 0.7223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6400  | total loss: \u001b[1m\u001b[32m1.25252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6400 | loss: 1.25252 - acc: 0.7501 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6401  | total loss: \u001b[1m\u001b[32m1.16395\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6401 | loss: 1.16395 - acc: 0.7751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6402  | total loss: \u001b[1m\u001b[32m1.40634\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6402 | loss: 1.40634 - acc: 0.7047 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6403  | total loss: \u001b[1m\u001b[32m1.30178\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6403 | loss: 1.30178 - acc: 0.7342 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6404  | total loss: \u001b[1m\u001b[32m1.52617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6404 | loss: 1.52617 - acc: 0.6680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6405  | total loss: \u001b[1m\u001b[32m1.40997\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6405 | loss: 1.40997 - acc: 0.7012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6406  | total loss: \u001b[1m\u001b[32m1.30555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6406 | loss: 1.30555 - acc: 0.7311 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6407  | total loss: \u001b[1m\u001b[32m1.21133\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6407 | loss: 1.21133 - acc: 0.7579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6408  | total loss: \u001b[1m\u001b[32m1.43425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6408 | loss: 1.43425 - acc: 0.6893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6409  | total loss: \u001b[1m\u001b[32m1.32688\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6409 | loss: 1.32688 - acc: 0.7204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6410  | total loss: \u001b[1m\u001b[32m1.53481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6410 | loss: 1.53481 - acc: 0.6626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6411  | total loss: \u001b[1m\u001b[32m1.41797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6411 | loss: 1.41797 - acc: 0.6964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6412  | total loss: \u001b[1m\u001b[32m1.31308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6412 | loss: 1.31308 - acc: 0.7267 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6413  | total loss: \u001b[1m\u001b[32m1.21851\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6413 | loss: 1.21851 - acc: 0.7540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6414  | total loss: \u001b[1m\u001b[32m1.37633\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6414 | loss: 1.37633 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6415  | total loss: \u001b[1m\u001b[32m1.27498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6415 | loss: 1.27498 - acc: 0.7365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6416  | total loss: \u001b[1m\u001b[32m1.18344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6416 | loss: 1.18344 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6417  | total loss: \u001b[1m\u001b[32m1.10039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6417 | loss: 1.10039 - acc: 0.7866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6418  | total loss: \u001b[1m\u001b[32m1.02471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6418 | loss: 1.02471 - acc: 0.8079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6419  | total loss: \u001b[1m\u001b[32m0.95541\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6419 | loss: 0.95541 - acc: 0.8271 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6420  | total loss: \u001b[1m\u001b[32m0.89167\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6420 | loss: 0.89167 - acc: 0.8444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6421  | total loss: \u001b[1m\u001b[32m0.83279\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6421 | loss: 0.83279 - acc: 0.8600 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6422  | total loss: \u001b[1m\u001b[32m1.13996\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6422 | loss: 1.13996 - acc: 0.7811 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6423  | total loss: \u001b[1m\u001b[32m1.05397\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6423 | loss: 1.05397 - acc: 0.8030 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6424  | total loss: \u001b[1m\u001b[32m0.97572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6424 | loss: 0.97572 - acc: 0.8227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6425  | total loss: \u001b[1m\u001b[32m0.90430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6425 | loss: 0.90430 - acc: 0.8404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6426  | total loss: \u001b[1m\u001b[32m1.17221\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6426 | loss: 1.17221 - acc: 0.7707 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6427  | total loss: \u001b[1m\u001b[32m1.07976\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6427 | loss: 1.07976 - acc: 0.7936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6428  | total loss: \u001b[1m\u001b[32m0.99610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6428 | loss: 0.99610 - acc: 0.8142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6429  | total loss: \u001b[1m\u001b[32m0.92019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6429 | loss: 0.92019 - acc: 0.8328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6430  | total loss: \u001b[1m\u001b[32m1.25670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6430 | loss: 1.25670 - acc: 0.7495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6431  | total loss: \u001b[1m\u001b[32m1.15414\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6431 | loss: 1.15414 - acc: 0.7746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6432  | total loss: \u001b[1m\u001b[32m1.06177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6432 | loss: 1.06177 - acc: 0.7971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6433  | total loss: \u001b[1m\u001b[32m0.97839\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6433 | loss: 0.97839 - acc: 0.8174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6434  | total loss: \u001b[1m\u001b[32m0.90294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6434 | loss: 0.90294 - acc: 0.8357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6435  | total loss: \u001b[1m\u001b[32m0.83447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6435 | loss: 0.83447 - acc: 0.8521 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6436  | total loss: \u001b[1m\u001b[32m1.15565\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6436 | loss: 1.15565 - acc: 0.7740 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6437  | total loss: \u001b[1m\u001b[32m1.06140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6437 | loss: 1.06140 - acc: 0.7966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6438  | total loss: \u001b[1m\u001b[32m0.97654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6438 | loss: 0.97654 - acc: 0.8170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6439  | total loss: \u001b[1m\u001b[32m0.89997\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6439 | loss: 0.89997 - acc: 0.8353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6440  | total loss: \u001b[1m\u001b[32m1.23479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6440 | loss: 1.23479 - acc: 0.7517 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6441  | total loss: \u001b[1m\u001b[32m1.13248\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6441 | loss: 1.13248 - acc: 0.7766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6442  | total loss: \u001b[1m\u001b[32m1.45587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6442 | loss: 1.45587 - acc: 0.6989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6443  | total loss: \u001b[1m\u001b[32m1.33272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6443 | loss: 1.33272 - acc: 0.7290 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6444  | total loss: \u001b[1m\u001b[32m1.63982\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6444 | loss: 1.63982 - acc: 0.6561 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6445  | total loss: \u001b[1m\u001b[32m1.50056\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6445 | loss: 1.50056 - acc: 0.6905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6446  | total loss: \u001b[1m\u001b[32m1.37643\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6446 | loss: 1.37643 - acc: 0.7215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6447  | total loss: \u001b[1m\u001b[32m1.26559\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6447 | loss: 1.26559 - acc: 0.7493 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6448  | total loss: \u001b[1m\u001b[32m1.54949\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6448 | loss: 1.54949 - acc: 0.6744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6449  | total loss: \u001b[1m\u001b[32m1.42329\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6449 | loss: 1.42329 - acc: 0.7069 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6450  | total loss: \u001b[1m\u001b[32m1.65276\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6450 | loss: 1.65276 - acc: 0.6505 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6451  | total loss: \u001b[1m\u001b[32m1.51894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6451 | loss: 1.51894 - acc: 0.6855 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6452  | total loss: \u001b[1m\u001b[32m1.74141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6452 | loss: 1.74141 - acc: 0.6241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6453  | total loss: \u001b[1m\u001b[32m1.60195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6453 | loss: 1.60195 - acc: 0.6617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6454  | total loss: \u001b[1m\u001b[32m1.47792\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6454 | loss: 1.47792 - acc: 0.6955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6455  | total loss: \u001b[1m\u001b[32m1.36729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6455 | loss: 1.36729 - acc: 0.7260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6456  | total loss: \u001b[1m\u001b[32m1.26823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6456 | loss: 1.26823 - acc: 0.7534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6457  | total loss: \u001b[1m\u001b[32m1.17914\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6457 | loss: 1.17914 - acc: 0.7780 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6458  | total loss: \u001b[1m\u001b[32m1.09862\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6458 | loss: 1.09862 - acc: 0.8002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6459  | total loss: \u001b[1m\u001b[32m1.02546\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6459 | loss: 1.02546 - acc: 0.8202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6460  | total loss: \u001b[1m\u001b[32m1.27302\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6460 | loss: 1.27302 - acc: 0.7525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6461  | total loss: \u001b[1m\u001b[32m1.18121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6461 | loss: 1.18121 - acc: 0.7772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6462  | total loss: \u001b[1m\u001b[32m1.45697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6462 | loss: 1.45697 - acc: 0.6995 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6463  | total loss: \u001b[1m\u001b[32m1.34663\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6463 | loss: 1.34663 - acc: 0.7295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6464  | total loss: \u001b[1m\u001b[32m1.57327\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6464 | loss: 1.57327 - acc: 0.6637 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6465  | total loss: \u001b[1m\u001b[32m1.45212\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6465 | loss: 1.45212 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6466  | total loss: \u001b[1m\u001b[32m1.34343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6466 | loss: 1.34343 - acc: 0.7276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6467  | total loss: \u001b[1m\u001b[32m1.24557\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6467 | loss: 1.24557 - acc: 0.7549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6468  | total loss: \u001b[1m\u001b[32m1.51291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6468 | loss: 1.51291 - acc: 0.6794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6469  | total loss: \u001b[1m\u001b[32m1.39825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6469 | loss: 1.39825 - acc: 0.7114 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6470  | total loss: \u001b[1m\u001b[32m1.29519\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6470 | loss: 1.29519 - acc: 0.7403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6471  | total loss: \u001b[1m\u001b[32m1.20219\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6471 | loss: 1.20219 - acc: 0.7663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6472  | total loss: \u001b[1m\u001b[32m1.45449\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6472 | loss: 1.45449 - acc: 0.6896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6473  | total loss: \u001b[1m\u001b[32m1.34528\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6473 | loss: 1.34528 - acc: 0.7207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6474  | total loss: \u001b[1m\u001b[32m1.57893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6474 | loss: 1.57893 - acc: 0.6557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6475  | total loss: \u001b[1m\u001b[32m1.45796\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6475 | loss: 1.45796 - acc: 0.6902 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6476  | total loss: \u001b[1m\u001b[32m1.34942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6476 | loss: 1.34942 - acc: 0.7212 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6477  | total loss: \u001b[1m\u001b[32m1.25166\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6477 | loss: 1.25166 - acc: 0.7490 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6478  | total loss: \u001b[1m\u001b[32m1.45296\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6478 | loss: 1.45296 - acc: 0.6884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6479  | total loss: \u001b[1m\u001b[32m1.34469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6479 | loss: 1.34469 - acc: 0.7196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6480  | total loss: \u001b[1m\u001b[32m1.24715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6480 | loss: 1.24715 - acc: 0.7476 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6481  | total loss: \u001b[1m\u001b[32m1.15890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6481 | loss: 1.15890 - acc: 0.7729 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6482  | total loss: \u001b[1m\u001b[32m1.07868\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6482 | loss: 1.07868 - acc: 0.7956 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6483  | total loss: \u001b[1m\u001b[32m1.00543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6483 | loss: 1.00543 - acc: 0.8160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6484  | total loss: \u001b[1m\u001b[32m0.93821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6484 | loss: 0.93821 - acc: 0.8344 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6485  | total loss: \u001b[1m\u001b[32m0.87626\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6485 | loss: 0.87626 - acc: 0.8510 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6486  | total loss: \u001b[1m\u001b[32m1.16968\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6486 | loss: 1.16968 - acc: 0.7730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6487  | total loss: \u001b[1m\u001b[32m1.08236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6487 | loss: 1.08236 - acc: 0.7957 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6488  | total loss: \u001b[1m\u001b[32m1.32469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6488 | loss: 1.32469 - acc: 0.7304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6489  | total loss: \u001b[1m\u001b[32m1.22101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6489 | loss: 1.22101 - acc: 0.7574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6490  | total loss: \u001b[1m\u001b[32m1.43401\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6490 | loss: 1.43401 - acc: 0.6959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6491  | total loss: \u001b[1m\u001b[32m1.31957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6491 | loss: 1.31957 - acc: 0.7263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6492  | total loss: \u001b[1m\u001b[32m1.59695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6492 | loss: 1.59695 - acc: 0.6537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6493  | total loss: \u001b[1m\u001b[32m1.46738\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6493 | loss: 1.46738 - acc: 0.6883 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6494  | total loss: \u001b[1m\u001b[32m1.73814\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6494 | loss: 1.73814 - acc: 0.6195 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6495  | total loss: \u001b[1m\u001b[32m1.59666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6495 | loss: 1.59666 - acc: 0.6576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6496  | total loss: \u001b[1m\u001b[32m1.77942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6496 | loss: 1.77942 - acc: 0.6061 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6497  | total loss: \u001b[1m\u001b[32m1.63667\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6497 | loss: 1.63667 - acc: 0.6455 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6498  | total loss: \u001b[1m\u001b[32m1.85238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6498 | loss: 1.85238 - acc: 0.5809 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6499  | total loss: \u001b[1m\u001b[32m1.70559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6499 | loss: 1.70559 - acc: 0.6228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6500  | total loss: \u001b[1m\u001b[32m1.87045\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6500 | loss: 1.87045 - acc: 0.5677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6501  | total loss: \u001b[1m\u001b[32m1.72547\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6501 | loss: 1.72547 - acc: 0.6109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6502  | total loss: \u001b[1m\u001b[32m1.59653\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6502 | loss: 1.59653 - acc: 0.6498 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6503  | total loss: \u001b[1m\u001b[32m1.48143\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6503 | loss: 1.48143 - acc: 0.6848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6504  | total loss: \u001b[1m\u001b[32m1.68115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6504 | loss: 1.68115 - acc: 0.6164 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6505  | total loss: \u001b[1m\u001b[32m1.55921\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6505 | loss: 1.55921 - acc: 0.6547 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6506  | total loss: \u001b[1m\u001b[32m1.75984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6506 | loss: 1.75984 - acc: 0.5893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6507  | total loss: \u001b[1m\u001b[32m1.63208\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6507 | loss: 1.63208 - acc: 0.6303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6508  | total loss: \u001b[1m\u001b[32m1.82990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6508 | loss: 1.82990 - acc: 0.5673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6509  | total loss: \u001b[1m\u001b[32m1.69745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6509 | loss: 1.69745 - acc: 0.6106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6510  | total loss: \u001b[1m\u001b[32m1.57913\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6510 | loss: 1.57913 - acc: 0.6495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6511  | total loss: \u001b[1m\u001b[32m1.47287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6511 | loss: 1.47287 - acc: 0.6846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6512  | total loss: \u001b[1m\u001b[32m1.69094\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6512 | loss: 1.69094 - acc: 0.6161 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6513  | total loss: \u001b[1m\u001b[32m1.57379\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6513 | loss: 1.57379 - acc: 0.6545 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6514  | total loss: \u001b[1m\u001b[32m1.74688\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6514 | loss: 1.74688 - acc: 0.5962 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6515  | total loss: \u001b[1m\u001b[32m1.62490\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6515 | loss: 1.62490 - acc: 0.6366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6516  | total loss: \u001b[1m\u001b[32m1.71546\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6516 | loss: 1.71546 - acc: 0.6015 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6517  | total loss: \u001b[1m\u001b[32m1.59729\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6517 | loss: 1.59729 - acc: 0.6413 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6518  | total loss: \u001b[1m\u001b[32m1.49086\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6518 | loss: 1.49086 - acc: 0.6772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6519  | total loss: \u001b[1m\u001b[32m1.39443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6519 | loss: 1.39443 - acc: 0.7095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6520  | total loss: \u001b[1m\u001b[32m1.59357\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6520 | loss: 1.59357 - acc: 0.6457 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6521  | total loss: \u001b[1m\u001b[32m1.48549\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6521 | loss: 1.48549 - acc: 0.6811 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6522  | total loss: \u001b[1m\u001b[32m1.38748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6522 | loss: 1.38748 - acc: 0.7130 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6523  | total loss: \u001b[1m\u001b[32m1.29806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6523 | loss: 1.29806 - acc: 0.7417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6524  | total loss: \u001b[1m\u001b[32m1.45705\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6524 | loss: 1.45705 - acc: 0.6890 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6525  | total loss: \u001b[1m\u001b[32m1.35820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6525 | loss: 1.35820 - acc: 0.7201 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6526  | total loss: \u001b[1m\u001b[32m1.26795\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6526 | loss: 1.26795 - acc: 0.7481 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6527  | total loss: \u001b[1m\u001b[32m1.18512\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6527 | loss: 1.18512 - acc: 0.7732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6528  | total loss: \u001b[1m\u001b[32m1.10870\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6528 | loss: 1.10870 - acc: 0.7959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6529  | total loss: \u001b[1m\u001b[32m1.03785\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6529 | loss: 1.03785 - acc: 0.8163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6530  | total loss: \u001b[1m\u001b[32m0.97186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6530 | loss: 0.97186 - acc: 0.8347 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6531  | total loss: \u001b[1m\u001b[32m0.91018\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6531 | loss: 0.91018 - acc: 0.8512 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6532  | total loss: \u001b[1m\u001b[32m1.20203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6532 | loss: 1.20203 - acc: 0.7661 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6533  | total loss: \u001b[1m\u001b[32m1.11385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6533 | loss: 1.11385 - acc: 0.7895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6534  | total loss: \u001b[1m\u001b[32m1.03318\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6534 | loss: 1.03318 - acc: 0.8105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6535  | total loss: \u001b[1m\u001b[32m0.95915\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6535 | loss: 0.95915 - acc: 0.8295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6536  | total loss: \u001b[1m\u001b[32m1.21035\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6536 | loss: 1.21035 - acc: 0.7608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6537  | total loss: \u001b[1m\u001b[32m1.11645\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6537 | loss: 1.11645 - acc: 0.7847 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6538  | total loss: \u001b[1m\u001b[32m1.44350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6538 | loss: 1.44350 - acc: 0.7063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6539  | total loss: \u001b[1m\u001b[32m1.32567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6539 | loss: 1.32567 - acc: 0.7356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6540  | total loss: \u001b[1m\u001b[32m1.21960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6540 | loss: 1.21960 - acc: 0.7621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6541  | total loss: \u001b[1m\u001b[32m1.12386\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6541 | loss: 1.12386 - acc: 0.7859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6542  | total loss: \u001b[1m\u001b[32m1.42396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6542 | loss: 1.42396 - acc: 0.7073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6543  | total loss: \u001b[1m\u001b[32m1.30781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6543 | loss: 1.30781 - acc: 0.7366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6544  | total loss: \u001b[1m\u001b[32m1.20348\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6544 | loss: 1.20348 - acc: 0.7629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6545  | total loss: \u001b[1m\u001b[32m1.10953\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6545 | loss: 1.10953 - acc: 0.7866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6546  | total loss: \u001b[1m\u001b[32m1.35879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6546 | loss: 1.35879 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6547  | total loss: \u001b[1m\u001b[32m1.24953\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6547 | loss: 1.24953 - acc: 0.7500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6548  | total loss: \u001b[1m\u001b[32m1.15141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6548 | loss: 1.15141 - acc: 0.7750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6549  | total loss: \u001b[1m\u001b[32m1.06305\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6549 | loss: 1.06305 - acc: 0.7975 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6550  | total loss: \u001b[1m\u001b[32m1.32369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6550 | loss: 1.32369 - acc: 0.7249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6551  | total loss: \u001b[1m\u001b[32m1.21830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6551 | loss: 1.21830 - acc: 0.7524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6552  | total loss: \u001b[1m\u001b[32m1.51013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6552 | loss: 1.51013 - acc: 0.6772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6553  | total loss: \u001b[1m\u001b[32m1.38733\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6553 | loss: 1.38733 - acc: 0.7095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6554  | total loss: \u001b[1m\u001b[32m1.67896\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6554 | loss: 1.67896 - acc: 0.6385 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6555  | total loss: \u001b[1m\u001b[32m1.54145\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6555 | loss: 1.54145 - acc: 0.6747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6556  | total loss: \u001b[1m\u001b[32m1.41880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6556 | loss: 1.41880 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6557  | total loss: \u001b[1m\u001b[32m1.30910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6557 | loss: 1.30910 - acc: 0.7365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6558  | total loss: \u001b[1m\u001b[32m1.21066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6558 | loss: 1.21066 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6559  | total loss: \u001b[1m\u001b[32m1.12199\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6559 | loss: 1.12199 - acc: 0.7865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6560  | total loss: \u001b[1m\u001b[32m1.04179\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6560 | loss: 1.04179 - acc: 0.8079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6561  | total loss: \u001b[1m\u001b[32m0.96893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6561 | loss: 0.96893 - acc: 0.8271 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6562  | total loss: \u001b[1m\u001b[32m1.22725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6562 | loss: 1.22725 - acc: 0.7515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6563  | total loss: \u001b[1m\u001b[32m1.13497\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6563 | loss: 1.13497 - acc: 0.7764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6564  | total loss: \u001b[1m\u001b[32m1.40209\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6564 | loss: 1.40209 - acc: 0.7059 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6565  | total loss: \u001b[1m\u001b[32m1.29257\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6565 | loss: 1.29257 - acc: 0.7353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6566  | total loss: \u001b[1m\u001b[32m1.19417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6566 | loss: 1.19417 - acc: 0.7618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6567  | total loss: \u001b[1m\u001b[32m1.10546\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6567 | loss: 1.10546 - acc: 0.7856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6568  | total loss: \u001b[1m\u001b[32m1.38705\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6568 | loss: 1.38705 - acc: 0.7142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6569  | total loss: \u001b[1m\u001b[32m1.27903\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6569 | loss: 1.27903 - acc: 0.7428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6570  | total loss: \u001b[1m\u001b[32m1.18189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6570 | loss: 1.18189 - acc: 0.7685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6571  | total loss: \u001b[1m\u001b[32m1.09424\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6571 | loss: 1.09424 - acc: 0.7916 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6572  | total loss: \u001b[1m\u001b[32m1.01486\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6572 | loss: 1.01486 - acc: 0.8125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6573  | total loss: \u001b[1m\u001b[32m0.94269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6573 | loss: 0.94269 - acc: 0.8312 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6574  | total loss: \u001b[1m\u001b[32m0.87684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6574 | loss: 0.87684 - acc: 0.8481 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6575  | total loss: \u001b[1m\u001b[32m0.81650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6575 | loss: 0.81650 - acc: 0.8633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6576  | total loss: \u001b[1m\u001b[32m0.76101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6576 | loss: 0.76101 - acc: 0.8770 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6577  | total loss: \u001b[1m\u001b[32m0.70981\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6577 | loss: 0.70981 - acc: 0.8893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6578  | total loss: \u001b[1m\u001b[32m0.98122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6578 | loss: 0.98122 - acc: 0.8218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6579  | total loss: \u001b[1m\u001b[32m0.90612\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6579 | loss: 0.90612 - acc: 0.8396 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6580  | total loss: \u001b[1m\u001b[32m1.22308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6580 | loss: 1.22308 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6581  | total loss: \u001b[1m\u001b[32m1.12319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6581 | loss: 1.12319 - acc: 0.7865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6582  | total loss: \u001b[1m\u001b[32m1.38361\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6582 | loss: 1.38361 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6583  | total loss: \u001b[1m\u001b[32m1.26818\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6583 | loss: 1.26818 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6584  | total loss: \u001b[1m\u001b[32m1.56341\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6584 | loss: 1.56341 - acc: 0.6749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6585  | total loss: \u001b[1m\u001b[32m1.43161\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6585 | loss: 1.43161 - acc: 0.7074 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6586  | total loss: \u001b[1m\u001b[32m1.65792\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6586 | loss: 1.65792 - acc: 0.6510 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6587  | total loss: \u001b[1m\u001b[32m1.51915\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6587 | loss: 1.51915 - acc: 0.6859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6588  | total loss: \u001b[1m\u001b[32m1.68740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6588 | loss: 1.68740 - acc: 0.6459 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6589  | total loss: \u001b[1m\u001b[32m1.54859\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6589 | loss: 1.54859 - acc: 0.6813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6590  | total loss: \u001b[1m\u001b[32m1.42496\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6590 | loss: 1.42496 - acc: 0.7131 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6591  | total loss: \u001b[1m\u001b[32m1.31460\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6591 | loss: 1.31460 - acc: 0.7418 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6592  | total loss: \u001b[1m\u001b[32m1.21577\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6592 | loss: 1.21577 - acc: 0.7677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6593  | total loss: \u001b[1m\u001b[32m1.12696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6593 | loss: 1.12696 - acc: 0.7909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6594  | total loss: \u001b[1m\u001b[32m1.04682\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6594 | loss: 1.04682 - acc: 0.8118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6595  | total loss: \u001b[1m\u001b[32m0.97417\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6595 | loss: 0.97417 - acc: 0.8306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6596  | total loss: \u001b[1m\u001b[32m1.27750\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6596 | loss: 1.27750 - acc: 0.7476 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6597  | total loss: \u001b[1m\u001b[32m1.18118\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6597 | loss: 1.18118 - acc: 0.7728 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6598  | total loss: \u001b[1m\u001b[32m1.09433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6598 | loss: 1.09433 - acc: 0.7955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6599  | total loss: \u001b[1m\u001b[32m1.01572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6599 | loss: 1.01572 - acc: 0.8160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6600  | total loss: \u001b[1m\u001b[32m0.94426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6600 | loss: 0.94426 - acc: 0.8344 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6601  | total loss: \u001b[1m\u001b[32m0.87903\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6601 | loss: 0.87903 - acc: 0.8509 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6602  | total loss: \u001b[1m\u001b[32m1.19426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6602 | loss: 1.19426 - acc: 0.7658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6603  | total loss: \u001b[1m\u001b[32m1.10289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6603 | loss: 1.10289 - acc: 0.7893 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6604  | total loss: \u001b[1m\u001b[32m1.02034\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6604 | loss: 1.02034 - acc: 0.8103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6605  | total loss: \u001b[1m\u001b[32m0.94551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6605 | loss: 0.94551 - acc: 0.8293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6606  | total loss: \u001b[1m\u001b[32m0.87743\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6606 | loss: 0.87743 - acc: 0.8464 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6607  | total loss: \u001b[1m\u001b[32m0.81528\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6607 | loss: 0.81528 - acc: 0.8617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6608  | total loss: \u001b[1m\u001b[32m1.16069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6608 | loss: 1.16069 - acc: 0.7756 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6609  | total loss: \u001b[1m\u001b[32m1.06916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6609 | loss: 1.06916 - acc: 0.7980 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6610  | total loss: \u001b[1m\u001b[32m0.98654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6610 | loss: 0.98654 - acc: 0.8182 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6611  | total loss: \u001b[1m\u001b[32m0.91173\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6611 | loss: 0.91173 - acc: 0.8364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6612  | total loss: \u001b[1m\u001b[32m0.84381\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6612 | loss: 0.84381 - acc: 0.8527 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6613  | total loss: \u001b[1m\u001b[32m0.78195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6613 | loss: 0.78195 - acc: 0.8675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6614  | total loss: \u001b[1m\u001b[32m1.11542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6614 | loss: 1.11542 - acc: 0.7879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6615  | total loss: \u001b[1m\u001b[32m1.02554\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6615 | loss: 1.02554 - acc: 0.8091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6616  | total loss: \u001b[1m\u001b[32m1.33364\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6616 | loss: 1.33364 - acc: 0.7282 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6617  | total loss: \u001b[1m\u001b[32m1.22228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6617 | loss: 1.22228 - acc: 0.7554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6618  | total loss: \u001b[1m\u001b[32m1.52100\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6618 | loss: 1.52100 - acc: 0.6870 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6619  | total loss: \u001b[1m\u001b[32m1.39233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6619 | loss: 1.39233 - acc: 0.7183 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6620  | total loss: \u001b[1m\u001b[32m1.63791\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6620 | loss: 1.63791 - acc: 0.6536 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6621  | total loss: \u001b[1m\u001b[32m1.49993\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6621 | loss: 1.49993 - acc: 0.6882 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6622  | total loss: \u001b[1m\u001b[32m1.68634\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6622 | loss: 1.68634 - acc: 0.6408 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6623  | total loss: \u001b[1m\u001b[32m1.54656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6623 | loss: 1.54656 - acc: 0.6767 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6624  | total loss: \u001b[1m\u001b[32m1.42218\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6624 | loss: 1.42218 - acc: 0.7091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6625  | total loss: \u001b[1m\u001b[32m1.31126\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6625 | loss: 1.31126 - acc: 0.7382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6626  | total loss: \u001b[1m\u001b[32m1.56579\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6626 | loss: 1.56579 - acc: 0.6715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6627  | total loss: \u001b[1m\u001b[32m1.44250\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6627 | loss: 1.44250 - acc: 0.7043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6628  | total loss: \u001b[1m\u001b[32m1.69746\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6628 | loss: 1.69746 - acc: 0.6339 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6629  | total loss: \u001b[1m\u001b[32m1.56366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6629 | loss: 1.56366 - acc: 0.6705 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6630  | total loss: \u001b[1m\u001b[32m1.72694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6630 | loss: 1.72694 - acc: 0.6249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6631  | total loss: \u001b[1m\u001b[32m1.59317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6631 | loss: 1.59317 - acc: 0.6624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6632  | total loss: \u001b[1m\u001b[32m1.47397\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6632 | loss: 1.47397 - acc: 0.6962 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6633  | total loss: \u001b[1m\u001b[32m1.36735\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6633 | loss: 1.36735 - acc: 0.7265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6634  | total loss: \u001b[1m\u001b[32m1.27155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6634 | loss: 1.27155 - acc: 0.7539 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6635  | total loss: \u001b[1m\u001b[32m1.18503\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6635 | loss: 1.18503 - acc: 0.7785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6636  | total loss: \u001b[1m\u001b[32m1.40978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6636 | loss: 1.40978 - acc: 0.7078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6637  | total loss: \u001b[1m\u001b[32m1.30885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6637 | loss: 1.30885 - acc: 0.7370 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6638  | total loss: \u001b[1m\u001b[32m1.53045\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6638 | loss: 1.53045 - acc: 0.6705 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6639  | total loss: \u001b[1m\u001b[32m1.41764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6639 | loss: 1.41764 - acc: 0.7034 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6640  | total loss: \u001b[1m\u001b[32m1.65694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6640 | loss: 1.65694 - acc: 0.6331 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6641  | total loss: \u001b[1m\u001b[32m1.53246\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6641 | loss: 1.53246 - acc: 0.6698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6642  | total loss: \u001b[1m\u001b[32m1.77060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6642 | loss: 1.77060 - acc: 0.6028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6643  | total loss: \u001b[1m\u001b[32m1.63651\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6643 | loss: 1.63651 - acc: 0.6425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6644  | total loss: \u001b[1m\u001b[32m1.85159\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6644 | loss: 1.85159 - acc: 0.5783 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6645  | total loss: \u001b[1m\u001b[32m1.71168\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6645 | loss: 1.71168 - acc: 0.6204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6646  | total loss: \u001b[1m\u001b[32m1.58669\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6646 | loss: 1.58669 - acc: 0.6584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6647  | total loss: \u001b[1m\u001b[32m1.47454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6647 | loss: 1.47454 - acc: 0.6925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6648  | total loss: \u001b[1m\u001b[32m1.67405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6648 | loss: 1.67405 - acc: 0.6304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6649  | total loss: \u001b[1m\u001b[32m1.55367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6649 | loss: 1.55367 - acc: 0.6674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6650  | total loss: \u001b[1m\u001b[32m1.44544\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6650 | loss: 1.44544 - acc: 0.7007 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6651  | total loss: \u001b[1m\u001b[32m1.34764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6651 | loss: 1.34764 - acc: 0.7306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6652  | total loss: \u001b[1m\u001b[32m1.55278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6652 | loss: 1.55278 - acc: 0.6647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6653  | total loss: \u001b[1m\u001b[32m1.44345\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6653 | loss: 1.44345 - acc: 0.6982 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6654  | total loss: \u001b[1m\u001b[32m1.34462\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6654 | loss: 1.34462 - acc: 0.7284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6655  | total loss: \u001b[1m\u001b[32m1.25480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6655 | loss: 1.25480 - acc: 0.7555 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6656  | total loss: \u001b[1m\u001b[32m1.45823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6656 | loss: 1.45823 - acc: 0.6943 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6657  | total loss: \u001b[1m\u001b[32m1.35541\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6657 | loss: 1.35541 - acc: 0.7248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6658  | total loss: \u001b[1m\u001b[32m1.58650\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6658 | loss: 1.58650 - acc: 0.6524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6659  | total loss: \u001b[1m\u001b[32m1.47019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6659 | loss: 1.47019 - acc: 0.6871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6660  | total loss: \u001b[1m\u001b[32m1.36520\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6660 | loss: 1.36520 - acc: 0.7184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6661  | total loss: \u001b[1m\u001b[32m1.27000\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6661 | loss: 1.27000 - acc: 0.7466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6662  | total loss: \u001b[1m\u001b[32m1.46504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6662 | loss: 1.46504 - acc: 0.6862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6663  | total loss: \u001b[1m\u001b[32m1.35855\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6663 | loss: 1.35855 - acc: 0.7176 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6664  | total loss: \u001b[1m\u001b[32m1.26207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6664 | loss: 1.26207 - acc: 0.7458 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6665  | total loss: \u001b[1m\u001b[32m1.17427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6665 | loss: 1.17427 - acc: 0.7712 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6666  | total loss: \u001b[1m\u001b[32m1.39778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6666 | loss: 1.39778 - acc: 0.7013 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6667  | total loss: \u001b[1m\u001b[32m1.29486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6667 | loss: 1.29486 - acc: 0.7311 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6668  | total loss: \u001b[1m\u001b[32m1.50452\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6668 | loss: 1.50452 - acc: 0.6723 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6669  | total loss: \u001b[1m\u001b[32m1.39038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6669 | loss: 1.39038 - acc: 0.7051 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6670  | total loss: \u001b[1m\u001b[32m1.28739\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6670 | loss: 1.28739 - acc: 0.7346 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6671  | total loss: \u001b[1m\u001b[32m1.19414\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6671 | loss: 1.19414 - acc: 0.7611 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6672  | total loss: \u001b[1m\u001b[32m1.10936\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6672 | loss: 1.10936 - acc: 0.7850 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6673  | total loss: \u001b[1m\u001b[32m1.03197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6673 | loss: 1.03197 - acc: 0.8065 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6674  | total loss: \u001b[1m\u001b[32m0.96104\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6674 | loss: 0.96104 - acc: 0.8259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6675  | total loss: \u001b[1m\u001b[32m0.89579\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6675 | loss: 0.89579 - acc: 0.8433 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6676  | total loss: \u001b[1m\u001b[32m1.20507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6676 | loss: 1.20507 - acc: 0.7589 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6677  | total loss: \u001b[1m\u001b[32m1.11334\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6677 | loss: 1.11334 - acc: 0.7830 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6678  | total loss: \u001b[1m\u001b[32m1.42231\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6678 | loss: 1.42231 - acc: 0.7047 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6679  | total loss: \u001b[1m\u001b[32m1.30833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6679 | loss: 1.30833 - acc: 0.7343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6680  | total loss: \u001b[1m\u001b[32m1.20570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6680 | loss: 1.20570 - acc: 0.7608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6681  | total loss: \u001b[1m\u001b[32m1.11301\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6681 | loss: 1.11301 - acc: 0.7848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6682  | total loss: \u001b[1m\u001b[32m1.02907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6682 | loss: 1.02907 - acc: 0.8063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6683  | total loss: \u001b[1m\u001b[32m0.95281\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6683 | loss: 0.95281 - acc: 0.8257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6684  | total loss: \u001b[1m\u001b[32m1.22346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6684 | loss: 1.22346 - acc: 0.7502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6685  | total loss: \u001b[1m\u001b[32m1.12685\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6685 | loss: 1.12685 - acc: 0.7752 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6686  | total loss: \u001b[1m\u001b[32m1.03964\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6686 | loss: 1.03964 - acc: 0.7977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6687  | total loss: \u001b[1m\u001b[32m0.96070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6687 | loss: 0.96070 - acc: 0.8179 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6688  | total loss: \u001b[1m\u001b[32m1.24037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6688 | loss: 1.24037 - acc: 0.7504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6689  | total loss: \u001b[1m\u001b[32m1.14087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6689 | loss: 1.14087 - acc: 0.7754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6690  | total loss: \u001b[1m\u001b[32m1.45103\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6690 | loss: 1.45103 - acc: 0.6978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6691  | total loss: \u001b[1m\u001b[32m1.33108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6691 | loss: 1.33108 - acc: 0.7280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6692  | total loss: \u001b[1m\u001b[32m1.22357\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6692 | loss: 1.22357 - acc: 0.7552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6693  | total loss: \u001b[1m\u001b[32m1.12698\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6693 | loss: 1.12698 - acc: 0.7797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6694  | total loss: \u001b[1m\u001b[32m1.03999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6694 | loss: 1.03999 - acc: 0.8017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6695  | total loss: \u001b[1m\u001b[32m0.96140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6695 | loss: 0.96140 - acc: 0.8216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6696  | total loss: \u001b[1m\u001b[32m1.20626\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6696 | loss: 1.20626 - acc: 0.7608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6697  | total loss: \u001b[1m\u001b[32m1.11072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6697 | loss: 1.11072 - acc: 0.7848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6698  | total loss: \u001b[1m\u001b[32m1.39575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6698 | loss: 1.39575 - acc: 0.7134 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6699  | total loss: \u001b[1m\u001b[32m1.28185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6699 | loss: 1.28185 - acc: 0.7421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6700  | total loss: \u001b[1m\u001b[32m1.53805\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6700 | loss: 1.53805 - acc: 0.6750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6701  | total loss: \u001b[1m\u001b[32m1.41146\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6701 | loss: 1.41146 - acc: 0.7075 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6702  | total loss: \u001b[1m\u001b[32m1.29835\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6702 | loss: 1.29835 - acc: 0.7368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6703  | total loss: \u001b[1m\u001b[32m1.19705\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6703 | loss: 1.19705 - acc: 0.7631 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6704  | total loss: \u001b[1m\u001b[32m1.46977\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6704 | loss: 1.46977 - acc: 0.6868 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6705  | total loss: \u001b[1m\u001b[32m1.35255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6705 | loss: 1.35255 - acc: 0.7181 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6706  | total loss: \u001b[1m\u001b[32m1.59602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6706 | loss: 1.59602 - acc: 0.6534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6707  | total loss: \u001b[1m\u001b[32m1.46824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6707 | loss: 1.46824 - acc: 0.6881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6708  | total loss: \u001b[1m\u001b[32m1.35422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6708 | loss: 1.35422 - acc: 0.7193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6709  | total loss: \u001b[1m\u001b[32m1.25218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6709 | loss: 1.25218 - acc: 0.7474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6710  | total loss: \u001b[1m\u001b[32m1.46861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6710 | loss: 1.46861 - acc: 0.6869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6711  | total loss: \u001b[1m\u001b[32m1.35624\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6711 | loss: 1.35624 - acc: 0.7182 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6712  | total loss: \u001b[1m\u001b[32m1.25559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6712 | loss: 1.25559 - acc: 0.7464 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6713  | total loss: \u001b[1m\u001b[32m1.16511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6713 | loss: 1.16511 - acc: 0.7718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6714  | total loss: \u001b[1m\u001b[32m1.41849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6714 | loss: 1.41849 - acc: 0.7017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6715  | total loss: \u001b[1m\u001b[32m1.31206\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6715 | loss: 1.31206 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6716  | total loss: \u001b[1m\u001b[32m1.58519\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6716 | loss: 1.58519 - acc: 0.6584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6717  | total loss: \u001b[1m\u001b[32m1.46338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6717 | loss: 1.46338 - acc: 0.6926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6718  | total loss: \u001b[1m\u001b[32m1.66994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6718 | loss: 1.66994 - acc: 0.6304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6719  | total loss: \u001b[1m\u001b[32m1.54168\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6719 | loss: 1.54168 - acc: 0.6674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6720  | total loss: \u001b[1m\u001b[32m1.42712\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6720 | loss: 1.42712 - acc: 0.7007 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6721  | total loss: \u001b[1m\u001b[32m1.32440\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 6721 | loss: 1.32440 - acc: 0.7306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6722  | total loss: \u001b[1m\u001b[32m1.55928\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6722 | loss: 1.55928 - acc: 0.6647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6723  | total loss: \u001b[1m\u001b[32m1.44402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6723 | loss: 1.44402 - acc: 0.6982 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6724  | total loss: \u001b[1m\u001b[32m1.34053\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6724 | loss: 1.34053 - acc: 0.7284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6725  | total loss: \u001b[1m\u001b[32m1.24719\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6725 | loss: 1.24719 - acc: 0.7555 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6726  | total loss: \u001b[1m\u001b[32m1.46446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6726 | loss: 1.46446 - acc: 0.6871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6727  | total loss: \u001b[1m\u001b[32m1.35837\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6727 | loss: 1.35837 - acc: 0.7184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6728  | total loss: \u001b[1m\u001b[32m1.26269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6728 | loss: 1.26269 - acc: 0.7466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6729  | total loss: \u001b[1m\u001b[32m1.17600\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6729 | loss: 1.17600 - acc: 0.7719 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6730  | total loss: \u001b[1m\u001b[32m1.40551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6730 | loss: 1.40551 - acc: 0.7019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6731  | total loss: \u001b[1m\u001b[32m1.30360\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6731 | loss: 1.30360 - acc: 0.7317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6732  | total loss: \u001b[1m\u001b[32m1.21147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6732 | loss: 1.21147 - acc: 0.7585 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6733  | total loss: \u001b[1m\u001b[32m1.12781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6733 | loss: 1.12781 - acc: 0.7827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6734  | total loss: \u001b[1m\u001b[32m1.35458\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6734 | loss: 1.35458 - acc: 0.7187 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6735  | total loss: \u001b[1m\u001b[32m1.25529\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6735 | loss: 1.25529 - acc: 0.7468 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6736  | total loss: \u001b[1m\u001b[32m1.16533\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6736 | loss: 1.16533 - acc: 0.7721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6737  | total loss: \u001b[1m\u001b[32m1.08348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6737 | loss: 1.08348 - acc: 0.7949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6738  | total loss: \u001b[1m\u001b[32m1.00868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6738 | loss: 1.00868 - acc: 0.8154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6739  | total loss: \u001b[1m\u001b[32m0.94003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6739 | loss: 0.94003 - acc: 0.8339 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6740  | total loss: \u001b[1m\u001b[32m1.22702\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6740 | loss: 1.22702 - acc: 0.7505 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6741  | total loss: \u001b[1m\u001b[32m1.13459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6741 | loss: 1.13459 - acc: 0.7754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6742  | total loss: \u001b[1m\u001b[32m1.38502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6742 | loss: 1.38502 - acc: 0.7050 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6743  | total loss: \u001b[1m\u001b[32m1.27620\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6743 | loss: 1.27620 - acc: 0.7345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6744  | total loss: \u001b[1m\u001b[32m1.51004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6744 | loss: 1.51004 - acc: 0.6682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6745  | total loss: \u001b[1m\u001b[32m1.38909\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6745 | loss: 1.38909 - acc: 0.7014 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6746  | total loss: \u001b[1m\u001b[32m1.28045\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6746 | loss: 1.28045 - acc: 0.7313 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6747  | total loss: \u001b[1m\u001b[32m1.18258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6747 | loss: 1.18258 - acc: 0.7581 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6748  | total loss: \u001b[1m\u001b[32m1.09415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6748 | loss: 1.09415 - acc: 0.7823 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6749  | total loss: \u001b[1m\u001b[32m1.01397\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6749 | loss: 1.01397 - acc: 0.8041 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6750  | total loss: \u001b[1m\u001b[32m1.26887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6750 | loss: 1.26887 - acc: 0.7380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6751  | total loss: \u001b[1m\u001b[32m1.17044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6751 | loss: 1.17044 - acc: 0.7642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6752  | total loss: \u001b[1m\u001b[32m1.08161\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6752 | loss: 1.08161 - acc: 0.7878 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6753  | total loss: \u001b[1m\u001b[32m1.00120\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6753 | loss: 1.00120 - acc: 0.8090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6754  | total loss: \u001b[1m\u001b[32m1.27668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6754 | loss: 1.27668 - acc: 0.7352 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6755  | total loss: \u001b[1m\u001b[32m1.17620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6755 | loss: 1.17620 - acc: 0.7617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6756  | total loss: \u001b[1m\u001b[32m1.45322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6756 | loss: 1.45322 - acc: 0.6927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6757  | total loss: \u001b[1m\u001b[32m1.33555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6757 | loss: 1.33555 - acc: 0.7234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6758  | total loss: \u001b[1m\u001b[32m1.59225\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6758 | loss: 1.59225 - acc: 0.6582 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6759  | total loss: \u001b[1m\u001b[32m1.46201\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6759 | loss: 1.46201 - acc: 0.6924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6760  | total loss: \u001b[1m\u001b[32m1.66934\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6760 | loss: 1.66934 - acc: 0.6303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6761  | total loss: \u001b[1m\u001b[32m1.53352\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6761 | loss: 1.53352 - acc: 0.6673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6762  | total loss: \u001b[1m\u001b[32m1.74273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6762 | loss: 1.74273 - acc: 0.6077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6763  | total loss: \u001b[1m\u001b[32m1.60237\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6763 | loss: 1.60237 - acc: 0.6469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6764  | total loss: \u001b[1m\u001b[32m1.47736\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6764 | loss: 1.47736 - acc: 0.6822 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6765  | total loss: \u001b[1m\u001b[32m1.36572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6765 | loss: 1.36572 - acc: 0.7140 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6766  | total loss: \u001b[1m\u001b[32m1.26567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6766 | loss: 1.26567 - acc: 0.7426 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6767  | total loss: \u001b[1m\u001b[32m1.17565\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6767 | loss: 1.17565 - acc: 0.7683 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6768  | total loss: \u001b[1m\u001b[32m1.43861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6768 | loss: 1.43861 - acc: 0.6986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6769  | total loss: \u001b[1m\u001b[32m1.33148\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6769 | loss: 1.33148 - acc: 0.7288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6770  | total loss: \u001b[1m\u001b[32m1.55739\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6770 | loss: 1.55739 - acc: 0.6630 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6771  | total loss: \u001b[1m\u001b[32m1.43943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6771 | loss: 1.43943 - acc: 0.6967 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6772  | total loss: \u001b[1m\u001b[32m1.59048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6772 | loss: 1.59048 - acc: 0.6485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6773  | total loss: \u001b[1m\u001b[32m1.47070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6773 | loss: 1.47070 - acc: 0.6836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6774  | total loss: \u001b[1m\u001b[32m1.71091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6774 | loss: 1.71091 - acc: 0.6153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6775  | total loss: \u001b[1m\u001b[32m1.58095\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6775 | loss: 1.58095 - acc: 0.6538 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6776  | total loss: \u001b[1m\u001b[32m1.76133\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6776 | loss: 1.76133 - acc: 0.5955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6777  | total loss: \u001b[1m\u001b[32m1.62864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6777 | loss: 1.62864 - acc: 0.6360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6778  | total loss: \u001b[1m\u001b[32m1.51016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6778 | loss: 1.51016 - acc: 0.6724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6779  | total loss: \u001b[1m\u001b[32m1.40391\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6779 | loss: 1.40391 - acc: 0.7051 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6780  | total loss: \u001b[1m\u001b[32m1.59615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6780 | loss: 1.59615 - acc: 0.6489 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6781  | total loss: \u001b[1m\u001b[32m1.48174\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6781 | loss: 1.48174 - acc: 0.6840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6782  | total loss: \u001b[1m\u001b[32m1.37881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6782 | loss: 1.37881 - acc: 0.7156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6783  | total loss: \u001b[1m\u001b[32m1.28573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6783 | loss: 1.28573 - acc: 0.7441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6784  | total loss: \u001b[1m\u001b[32m1.52903\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6784 | loss: 1.52903 - acc: 0.6696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6785  | total loss: \u001b[1m\u001b[32m1.42008\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6785 | loss: 1.42008 - acc: 0.7027 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6786  | total loss: \u001b[1m\u001b[32m1.56762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6786 | loss: 1.56762 - acc: 0.6538 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6787  | total loss: \u001b[1m\u001b[32m1.45455\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6787 | loss: 1.45455 - acc: 0.6885 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6788  | total loss: \u001b[1m\u001b[32m1.35253\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6788 | loss: 1.35253 - acc: 0.7196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6789  | total loss: \u001b[1m\u001b[32m1.26003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6789 | loss: 1.26003 - acc: 0.7477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6790  | total loss: \u001b[1m\u001b[32m1.50724\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6790 | loss: 1.50724 - acc: 0.6729 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6791  | total loss: \u001b[1m\u001b[32m1.39819\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6791 | loss: 1.39819 - acc: 0.7056 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6792  | total loss: \u001b[1m\u001b[32m1.60389\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6792 | loss: 1.60389 - acc: 0.6422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6793  | total loss: \u001b[1m\u001b[32m1.48508\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6793 | loss: 1.48508 - acc: 0.6780 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6794  | total loss: \u001b[1m\u001b[32m1.65877\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6794 | loss: 1.65877 - acc: 0.6245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6795  | total loss: \u001b[1m\u001b[32m1.53492\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6795 | loss: 1.53492 - acc: 0.6620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6796  | total loss: \u001b[1m\u001b[32m1.71825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6796 | loss: 1.71825 - acc: 0.6029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6797  | total loss: \u001b[1m\u001b[32m1.58938\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6797 | loss: 1.58938 - acc: 0.6427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6798  | total loss: \u001b[1m\u001b[32m1.77515\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6798 | loss: 1.77515 - acc: 0.5784 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6799  | total loss: \u001b[1m\u001b[32m1.64210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6799 | loss: 1.64210 - acc: 0.6206 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6800  | total loss: \u001b[1m\u001b[32m1.85216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6800 | loss: 1.85216 - acc: 0.5585 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6801  | total loss: \u001b[1m\u001b[32m1.71353\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6801 | loss: 1.71353 - acc: 0.6026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6802  | total loss: \u001b[1m\u001b[32m1.58966\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6802 | loss: 1.58966 - acc: 0.6424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6803  | total loss: \u001b[1m\u001b[32m1.47848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6803 | loss: 1.47848 - acc: 0.6781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6804  | total loss: \u001b[1m\u001b[32m1.65866\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6804 | loss: 1.65866 - acc: 0.6246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6805  | total loss: \u001b[1m\u001b[32m1.54083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6805 | loss: 1.54083 - acc: 0.6622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6806  | total loss: \u001b[1m\u001b[32m1.75752\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6806 | loss: 1.75752 - acc: 0.5959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6807  | total loss: \u001b[1m\u001b[32m1.63053\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6807 | loss: 1.63053 - acc: 0.6363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6808  | total loss: \u001b[1m\u001b[32m1.51645\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6808 | loss: 1.51645 - acc: 0.6727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6809  | total loss: \u001b[1m\u001b[32m1.41344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6809 | loss: 1.41344 - acc: 0.7054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6810  | total loss: \u001b[1m\u001b[32m1.31990\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6810 | loss: 1.31990 - acc: 0.7349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6811  | total loss: \u001b[1m\u001b[32m1.23447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6811 | loss: 1.23447 - acc: 0.7614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6812  | total loss: \u001b[1m\u001b[32m1.40722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6812 | loss: 1.40722 - acc: 0.7067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6813  | total loss: \u001b[1m\u001b[32m1.31057\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6813 | loss: 1.31057 - acc: 0.7360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6814  | total loss: \u001b[1m\u001b[32m1.22236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6814 | loss: 1.22236 - acc: 0.7624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6815  | total loss: \u001b[1m\u001b[32m1.14143\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6815 | loss: 1.14143 - acc: 0.7862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6816  | total loss: \u001b[1m\u001b[32m1.37957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6816 | loss: 1.37957 - acc: 0.7076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6817  | total loss: \u001b[1m\u001b[32m1.28041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6817 | loss: 1.28041 - acc: 0.7368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6818  | total loss: \u001b[1m\u001b[32m1.19011\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6818 | loss: 1.19011 - acc: 0.7631 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6819  | total loss: \u001b[1m\u001b[32m1.10755\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6819 | loss: 1.10755 - acc: 0.7868 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6820  | total loss: \u001b[1m\u001b[32m1.37022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6820 | loss: 1.37022 - acc: 0.7153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6821  | total loss: \u001b[1m\u001b[32m1.26760\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6821 | loss: 1.26760 - acc: 0.7437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6822  | total loss: \u001b[1m\u001b[32m1.17441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6822 | loss: 1.17441 - acc: 0.7694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6823  | total loss: \u001b[1m\u001b[32m1.08950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6823 | loss: 1.08950 - acc: 0.7924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6824  | total loss: \u001b[1m\u001b[32m1.01186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6824 | loss: 1.01186 - acc: 0.8132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6825  | total loss: \u001b[1m\u001b[32m0.94063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6825 | loss: 0.94063 - acc: 0.8319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6826  | total loss: \u001b[1m\u001b[32m0.87508\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6826 | loss: 0.87508 - acc: 0.8487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6827  | total loss: \u001b[1m\u001b[32m0.81457\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6827 | loss: 0.81457 - acc: 0.8638 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6828  | total loss: \u001b[1m\u001b[32m0.75858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6828 | loss: 0.75858 - acc: 0.8774 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6829  | total loss: \u001b[1m\u001b[32m0.70665\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6829 | loss: 0.70665 - acc: 0.8897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6830  | total loss: \u001b[1m\u001b[32m1.09620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6830 | loss: 1.09620 - acc: 0.8007 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6831  | total loss: \u001b[1m\u001b[32m1.00845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6831 | loss: 1.00845 - acc: 0.8206 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6832  | total loss: \u001b[1m\u001b[32m1.32883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6832 | loss: 1.32883 - acc: 0.7457 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6833  | total loss: \u001b[1m\u001b[32m1.21737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6833 | loss: 1.21737 - acc: 0.7712 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6834  | total loss: \u001b[1m\u001b[32m1.11706\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6834 | loss: 1.11706 - acc: 0.7940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6835  | total loss: \u001b[1m\u001b[32m1.02662\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6835 | loss: 1.02662 - acc: 0.8146 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6836  | total loss: \u001b[1m\u001b[32m0.94493\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6836 | loss: 0.94493 - acc: 0.8332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6837  | total loss: \u001b[1m\u001b[32m0.87099\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6837 | loss: 0.87099 - acc: 0.8499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6838  | total loss: \u001b[1m\u001b[32m0.80390\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6838 | loss: 0.80390 - acc: 0.8649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6839  | total loss: \u001b[1m\u001b[32m0.74290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6839 | loss: 0.74290 - acc: 0.8784 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6840  | total loss: \u001b[1m\u001b[32m1.11789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6840 | loss: 1.11789 - acc: 0.7905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6841  | total loss: \u001b[1m\u001b[32m1.02490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6841 | loss: 1.02490 - acc: 0.8115 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6842  | total loss: \u001b[1m\u001b[32m0.94116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6842 | loss: 0.94116 - acc: 0.8303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6843  | total loss: \u001b[1m\u001b[32m0.86561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6843 | loss: 0.86561 - acc: 0.8473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6844  | total loss: \u001b[1m\u001b[32m1.18885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6844 | loss: 1.18885 - acc: 0.7769 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6845  | total loss: \u001b[1m\u001b[32m1.08858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6845 | loss: 1.08858 - acc: 0.7992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6846  | total loss: \u001b[1m\u001b[32m1.42714\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6846 | loss: 1.42714 - acc: 0.7193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6847  | total loss: \u001b[1m\u001b[32m1.30410\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6847 | loss: 1.30410 - acc: 0.7473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6848  | total loss: \u001b[1m\u001b[32m1.19403\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6848 | loss: 1.19403 - acc: 0.7726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6849  | total loss: \u001b[1m\u001b[32m1.09543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6849 | loss: 1.09543 - acc: 0.7953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6850  | total loss: \u001b[1m\u001b[32m1.43596\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6850 | loss: 1.43596 - acc: 0.7158 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6851  | total loss: \u001b[1m\u001b[32m1.31443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6851 | loss: 1.31443 - acc: 0.7442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6852  | total loss: \u001b[1m\u001b[32m1.20582\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6852 | loss: 1.20582 - acc: 0.7698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6853  | total loss: \u001b[1m\u001b[32m1.10857\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6853 | loss: 1.10857 - acc: 0.7928 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6854  | total loss: \u001b[1m\u001b[32m1.37987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6854 | loss: 1.37987 - acc: 0.7207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6855  | total loss: \u001b[1m\u001b[32m1.26644\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6855 | loss: 1.26644 - acc: 0.7486 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6856  | total loss: \u001b[1m\u001b[32m1.16501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6856 | loss: 1.16501 - acc: 0.7738 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6857  | total loss: \u001b[1m\u001b[32m1.07412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6857 | loss: 1.07412 - acc: 0.7964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6858  | total loss: \u001b[1m\u001b[32m0.99243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6858 | loss: 0.99243 - acc: 0.8167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6859  | total loss: \u001b[1m\u001b[32m0.91878\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6859 | loss: 0.91878 - acc: 0.8351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6860  | total loss: \u001b[1m\u001b[32m0.85215\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6860 | loss: 0.85215 - acc: 0.8516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6861  | total loss: \u001b[1m\u001b[32m0.79163\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6861 | loss: 0.79163 - acc: 0.8664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6862  | total loss: \u001b[1m\u001b[32m1.11939\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6862 | loss: 1.11939 - acc: 0.7798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6863  | total loss: \u001b[1m\u001b[32m1.03158\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6863 | loss: 1.03158 - acc: 0.8018 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6864  | total loss: \u001b[1m\u001b[32m1.32995\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6864 | loss: 1.32995 - acc: 0.7288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6865  | total loss: \u001b[1m\u001b[32m1.22165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6865 | loss: 1.22165 - acc: 0.7559 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6866  | total loss: \u001b[1m\u001b[32m1.51485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6866 | loss: 1.51485 - acc: 0.6874 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6867  | total loss: \u001b[1m\u001b[32m1.38955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6867 | loss: 1.38955 - acc: 0.7187 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6868  | total loss: \u001b[1m\u001b[32m1.52770\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6868 | loss: 1.52770 - acc: 0.6754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6869  | total loss: \u001b[1m\u001b[32m1.40314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6869 | loss: 1.40314 - acc: 0.7079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6870  | total loss: \u001b[1m\u001b[32m1.62081\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6870 | loss: 1.62081 - acc: 0.6514 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6871  | total loss: \u001b[1m\u001b[32m1.48932\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6871 | loss: 1.48932 - acc: 0.6862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6872  | total loss: \u001b[1m\u001b[32m1.70725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6872 | loss: 1.70725 - acc: 0.6247 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6873  | total loss: \u001b[1m\u001b[32m1.57004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6873 | loss: 1.57004 - acc: 0.6623 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6874  | total loss: \u001b[1m\u001b[32m1.78157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6874 | loss: 1.78157 - acc: 0.6032 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6875  | total loss: \u001b[1m\u001b[32m1.64035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6875 | loss: 1.64035 - acc: 0.6429 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6876  | total loss: \u001b[1m\u001b[32m1.51483\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6876 | loss: 1.51483 - acc: 0.6786 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6877  | total loss: \u001b[1m\u001b[32m1.40290\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6877 | loss: 1.40290 - acc: 0.7107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6878  | total loss: \u001b[1m\u001b[32m1.30270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6878 | loss: 1.30270 - acc: 0.7396 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6879  | total loss: \u001b[1m\u001b[32m1.21259\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6879 | loss: 1.21259 - acc: 0.7657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6880  | total loss: \u001b[1m\u001b[32m1.44973\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6880 | loss: 1.44973 - acc: 0.6891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6881  | total loss: \u001b[1m\u001b[32m1.34506\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6881 | loss: 1.34506 - acc: 0.7202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6882  | total loss: \u001b[1m\u001b[32m1.57421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6882 | loss: 1.57421 - acc: 0.6482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6883  | total loss: \u001b[1m\u001b[32m1.45804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6883 | loss: 1.45804 - acc: 0.6834 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6884  | total loss: \u001b[1m\u001b[32m1.35387\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6884 | loss: 1.35387 - acc: 0.7150 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6885  | total loss: \u001b[1m\u001b[32m1.26002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6885 | loss: 1.26002 - acc: 0.7435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6886  | total loss: \u001b[1m\u001b[32m1.46764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6886 | loss: 1.46764 - acc: 0.6763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6887  | total loss: \u001b[1m\u001b[32m1.36218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6887 | loss: 1.36218 - acc: 0.7087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6888  | total loss: \u001b[1m\u001b[32m1.58960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6888 | loss: 1.58960 - acc: 0.6378 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6889  | total loss: \u001b[1m\u001b[32m1.47253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6889 | loss: 1.47253 - acc: 0.6740 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6890  | total loss: \u001b[1m\u001b[32m1.64701\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6890 | loss: 1.64701 - acc: 0.6209 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6891  | total loss: \u001b[1m\u001b[32m1.52537\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6891 | loss: 1.52537 - acc: 0.6588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6892  | total loss: \u001b[1m\u001b[32m1.41628\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6892 | loss: 1.41628 - acc: 0.6929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6893  | total loss: \u001b[1m\u001b[32m1.31801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6893 | loss: 1.31801 - acc: 0.7236 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6894  | total loss: \u001b[1m\u001b[32m1.55199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6894 | loss: 1.55199 - acc: 0.6584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6895  | total loss: \u001b[1m\u001b[32m1.43994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6895 | loss: 1.43994 - acc: 0.6926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6896  | total loss: \u001b[1m\u001b[32m1.60653\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6896 | loss: 1.60653 - acc: 0.6376 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6897  | total loss: \u001b[1m\u001b[32m1.48939\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6897 | loss: 1.48939 - acc: 0.6738 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6898  | total loss: \u001b[1m\u001b[32m1.71209\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6898 | loss: 1.71209 - acc: 0.6065 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6899  | total loss: \u001b[1m\u001b[32m1.58532\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6899 | loss: 1.58532 - acc: 0.6458 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6900  | total loss: \u001b[1m\u001b[32m1.78092\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6900 | loss: 1.78092 - acc: 0.5884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6901  | total loss: \u001b[1m\u001b[32m1.64868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6901 | loss: 1.64868 - acc: 0.6295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6902  | total loss: \u001b[1m\u001b[32m1.80832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6902 | loss: 1.80832 - acc: 0.5809 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6903  | total loss: \u001b[1m\u001b[32m1.67498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6903 | loss: 1.67498 - acc: 0.6228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6904  | total loss: \u001b[1m\u001b[32m1.55551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6904 | loss: 1.55551 - acc: 0.6605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6905  | total loss: \u001b[1m\u001b[32m1.44797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6905 | loss: 1.44797 - acc: 0.6945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6906  | total loss: \u001b[1m\u001b[32m1.65477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6906 | loss: 1.65477 - acc: 0.6250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6907  | total loss: \u001b[1m\u001b[32m1.53714\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6907 | loss: 1.53714 - acc: 0.6625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6908  | total loss: \u001b[1m\u001b[32m1.73641\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6908 | loss: 1.73641 - acc: 0.5963 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6909  | total loss: \u001b[1m\u001b[32m1.61121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6909 | loss: 1.61121 - acc: 0.6366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6910  | total loss: \u001b[1m\u001b[32m1.49870\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6910 | loss: 1.49870 - acc: 0.6730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6911  | total loss: \u001b[1m\u001b[32m1.39707\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6911 | loss: 1.39707 - acc: 0.7057 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6912  | total loss: \u001b[1m\u001b[32m1.30475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6912 | loss: 1.30475 - acc: 0.7351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6913  | total loss: \u001b[1m\u001b[32m1.22039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6913 | loss: 1.22039 - acc: 0.7616 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6914  | total loss: \u001b[1m\u001b[32m1.46271\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6914 | loss: 1.46271 - acc: 0.6854 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6915  | total loss: \u001b[1m\u001b[32m1.36037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6915 | loss: 1.36037 - acc: 0.7169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6916  | total loss: \u001b[1m\u001b[32m1.58586\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6916 | loss: 1.58586 - acc: 0.6523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6917  | total loss: \u001b[1m\u001b[32m1.47025\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6917 | loss: 1.47025 - acc: 0.6871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6918  | total loss: \u001b[1m\u001b[32m1.36576\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6918 | loss: 1.36576 - acc: 0.7184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6919  | total loss: \u001b[1m\u001b[32m1.27089\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6919 | loss: 1.27089 - acc: 0.7466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6920  | total loss: \u001b[1m\u001b[32m1.49643\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6920 | loss: 1.49643 - acc: 0.6790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6921  | total loss: \u001b[1m\u001b[32m1.38707\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6921 | loss: 1.38707 - acc: 0.7111 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6922  | total loss: \u001b[1m\u001b[32m1.62511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6922 | loss: 1.62511 - acc: 0.6472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6923  | total loss: \u001b[1m\u001b[32m1.50245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6923 | loss: 1.50245 - acc: 0.6825 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6924  | total loss: \u001b[1m\u001b[32m1.73316\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6924 | loss: 1.73316 - acc: 0.6214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6925  | total loss: \u001b[1m\u001b[32m1.60012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6925 | loss: 1.60012 - acc: 0.6592 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6926  | total loss: \u001b[1m\u001b[32m1.76243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6926 | loss: 1.76243 - acc: 0.6076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6927  | total loss: \u001b[1m\u001b[32m1.62749\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6927 | loss: 1.62749 - acc: 0.6468 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6928  | total loss: \u001b[1m\u001b[32m1.85194\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6928 | loss: 1.85194 - acc: 0.5821 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6929  | total loss: \u001b[1m\u001b[32m1.70959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6929 | loss: 1.70959 - acc: 0.6239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6930  | total loss: \u001b[1m\u001b[32m1.58212\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6930 | loss: 1.58212 - acc: 0.6615 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6931  | total loss: \u001b[1m\u001b[32m1.46752\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6931 | loss: 1.46752 - acc: 0.6954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6932  | total loss: \u001b[1m\u001b[32m1.63489\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6932 | loss: 1.63489 - acc: 0.6401 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6933  | total loss: \u001b[1m\u001b[32m1.51512\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6933 | loss: 1.51512 - acc: 0.6761 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6934  | total loss: \u001b[1m\u001b[32m1.68839\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6934 | loss: 1.68839 - acc: 0.6228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6935  | total loss: \u001b[1m\u001b[32m1.56385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6935 | loss: 1.56385 - acc: 0.6605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6936  | total loss: \u001b[1m\u001b[32m1.45189\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6936 | loss: 1.45189 - acc: 0.6945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6937  | total loss: \u001b[1m\u001b[32m1.35079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6937 | loss: 1.35079 - acc: 0.7250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6938  | total loss: \u001b[1m\u001b[32m1.58216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6938 | loss: 1.58216 - acc: 0.6525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6939  | total loss: \u001b[1m\u001b[32m1.46741\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6939 | loss: 1.46741 - acc: 0.6873 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6940  | total loss: \u001b[1m\u001b[32m1.62989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6940 | loss: 1.62989 - acc: 0.6328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6941  | total loss: \u001b[1m\u001b[32m1.51036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6941 | loss: 1.51036 - acc: 0.6695 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6942  | total loss: \u001b[1m\u001b[32m1.68094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6942 | loss: 1.68094 - acc: 0.6240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6943  | total loss: \u001b[1m\u001b[32m1.55659\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 6943 | loss: 1.55659 - acc: 0.6616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6944  | total loss: \u001b[1m\u001b[32m1.77393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6944 | loss: 1.77393 - acc: 0.5955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6945  | total loss: \u001b[1m\u001b[32m1.64106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6945 | loss: 1.64106 - acc: 0.6359 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6946  | total loss: \u001b[1m\u001b[32m1.82472\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6946 | loss: 1.82472 - acc: 0.5795 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6947  | total loss: \u001b[1m\u001b[32m1.68813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6947 | loss: 1.68813 - acc: 0.6215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6948  | total loss: \u001b[1m\u001b[32m1.56570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6948 | loss: 1.56570 - acc: 0.6594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6949  | total loss: \u001b[1m\u001b[32m1.45552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6949 | loss: 1.45552 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6950  | total loss: \u001b[1m\u001b[32m1.35587\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6950 | loss: 1.35587 - acc: 0.7241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6951  | total loss: \u001b[1m\u001b[32m1.26530\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6951 | loss: 1.26530 - acc: 0.7517 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6952  | total loss: \u001b[1m\u001b[32m1.51003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6952 | loss: 1.51003 - acc: 0.6765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6953  | total loss: \u001b[1m\u001b[32m1.40258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6953 | loss: 1.40258 - acc: 0.7089 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6954  | total loss: \u001b[1m\u001b[32m1.60074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6954 | loss: 1.60074 - acc: 0.6451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6955  | total loss: \u001b[1m\u001b[32m1.48376\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6955 | loss: 1.48376 - acc: 0.6806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6956  | total loss: \u001b[1m\u001b[32m1.68084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6956 | loss: 1.68084 - acc: 0.6197 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6957  | total loss: \u001b[1m\u001b[32m1.55608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6957 | loss: 1.55608 - acc: 0.6577 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6958  | total loss: \u001b[1m\u001b[32m1.73117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6958 | loss: 1.73117 - acc: 0.6062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6959  | total loss: \u001b[1m\u001b[32m1.60210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6959 | loss: 1.60210 - acc: 0.6456 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6960  | total loss: \u001b[1m\u001b[32m1.48610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6960 | loss: 1.48610 - acc: 0.6810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6961  | total loss: \u001b[1m\u001b[32m1.38142\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6961 | loss: 1.38142 - acc: 0.7129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6962  | total loss: \u001b[1m\u001b[32m1.60998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6962 | loss: 1.60998 - acc: 0.6416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6963  | total loss: \u001b[1m\u001b[32m1.49243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6963 | loss: 1.49243 - acc: 0.6775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6964  | total loss: \u001b[1m\u001b[32m1.38639\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6964 | loss: 1.38639 - acc: 0.7097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6965  | total loss: \u001b[1m\u001b[32m1.29031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6965 | loss: 1.29031 - acc: 0.7388 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6966  | total loss: \u001b[1m\u001b[32m1.51132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6966 | loss: 1.51132 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6967  | total loss: \u001b[1m\u001b[32m1.40159\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6967 | loss: 1.40159 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6968  | total loss: \u001b[1m\u001b[32m1.65035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6968 | loss: 1.65035 - acc: 0.6343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6969  | total loss: \u001b[1m\u001b[32m1.52658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6969 | loss: 1.52658 - acc: 0.6709 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6970  | total loss: \u001b[1m\u001b[32m1.41514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6970 | loss: 1.41514 - acc: 0.7038 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 6971  | total loss: \u001b[1m\u001b[32m1.31441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6971 | loss: 1.31441 - acc: 0.7334 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6972  | total loss: \u001b[1m\u001b[32m1.22296\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6972 | loss: 1.22296 - acc: 0.7601 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6973  | total loss: \u001b[1m\u001b[32m1.13955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6973 | loss: 1.13955 - acc: 0.7841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6974  | total loss: \u001b[1m\u001b[32m1.40422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6974 | loss: 1.40422 - acc: 0.7057 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6975  | total loss: \u001b[1m\u001b[32m1.30103\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6975 | loss: 1.30103 - acc: 0.7351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6976  | total loss: \u001b[1m\u001b[32m1.49636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6976 | loss: 1.49636 - acc: 0.6759 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6977  | total loss: \u001b[1m\u001b[32m1.38339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6977 | loss: 1.38339 - acc: 0.7083 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6978  | total loss: \u001b[1m\u001b[32m1.28142\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6978 | loss: 1.28142 - acc: 0.7375 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6979  | total loss: \u001b[1m\u001b[32m1.18905\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6979 | loss: 1.18905 - acc: 0.7637 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6980  | total loss: \u001b[1m\u001b[32m1.43237\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6980 | loss: 1.43237 - acc: 0.6945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6981  | total loss: \u001b[1m\u001b[32m1.32400\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6981 | loss: 1.32400 - acc: 0.7250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6982  | total loss: \u001b[1m\u001b[32m1.54959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6982 | loss: 1.54959 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6983  | total loss: \u001b[1m\u001b[32m1.42954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6983 | loss: 1.42954 - acc: 0.7001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6984  | total loss: \u001b[1m\u001b[32m1.32154\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6984 | loss: 1.32154 - acc: 0.7301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6985  | total loss: \u001b[1m\u001b[32m1.22403\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6985 | loss: 1.22403 - acc: 0.7571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6986  | total loss: \u001b[1m\u001b[32m1.13568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6986 | loss: 1.13568 - acc: 0.7814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6987  | total loss: \u001b[1m\u001b[32m1.05531\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6987 | loss: 1.05531 - acc: 0.8033 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6988  | total loss: \u001b[1m\u001b[32m1.33723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6988 | loss: 1.33723 - acc: 0.7229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6989  | total loss: \u001b[1m\u001b[32m1.23552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6989 | loss: 1.23552 - acc: 0.7506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6990  | total loss: \u001b[1m\u001b[32m1.50211\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6990 | loss: 1.50211 - acc: 0.6756 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6991  | total loss: \u001b[1m\u001b[32m1.38400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6991 | loss: 1.38400 - acc: 0.7080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6992  | total loss: \u001b[1m\u001b[32m1.27785\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6992 | loss: 1.27785 - acc: 0.7372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6993  | total loss: \u001b[1m\u001b[32m1.18215\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6993 | loss: 1.18215 - acc: 0.7635 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6994  | total loss: \u001b[1m\u001b[32m1.09557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6994 | loss: 1.09557 - acc: 0.7871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6995  | total loss: \u001b[1m\u001b[32m1.01697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6995 | loss: 1.01697 - acc: 0.8084 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6996  | total loss: \u001b[1m\u001b[32m0.94533\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6996 | loss: 0.94533 - acc: 0.8276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6997  | total loss: \u001b[1m\u001b[32m0.87978\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 6997 | loss: 0.87978 - acc: 0.8448 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6998  | total loss: \u001b[1m\u001b[32m1.19591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6998 | loss: 1.19591 - acc: 0.7603 -- iter: 14/14\n",
      "--\n",
      "Training Step: 6999  | total loss: \u001b[1m\u001b[32m1.10384\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 6999 | loss: 1.10384 - acc: 0.7843 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7000  | total loss: \u001b[1m\u001b[32m1.38185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7000 | loss: 1.38185 - acc: 0.7130 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7001  | total loss: \u001b[1m\u001b[32m1.27102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7001 | loss: 1.27102 - acc: 0.7417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7002  | total loss: \u001b[1m\u001b[32m1.17132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7002 | loss: 1.17132 - acc: 0.7675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7003  | total loss: \u001b[1m\u001b[32m1.08139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7003 | loss: 1.08139 - acc: 0.7908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7004  | total loss: \u001b[1m\u001b[32m1.33699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7004 | loss: 1.33699 - acc: 0.7260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7005  | total loss: \u001b[1m\u001b[32m1.23043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7005 | loss: 1.23043 - acc: 0.7534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7006  | total loss: \u001b[1m\u001b[32m1.52237\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7006 | loss: 1.52237 - acc: 0.6781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7007  | total loss: \u001b[1m\u001b[32m1.39832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7007 | loss: 1.39832 - acc: 0.7103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7008  | total loss: \u001b[1m\u001b[32m1.58363\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7008 | loss: 1.58363 - acc: 0.6607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7009  | total loss: \u001b[1m\u001b[32m1.45529\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7009 | loss: 1.45529 - acc: 0.6946 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7010  | total loss: \u001b[1m\u001b[32m1.70104\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7010 | loss: 1.70104 - acc: 0.6251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7011  | total loss: \u001b[1m\u001b[32m1.56344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7011 | loss: 1.56344 - acc: 0.6626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7012  | total loss: \u001b[1m\u001b[32m1.44081\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7012 | loss: 1.44081 - acc: 0.6964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7013  | total loss: \u001b[1m\u001b[32m1.33124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7013 | loss: 1.33124 - acc: 0.7267 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7014  | total loss: \u001b[1m\u001b[32m1.54199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7014 | loss: 1.54199 - acc: 0.6683 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7015  | total loss: \u001b[1m\u001b[32m1.42380\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7015 | loss: 1.42380 - acc: 0.7015 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7016  | total loss: \u001b[1m\u001b[32m1.31810\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7016 | loss: 1.31810 - acc: 0.7314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7017  | total loss: \u001b[1m\u001b[32m1.22321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7017 | loss: 1.22321 - acc: 0.7582 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7018  | total loss: \u001b[1m\u001b[32m1.45100\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7018 | loss: 1.45100 - acc: 0.6895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7019  | total loss: \u001b[1m\u001b[32m1.34322\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7019 | loss: 1.34322 - acc: 0.7206 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7020  | total loss: \u001b[1m\u001b[32m1.54837\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7020 | loss: 1.54837 - acc: 0.6628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7021  | total loss: \u001b[1m\u001b[32m1.43184\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7021 | loss: 1.43184 - acc: 0.6965 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7022  | total loss: \u001b[1m\u001b[32m1.65020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7022 | loss: 1.65020 - acc: 0.6340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7023  | total loss: \u001b[1m\u001b[32m1.52496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7023 | loss: 1.52496 - acc: 0.6706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7024  | total loss: \u001b[1m\u001b[32m1.71138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7024 | loss: 1.71138 - acc: 0.6107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7025  | total loss: \u001b[1m\u001b[32m1.58189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7025 | loss: 1.58189 - acc: 0.6496 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7026  | total loss: \u001b[1m\u001b[32m1.46608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7026 | loss: 1.46608 - acc: 0.6847 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7027  | total loss: \u001b[1m\u001b[32m1.36209\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7027 | loss: 1.36209 - acc: 0.7162 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7028  | total loss: \u001b[1m\u001b[32m1.49646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7028 | loss: 1.49646 - acc: 0.6732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7029  | total loss: \u001b[1m\u001b[32m1.38944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7029 | loss: 1.38944 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7030  | total loss: \u001b[1m\u001b[32m1.29291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7030 | loss: 1.29291 - acc: 0.7353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7031  | total loss: \u001b[1m\u001b[32m1.20540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7031 | loss: 1.20540 - acc: 0.7617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7032  | total loss: \u001b[1m\u001b[32m1.44247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7032 | loss: 1.44247 - acc: 0.6856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7033  | total loss: \u001b[1m\u001b[32m1.33904\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7033 | loss: 1.33904 - acc: 0.7170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7034  | total loss: \u001b[1m\u001b[32m1.24556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7034 | loss: 1.24556 - acc: 0.7453 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7035  | total loss: \u001b[1m\u001b[32m1.16066\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7035 | loss: 1.16066 - acc: 0.7708 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7036  | total loss: \u001b[1m\u001b[32m1.08317\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7036 | loss: 1.08317 - acc: 0.7937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7037  | total loss: \u001b[1m\u001b[32m1.01207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7037 | loss: 1.01207 - acc: 0.8143 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7038  | total loss: \u001b[1m\u001b[32m1.21031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7038 | loss: 1.21031 - acc: 0.7472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7039  | total loss: \u001b[1m\u001b[32m1.12420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7039 | loss: 1.12420 - acc: 0.7725 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7040  | total loss: \u001b[1m\u001b[32m1.04571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7040 | loss: 1.04571 - acc: 0.7952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7041  | total loss: \u001b[1m\u001b[32m0.97387\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7041 | loss: 0.97387 - acc: 0.8157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7042  | total loss: \u001b[1m\u001b[32m1.26681\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7042 | loss: 1.26681 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7043  | total loss: \u001b[1m\u001b[32m1.17107\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7043 | loss: 1.17107 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7044  | total loss: \u001b[1m\u001b[32m1.46290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7044 | loss: 1.46290 - acc: 0.6846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7045  | total loss: \u001b[1m\u001b[32m1.34714\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7045 | loss: 1.34714 - acc: 0.7162 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7046  | total loss: \u001b[1m\u001b[32m1.58186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7046 | loss: 1.58186 - acc: 0.6588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7047  | total loss: \u001b[1m\u001b[32m1.45480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7047 | loss: 1.45480 - acc: 0.6930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7048  | total loss: \u001b[1m\u001b[32m1.34075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7048 | loss: 1.34075 - acc: 0.7237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7049  | total loss: \u001b[1m\u001b[32m1.23809\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7049 | loss: 1.23809 - acc: 0.7513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7050  | total loss: \u001b[1m\u001b[32m1.47754\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7050 | loss: 1.47754 - acc: 0.6762 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7051  | total loss: \u001b[1m\u001b[32m1.36151\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7051 | loss: 1.36151 - acc: 0.7086 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7052  | total loss: \u001b[1m\u001b[32m1.62382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7052 | loss: 1.62382 - acc: 0.6377 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7053  | total loss: \u001b[1m\u001b[32m1.49448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7053 | loss: 1.49448 - acc: 0.6739 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7054  | total loss: \u001b[1m\u001b[32m1.72737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7054 | loss: 1.72737 - acc: 0.6137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7055  | total loss: \u001b[1m\u001b[32m1.58977\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7055 | loss: 1.58977 - acc: 0.6523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7056  | total loss: \u001b[1m\u001b[32m1.82814\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7056 | loss: 1.82814 - acc: 0.5871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7057  | total loss: \u001b[1m\u001b[32m1.68321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7057 | loss: 1.68321 - acc: 0.6284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7058  | total loss: \u001b[1m\u001b[32m1.90848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7058 | loss: 1.90848 - acc: 0.5655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7059  | total loss: \u001b[1m\u001b[32m1.75891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7059 | loss: 1.75891 - acc: 0.6090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7060  | total loss: \u001b[1m\u001b[32m1.96574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7060 | loss: 1.96574 - acc: 0.5481 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7061  | total loss: \u001b[1m\u001b[32m1.81435\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7061 | loss: 1.81435 - acc: 0.5933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7062  | total loss: \u001b[1m\u001b[32m1.97366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7062 | loss: 1.97366 - acc: 0.5482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7063  | total loss: \u001b[1m\u001b[32m1.82550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7063 | loss: 1.82550 - acc: 0.5934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7064  | total loss: \u001b[1m\u001b[32m1.98033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7064 | loss: 1.98033 - acc: 0.5412 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7065  | total loss: \u001b[1m\u001b[32m1.83526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7065 | loss: 1.83526 - acc: 0.5871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7066  | total loss: \u001b[1m\u001b[32m1.95497\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7066 | loss: 1.95497 - acc: 0.5427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7067  | total loss: \u001b[1m\u001b[32m1.81579\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7067 | loss: 1.81579 - acc: 0.5884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7068  | total loss: \u001b[1m\u001b[32m1.94628\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7068 | loss: 1.94628 - acc: 0.5438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7069  | total loss: \u001b[1m\u001b[32m1.81082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7069 | loss: 1.81082 - acc: 0.5895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7070  | total loss: \u001b[1m\u001b[32m1.68980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7070 | loss: 1.68980 - acc: 0.6305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7071  | total loss: \u001b[1m\u001b[32m1.58104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7071 | loss: 1.58104 - acc: 0.6675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7072  | total loss: \u001b[1m\u001b[32m1.74934\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7072 | loss: 1.74934 - acc: 0.6079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7073  | total loss: \u001b[1m\u001b[32m1.63441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7073 | loss: 1.63441 - acc: 0.6471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7074  | total loss: \u001b[1m\u001b[32m1.76370\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7074 | loss: 1.76370 - acc: 0.5967 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7075  | total loss: \u001b[1m\u001b[32m1.64716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7075 | loss: 1.64716 - acc: 0.6370 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7076  | total loss: \u001b[1m\u001b[32m1.54185\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7076 | loss: 1.54185 - acc: 0.6733 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7077  | total loss: \u001b[1m\u001b[32m1.44608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7077 | loss: 1.44608 - acc: 0.7060 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7078  | total loss: \u001b[1m\u001b[32m1.35840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7078 | loss: 1.35840 - acc: 0.7354 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7079  | total loss: \u001b[1m\u001b[32m1.27757\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7079 | loss: 1.27757 - acc: 0.7618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7080  | total loss: \u001b[1m\u001b[32m1.51979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7080 | loss: 1.51979 - acc: 0.6856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7081  | total loss: \u001b[1m\u001b[32m1.41944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7081 | loss: 1.41944 - acc: 0.7171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7082  | total loss: \u001b[1m\u001b[32m1.64516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7082 | loss: 1.64516 - acc: 0.6454 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7083  | total loss: \u001b[1m\u001b[32m1.53025\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7083 | loss: 1.53025 - acc: 0.6808 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7084  | total loss: \u001b[1m\u001b[32m1.71372\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7084 | loss: 1.71372 - acc: 0.6199 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7085  | total loss: \u001b[1m\u001b[32m1.59094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7085 | loss: 1.59094 - acc: 0.6579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7086  | total loss: \u001b[1m\u001b[32m1.47988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7086 | loss: 1.47988 - acc: 0.6921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7087  | total loss: \u001b[1m\u001b[32m1.37894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7087 | loss: 1.37894 - acc: 0.7229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7088  | total loss: \u001b[1m\u001b[32m1.58240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7088 | loss: 1.58240 - acc: 0.6578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7089  | total loss: \u001b[1m\u001b[32m1.46943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7089 | loss: 1.46943 - acc: 0.6920 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7090  | total loss: \u001b[1m\u001b[32m1.66803\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7090 | loss: 1.66803 - acc: 0.6299 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7091  | total loss: \u001b[1m\u001b[32m1.54569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7091 | loss: 1.54569 - acc: 0.6669 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7092  | total loss: \u001b[1m\u001b[32m1.71540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7092 | loss: 1.71540 - acc: 0.6145 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7093  | total loss: \u001b[1m\u001b[32m1.58823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7093 | loss: 1.58823 - acc: 0.6531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7094  | total loss: \u001b[1m\u001b[32m1.47363\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7094 | loss: 1.47363 - acc: 0.6878 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7095  | total loss: \u001b[1m\u001b[32m1.36993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7095 | loss: 1.36993 - acc: 0.7190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7096  | total loss: \u001b[1m\u001b[32m1.27566\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7096 | loss: 1.27566 - acc: 0.7471 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7097  | total loss: \u001b[1m\u001b[32m1.18957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7097 | loss: 1.18957 - acc: 0.7724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7098  | total loss: \u001b[1m\u001b[32m1.11056\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7098 | loss: 1.11056 - acc: 0.7951 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7099  | total loss: \u001b[1m\u001b[32m1.03772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7099 | loss: 1.03772 - acc: 0.8156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7100  | total loss: \u001b[1m\u001b[32m1.31929\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7100 | loss: 1.31929 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7101  | total loss: \u001b[1m\u001b[32m1.22287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7101 | loss: 1.22287 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7102  | total loss: \u001b[1m\u001b[32m1.13502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7102 | loss: 1.13502 - acc: 0.7846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7103  | total loss: \u001b[1m\u001b[32m1.05469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7103 | loss: 1.05469 - acc: 0.8061 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7104  | total loss: \u001b[1m\u001b[32m0.98096\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7104 | loss: 0.98096 - acc: 0.8255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7105  | total loss: \u001b[1m\u001b[32m0.91305\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7105 | loss: 0.91305 - acc: 0.8430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7106  | total loss: \u001b[1m\u001b[32m1.20500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7106 | loss: 1.20500 - acc: 0.7658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7107  | total loss: \u001b[1m\u001b[32m1.11240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7107 | loss: 1.11240 - acc: 0.7892 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7108  | total loss: \u001b[1m\u001b[32m1.37784\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7108 | loss: 1.37784 - acc: 0.7175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7109  | total loss: \u001b[1m\u001b[32m1.26717\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7109 | loss: 1.26717 - acc: 0.7457 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7110  | total loss: \u001b[1m\u001b[32m1.16736\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7110 | loss: 1.16736 - acc: 0.7711 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7111  | total loss: \u001b[1m\u001b[32m1.07711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7111 | loss: 1.07711 - acc: 0.7940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7112  | total loss: \u001b[1m\u001b[32m0.99526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7112 | loss: 0.99526 - acc: 0.8146 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7113  | total loss: \u001b[1m\u001b[32m0.92083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7113 | loss: 0.92083 - acc: 0.8332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7114  | total loss: \u001b[1m\u001b[32m0.85293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7114 | loss: 0.85293 - acc: 0.8498 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7115  | total loss: \u001b[1m\u001b[32m0.79082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7115 | loss: 0.79082 - acc: 0.8649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7116  | total loss: \u001b[1m\u001b[32m1.14924\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7116 | loss: 1.14924 - acc: 0.7784 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7117  | total loss: \u001b[1m\u001b[32m1.05625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7117 | loss: 1.05625 - acc: 0.8005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7118  | total loss: \u001b[1m\u001b[32m1.31435\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7118 | loss: 1.31435 - acc: 0.7348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7119  | total loss: \u001b[1m\u001b[32m1.20482\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7119 | loss: 1.20482 - acc: 0.7613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7120  | total loss: \u001b[1m\u001b[32m1.49604\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7120 | loss: 1.49604 - acc: 0.6923 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7121  | total loss: \u001b[1m\u001b[32m1.36933\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7121 | loss: 1.36933 - acc: 0.7231 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7122  | total loss: \u001b[1m\u001b[32m1.65896\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7122 | loss: 1.65896 - acc: 0.6508 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7123  | total loss: \u001b[1m\u001b[32m1.51803\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7123 | loss: 1.51803 - acc: 0.6857 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7124  | total loss: \u001b[1m\u001b[32m1.39232\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7124 | loss: 1.39232 - acc: 0.7171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7125  | total loss: \u001b[1m\u001b[32m1.27998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7125 | loss: 1.27998 - acc: 0.7454 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7126  | total loss: \u001b[1m\u001b[32m1.54244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7126 | loss: 1.54244 - acc: 0.6780 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7127  | total loss: \u001b[1m\u001b[32m1.41678\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7127 | loss: 1.41678 - acc: 0.7102 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7128  | total loss: \u001b[1m\u001b[32m1.30454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7128 | loss: 1.30454 - acc: 0.7392 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7129  | total loss: \u001b[1m\u001b[32m1.20402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7129 | loss: 1.20402 - acc: 0.7653 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7130  | total loss: \u001b[1m\u001b[32m1.46780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7130 | loss: 1.46780 - acc: 0.6887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7131  | total loss: \u001b[1m\u001b[32m1.35210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7131 | loss: 1.35210 - acc: 0.7199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7132  | total loss: \u001b[1m\u001b[32m1.53655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7132 | loss: 1.53655 - acc: 0.6693 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7133  | total loss: \u001b[1m\u001b[32m1.41583\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7133 | loss: 1.41583 - acc: 0.7024 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7134  | total loss: \u001b[1m\u001b[32m1.62856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7134 | loss: 1.62856 - acc: 0.6464 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7135  | total loss: \u001b[1m\u001b[32m1.50087\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7135 | loss: 1.50087 - acc: 0.6818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7136  | total loss: \u001b[1m\u001b[32m1.38691\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7136 | loss: 1.38691 - acc: 0.7136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7137  | total loss: \u001b[1m\u001b[32m1.28483\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7137 | loss: 1.28483 - acc: 0.7422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7138  | total loss: \u001b[1m\u001b[32m1.52364\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7138 | loss: 1.52364 - acc: 0.6752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7139  | total loss: \u001b[1m\u001b[32m1.40873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7139 | loss: 1.40873 - acc: 0.7076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7140  | total loss: \u001b[1m\u001b[32m1.66869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7140 | loss: 1.66869 - acc: 0.6369 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7141  | total loss: \u001b[1m\u001b[32m1.54082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7141 | loss: 1.54082 - acc: 0.6732 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7142  | total loss: \u001b[1m\u001b[32m1.42642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7142 | loss: 1.42642 - acc: 0.7059 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7143  | total loss: \u001b[1m\u001b[32m1.32367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7143 | loss: 1.32367 - acc: 0.7353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7144  | total loss: \u001b[1m\u001b[32m1.23095\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7144 | loss: 1.23095 - acc: 0.7618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7145  | total loss: \u001b[1m\u001b[32m1.14687\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7145 | loss: 1.14687 - acc: 0.7856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7146  | total loss: \u001b[1m\u001b[32m1.07022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7146 | loss: 1.07022 - acc: 0.8070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7147  | total loss: \u001b[1m\u001b[32m0.99998\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7147 | loss: 0.99998 - acc: 0.8263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7148  | total loss: \u001b[1m\u001b[32m0.93529\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7148 | loss: 0.93529 - acc: 0.8437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7149  | total loss: \u001b[1m\u001b[32m0.87542\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7149 | loss: 0.87542 - acc: 0.8593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7150  | total loss: \u001b[1m\u001b[32m1.15851\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7150 | loss: 1.15851 - acc: 0.7805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7151  | total loss: \u001b[1m\u001b[32m1.07385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7151 | loss: 1.07385 - acc: 0.8025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7152  | total loss: \u001b[1m\u001b[32m1.35289\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7152 | loss: 1.35289 - acc: 0.7294 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7153  | total loss: \u001b[1m\u001b[32m1.24783\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7153 | loss: 1.24783 - acc: 0.7564 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7154  | total loss: \u001b[1m\u001b[32m1.52330\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7154 | loss: 1.52330 - acc: 0.6808 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7155  | total loss: \u001b[1m\u001b[32m1.40144\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7155 | loss: 1.40144 - acc: 0.7127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7156  | total loss: \u001b[1m\u001b[32m1.65885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7156 | loss: 1.65885 - acc: 0.6414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7157  | total loss: \u001b[1m\u001b[32m1.52472\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7157 | loss: 1.52472 - acc: 0.6773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7158  | total loss: \u001b[1m\u001b[32m1.76369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7158 | loss: 1.76369 - acc: 0.6096 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7159  | total loss: \u001b[1m\u001b[32m1.62121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7159 | loss: 1.62121 - acc: 0.6486 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7160  | total loss: \u001b[1m\u001b[32m1.49403\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7160 | loss: 1.49403 - acc: 0.6838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7161  | total loss: \u001b[1m\u001b[32m1.38017\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7161 | loss: 1.38017 - acc: 0.7154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7162  | total loss: \u001b[1m\u001b[32m1.27791\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7162 | loss: 1.27791 - acc: 0.7438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7163  | total loss: \u001b[1m\u001b[32m1.18570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7163 | loss: 1.18570 - acc: 0.7695 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7164  | total loss: \u001b[1m\u001b[32m1.43106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7164 | loss: 1.43106 - acc: 0.6997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7165  | total loss: \u001b[1m\u001b[32m1.32336\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7165 | loss: 1.32336 - acc: 0.7297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7166  | total loss: \u001b[1m\u001b[32m1.22640\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7166 | loss: 1.22640 - acc: 0.7567 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7167  | total loss: \u001b[1m\u001b[32m1.13874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7167 | loss: 1.13874 - acc: 0.7810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7168  | total loss: \u001b[1m\u001b[32m1.35665\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7168 | loss: 1.35665 - acc: 0.7172 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7169  | total loss: \u001b[1m\u001b[32m1.25534\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7169 | loss: 1.25534 - acc: 0.7455 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7170  | total loss: \u001b[1m\u001b[32m1.47829\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7170 | loss: 1.47829 - acc: 0.6852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7171  | total loss: \u001b[1m\u001b[32m1.36499\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7171 | loss: 1.36499 - acc: 0.7167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7172  | total loss: \u001b[1m\u001b[32m1.61925\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7172 | loss: 1.61925 - acc: 0.6450 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7173  | total loss: \u001b[1m\u001b[32m1.49283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7173 | loss: 1.49283 - acc: 0.6805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7174  | total loss: \u001b[1m\u001b[32m1.74052\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7174 | loss: 1.74052 - acc: 0.6125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7175  | total loss: \u001b[1m\u001b[32m1.60386\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7175 | loss: 1.60386 - acc: 0.6512 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7176  | total loss: \u001b[1m\u001b[32m1.48176\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7176 | loss: 1.48176 - acc: 0.6861 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7177  | total loss: \u001b[1m\u001b[32m1.37232\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7177 | loss: 1.37232 - acc: 0.7175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7178  | total loss: \u001b[1m\u001b[32m1.54864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7178 | loss: 1.54864 - acc: 0.6600 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7179  | total loss: \u001b[1m\u001b[32m1.43314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7179 | loss: 1.43314 - acc: 0.6940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7180  | total loss: \u001b[1m\u001b[32m1.64138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7180 | loss: 1.64138 - acc: 0.6318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7181  | total loss: \u001b[1m\u001b[32m1.51780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7181 | loss: 1.51780 - acc: 0.6686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7182  | total loss: \u001b[1m\u001b[32m1.40709\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7182 | loss: 1.40709 - acc: 0.7017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7183  | total loss: \u001b[1m\u001b[32m1.30747\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7183 | loss: 1.30747 - acc: 0.7316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7184  | total loss: \u001b[1m\u001b[32m1.50532\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7184 | loss: 1.50532 - acc: 0.6727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7185  | total loss: \u001b[1m\u001b[32m1.39586\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7185 | loss: 1.39586 - acc: 0.7054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7186  | total loss: \u001b[1m\u001b[32m1.60445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7186 | loss: 1.60445 - acc: 0.6420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7187  | total loss: \u001b[1m\u001b[32m1.48574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7187 | loss: 1.48574 - acc: 0.6778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7188  | total loss: \u001b[1m\u001b[32m1.66023\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7188 | loss: 1.66023 - acc: 0.6243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7189  | total loss: \u001b[1m\u001b[32m1.53713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7189 | loss: 1.53713 - acc: 0.6619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7190  | total loss: \u001b[1m\u001b[32m1.42673\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7190 | loss: 1.42673 - acc: 0.6957 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7191  | total loss: \u001b[1m\u001b[32m1.32726\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7191 | loss: 1.32726 - acc: 0.7261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7192  | total loss: \u001b[1m\u001b[32m1.51458\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7192 | loss: 1.51458 - acc: 0.6678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7193  | total loss: \u001b[1m\u001b[32m1.40596\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7193 | loss: 1.40596 - acc: 0.7010 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7194  | total loss: \u001b[1m\u001b[32m1.59283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7194 | loss: 1.59283 - acc: 0.6452 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7195  | total loss: \u001b[1m\u001b[32m1.47662\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7195 | loss: 1.47662 - acc: 0.6807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7196  | total loss: \u001b[1m\u001b[32m1.66226\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7196 | loss: 1.66226 - acc: 0.6269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7197  | total loss: \u001b[1m\u001b[32m1.53987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7197 | loss: 1.53987 - acc: 0.6642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7198  | total loss: \u001b[1m\u001b[32m1.75636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7198 | loss: 1.75636 - acc: 0.5978 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7199  | total loss: \u001b[1m\u001b[32m1.62589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7199 | loss: 1.62589 - acc: 0.6380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7200  | total loss: \u001b[1m\u001b[32m1.83425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7200 | loss: 1.83425 - acc: 0.5742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7201  | total loss: \u001b[1m\u001b[32m1.69785\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7201 | loss: 1.69785 - acc: 0.6168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7202  | total loss: \u001b[1m\u001b[32m1.85471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7202 | loss: 1.85471 - acc: 0.5694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7203  | total loss: \u001b[1m\u001b[32m1.71831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7203 | loss: 1.71831 - acc: 0.6125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7204  | total loss: \u001b[1m\u001b[32m1.85725\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7204 | loss: 1.85725 - acc: 0.5584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7205  | total loss: \u001b[1m\u001b[32m1.72276\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7205 | loss: 1.72276 - acc: 0.6025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7206  | total loss: \u001b[1m\u001b[32m1.87611\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7206 | loss: 1.87611 - acc: 0.5494 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7207  | total loss: \u001b[1m\u001b[32m1.74201\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7207 | loss: 1.74201 - acc: 0.5945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7208  | total loss: \u001b[1m\u001b[32m1.89930\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7208 | loss: 1.89930 - acc: 0.5422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7209  | total loss: \u001b[1m\u001b[32m1.76519\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7209 | loss: 1.76519 - acc: 0.5879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7210  | total loss: \u001b[1m\u001b[32m1.64527\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7210 | loss: 1.64527 - acc: 0.6292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7211  | total loss: \u001b[1m\u001b[32m1.53743\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7211 | loss: 1.53743 - acc: 0.6662 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7212  | total loss: \u001b[1m\u001b[32m1.43983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7212 | loss: 1.43983 - acc: 0.6996 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7213  | total loss: \u001b[1m\u001b[32m1.35089\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7213 | loss: 1.35089 - acc: 0.7297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7214  | total loss: \u001b[1m\u001b[32m1.53914\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7214 | loss: 1.53914 - acc: 0.6710 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7215  | total loss: \u001b[1m\u001b[32m1.43789\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7215 | loss: 1.43789 - acc: 0.7039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7216  | total loss: \u001b[1m\u001b[32m1.65181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7216 | loss: 1.65181 - acc: 0.6335 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7217  | total loss: \u001b[1m\u001b[32m1.53778\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7217 | loss: 1.53778 - acc: 0.6701 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7218  | total loss: \u001b[1m\u001b[32m1.43438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7218 | loss: 1.43438 - acc: 0.7031 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7219  | total loss: \u001b[1m\u001b[32m1.34011\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7219 | loss: 1.34011 - acc: 0.7328 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7220  | total loss: \u001b[1m\u001b[32m1.55388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7220 | loss: 1.55388 - acc: 0.6667 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7221  | total loss: \u001b[1m\u001b[32m1.44542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7221 | loss: 1.44542 - acc: 0.7000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7222  | total loss: \u001b[1m\u001b[32m1.60222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7222 | loss: 1.60222 - acc: 0.6514 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7223  | total loss: \u001b[1m\u001b[32m1.48744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7223 | loss: 1.48744 - acc: 0.6863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7224  | total loss: \u001b[1m\u001b[32m1.70181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7224 | loss: 1.70181 - acc: 0.6177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7225  | total loss: \u001b[1m\u001b[32m1.57633\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7225 | loss: 1.57633 - acc: 0.6559 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7226  | total loss: \u001b[1m\u001b[32m1.73067\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7226 | loss: 1.73067 - acc: 0.6046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7227  | total loss: \u001b[1m\u001b[32m1.60221\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7227 | loss: 1.60221 - acc: 0.6441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7228  | total loss: \u001b[1m\u001b[32m1.48639\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7228 | loss: 1.48639 - acc: 0.6797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7229  | total loss: \u001b[1m\u001b[32m1.38151\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7229 | loss: 1.38151 - acc: 0.7117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7230  | total loss: \u001b[1m\u001b[32m1.57893\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7230 | loss: 1.57893 - acc: 0.6549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7231  | total loss: \u001b[1m\u001b[32m1.46360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7231 | loss: 1.46360 - acc: 0.6894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7232  | total loss: \u001b[1m\u001b[32m1.60841\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7232 | loss: 1.60841 - acc: 0.6419 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7233  | total loss: \u001b[1m\u001b[32m1.48956\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7233 | loss: 1.48956 - acc: 0.6777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7234  | total loss: \u001b[1m\u001b[32m1.38220\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7234 | loss: 1.38220 - acc: 0.7099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7235  | total loss: \u001b[1m\u001b[32m1.28482\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7235 | loss: 1.28482 - acc: 0.7389 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7236  | total loss: \u001b[1m\u001b[32m1.19609\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7236 | loss: 1.19609 - acc: 0.7650 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7237  | total loss: \u001b[1m\u001b[32m1.11488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7237 | loss: 1.11488 - acc: 0.7885 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7238  | total loss: \u001b[1m\u001b[32m1.35790\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7238 | loss: 1.35790 - acc: 0.7168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7239  | total loss: \u001b[1m\u001b[32m1.25829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7239 | loss: 1.25829 - acc: 0.7451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7240  | total loss: \u001b[1m\u001b[32m1.16772\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7240 | loss: 1.16772 - acc: 0.7706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7241  | total loss: \u001b[1m\u001b[32m1.08505\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7241 | loss: 1.08505 - acc: 0.7936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7242  | total loss: \u001b[1m\u001b[32m1.31946\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7242 | loss: 1.31946 - acc: 0.7285 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7243  | total loss: \u001b[1m\u001b[32m1.21972\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7243 | loss: 1.21972 - acc: 0.7556 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7244  | total loss: \u001b[1m\u001b[32m1.46829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7244 | loss: 1.46829 - acc: 0.6872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7245  | total loss: \u001b[1m\u001b[32m1.35298\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7245 | loss: 1.35298 - acc: 0.7185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7246  | total loss: \u001b[1m\u001b[32m1.59506\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7246 | loss: 1.59506 - acc: 0.6538 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7247  | total loss: \u001b[1m\u001b[32m1.46754\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7247 | loss: 1.46754 - acc: 0.6884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7248  | total loss: \u001b[1m\u001b[32m1.35308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7248 | loss: 1.35308 - acc: 0.7196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7249  | total loss: \u001b[1m\u001b[32m1.25004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7249 | loss: 1.25004 - acc: 0.7476 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7250  | total loss: \u001b[1m\u001b[32m1.15698\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7250 | loss: 1.15698 - acc: 0.7729 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7251  | total loss: \u001b[1m\u001b[32m1.07264\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7251 | loss: 1.07264 - acc: 0.7956 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7252  | total loss: \u001b[1m\u001b[32m1.34012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7252 | loss: 1.34012 - acc: 0.7160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7253  | total loss: \u001b[1m\u001b[32m1.23676\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7253 | loss: 1.23676 - acc: 0.7444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7254  | total loss: \u001b[1m\u001b[32m1.44525\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7254 | loss: 1.44525 - acc: 0.6914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7255  | total loss: \u001b[1m\u001b[32m1.33163\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7255 | loss: 1.33163 - acc: 0.7223 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7256  | total loss: \u001b[1m\u001b[32m1.22949\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7256 | loss: 1.22949 - acc: 0.7500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7257  | total loss: \u001b[1m\u001b[32m1.13736\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7257 | loss: 1.13736 - acc: 0.7750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7258  | total loss: \u001b[1m\u001b[32m1.05398\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7258 | loss: 1.05398 - acc: 0.7975 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7259  | total loss: \u001b[1m\u001b[32m0.97824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7259 | loss: 0.97824 - acc: 0.8178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7260  | total loss: \u001b[1m\u001b[32m0.90918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7260 | loss: 0.90918 - acc: 0.8360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7261  | total loss: \u001b[1m\u001b[32m0.84595\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7261 | loss: 0.84595 - acc: 0.8524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7262  | total loss: \u001b[1m\u001b[32m0.78786\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7262 | loss: 0.78786 - acc: 0.8672 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7263  | total loss: \u001b[1m\u001b[32m0.73430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7263 | loss: 0.73430 - acc: 0.8804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7264  | total loss: \u001b[1m\u001b[32m0.68476\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7264 | loss: 0.68476 - acc: 0.8924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7265  | total loss: \u001b[1m\u001b[32m0.63880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7265 | loss: 0.63880 - acc: 0.9032 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7266  | total loss: \u001b[1m\u001b[32m1.00101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7266 | loss: 1.00101 - acc: 0.8128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7267  | total loss: \u001b[1m\u001b[32m0.92164\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7267 | loss: 0.92164 - acc: 0.8316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7268  | total loss: \u001b[1m\u001b[32m0.84968\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7268 | loss: 0.84968 - acc: 0.8484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7269  | total loss: \u001b[1m\u001b[32m0.78427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7269 | loss: 0.78427 - acc: 0.8636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7270  | total loss: \u001b[1m\u001b[32m1.12884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7270 | loss: 1.12884 - acc: 0.7772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7271  | total loss: \u001b[1m\u001b[32m1.03486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7271 | loss: 1.03486 - acc: 0.7995 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7272  | total loss: \u001b[1m\u001b[32m1.33642\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7272 | loss: 1.33642 - acc: 0.7267 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7273  | total loss: \u001b[1m\u001b[32m1.22220\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7273 | loss: 1.22220 - acc: 0.7540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7274  | total loss: \u001b[1m\u001b[32m1.55697\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7274 | loss: 1.55697 - acc: 0.6786 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7275  | total loss: \u001b[1m\u001b[32m1.42229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7275 | loss: 1.42229 - acc: 0.7107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7276  | total loss: \u001b[1m\u001b[32m1.68055\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7276 | loss: 1.68055 - acc: 0.6468 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7277  | total loss: \u001b[1m\u001b[32m1.53609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7277 | loss: 1.53609 - acc: 0.6821 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7278  | total loss: \u001b[1m\u001b[32m1.40744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7278 | loss: 1.40744 - acc: 0.7139 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7279  | total loss: \u001b[1m\u001b[32m1.29271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7279 | loss: 1.29271 - acc: 0.7425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7280  | total loss: \u001b[1m\u001b[32m1.19018\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7280 | loss: 1.19018 - acc: 0.7683 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7281  | total loss: \u001b[1m\u001b[32m1.09831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7281 | loss: 1.09831 - acc: 0.7914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7282  | total loss: \u001b[1m\u001b[32m1.38636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7282 | loss: 1.38636 - acc: 0.7123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7283  | total loss: \u001b[1m\u001b[32m1.27599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7283 | loss: 1.27599 - acc: 0.7411 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7284  | total loss: \u001b[1m\u001b[32m1.17731\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7284 | loss: 1.17731 - acc: 0.7670 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7285  | total loss: \u001b[1m\u001b[32m1.08881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7285 | loss: 1.08881 - acc: 0.7903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7286  | total loss: \u001b[1m\u001b[32m1.32993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7286 | loss: 1.32993 - acc: 0.7255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7287  | total loss: \u001b[1m\u001b[32m1.22680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7287 | loss: 1.22680 - acc: 0.7530 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7288  | total loss: \u001b[1m\u001b[32m1.48299\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7288 | loss: 1.48299 - acc: 0.6848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7289  | total loss: \u001b[1m\u001b[32m1.36589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7289 | loss: 1.36589 - acc: 0.7163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7290  | total loss: \u001b[1m\u001b[32m1.26115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7290 | loss: 1.26115 - acc: 0.7447 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7291  | total loss: \u001b[1m\u001b[32m1.16715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7291 | loss: 1.16715 - acc: 0.7702 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7292  | total loss: \u001b[1m\u001b[32m1.46013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7292 | loss: 1.46013 - acc: 0.6932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7293  | total loss: \u001b[1m\u001b[32m1.34699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7293 | loss: 1.34699 - acc: 0.7239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7294  | total loss: \u001b[1m\u001b[32m1.59863\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7294 | loss: 1.59863 - acc: 0.6515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7295  | total loss: \u001b[1m\u001b[32m1.47335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7295 | loss: 1.47335 - acc: 0.6864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7296  | total loss: \u001b[1m\u001b[32m1.67866\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7296 | loss: 1.67866 - acc: 0.6249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7297  | total loss: \u001b[1m\u001b[32m1.54781\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7297 | loss: 1.54781 - acc: 0.6624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7298  | total loss: \u001b[1m\u001b[32m1.72715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7298 | loss: 1.72715 - acc: 0.6033 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7299  | total loss: \u001b[1m\u001b[32m1.59429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7299 | loss: 1.59429 - acc: 0.6430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7300  | total loss: \u001b[1m\u001b[32m1.76380\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7300 | loss: 1.76380 - acc: 0.5929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7301  | total loss: \u001b[1m\u001b[32m1.63024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7301 | loss: 1.63024 - acc: 0.6336 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7302  | total loss: \u001b[1m\u001b[32m1.51121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7302 | loss: 1.51121 - acc: 0.6703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7303  | total loss: \u001b[1m\u001b[32m1.40468\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7303 | loss: 1.40468 - acc: 0.7033 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7304  | total loss: \u001b[1m\u001b[32m1.61301\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7304 | loss: 1.61301 - acc: 0.6329 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7305  | total loss: \u001b[1m\u001b[32m1.49733\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7305 | loss: 1.49733 - acc: 0.6696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7306  | total loss: \u001b[1m\u001b[32m1.39360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7306 | loss: 1.39360 - acc: 0.7027 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7307  | total loss: \u001b[1m\u001b[32m1.30011\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7307 | loss: 1.30011 - acc: 0.7324 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7308  | total loss: \u001b[1m\u001b[32m1.48960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7308 | loss: 1.48960 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7309  | total loss: \u001b[1m\u001b[32m1.38602\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7309 | loss: 1.38602 - acc: 0.7061 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7310  | total loss: \u001b[1m\u001b[32m1.29244\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7310 | loss: 1.29244 - acc: 0.7355 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7311  | total loss: \u001b[1m\u001b[32m1.20742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7311 | loss: 1.20742 - acc: 0.7619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7312  | total loss: \u001b[1m\u001b[32m1.12974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7312 | loss: 1.12974 - acc: 0.7858 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7313  | total loss: \u001b[1m\u001b[32m1.05834\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7313 | loss: 1.05834 - acc: 0.8072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7314  | total loss: \u001b[1m\u001b[32m1.30573\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7314 | loss: 1.30573 - acc: 0.7336 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7315  | total loss: \u001b[1m\u001b[32m1.21427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7315 | loss: 1.21427 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7316  | total loss: \u001b[1m\u001b[32m1.45173\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7316 | loss: 1.45173 - acc: 0.6914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7317  | total loss: \u001b[1m\u001b[32m1.34444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7317 | loss: 1.34444 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7318  | total loss: \u001b[1m\u001b[32m1.24735\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7318 | loss: 1.24735 - acc: 0.7500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7319  | total loss: \u001b[1m\u001b[32m1.15911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7319 | loss: 1.15911 - acc: 0.7750 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7320  | total loss: \u001b[1m\u001b[32m1.07860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7320 | loss: 1.07860 - acc: 0.7975 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7321  | total loss: \u001b[1m\u001b[32m1.00481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7321 | loss: 1.00481 - acc: 0.8178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7322  | total loss: \u001b[1m\u001b[32m0.93692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7322 | loss: 0.93692 - acc: 0.8360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7323  | total loss: \u001b[1m\u001b[32m0.87421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7323 | loss: 0.87421 - acc: 0.8524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7324  | total loss: \u001b[1m\u001b[32m1.17845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7324 | loss: 1.17845 - acc: 0.7743 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7325  | total loss: \u001b[1m\u001b[32m1.08922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7325 | loss: 1.08922 - acc: 0.7969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7326  | total loss: \u001b[1m\u001b[32m1.32951\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7326 | loss: 1.32951 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7327  | total loss: \u001b[1m\u001b[32m1.22421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7327 | loss: 1.22421 - acc: 0.7647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7328  | total loss: \u001b[1m\u001b[32m1.50992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7328 | loss: 1.50992 - acc: 0.6883 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7329  | total loss: \u001b[1m\u001b[32m1.38679\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7329 | loss: 1.38679 - acc: 0.7194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7330  | total loss: \u001b[1m\u001b[32m1.61044\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7330 | loss: 1.61044 - acc: 0.6618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7331  | total loss: \u001b[1m\u001b[32m1.47844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7331 | loss: 1.47844 - acc: 0.6956 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7332  | total loss: \u001b[1m\u001b[32m1.72521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7332 | loss: 1.72521 - acc: 0.6332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7333  | total loss: \u001b[1m\u001b[32m1.58369\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7333 | loss: 1.58369 - acc: 0.6699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7334  | total loss: \u001b[1m\u001b[32m1.80369\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7334 | loss: 1.80369 - acc: 0.6100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7335  | total loss: \u001b[1m\u001b[32m1.65695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7335 | loss: 1.65695 - acc: 0.6490 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7336  | total loss: \u001b[1m\u001b[32m1.52609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7336 | loss: 1.52609 - acc: 0.6841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7337  | total loss: \u001b[1m\u001b[32m1.40908\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7337 | loss: 1.40908 - acc: 0.7157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7338  | total loss: \u001b[1m\u001b[32m1.30412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7338 | loss: 1.30412 - acc: 0.7441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7339  | total loss: \u001b[1m\u001b[32m1.20962\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7339 | loss: 1.20962 - acc: 0.7697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7340  | total loss: \u001b[1m\u001b[32m1.44930\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7340 | loss: 1.44930 - acc: 0.7070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7341  | total loss: \u001b[1m\u001b[32m1.34026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7341 | loss: 1.34026 - acc: 0.7363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7342  | total loss: \u001b[1m\u001b[32m1.57316\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7342 | loss: 1.57316 - acc: 0.6698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7343  | total loss: \u001b[1m\u001b[32m1.45254\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7343 | loss: 1.45254 - acc: 0.7029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7344  | total loss: \u001b[1m\u001b[32m1.34439\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7344 | loss: 1.34439 - acc: 0.7326 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7345  | total loss: \u001b[1m\u001b[32m1.24705\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7345 | loss: 1.24705 - acc: 0.7593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7346  | total loss: \u001b[1m\u001b[32m1.15908\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7346 | loss: 1.15908 - acc: 0.7834 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7347  | total loss: \u001b[1m\u001b[32m1.07923\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7347 | loss: 1.07923 - acc: 0.8050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7348  | total loss: \u001b[1m\u001b[32m1.00641\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7348 | loss: 1.00641 - acc: 0.8245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7349  | total loss: \u001b[1m\u001b[32m0.93969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7349 | loss: 0.93969 - acc: 0.8421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7350  | total loss: \u001b[1m\u001b[32m0.87828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7350 | loss: 0.87828 - acc: 0.8579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7351  | total loss: \u001b[1m\u001b[32m0.82152\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7351 | loss: 0.82152 - acc: 0.8721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7352  | total loss: \u001b[1m\u001b[32m0.76885\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7352 | loss: 0.76885 - acc: 0.8849 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7353  | total loss: \u001b[1m\u001b[32m0.71980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7353 | loss: 0.71980 - acc: 0.8964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7354  | total loss: \u001b[1m\u001b[32m0.67399\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7354 | loss: 0.67399 - acc: 0.9068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7355  | total loss: \u001b[1m\u001b[32m0.63111\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7355 | loss: 0.63111 - acc: 0.9161 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7356  | total loss: \u001b[1m\u001b[32m0.59088\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7356 | loss: 0.59088 - acc: 0.9245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7357  | total loss: \u001b[1m\u001b[32m0.55309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7357 | loss: 0.55309 - acc: 0.9320 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7358  | total loss: \u001b[1m\u001b[32m0.91096\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7358 | loss: 0.91096 - acc: 0.8460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7359  | total loss: \u001b[1m\u001b[32m0.83900\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7359 | loss: 0.83900 - acc: 0.8614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7360  | total loss: \u001b[1m\u001b[32m1.13247\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7360 | loss: 1.13247 - acc: 0.7895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7361  | total loss: \u001b[1m\u001b[32m1.03758\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7361 | loss: 1.03758 - acc: 0.8106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7362  | total loss: \u001b[1m\u001b[32m1.33052\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7362 | loss: 1.33052 - acc: 0.7367 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7363  | total loss: \u001b[1m\u001b[32m1.21610\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7363 | loss: 1.21610 - acc: 0.7630 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7364  | total loss: \u001b[1m\u001b[32m1.50401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7364 | loss: 1.50401 - acc: 0.6938 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7365  | total loss: \u001b[1m\u001b[32m1.37350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7365 | loss: 1.37350 - acc: 0.7244 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7366  | total loss: \u001b[1m\u001b[32m1.25678\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7366 | loss: 1.25678 - acc: 0.7520 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7367  | total loss: \u001b[1m\u001b[32m1.15225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7367 | loss: 1.15225 - acc: 0.7768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7368  | total loss: \u001b[1m\u001b[32m1.44464\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7368 | loss: 1.44464 - acc: 0.6991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7369  | total loss: \u001b[1m\u001b[32m1.32272\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7369 | loss: 1.32272 - acc: 0.7292 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7370  | total loss: \u001b[1m\u001b[32m1.57557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7370 | loss: 1.57557 - acc: 0.6706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7371  | total loss: \u001b[1m\u001b[32m1.44281\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7371 | loss: 1.44281 - acc: 0.7035 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7372  | total loss: \u001b[1m\u001b[32m1.32444\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7372 | loss: 1.32444 - acc: 0.7332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7373  | total loss: \u001b[1m\u001b[32m1.21875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7373 | loss: 1.21875 - acc: 0.7598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7374  | total loss: \u001b[1m\u001b[32m1.46076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7374 | loss: 1.46076 - acc: 0.6910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7375  | total loss: \u001b[1m\u001b[32m1.34318\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7375 | loss: 1.34318 - acc: 0.7219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7376  | total loss: \u001b[1m\u001b[32m1.56675\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7376 | loss: 1.56675 - acc: 0.6569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7377  | total loss: \u001b[1m\u001b[32m1.44098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7377 | loss: 1.44098 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7378  | total loss: \u001b[1m\u001b[32m1.32894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7378 | loss: 1.32894 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7379  | total loss: \u001b[1m\u001b[32m1.22886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7379 | loss: 1.22886 - acc: 0.7498 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7380  | total loss: \u001b[1m\u001b[32m1.13917\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7380 | loss: 1.13917 - acc: 0.7749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7381  | total loss: \u001b[1m\u001b[32m1.05848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7381 | loss: 1.05848 - acc: 0.7974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7382  | total loss: \u001b[1m\u001b[32m0.98556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7382 | loss: 0.98556 - acc: 0.8176 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7383  | total loss: \u001b[1m\u001b[32m0.91933\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7383 | loss: 0.91933 - acc: 0.8359 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7384  | total loss: \u001b[1m\u001b[32m0.85889\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7384 | loss: 0.85889 - acc: 0.8523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7385  | total loss: \u001b[1m\u001b[32m0.80345\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7385 | loss: 0.80345 - acc: 0.8671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7386  | total loss: \u001b[1m\u001b[32m1.13186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7386 | loss: 1.13186 - acc: 0.7804 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7387  | total loss: \u001b[1m\u001b[32m1.04768\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7387 | loss: 1.04768 - acc: 0.8023 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7388  | total loss: \u001b[1m\u001b[32m1.30028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7388 | loss: 1.30028 - acc: 0.7292 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7389  | total loss: \u001b[1m\u001b[32m1.19910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7389 | loss: 1.19910 - acc: 0.7563 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7390  | total loss: \u001b[1m\u001b[32m1.43584\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7390 | loss: 1.43584 - acc: 0.6950 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7391  | total loss: \u001b[1m\u001b[32m1.32187\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7391 | loss: 1.32187 - acc: 0.7255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7392  | total loss: \u001b[1m\u001b[32m1.55380\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7392 | loss: 1.55380 - acc: 0.6601 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7393  | total loss: \u001b[1m\u001b[32m1.42952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7393 | loss: 1.42952 - acc: 0.6941 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7394  | total loss: \u001b[1m\u001b[32m1.68132\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7394 | loss: 1.68132 - acc: 0.6318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7395  | total loss: \u001b[1m\u001b[32m1.54643\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7395 | loss: 1.54643 - acc: 0.6686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7396  | total loss: \u001b[1m\u001b[32m1.42602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7396 | loss: 1.42602 - acc: 0.7018 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7397  | total loss: \u001b[1m\u001b[32m1.31821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7397 | loss: 1.31821 - acc: 0.7316 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7398  | total loss: \u001b[1m\u001b[32m1.57024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7398 | loss: 1.57024 - acc: 0.6656 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7399  | total loss: \u001b[1m\u001b[32m1.44915\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7399 | loss: 1.44915 - acc: 0.6990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7400  | total loss: \u001b[1m\u001b[32m1.34071\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7400 | loss: 1.34071 - acc: 0.7291 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7401  | total loss: \u001b[1m\u001b[32m1.24323\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7401 | loss: 1.24323 - acc: 0.7562 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7402  | total loss: \u001b[1m\u001b[32m1.15526\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7402 | loss: 1.15526 - acc: 0.7806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7403  | total loss: \u001b[1m\u001b[32m1.07551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7403 | loss: 1.07551 - acc: 0.8025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7404  | total loss: \u001b[1m\u001b[32m1.00288\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7404 | loss: 1.00288 - acc: 0.8223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7405  | total loss: \u001b[1m\u001b[32m0.93643\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7405 | loss: 0.93643 - acc: 0.8400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7406  | total loss: \u001b[1m\u001b[32m1.22033\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7406 | loss: 1.22033 - acc: 0.7632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7407  | total loss: \u001b[1m\u001b[32m1.13048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7407 | loss: 1.13048 - acc: 0.7869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7408  | total loss: \u001b[1m\u001b[32m1.36438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7408 | loss: 1.36438 - acc: 0.7082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7409  | total loss: \u001b[1m\u001b[32m1.25974\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7409 | loss: 1.25974 - acc: 0.7374 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7410  | total loss: \u001b[1m\u001b[32m1.46659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7410 | loss: 1.46659 - acc: 0.6779 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7411  | total loss: \u001b[1m\u001b[32m1.35224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7411 | loss: 1.35224 - acc: 0.7101 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7412  | total loss: \u001b[1m\u001b[32m1.24954\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7412 | loss: 1.24954 - acc: 0.7391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7413  | total loss: \u001b[1m\u001b[32m1.15702\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7413 | loss: 1.15702 - acc: 0.7652 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7414  | total loss: \u001b[1m\u001b[32m1.07336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7414 | loss: 1.07336 - acc: 0.7887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7415  | total loss: \u001b[1m\u001b[32m0.99743\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7415 | loss: 0.99743 - acc: 0.8098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7416  | total loss: \u001b[1m\u001b[32m0.92822\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7416 | loss: 0.92822 - acc: 0.8288 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7417  | total loss: \u001b[1m\u001b[32m0.86490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7417 | loss: 0.86490 - acc: 0.8459 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7418  | total loss: \u001b[1m\u001b[32m0.80673\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7418 | loss: 0.80673 - acc: 0.8613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7419  | total loss: \u001b[1m\u001b[32m0.75310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7419 | loss: 0.75310 - acc: 0.8752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7420  | total loss: \u001b[1m\u001b[32m0.70347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7420 | loss: 0.70347 - acc: 0.8877 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7421  | total loss: \u001b[1m\u001b[32m0.65742\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7421 | loss: 0.65742 - acc: 0.8989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7422  | total loss: \u001b[1m\u001b[32m0.61456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7422 | loss: 0.61456 - acc: 0.9090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7423  | total loss: \u001b[1m\u001b[32m0.57459\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7423 | loss: 0.57459 - acc: 0.9181 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7424  | total loss: \u001b[1m\u001b[32m0.53725\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7424 | loss: 0.53725 - acc: 0.9263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7425  | total loss: \u001b[1m\u001b[32m0.50231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7425 | loss: 0.50231 - acc: 0.9337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7426  | total loss: \u001b[1m\u001b[32m0.46960\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7426 | loss: 0.46960 - acc: 0.9403 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7427  | total loss: \u001b[1m\u001b[32m0.43894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7427 | loss: 0.43894 - acc: 0.9463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7428  | total loss: \u001b[1m\u001b[32m0.41022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7428 | loss: 0.41022 - acc: 0.9517 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7429  | total loss: \u001b[1m\u001b[32m0.38329\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7429 | loss: 0.38329 - acc: 0.9565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7430  | total loss: \u001b[1m\u001b[32m0.35806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7430 | loss: 0.35806 - acc: 0.9608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7431  | total loss: \u001b[1m\u001b[32m0.33442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7431 | loss: 0.33442 - acc: 0.9648 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7432  | total loss: \u001b[1m\u001b[32m0.31229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7432 | loss: 0.31229 - acc: 0.9683 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7433  | total loss: \u001b[1m\u001b[32m0.29159\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7433 | loss: 0.29159 - acc: 0.9715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7434  | total loss: \u001b[1m\u001b[32m0.75697\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7434 | loss: 0.75697 - acc: 0.8743 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7435  | total loss: \u001b[1m\u001b[32m0.69088\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7435 | loss: 0.69088 - acc: 0.8869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7436  | total loss: \u001b[1m\u001b[32m1.11198\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7436 | loss: 1.11198 - acc: 0.8053 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7437  | total loss: \u001b[1m\u001b[32m1.01038\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7437 | loss: 1.01038 - acc: 0.8248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7438  | total loss: \u001b[1m\u001b[32m1.35992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7438 | loss: 1.35992 - acc: 0.7566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7439  | total loss: \u001b[1m\u001b[32m1.23422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7439 | loss: 1.23422 - acc: 0.7809 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7440  | total loss: \u001b[1m\u001b[32m1.12157\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7440 | loss: 1.12157 - acc: 0.8028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7441  | total loss: \u001b[1m\u001b[32m1.02057\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7441 | loss: 1.02057 - acc: 0.8226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7442  | total loss: \u001b[1m\u001b[32m0.92997\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7442 | loss: 0.92997 - acc: 0.8403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7443  | total loss: \u001b[1m\u001b[32m0.84864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7443 | loss: 0.84864 - acc: 0.8563 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7444  | total loss: \u001b[1m\u001b[32m1.20516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7444 | loss: 1.20516 - acc: 0.7778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7445  | total loss: \u001b[1m\u001b[32m1.09703\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7445 | loss: 1.09703 - acc: 0.8000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7446  | total loss: \u001b[1m\u001b[32m1.47486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7446 | loss: 1.47486 - acc: 0.7200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7447  | total loss: \u001b[1m\u001b[32m1.34121\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7447 | loss: 1.34121 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7448  | total loss: \u001b[1m\u001b[32m1.68041\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7448 | loss: 1.68041 - acc: 0.6732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7449  | total loss: \u001b[1m\u001b[32m1.52844\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7449 | loss: 1.52844 - acc: 0.7059 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7450  | total loss: \u001b[1m\u001b[32m1.39291\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 7450 | loss: 1.39291 - acc: 0.7353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7451  | total loss: \u001b[1m\u001b[32m1.27197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7451 | loss: 1.27197 - acc: 0.7618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7452  | total loss: \u001b[1m\u001b[32m1.16396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7452 | loss: 1.16396 - acc: 0.7856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7453  | total loss: \u001b[1m\u001b[32m1.06738\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7453 | loss: 1.06738 - acc: 0.8070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7454  | total loss: \u001b[1m\u001b[32m1.37198\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7454 | loss: 1.37198 - acc: 0.7335 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7455  | total loss: \u001b[1m\u001b[32m1.25605\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7455 | loss: 1.25605 - acc: 0.7601 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7456  | total loss: \u001b[1m\u001b[32m1.51469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7456 | loss: 1.51469 - acc: 0.6984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7457  | total loss: \u001b[1m\u001b[32m1.38667\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7457 | loss: 1.38667 - acc: 0.7286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7458  | total loss: \u001b[1m\u001b[32m1.67226\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7458 | loss: 1.67226 - acc: 0.6557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7459  | total loss: \u001b[1m\u001b[32m1.53150\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7459 | loss: 1.53150 - acc: 0.6901 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7460  | total loss: \u001b[1m\u001b[32m1.74766\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7460 | loss: 1.74766 - acc: 0.6283 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7461  | total loss: \u001b[1m\u001b[32m1.60308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7461 | loss: 1.60308 - acc: 0.6654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7462  | total loss: \u001b[1m\u001b[32m1.80085\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7462 | loss: 1.80085 - acc: 0.6060 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7463  | total loss: \u001b[1m\u001b[32m1.65513\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7463 | loss: 1.65513 - acc: 0.6454 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7464  | total loss: \u001b[1m\u001b[32m1.52592\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7464 | loss: 1.52592 - acc: 0.6809 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7465  | total loss: \u001b[1m\u001b[32m1.41109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7465 | loss: 1.41109 - acc: 0.7128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7466  | total loss: \u001b[1m\u001b[32m1.30869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7466 | loss: 1.30869 - acc: 0.7415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7467  | total loss: \u001b[1m\u001b[32m1.21701\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7467 | loss: 1.21701 - acc: 0.7674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7468  | total loss: \u001b[1m\u001b[32m1.41750\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7468 | loss: 1.41750 - acc: 0.7121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7469  | total loss: \u001b[1m\u001b[32m1.31562\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7469 | loss: 1.31562 - acc: 0.7409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7470  | total loss: \u001b[1m\u001b[32m1.56832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7470 | loss: 1.56832 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7471  | total loss: \u001b[1m\u001b[32m1.45253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7471 | loss: 1.45253 - acc: 0.7001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7472  | total loss: \u001b[1m\u001b[32m1.34879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7472 | loss: 1.34879 - acc: 0.7301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7473  | total loss: \u001b[1m\u001b[32m1.25543\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7473 | loss: 1.25543 - acc: 0.7571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7474  | total loss: \u001b[1m\u001b[32m1.47737\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7474 | loss: 1.47737 - acc: 0.6885 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7475  | total loss: \u001b[1m\u001b[32m1.37107\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7475 | loss: 1.37107 - acc: 0.7197 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7476  | total loss: \u001b[1m\u001b[32m1.59573\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7476 | loss: 1.59573 - acc: 0.6548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7477  | total loss: \u001b[1m\u001b[32m1.47817\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7477 | loss: 1.47817 - acc: 0.6894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7478  | total loss: \u001b[1m\u001b[32m1.37256\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7478 | loss: 1.37256 - acc: 0.7204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7479  | total loss: \u001b[1m\u001b[32m1.27727\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7479 | loss: 1.27727 - acc: 0.7484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7480  | total loss: \u001b[1m\u001b[32m1.50021\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7480 | loss: 1.50021 - acc: 0.6807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7481  | total loss: \u001b[1m\u001b[32m1.39171\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7481 | loss: 1.39171 - acc: 0.7126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7482  | total loss: \u001b[1m\u001b[32m1.29382\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7482 | loss: 1.29382 - acc: 0.7414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7483  | total loss: \u001b[1m\u001b[32m1.20510\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7483 | loss: 1.20510 - acc: 0.7672 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7484  | total loss: \u001b[1m\u001b[32m1.12429\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7484 | loss: 1.12429 - acc: 0.7905 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7485  | total loss: \u001b[1m\u001b[32m1.05033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7485 | loss: 1.05033 - acc: 0.8114 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7486  | total loss: \u001b[1m\u001b[32m1.25983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7486 | loss: 1.25983 - acc: 0.7446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7487  | total loss: \u001b[1m\u001b[32m1.17019\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7487 | loss: 1.17019 - acc: 0.7701 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7488  | total loss: \u001b[1m\u001b[32m1.42861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7488 | loss: 1.42861 - acc: 0.7003 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7489  | total loss: \u001b[1m\u001b[32m1.32115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7489 | loss: 1.32115 - acc: 0.7302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7490  | total loss: \u001b[1m\u001b[32m1.57112\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7490 | loss: 1.57112 - acc: 0.6572 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7491  | total loss: \u001b[1m\u001b[32m1.44956\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7491 | loss: 1.44956 - acc: 0.6915 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7492  | total loss: \u001b[1m\u001b[32m1.34028\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7492 | loss: 1.34028 - acc: 0.7223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7493  | total loss: \u001b[1m\u001b[32m1.24171\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7493 | loss: 1.24171 - acc: 0.7501 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7494  | total loss: \u001b[1m\u001b[32m1.15247\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7494 | loss: 1.15247 - acc: 0.7751 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7495  | total loss: \u001b[1m\u001b[32m1.07134\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7495 | loss: 1.07134 - acc: 0.7976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7496  | total loss: \u001b[1m\u001b[32m0.99728\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7496 | loss: 0.99728 - acc: 0.8178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7497  | total loss: \u001b[1m\u001b[32m0.92940\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7497 | loss: 0.92940 - acc: 0.8360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7498  | total loss: \u001b[1m\u001b[32m0.86694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7498 | loss: 0.86694 - acc: 0.8524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7499  | total loss: \u001b[1m\u001b[32m0.80924\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7499 | loss: 0.80924 - acc: 0.8672 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7500  | total loss: \u001b[1m\u001b[32m0.75578\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7500 | loss: 0.75578 - acc: 0.8805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7501  | total loss: \u001b[1m\u001b[32m0.70608\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7501 | loss: 0.70608 - acc: 0.8924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7502  | total loss: \u001b[1m\u001b[32m1.04668\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7502 | loss: 1.04668 - acc: 0.8103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7503  | total loss: \u001b[1m\u001b[32m0.96564\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7503 | loss: 0.96564 - acc: 0.8293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7504  | total loss: \u001b[1m\u001b[32m1.28449\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7504 | loss: 1.28449 - acc: 0.7464 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7505  | total loss: \u001b[1m\u001b[32m1.17895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7505 | loss: 1.17895 - acc: 0.7717 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7506  | total loss: \u001b[1m\u001b[32m1.08386\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7506 | loss: 1.08386 - acc: 0.7946 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7507  | total loss: \u001b[1m\u001b[32m0.99798\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7507 | loss: 0.99798 - acc: 0.8151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7508  | total loss: \u001b[1m\u001b[32m1.24867\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7508 | loss: 1.24867 - acc: 0.7479 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7509  | total loss: \u001b[1m\u001b[32m1.14610\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7509 | loss: 1.14610 - acc: 0.7731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7510  | total loss: \u001b[1m\u001b[32m1.05381\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7510 | loss: 1.05381 - acc: 0.7958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7511  | total loss: \u001b[1m\u001b[32m0.97060\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7511 | loss: 0.97060 - acc: 0.8162 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7512  | total loss: \u001b[1m\u001b[32m1.28099\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7512 | loss: 1.28099 - acc: 0.7417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7513  | total loss: \u001b[1m\u001b[32m1.17516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7513 | loss: 1.17516 - acc: 0.7676 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7514  | total loss: \u001b[1m\u001b[32m1.08011\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7514 | loss: 1.08011 - acc: 0.7908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7515  | total loss: \u001b[1m\u001b[32m0.99456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7515 | loss: 0.99456 - acc: 0.8117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7516  | total loss: \u001b[1m\u001b[32m1.32325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7516 | loss: 1.32325 - acc: 0.7305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7517  | total loss: \u001b[1m\u001b[32m1.21383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7517 | loss: 1.21383 - acc: 0.7575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7518  | total loss: \u001b[1m\u001b[32m1.11574\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7518 | loss: 1.11574 - acc: 0.7817 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7519  | total loss: \u001b[1m\u001b[32m1.02761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7519 | loss: 1.02761 - acc: 0.8036 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7520  | total loss: \u001b[1m\u001b[32m1.30590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7520 | loss: 1.30590 - acc: 0.7304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7521  | total loss: \u001b[1m\u001b[32m1.19935\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7521 | loss: 1.19935 - acc: 0.7573 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7522  | total loss: \u001b[1m\u001b[32m1.43875\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7522 | loss: 1.43875 - acc: 0.6959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7523  | total loss: \u001b[1m\u001b[32m1.32031\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7523 | loss: 1.32031 - acc: 0.7263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7524  | total loss: \u001b[1m\u001b[32m1.21441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7524 | loss: 1.21441 - acc: 0.7537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7525  | total loss: \u001b[1m\u001b[32m1.11950\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7525 | loss: 1.11950 - acc: 0.7783 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7526  | total loss: \u001b[1m\u001b[32m1.39762\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7526 | loss: 1.39762 - acc: 0.7076 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7527  | total loss: \u001b[1m\u001b[32m1.28542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7527 | loss: 1.28542 - acc: 0.7368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7528  | total loss: \u001b[1m\u001b[32m1.18503\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7528 | loss: 1.18503 - acc: 0.7632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7529  | total loss: \u001b[1m\u001b[32m1.09494\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7529 | loss: 1.09494 - acc: 0.7868 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7530  | total loss: \u001b[1m\u001b[32m1.35013\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7530 | loss: 1.35013 - acc: 0.7153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7531  | total loss: \u001b[1m\u001b[32m1.24424\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7531 | loss: 1.24424 - acc: 0.7438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7532  | total loss: \u001b[1m\u001b[32m1.54337\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7532 | loss: 1.54337 - acc: 0.6694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7533  | total loss: \u001b[1m\u001b[32m1.41975\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7533 | loss: 1.41975 - acc: 0.7025 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7534  | total loss: \u001b[1m\u001b[32m1.30930\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7534 | loss: 1.30930 - acc: 0.7322 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7535  | total loss: \u001b[1m\u001b[32m1.21033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7535 | loss: 1.21033 - acc: 0.7590 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7536  | total loss: \u001b[1m\u001b[32m1.43537\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7536 | loss: 1.43537 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7537  | total loss: \u001b[1m\u001b[32m1.32459\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7537 | loss: 1.32459 - acc: 0.7276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7538  | total loss: \u001b[1m\u001b[32m1.57454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7538 | loss: 1.57454 - acc: 0.6549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7539  | total loss: \u001b[1m\u001b[32m1.45140\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7539 | loss: 1.45140 - acc: 0.6894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7540  | total loss: \u001b[1m\u001b[32m1.34134\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7540 | loss: 1.34134 - acc: 0.7204 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7541  | total loss: \u001b[1m\u001b[32m1.24266\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7541 | loss: 1.24266 - acc: 0.7484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7542  | total loss: \u001b[1m\u001b[32m1.44402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7542 | loss: 1.44402 - acc: 0.6878 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7543  | total loss: \u001b[1m\u001b[32m1.33572\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7543 | loss: 1.33572 - acc: 0.7191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7544  | total loss: \u001b[1m\u001b[32m1.23853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7544 | loss: 1.23853 - acc: 0.7472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7545  | total loss: \u001b[1m\u001b[32m1.15094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7545 | loss: 1.15094 - acc: 0.7724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7546  | total loss: \u001b[1m\u001b[32m1.42502\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7546 | loss: 1.42502 - acc: 0.6952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7547  | total loss: \u001b[1m\u001b[32m1.31874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7547 | loss: 1.31874 - acc: 0.7257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7548  | total loss: \u001b[1m\u001b[32m1.22311\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7548 | loss: 1.22311 - acc: 0.7531 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7549  | total loss: \u001b[1m\u001b[32m1.13671\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7549 | loss: 1.13671 - acc: 0.7778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7550  | total loss: \u001b[1m\u001b[32m1.05830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7550 | loss: 1.05830 - acc: 0.8000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7551  | total loss: \u001b[1m\u001b[32m0.98681\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7551 | loss: 0.98681 - acc: 0.8200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7552  | total loss: \u001b[1m\u001b[32m0.92133\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7552 | loss: 0.92133 - acc: 0.8380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7553  | total loss: \u001b[1m\u001b[32m0.86108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7553 | loss: 0.86108 - acc: 0.8542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7554  | total loss: \u001b[1m\u001b[32m0.80541\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7554 | loss: 0.80541 - acc: 0.8688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7555  | total loss: \u001b[1m\u001b[32m0.75375\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7555 | loss: 0.75375 - acc: 0.8819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7556  | total loss: \u001b[1m\u001b[32m0.70567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7556 | loss: 0.70567 - acc: 0.8937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7557  | total loss: \u001b[1m\u001b[32m0.66078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7557 | loss: 0.66078 - acc: 0.9043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7558  | total loss: \u001b[1m\u001b[32m0.61877\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7558 | loss: 0.61877 - acc: 0.9139 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7559  | total loss: \u001b[1m\u001b[32m0.57938\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7559 | loss: 0.57938 - acc: 0.9225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7560  | total loss: \u001b[1m\u001b[32m0.54240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7560 | loss: 0.54240 - acc: 0.9303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7561  | total loss: \u001b[1m\u001b[32m0.50764\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7561 | loss: 0.50764 - acc: 0.9372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7562  | total loss: \u001b[1m\u001b[32m0.47497\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7562 | loss: 0.47497 - acc: 0.9435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7563  | total loss: \u001b[1m\u001b[32m0.44424\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7563 | loss: 0.44424 - acc: 0.9492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7564  | total loss: \u001b[1m\u001b[32m0.86048\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7564 | loss: 0.86048 - acc: 0.8543 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7565  | total loss: \u001b[1m\u001b[32m0.78950\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7565 | loss: 0.78950 - acc: 0.8688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7566  | total loss: \u001b[1m\u001b[32m1.10283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7566 | loss: 1.10283 - acc: 0.7962 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7567  | total loss: \u001b[1m\u001b[32m1.00718\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7567 | loss: 1.00718 - acc: 0.8166 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7568  | total loss: \u001b[1m\u001b[32m1.35382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7568 | loss: 1.35382 - acc: 0.7421 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7569  | total loss: \u001b[1m\u001b[32m1.23361\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7569 | loss: 1.23361 - acc: 0.7679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7570  | total loss: \u001b[1m\u001b[32m1.12584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7570 | loss: 1.12584 - acc: 0.7911 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7571  | total loss: \u001b[1m\u001b[32m1.02913\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7571 | loss: 1.02913 - acc: 0.8120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7572  | total loss: \u001b[1m\u001b[32m0.94225\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7572 | loss: 0.94225 - acc: 0.8308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7573  | total loss: \u001b[1m\u001b[32m0.86409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7573 | loss: 0.86409 - acc: 0.8477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7574  | total loss: \u001b[1m\u001b[32m0.79367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7574 | loss: 0.79367 - acc: 0.8629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7575  | total loss: \u001b[1m\u001b[32m0.73012\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7575 | loss: 0.73012 - acc: 0.8766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7576  | total loss: \u001b[1m\u001b[32m1.05806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7576 | loss: 1.05806 - acc: 0.7961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7577  | total loss: \u001b[1m\u001b[32m0.96815\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7577 | loss: 0.96815 - acc: 0.8165 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7578  | total loss: \u001b[1m\u001b[32m1.34138\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7578 | loss: 1.34138 - acc: 0.7349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7579  | total loss: \u001b[1m\u001b[32m1.22423\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7579 | loss: 1.22423 - acc: 0.7614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7580  | total loss: \u001b[1m\u001b[32m1.11947\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7580 | loss: 1.11947 - acc: 0.7852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7581  | total loss: \u001b[1m\u001b[32m1.02569\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7581 | loss: 1.02569 - acc: 0.8067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7582  | total loss: \u001b[1m\u001b[32m0.94162\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7582 | loss: 0.94162 - acc: 0.8260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7583  | total loss: \u001b[1m\u001b[32m0.86612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7583 | loss: 0.86612 - acc: 0.8434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7584  | total loss: \u001b[1m\u001b[32m0.79817\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7584 | loss: 0.79817 - acc: 0.8591 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7585  | total loss: \u001b[1m\u001b[32m0.73687\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7585 | loss: 0.73687 - acc: 0.8732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7586  | total loss: \u001b[1m\u001b[32m1.10372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7586 | loss: 1.10372 - acc: 0.7930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7587  | total loss: \u001b[1m\u001b[32m1.01199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7587 | loss: 1.01199 - acc: 0.8137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7588  | total loss: \u001b[1m\u001b[32m0.92966\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7588 | loss: 0.92966 - acc: 0.8323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7589  | total loss: \u001b[1m\u001b[32m0.85562\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7589 | loss: 0.85562 - acc: 0.8491 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7590  | total loss: \u001b[1m\u001b[32m1.20363\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7590 | loss: 1.20363 - acc: 0.7713 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7591  | total loss: \u001b[1m\u001b[32m1.10269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7591 | loss: 1.10269 - acc: 0.7942 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7592  | total loss: \u001b[1m\u001b[32m1.40189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7592 | loss: 1.40189 - acc: 0.7148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7593  | total loss: \u001b[1m\u001b[32m1.28263\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7593 | loss: 1.28263 - acc: 0.7433 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7594  | total loss: \u001b[1m\u001b[32m1.53143\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7594 | loss: 1.53143 - acc: 0.6833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7595  | total loss: \u001b[1m\u001b[32m1.40157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7595 | loss: 1.40157 - acc: 0.7149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7596  | total loss: \u001b[1m\u001b[32m1.66623\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7596 | loss: 1.66623 - acc: 0.6434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7597  | total loss: \u001b[1m\u001b[32m1.52610\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7597 | loss: 1.52610 - acc: 0.6791 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7598  | total loss: \u001b[1m\u001b[32m1.40163\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7598 | loss: 1.40163 - acc: 0.7112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7599  | total loss: \u001b[1m\u001b[32m1.29087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7599 | loss: 1.29087 - acc: 0.7401 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7600  | total loss: \u001b[1m\u001b[32m1.53736\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7600 | loss: 1.53736 - acc: 0.6732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7601  | total loss: \u001b[1m\u001b[32m1.41555\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7601 | loss: 1.41555 - acc: 0.7059 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7602  | total loss: \u001b[1m\u001b[32m1.66938\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7602 | loss: 1.66938 - acc: 0.6353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7603  | total loss: \u001b[1m\u001b[32m1.53758\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7603 | loss: 1.53758 - acc: 0.6718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7604  | total loss: \u001b[1m\u001b[32m1.42047\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7604 | loss: 1.42047 - acc: 0.7046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7605  | total loss: \u001b[1m\u001b[32m1.31605\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7605 | loss: 1.31605 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7606  | total loss: \u001b[1m\u001b[32m1.49538\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7606 | loss: 1.49538 - acc: 0.6821 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7607  | total loss: \u001b[1m\u001b[32m1.38501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7607 | loss: 1.38501 - acc: 0.7139 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7608  | total loss: \u001b[1m\u001b[32m1.61654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7608 | loss: 1.61654 - acc: 0.6425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7609  | total loss: \u001b[1m\u001b[32m1.49600\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7609 | loss: 1.49600 - acc: 0.6783 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7610  | total loss: \u001b[1m\u001b[32m1.73200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7610 | loss: 1.73200 - acc: 0.6105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7611  | total loss: \u001b[1m\u001b[32m1.60243\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7611 | loss: 1.60243 - acc: 0.6494 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7612  | total loss: \u001b[1m\u001b[32m1.81851\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7612 | loss: 1.81851 - acc: 0.5845 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7613  | total loss: \u001b[1m\u001b[32m1.68316\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7613 | loss: 1.68316 - acc: 0.6260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7614  | total loss: \u001b[1m\u001b[32m1.56252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7614 | loss: 1.56252 - acc: 0.6634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7615  | total loss: \u001b[1m\u001b[32m1.45450\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7615 | loss: 1.45450 - acc: 0.6971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7616  | total loss: \u001b[1m\u001b[32m1.67478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7616 | loss: 1.67478 - acc: 0.6274 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7617  | total loss: \u001b[1m\u001b[32m1.55632\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7617 | loss: 1.55632 - acc: 0.6646 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7618  | total loss: \u001b[1m\u001b[32m1.44992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7618 | loss: 1.44992 - acc: 0.6982 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7619  | total loss: \u001b[1m\u001b[32m1.35382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7619 | loss: 1.35382 - acc: 0.7284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7620  | total loss: \u001b[1m\u001b[32m1.26650\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7620 | loss: 1.26650 - acc: 0.7555 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7621  | total loss: \u001b[1m\u001b[32m1.18666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7621 | loss: 1.18666 - acc: 0.7800 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7622  | total loss: \u001b[1m\u001b[32m1.11319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7622 | loss: 1.11319 - acc: 0.8020 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7623  | total loss: \u001b[1m\u001b[32m1.04519\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7623 | loss: 1.04519 - acc: 0.8218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7624  | total loss: \u001b[1m\u001b[32m1.31434\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7624 | loss: 1.31434 - acc: 0.7467 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7625  | total loss: \u001b[1m\u001b[32m1.22305\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7625 | loss: 1.22305 - acc: 0.7721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7626  | total loss: \u001b[1m\u001b[32m1.13955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7626 | loss: 1.13955 - acc: 0.7949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7627  | total loss: \u001b[1m\u001b[32m1.06285\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7627 | loss: 1.06285 - acc: 0.8154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7628  | total loss: \u001b[1m\u001b[32m1.36219\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7628 | loss: 1.36219 - acc: 0.7338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7629  | total loss: \u001b[1m\u001b[32m1.26086\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7629 | loss: 1.26086 - acc: 0.7605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7630  | total loss: \u001b[1m\u001b[32m1.51313\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7630 | loss: 1.51313 - acc: 0.6844 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7631  | total loss: \u001b[1m\u001b[32m1.39581\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7631 | loss: 1.39581 - acc: 0.7160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7632  | total loss: \u001b[1m\u001b[32m1.65202\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7632 | loss: 1.65202 - acc: 0.6444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7633  | total loss: \u001b[1m\u001b[32m1.52104\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7633 | loss: 1.52104 - acc: 0.6799 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7634  | total loss: \u001b[1m\u001b[32m1.72159\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7634 | loss: 1.72159 - acc: 0.6262 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7635  | total loss: \u001b[1m\u001b[32m1.58473\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7635 | loss: 1.58473 - acc: 0.6636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7636  | total loss: \u001b[1m\u001b[32m1.77049\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7636 | loss: 1.77049 - acc: 0.6044 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7637  | total loss: \u001b[1m\u001b[32m1.63039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7637 | loss: 1.63039 - acc: 0.6439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7638  | total loss: \u001b[1m\u001b[32m1.50499\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7638 | loss: 1.50499 - acc: 0.6796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7639  | total loss: \u001b[1m\u001b[32m1.39241\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7639 | loss: 1.39241 - acc: 0.7116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7640  | total loss: \u001b[1m\u001b[32m1.29097\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7640 | loss: 1.29097 - acc: 0.7404 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7641  | total loss: \u001b[1m\u001b[32m1.19918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7641 | loss: 1.19918 - acc: 0.7664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7642  | total loss: \u001b[1m\u001b[32m1.11578\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7642 | loss: 1.11578 - acc: 0.7898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7643  | total loss: \u001b[1m\u001b[32m1.03966\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7643 | loss: 1.03966 - acc: 0.8108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7644  | total loss: \u001b[1m\u001b[32m1.29355\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7644 | loss: 1.29355 - acc: 0.7440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7645  | total loss: \u001b[1m\u001b[32m1.19799\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7645 | loss: 1.19799 - acc: 0.7696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7646  | total loss: \u001b[1m\u001b[32m1.11133\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7646 | loss: 1.11133 - acc: 0.7926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7647  | total loss: \u001b[1m\u001b[32m1.03245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7647 | loss: 1.03245 - acc: 0.8134 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7648  | total loss: \u001b[1m\u001b[32m1.24584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7648 | loss: 1.24584 - acc: 0.7535 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7649  | total loss: \u001b[1m\u001b[32m1.15203\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7649 | loss: 1.15203 - acc: 0.7781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7650  | total loss: \u001b[1m\u001b[32m1.06697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7650 | loss: 1.06697 - acc: 0.8003 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7651  | total loss: \u001b[1m\u001b[32m0.98959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7651 | loss: 0.98959 - acc: 0.8203 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7652  | total loss: \u001b[1m\u001b[32m1.28195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7652 | loss: 1.28195 - acc: 0.7382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7653  | total loss: \u001b[1m\u001b[32m1.18203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7653 | loss: 1.18203 - acc: 0.7644 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7654  | total loss: \u001b[1m\u001b[32m1.09179\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7654 | loss: 1.09179 - acc: 0.7880 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7655  | total loss: \u001b[1m\u001b[32m1.01007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7655 | loss: 1.01007 - acc: 0.8092 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7656  | total loss: \u001b[1m\u001b[32m0.93582\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7656 | loss: 0.93582 - acc: 0.8283 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7657  | total loss: \u001b[1m\u001b[32m0.86814\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7657 | loss: 0.86814 - acc: 0.8454 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7658  | total loss: \u001b[1m\u001b[32m0.80625\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7658 | loss: 0.80625 - acc: 0.8609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7659  | total loss: \u001b[1m\u001b[32m0.74948\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7659 | loss: 0.74948 - acc: 0.8748 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7660  | total loss: \u001b[1m\u001b[32m0.69726\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7660 | loss: 0.69726 - acc: 0.8873 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7661  | total loss: \u001b[1m\u001b[32m0.64908\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7661 | loss: 0.64908 - acc: 0.8986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7662  | total loss: \u001b[1m\u001b[32m1.02616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7662 | loss: 1.02616 - acc: 0.8087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7663  | total loss: \u001b[1m\u001b[32m0.94359\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7663 | loss: 0.94359 - acc: 0.8279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7664  | total loss: \u001b[1m\u001b[32m0.86884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7664 | loss: 0.86884 - acc: 0.8451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7665  | total loss: \u001b[1m\u001b[32m0.80102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7665 | loss: 0.80102 - acc: 0.8606 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7666  | total loss: \u001b[1m\u001b[32m0.73937\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7666 | loss: 0.73937 - acc: 0.8745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7667  | total loss: \u001b[1m\u001b[32m0.68319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7667 | loss: 0.68319 - acc: 0.8871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7668  | total loss: \u001b[1m\u001b[32m0.63190\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7668 | loss: 0.63190 - acc: 0.8984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7669  | total loss: \u001b[1m\u001b[32m0.58498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7669 | loss: 0.58498 - acc: 0.9085 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7670  | total loss: \u001b[1m\u001b[32m0.54197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7670 | loss: 0.54197 - acc: 0.9177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7671  | total loss: \u001b[1m\u001b[32m0.50248\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7671 | loss: 0.50248 - acc: 0.9259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7672  | total loss: \u001b[1m\u001b[32m0.88378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7672 | loss: 0.88378 - acc: 0.8405 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7673  | total loss: \u001b[1m\u001b[32m0.80920\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7673 | loss: 0.80920 - acc: 0.8564 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7674  | total loss: \u001b[1m\u001b[32m1.18987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7674 | loss: 1.18987 - acc: 0.7708 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7675  | total loss: \u001b[1m\u001b[32m1.08488\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7675 | loss: 1.08488 - acc: 0.7937 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7676  | total loss: \u001b[1m\u001b[32m0.99069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7676 | loss: 0.99069 - acc: 0.8143 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7677  | total loss: \u001b[1m\u001b[32m0.90608\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7677 | loss: 0.90608 - acc: 0.8329 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7678  | total loss: \u001b[1m\u001b[32m0.82999\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7678 | loss: 0.82999 - acc: 0.8496 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7679  | total loss: \u001b[1m\u001b[32m0.76147\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7679 | loss: 0.76147 - acc: 0.8646 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7680  | total loss: \u001b[1m\u001b[32m1.06188\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7680 | loss: 1.06188 - acc: 0.7925 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7681  | total loss: \u001b[1m\u001b[32m0.97044\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7681 | loss: 0.97044 - acc: 0.8132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7682  | total loss: \u001b[1m\u001b[32m1.34235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7682 | loss: 1.34235 - acc: 0.7319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7683  | total loss: \u001b[1m\u001b[32m1.22405\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7683 | loss: 1.22405 - acc: 0.7587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7684  | total loss: \u001b[1m\u001b[32m1.11832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7684 | loss: 1.11832 - acc: 0.7828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7685  | total loss: \u001b[1m\u001b[32m1.02372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7685 | loss: 1.02372 - acc: 0.8046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7686  | total loss: \u001b[1m\u001b[32m0.93896\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7686 | loss: 0.93896 - acc: 0.8241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7687  | total loss: \u001b[1m\u001b[32m0.86289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7687 | loss: 0.86289 - acc: 0.8417 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7688  | total loss: \u001b[1m\u001b[32m0.79448\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7688 | loss: 0.79448 - acc: 0.8575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7689  | total loss: \u001b[1m\u001b[32m0.73282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7689 | loss: 0.73282 - acc: 0.8718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7690  | total loss: \u001b[1m\u001b[32m1.06527\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7690 | loss: 1.06527 - acc: 0.7917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7691  | total loss: \u001b[1m\u001b[32m0.97674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7691 | loss: 0.97674 - acc: 0.8126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7692  | total loss: \u001b[1m\u001b[32m1.23488\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7692 | loss: 1.23488 - acc: 0.7527 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7693  | total loss: \u001b[1m\u001b[32m1.13049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7693 | loss: 1.13049 - acc: 0.7775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7694  | total loss: \u001b[1m\u001b[32m1.45601\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7694 | loss: 1.45601 - acc: 0.6997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7695  | total loss: \u001b[1m\u001b[32m1.33148\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7695 | loss: 1.33148 - acc: 0.7297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7696  | total loss: \u001b[1m\u001b[32m1.22049\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7696 | loss: 1.22049 - acc: 0.7568 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7697  | total loss: \u001b[1m\u001b[32m1.12141\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7697 | loss: 1.12141 - acc: 0.7811 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7698  | total loss: \u001b[1m\u001b[32m1.44053\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7698 | loss: 1.44053 - acc: 0.7030 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7699  | total loss: \u001b[1m\u001b[32m1.32138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7699 | loss: 1.32138 - acc: 0.7327 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7700  | total loss: \u001b[1m\u001b[32m1.21523\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7700 | loss: 1.21523 - acc: 0.7594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7701  | total loss: \u001b[1m\u001b[32m1.12043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7701 | loss: 1.12043 - acc: 0.7835 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7702  | total loss: \u001b[1m\u001b[32m1.41944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7702 | loss: 1.41944 - acc: 0.7123 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7703  | total loss: \u001b[1m\u001b[32m1.30584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7703 | loss: 1.30584 - acc: 0.7410 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7704  | total loss: \u001b[1m\u001b[32m1.48019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7704 | loss: 1.48019 - acc: 0.6955 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7705  | total loss: \u001b[1m\u001b[32m1.36258\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7705 | loss: 1.36258 - acc: 0.7260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7706  | total loss: \u001b[1m\u001b[32m1.59808\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7706 | loss: 1.59808 - acc: 0.6605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7707  | total loss: \u001b[1m\u001b[32m1.47111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7707 | loss: 1.47111 - acc: 0.6945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7708  | total loss: \u001b[1m\u001b[32m1.68172\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7708 | loss: 1.68172 - acc: 0.6322 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7709  | total loss: \u001b[1m\u001b[32m1.54935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7709 | loss: 1.54935 - acc: 0.6689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7710  | total loss: \u001b[1m\u001b[32m1.77613\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7710 | loss: 1.77613 - acc: 0.6020 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7711  | total loss: \u001b[1m\u001b[32m1.63772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7711 | loss: 1.63772 - acc: 0.6418 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7712  | total loss: \u001b[1m\u001b[32m1.76575\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7712 | loss: 1.76575 - acc: 0.5991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7713  | total loss: \u001b[1m\u001b[32m1.63197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7713 | loss: 1.63197 - acc: 0.6392 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7714  | total loss: \u001b[1m\u001b[32m1.83497\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7714 | loss: 1.83497 - acc: 0.5824 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7715  | total loss: \u001b[1m\u001b[32m1.69781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7715 | loss: 1.69781 - acc: 0.6242 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7716  | total loss: \u001b[1m\u001b[32m1.57579\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7716 | loss: 1.57579 - acc: 0.6617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7717  | total loss: \u001b[1m\u001b[32m1.46670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7717 | loss: 1.46670 - acc: 0.6956 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7718  | total loss: \u001b[1m\u001b[32m1.63359\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7718 | loss: 1.63359 - acc: 0.6403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7719  | total loss: \u001b[1m\u001b[32m1.51963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7719 | loss: 1.51963 - acc: 0.6763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7720  | total loss: \u001b[1m\u001b[32m1.69974\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7720 | loss: 1.69974 - acc: 0.6158 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7721  | total loss: \u001b[1m\u001b[32m1.58031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7721 | loss: 1.58031 - acc: 0.6542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7722  | total loss: \u001b[1m\u001b[32m1.47315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7722 | loss: 1.47315 - acc: 0.6888 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7723  | total loss: \u001b[1m\u001b[32m1.37640\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7723 | loss: 1.37640 - acc: 0.7199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7724  | total loss: \u001b[1m\u001b[32m1.28849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7724 | loss: 1.28849 - acc: 0.7479 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7725  | total loss: \u001b[1m\u001b[32m1.20806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7725 | loss: 1.20806 - acc: 0.7731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7726  | total loss: \u001b[1m\u001b[32m1.43437\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7726 | loss: 1.43437 - acc: 0.6958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7727  | total loss: \u001b[1m\u001b[32m1.33711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7727 | loss: 1.33711 - acc: 0.7262 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7728  | total loss: \u001b[1m\u001b[32m1.54534\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7728 | loss: 1.54534 - acc: 0.6679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7729  | total loss: \u001b[1m\u001b[32m1.43591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7729 | loss: 1.43591 - acc: 0.7011 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7730  | total loss: \u001b[1m\u001b[32m1.33686\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7730 | loss: 1.33686 - acc: 0.7310 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7731  | total loss: \u001b[1m\u001b[32m1.24671\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7731 | loss: 1.24671 - acc: 0.7579 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7732  | total loss: \u001b[1m\u001b[32m1.43814\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7732 | loss: 1.43814 - acc: 0.6964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7733  | total loss: \u001b[1m\u001b[32m1.33593\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7733 | loss: 1.33593 - acc: 0.7268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7734  | total loss: \u001b[1m\u001b[32m1.58397\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7734 | loss: 1.58397 - acc: 0.6541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7735  | total loss: \u001b[1m\u001b[32m1.46633\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7735 | loss: 1.46633 - acc: 0.6887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7736  | total loss: \u001b[1m\u001b[32m1.68952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7736 | loss: 1.68952 - acc: 0.6198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7737  | total loss: \u001b[1m\u001b[32m1.56166\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7737 | loss: 1.56166 - acc: 0.6578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7738  | total loss: \u001b[1m\u001b[32m1.73670\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7738 | loss: 1.73670 - acc: 0.5992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7739  | total loss: \u001b[1m\u001b[32m1.60528\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7739 | loss: 1.60528 - acc: 0.6393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7740  | total loss: \u001b[1m\u001b[32m1.48744\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7740 | loss: 1.48744 - acc: 0.6753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7741  | total loss: \u001b[1m\u001b[32m1.38133\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7741 | loss: 1.38133 - acc: 0.7078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7742  | total loss: \u001b[1m\u001b[32m1.62192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7742 | loss: 1.62192 - acc: 0.6370 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7743  | total loss: \u001b[1m\u001b[32m1.50229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7743 | loss: 1.50229 - acc: 0.6733 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7744  | total loss: \u001b[1m\u001b[32m1.39457\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7744 | loss: 1.39457 - acc: 0.7060 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7745  | total loss: \u001b[1m\u001b[32m1.29709\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7745 | loss: 1.29709 - acc: 0.7354 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7746  | total loss: \u001b[1m\u001b[32m1.20840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7746 | loss: 1.20840 - acc: 0.7619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7747  | total loss: \u001b[1m\u001b[32m1.12726\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7747 | loss: 1.12726 - acc: 0.7857 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7748  | total loss: \u001b[1m\u001b[32m1.05263\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7748 | loss: 1.05263 - acc: 0.8071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7749  | total loss: \u001b[1m\u001b[32m0.98364\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7749 | loss: 0.98364 - acc: 0.8264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7750  | total loss: \u001b[1m\u001b[32m1.28213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7750 | loss: 1.28213 - acc: 0.7438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7751  | total loss: \u001b[1m\u001b[32m1.18747\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7751 | loss: 1.18747 - acc: 0.7694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7752  | total loss: \u001b[1m\u001b[32m1.10127\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7752 | loss: 1.10127 - acc: 0.7924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7753  | total loss: \u001b[1m\u001b[32m1.02247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7753 | loss: 1.02247 - acc: 0.8132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7754  | total loss: \u001b[1m\u001b[32m1.33837\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7754 | loss: 1.33837 - acc: 0.7319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7755  | total loss: \u001b[1m\u001b[32m1.23421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7755 | loss: 1.23421 - acc: 0.7587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7756  | total loss: \u001b[1m\u001b[32m1.45993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7756 | loss: 1.45993 - acc: 0.6971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7757  | total loss: \u001b[1m\u001b[32m1.34338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7757 | loss: 1.34338 - acc: 0.7274 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7758  | total loss: \u001b[1m\u001b[32m1.23845\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7758 | loss: 1.23845 - acc: 0.7547 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7759  | total loss: \u001b[1m\u001b[32m1.14371\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7759 | loss: 1.14371 - acc: 0.7792 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7760  | total loss: \u001b[1m\u001b[32m1.37345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7760 | loss: 1.37345 - acc: 0.7156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7761  | total loss: \u001b[1m\u001b[32m1.26488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7761 | loss: 1.26488 - acc: 0.7440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7762  | total loss: \u001b[1m\u001b[32m1.16711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7762 | loss: 1.16711 - acc: 0.7696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7763  | total loss: \u001b[1m\u001b[32m1.07878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7763 | loss: 1.07878 - acc: 0.7926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7764  | total loss: \u001b[1m\u001b[32m1.35614\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7764 | loss: 1.35614 - acc: 0.7205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7765  | total loss: \u001b[1m\u001b[32m1.24868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7765 | loss: 1.24868 - acc: 0.7485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7766  | total loss: \u001b[1m\u001b[32m1.53710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7766 | loss: 1.53710 - acc: 0.6736 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7767  | total loss: \u001b[1m\u001b[32m1.41258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7767 | loss: 1.41258 - acc: 0.7063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7768  | total loss: \u001b[1m\u001b[32m1.30114\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7768 | loss: 1.30114 - acc: 0.7356 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7769  | total loss: \u001b[1m\u001b[32m1.20112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7769 | loss: 1.20112 - acc: 0.7621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7770  | total loss: \u001b[1m\u001b[32m1.46748\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7770 | loss: 1.46748 - acc: 0.6859 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7771  | total loss: \u001b[1m\u001b[32m1.35168\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7771 | loss: 1.35168 - acc: 0.7173 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7772  | total loss: \u001b[1m\u001b[32m1.55192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7772 | loss: 1.55192 - acc: 0.6598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7773  | total loss: \u001b[1m\u001b[32m1.42940\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7773 | loss: 1.42940 - acc: 0.6939 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7774  | total loss: \u001b[1m\u001b[32m1.66824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7774 | loss: 1.66824 - acc: 0.6245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7775  | total loss: \u001b[1m\u001b[32m1.53655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7775 | loss: 1.53655 - acc: 0.6620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7776  | total loss: \u001b[1m\u001b[32m1.41924\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7776 | loss: 1.41924 - acc: 0.6958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7777  | total loss: \u001b[1m\u001b[32m1.31437\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7777 | loss: 1.31437 - acc: 0.7262 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7778  | total loss: \u001b[1m\u001b[32m1.58219\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7778 | loss: 1.58219 - acc: 0.6536 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7779  | total loss: \u001b[1m\u001b[32m1.46244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7779 | loss: 1.46244 - acc: 0.6883 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7780  | total loss: \u001b[1m\u001b[32m1.62593\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7780 | loss: 1.62593 - acc: 0.6409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7781  | total loss: \u001b[1m\u001b[32m1.50376\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7781 | loss: 1.50376 - acc: 0.6768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7782  | total loss: \u001b[1m\u001b[32m1.39452\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7782 | loss: 1.39452 - acc: 0.7091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7783  | total loss: \u001b[1m\u001b[32m1.29638\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7783 | loss: 1.29638 - acc: 0.7382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7784  | total loss: \u001b[1m\u001b[32m1.53061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7784 | loss: 1.53061 - acc: 0.6644 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7785  | total loss: \u001b[1m\u001b[32m1.41910\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7785 | loss: 1.41910 - acc: 0.6979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7786  | total loss: \u001b[1m\u001b[32m1.31876\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7786 | loss: 1.31876 - acc: 0.7281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7787  | total loss: \u001b[1m\u001b[32m1.22799\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7787 | loss: 1.22799 - acc: 0.7553 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7788  | total loss: \u001b[1m\u001b[32m1.14543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7788 | loss: 1.14543 - acc: 0.7798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7789  | total loss: \u001b[1m\u001b[32m1.06989\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7789 | loss: 1.06989 - acc: 0.8018 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7790  | total loss: \u001b[1m\u001b[32m1.35348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7790 | loss: 1.35348 - acc: 0.7216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7791  | total loss: \u001b[1m\u001b[32m1.25526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7791 | loss: 1.25526 - acc: 0.7495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7792  | total loss: \u001b[1m\u001b[32m1.51758\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7792 | loss: 1.51758 - acc: 0.6745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7793  | total loss: \u001b[1m\u001b[32m1.40253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7793 | loss: 1.40253 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7794  | total loss: \u001b[1m\u001b[32m1.62692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7794 | loss: 1.62692 - acc: 0.6435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7795  | total loss: \u001b[1m\u001b[32m1.50152\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7795 | loss: 1.50152 - acc: 0.6792 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7796  | total loss: \u001b[1m\u001b[32m1.38889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7796 | loss: 1.38889 - acc: 0.7112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7797  | total loss: \u001b[1m\u001b[32m1.28731\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7797 | loss: 1.28731 - acc: 0.7401 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7798  | total loss: \u001b[1m\u001b[32m1.19531\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7798 | loss: 1.19531 - acc: 0.7661 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7799  | total loss: \u001b[1m\u001b[32m1.11159\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7799 | loss: 1.11159 - acc: 0.7895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7800  | total loss: \u001b[1m\u001b[32m1.03504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7800 | loss: 1.03504 - acc: 0.8105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7801  | total loss: \u001b[1m\u001b[32m0.96474\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7801 | loss: 0.96474 - acc: 0.8295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7802  | total loss: \u001b[1m\u001b[32m1.27017\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7802 | loss: 1.27017 - acc: 0.7465 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7803  | total loss: \u001b[1m\u001b[32m1.17427\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7803 | loss: 1.17427 - acc: 0.7719 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7804  | total loss: \u001b[1m\u001b[32m1.08721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7804 | loss: 1.08721 - acc: 0.7947 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7805  | total loss: \u001b[1m\u001b[32m1.00789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7805 | loss: 1.00789 - acc: 0.8152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7806  | total loss: \u001b[1m\u001b[32m1.25567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7806 | loss: 1.25567 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7807  | total loss: \u001b[1m\u001b[32m1.15808\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7807 | loss: 1.15808 - acc: 0.7732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7808  | total loss: \u001b[1m\u001b[32m1.42396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7808 | loss: 1.42396 - acc: 0.6959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7809  | total loss: \u001b[1m\u001b[32m1.30946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7809 | loss: 1.30946 - acc: 0.7263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7810  | total loss: \u001b[1m\u001b[32m1.20654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7810 | loss: 1.20654 - acc: 0.7537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7811  | total loss: \u001b[1m\u001b[32m1.11378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7811 | loss: 1.11378 - acc: 0.7783 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7812  | total loss: \u001b[1m\u001b[32m1.02990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7812 | loss: 1.02990 - acc: 0.8005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7813  | total loss: \u001b[1m\u001b[32m0.95380\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7813 | loss: 0.95380 - acc: 0.8204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7814  | total loss: \u001b[1m\u001b[32m0.88451\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7814 | loss: 0.88451 - acc: 0.8384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7815  | total loss: \u001b[1m\u001b[32m0.82119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7815 | loss: 0.82119 - acc: 0.8545 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7816  | total loss: \u001b[1m\u001b[32m1.11886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7816 | loss: 1.11886 - acc: 0.7762 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7817  | total loss: \u001b[1m\u001b[32m1.03082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7817 | loss: 1.03082 - acc: 0.7986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7818  | total loss: \u001b[1m\u001b[32m0.95117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7818 | loss: 0.95117 - acc: 0.8187 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7819  | total loss: \u001b[1m\u001b[32m0.87890\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7819 | loss: 0.87890 - acc: 0.8369 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7820  | total loss: \u001b[1m\u001b[32m1.14781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7820 | loss: 1.14781 - acc: 0.7746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7821  | total loss: \u001b[1m\u001b[32m1.05514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7821 | loss: 1.05514 - acc: 0.7971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7822  | total loss: \u001b[1m\u001b[32m1.39825\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7822 | loss: 1.39825 - acc: 0.7174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7823  | total loss: \u001b[1m\u001b[32m1.28102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7823 | loss: 1.28102 - acc: 0.7457 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7824  | total loss: \u001b[1m\u001b[32m1.17595\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7824 | loss: 1.17595 - acc: 0.7711 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7825  | total loss: \u001b[1m\u001b[32m1.08158\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7825 | loss: 1.08158 - acc: 0.7940 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7826  | total loss: \u001b[1m\u001b[32m0.99661\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7826 | loss: 0.99661 - acc: 0.8146 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7827  | total loss: \u001b[1m\u001b[32m0.91989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7827 | loss: 0.91989 - acc: 0.8331 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7828  | total loss: \u001b[1m\u001b[32m1.25235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7828 | loss: 1.25235 - acc: 0.7498 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7829  | total loss: \u001b[1m\u001b[32m1.15014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7829 | loss: 1.15014 - acc: 0.7748 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7830  | total loss: \u001b[1m\u001b[32m1.45885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7830 | loss: 1.45885 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7831  | total loss: \u001b[1m\u001b[32m1.33735\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7831 | loss: 1.33735 - acc: 0.7276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7832  | total loss: \u001b[1m\u001b[32m1.62747\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7832 | loss: 1.62747 - acc: 0.6549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7833  | total loss: \u001b[1m\u001b[32m1.49158\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7833 | loss: 1.49158 - acc: 0.6894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7834  | total loss: \u001b[1m\u001b[32m1.37057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7834 | loss: 1.37057 - acc: 0.7204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7835  | total loss: \u001b[1m\u001b[32m1.26259\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7835 | loss: 1.26259 - acc: 0.7484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7836  | total loss: \u001b[1m\u001b[32m1.55930\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7836 | loss: 1.55930 - acc: 0.6736 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7837  | total loss: \u001b[1m\u001b[32m1.43455\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7837 | loss: 1.43455 - acc: 0.7062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7838  | total loss: \u001b[1m\u001b[32m1.32338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7838 | loss: 1.32338 - acc: 0.7356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7839  | total loss: \u001b[1m\u001b[32m1.22400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7839 | loss: 1.22400 - acc: 0.7620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7840  | total loss: \u001b[1m\u001b[32m1.13481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7840 | loss: 1.13481 - acc: 0.7858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7841  | total loss: \u001b[1m\u001b[32m1.05441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7841 | loss: 1.05441 - acc: 0.8072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7842  | total loss: \u001b[1m\u001b[32m1.27330\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7842 | loss: 1.27330 - acc: 0.7479 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7843  | total loss: \u001b[1m\u001b[32m1.17881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7843 | loss: 1.17881 - acc: 0.7731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7844  | total loss: \u001b[1m\u001b[32m1.09364\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7844 | loss: 1.09364 - acc: 0.7958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7845  | total loss: \u001b[1m\u001b[32m1.01653\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7845 | loss: 1.01653 - acc: 0.8163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7846  | total loss: \u001b[1m\u001b[32m1.29164\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7846 | loss: 1.29164 - acc: 0.7418 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7847  | total loss: \u001b[1m\u001b[32m1.19406\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7847 | loss: 1.19406 - acc: 0.7676 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7848  | total loss: \u001b[1m\u001b[32m1.10599\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7848 | loss: 1.10599 - acc: 0.7908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7849  | total loss: \u001b[1m\u001b[32m1.02618\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7849 | loss: 1.02618 - acc: 0.8117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7850  | total loss: \u001b[1m\u001b[32m0.95358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7850 | loss: 0.95358 - acc: 0.8306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7851  | total loss: \u001b[1m\u001b[32m0.88725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7851 | loss: 0.88725 - acc: 0.8475 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7852  | total loss: \u001b[1m\u001b[32m1.19883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7852 | loss: 1.19883 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7853  | total loss: \u001b[1m\u001b[32m1.10672\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7853 | loss: 1.10672 - acc: 0.7865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7854  | total loss: \u001b[1m\u001b[32m1.39301\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7854 | loss: 1.39301 - acc: 0.7150 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7855  | total loss: \u001b[1m\u001b[32m1.28161\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7855 | loss: 1.28161 - acc: 0.7435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7856  | total loss: \u001b[1m\u001b[32m1.47975\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7856 | loss: 1.47975 - acc: 0.6906 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7857  | total loss: \u001b[1m\u001b[32m1.36067\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7857 | loss: 1.36067 - acc: 0.7215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7858  | total loss: \u001b[1m\u001b[32m1.25395\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7858 | loss: 1.25395 - acc: 0.7494 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7859  | total loss: \u001b[1m\u001b[32m1.15804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7859 | loss: 1.15804 - acc: 0.7744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7860  | total loss: \u001b[1m\u001b[32m1.45541\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7860 | loss: 1.45541 - acc: 0.6970 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7861  | total loss: \u001b[1m\u001b[32m1.33989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7861 | loss: 1.33989 - acc: 0.7273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7862  | total loss: \u001b[1m\u001b[32m1.23626\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7862 | loss: 1.23626 - acc: 0.7546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7863  | total loss: \u001b[1m\u001b[32m1.14300\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7863 | loss: 1.14300 - acc: 0.7791 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7864  | total loss: \u001b[1m\u001b[32m1.41216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7864 | loss: 1.41216 - acc: 0.7083 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7865  | total loss: \u001b[1m\u001b[32m1.30156\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7865 | loss: 1.30156 - acc: 0.7375 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7866  | total loss: \u001b[1m\u001b[32m1.56842\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7866 | loss: 1.56842 - acc: 0.6637 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7867  | total loss: \u001b[1m\u001b[32m1.44347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7867 | loss: 1.44347 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7868  | total loss: \u001b[1m\u001b[32m1.70637\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7868 | loss: 1.70637 - acc: 0.6276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7869  | total loss: \u001b[1m\u001b[32m1.56980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7869 | loss: 1.56980 - acc: 0.6649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7870  | total loss: \u001b[1m\u001b[32m1.73477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7870 | loss: 1.73477 - acc: 0.6127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7871  | total loss: \u001b[1m\u001b[32m1.59811\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7871 | loss: 1.59811 - acc: 0.6514 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7872  | total loss: \u001b[1m\u001b[32m1.81104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7872 | loss: 1.81104 - acc: 0.5863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7873  | total loss: \u001b[1m\u001b[32m1.67001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7873 | loss: 1.67001 - acc: 0.6276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7874  | total loss: \u001b[1m\u001b[32m1.54452\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7874 | loss: 1.54452 - acc: 0.6649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7875  | total loss: \u001b[1m\u001b[32m1.43242\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7875 | loss: 1.43242 - acc: 0.6984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7876  | total loss: \u001b[1m\u001b[32m1.61712\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7876 | loss: 1.61712 - acc: 0.6428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7877  | total loss: \u001b[1m\u001b[32m1.49905\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7877 | loss: 1.49905 - acc: 0.6785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7878  | total loss: \u001b[1m\u001b[32m1.68615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7878 | loss: 1.68615 - acc: 0.6250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7879  | total loss: \u001b[1m\u001b[32m1.56280\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7879 | loss: 1.56280 - acc: 0.6625 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7880  | total loss: \u001b[1m\u001b[32m1.75501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7880 | loss: 1.75501 - acc: 0.6034 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7881  | total loss: \u001b[1m\u001b[32m1.62677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7881 | loss: 1.62677 - acc: 0.6430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7882  | total loss: \u001b[1m\u001b[32m1.79966\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7882 | loss: 1.79966 - acc: 0.5859 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7883  | total loss: \u001b[1m\u001b[32m1.66934\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7883 | loss: 1.66934 - acc: 0.6273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7884  | total loss: \u001b[1m\u001b[32m1.55291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7884 | loss: 1.55291 - acc: 0.6646 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7885  | total loss: \u001b[1m\u001b[32m1.44830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7885 | loss: 1.44830 - acc: 0.6981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7886  | total loss: \u001b[1m\u001b[32m1.35367\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7886 | loss: 1.35367 - acc: 0.7283 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7887  | total loss: \u001b[1m\u001b[32m1.26746\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7887 | loss: 1.26746 - acc: 0.7555 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7888  | total loss: \u001b[1m\u001b[32m1.46446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7888 | loss: 1.46446 - acc: 0.6942 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7889  | total loss: \u001b[1m\u001b[32m1.36502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7889 | loss: 1.36502 - acc: 0.7248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7890  | total loss: \u001b[1m\u001b[32m1.60444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7890 | loss: 1.60444 - acc: 0.6523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7891  | total loss: \u001b[1m\u001b[32m1.48984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7891 | loss: 1.48984 - acc: 0.6871 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7892  | total loss: \u001b[1m\u001b[32m1.66345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7892 | loss: 1.66345 - acc: 0.6327 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7893  | total loss: \u001b[1m\u001b[32m1.54270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7893 | loss: 1.54270 - acc: 0.6694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7894  | total loss: \u001b[1m\u001b[32m1.71954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7894 | loss: 1.71954 - acc: 0.6167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7895  | total loss: \u001b[1m\u001b[32m1.59344\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7895 | loss: 1.59344 - acc: 0.6551 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7896  | total loss: \u001b[1m\u001b[32m1.47988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7896 | loss: 1.47988 - acc: 0.6896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7897  | total loss: \u001b[1m\u001b[32m1.37709\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7897 | loss: 1.37709 - acc: 0.7206 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7898  | total loss: \u001b[1m\u001b[32m1.28355\u001b[0m\u001b[0m | time: 0.016s\n",
      "| Adam | epoch: 7898 | loss: 1.28355 - acc: 0.7485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7899  | total loss: \u001b[1m\u001b[32m1.19796\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7899 | loss: 1.19796 - acc: 0.7737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7900  | total loss: \u001b[1m\u001b[32m1.11922\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7900 | loss: 1.11922 - acc: 0.7963 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7901  | total loss: \u001b[1m\u001b[32m1.04641\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7901 | loss: 1.04641 - acc: 0.8167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7902  | total loss: \u001b[1m\u001b[32m0.97878\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7902 | loss: 0.97878 - acc: 0.8350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7903  | total loss: \u001b[1m\u001b[32m0.91571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7903 | loss: 0.91571 - acc: 0.8515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7904  | total loss: \u001b[1m\u001b[32m0.85670\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7904 | loss: 0.85670 - acc: 0.8664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7905  | total loss: \u001b[1m\u001b[32m0.80133\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7905 | loss: 0.80133 - acc: 0.8797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7906  | total loss: \u001b[1m\u001b[32m1.12306\u001b[0m\u001b[0m | time: 0.024s\n",
      "| Adam | epoch: 7906 | loss: 1.12306 - acc: 0.7918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7907  | total loss: \u001b[1m\u001b[32m1.03775\u001b[0m\u001b[0m | time: 0.020s\n",
      "| Adam | epoch: 7907 | loss: 1.03775 - acc: 0.8126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7908  | total loss: \u001b[1m\u001b[32m0.95979\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 7908 | loss: 0.95979 - acc: 0.8313 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7909  | total loss: \u001b[1m\u001b[32m0.88837\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7909 | loss: 0.88837 - acc: 0.8482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7910  | total loss: \u001b[1m\u001b[32m1.22362\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7910 | loss: 1.22362 - acc: 0.7634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7911  | total loss: \u001b[1m\u001b[32m1.12420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7911 | loss: 1.12420 - acc: 0.7870 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7912  | total loss: \u001b[1m\u001b[32m1.44091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7912 | loss: 1.44091 - acc: 0.7083 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7913  | total loss: \u001b[1m\u001b[32m1.31970\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7913 | loss: 1.31970 - acc: 0.7375 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7914  | total loss: \u001b[1m\u001b[32m1.58984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7914 | loss: 1.58984 - acc: 0.6637 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7915  | total loss: \u001b[1m\u001b[32m1.45486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7915 | loss: 1.45486 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7916  | total loss: \u001b[1m\u001b[32m1.73281\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7916 | loss: 1.73281 - acc: 0.6276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7917  | total loss: \u001b[1m\u001b[32m1.58572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7917 | loss: 1.58572 - acc: 0.6649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7918  | total loss: \u001b[1m\u001b[32m1.77896\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7918 | loss: 1.77896 - acc: 0.6055 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7919  | total loss: \u001b[1m\u001b[32m1.63028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7919 | loss: 1.63028 - acc: 0.6450 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7920  | total loss: \u001b[1m\u001b[32m1.86429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7920 | loss: 1.86429 - acc: 0.5805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7921  | total loss: \u001b[1m\u001b[32m1.71083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7921 | loss: 1.71083 - acc: 0.6224 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7922  | total loss: \u001b[1m\u001b[32m1.87567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7922 | loss: 1.87567 - acc: 0.5673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7923  | total loss: \u001b[1m\u001b[32m1.72542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7923 | loss: 1.72542 - acc: 0.6106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7924  | total loss: \u001b[1m\u001b[32m1.59218\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7924 | loss: 1.59218 - acc: 0.6495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7925  | total loss: \u001b[1m\u001b[32m1.47366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7925 | loss: 1.47366 - acc: 0.6846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7926  | total loss: \u001b[1m\u001b[32m1.66081\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7926 | loss: 1.66081 - acc: 0.6304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7927  | total loss: \u001b[1m\u001b[32m1.53772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7927 | loss: 1.53772 - acc: 0.6674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7928  | total loss: \u001b[1m\u001b[32m1.42778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7928 | loss: 1.42778 - acc: 0.7006 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7929  | total loss: \u001b[1m\u001b[32m1.32913\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7929 | loss: 1.32913 - acc: 0.7306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7930  | total loss: \u001b[1m\u001b[32m1.24011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7930 | loss: 1.24011 - acc: 0.7575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7931  | total loss: \u001b[1m\u001b[32m1.15930\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7931 | loss: 1.15930 - acc: 0.7818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7932  | total loss: \u001b[1m\u001b[32m1.08549\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7932 | loss: 1.08549 - acc: 0.8036 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7933  | total loss: \u001b[1m\u001b[32m1.01766\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7933 | loss: 1.01766 - acc: 0.8232 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7934  | total loss: \u001b[1m\u001b[32m1.27870\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7934 | loss: 1.27870 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7935  | total loss: \u001b[1m\u001b[32m1.18921\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7935 | loss: 1.18921 - acc: 0.7732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7936  | total loss: \u001b[1m\u001b[32m1.38944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7936 | loss: 1.38944 - acc: 0.7173 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7937  | total loss: \u001b[1m\u001b[32m1.28763\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7937 | loss: 1.28763 - acc: 0.7456 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7938  | total loss: \u001b[1m\u001b[32m1.50874\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7938 | loss: 1.50874 - acc: 0.6782 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7939  | total loss: \u001b[1m\u001b[32m1.39461\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7939 | loss: 1.39461 - acc: 0.7104 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7940  | total loss: \u001b[1m\u001b[32m1.60766\u001b[0m\u001b[0m | time: 0.020s\n",
      "| Adam | epoch: 7940 | loss: 1.60766 - acc: 0.6465 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7941  | total loss: \u001b[1m\u001b[32m1.48404\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7941 | loss: 1.48404 - acc: 0.6818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7942  | total loss: \u001b[1m\u001b[32m1.37294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7942 | loss: 1.37294 - acc: 0.7136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7943  | total loss: \u001b[1m\u001b[32m1.27274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7943 | loss: 1.27274 - acc: 0.7423 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7944  | total loss: \u001b[1m\u001b[32m1.48229\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7944 | loss: 1.48229 - acc: 0.6823 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7945  | total loss: \u001b[1m\u001b[32m1.37074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7945 | loss: 1.37074 - acc: 0.7141 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7946  | total loss: \u001b[1m\u001b[32m1.27011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7946 | loss: 1.27011 - acc: 0.7427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7947  | total loss: \u001b[1m\u001b[32m1.17900\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7947 | loss: 1.17900 - acc: 0.7684 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7948  | total loss: \u001b[1m\u001b[32m1.40959\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7948 | loss: 1.40959 - acc: 0.7059 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7949  | total loss: \u001b[1m\u001b[32m1.30364\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7949 | loss: 1.30364 - acc: 0.7353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7950  | total loss: \u001b[1m\u001b[32m1.20791\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7950 | loss: 1.20791 - acc: 0.7618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7951  | total loss: \u001b[1m\u001b[32m1.12108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7951 | loss: 1.12108 - acc: 0.7856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7952  | total loss: \u001b[1m\u001b[32m1.33318\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7952 | loss: 1.33318 - acc: 0.7213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7953  | total loss: \u001b[1m\u001b[32m1.23278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7953 | loss: 1.23278 - acc: 0.7492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7954  | total loss: \u001b[1m\u001b[32m1.14200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7954 | loss: 1.14200 - acc: 0.7743 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7955  | total loss: \u001b[1m\u001b[32m1.05963\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7955 | loss: 1.05963 - acc: 0.7968 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7956  | total loss: \u001b[1m\u001b[32m1.32290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7956 | loss: 1.32290 - acc: 0.7314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7957  | total loss: \u001b[1m\u001b[32m1.22151\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7957 | loss: 1.22151 - acc: 0.7583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7958  | total loss: \u001b[1m\u001b[32m1.12993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7958 | loss: 1.12993 - acc: 0.7825 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7959  | total loss: \u001b[1m\u001b[32m1.04695\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7959 | loss: 1.04695 - acc: 0.8042 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7960  | total loss: \u001b[1m\u001b[32m1.33392\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7960 | loss: 1.33392 - acc: 0.7309 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7961  | total loss: \u001b[1m\u001b[32m1.22988\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7961 | loss: 1.22988 - acc: 0.7578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7962  | total loss: \u001b[1m\u001b[32m1.13610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7962 | loss: 1.13610 - acc: 0.7821 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7963  | total loss: \u001b[1m\u001b[32m1.05129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7963 | loss: 1.05129 - acc: 0.8039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7964  | total loss: \u001b[1m\u001b[32m1.32221\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7964 | loss: 1.32221 - acc: 0.7306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7965  | total loss: \u001b[1m\u001b[32m1.21836\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7965 | loss: 1.21836 - acc: 0.7575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7966  | total loss: \u001b[1m\u001b[32m1.47760\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7966 | loss: 1.47760 - acc: 0.6889 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7967  | total loss: \u001b[1m\u001b[32m1.35879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7967 | loss: 1.35879 - acc: 0.7200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7968  | total loss: \u001b[1m\u001b[32m1.25222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7968 | loss: 1.25222 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7969  | total loss: \u001b[1m\u001b[32m1.15637\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7969 | loss: 1.15637 - acc: 0.7732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7970  | total loss: \u001b[1m\u001b[32m1.06990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7970 | loss: 1.06990 - acc: 0.7959 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7971  | total loss: \u001b[1m\u001b[32m0.99164\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7971 | loss: 0.99164 - acc: 0.8163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7972  | total loss: \u001b[1m\u001b[32m1.26247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7972 | loss: 1.26247 - acc: 0.7418 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7973  | total loss: \u001b[1m\u001b[32m1.16448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7973 | loss: 1.16448 - acc: 0.7676 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7974  | total loss: \u001b[1m\u001b[32m1.07619\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7974 | loss: 1.07619 - acc: 0.7909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7975  | total loss: \u001b[1m\u001b[32m0.99640\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7975 | loss: 0.99640 - acc: 0.8118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7976  | total loss: \u001b[1m\u001b[32m1.30675\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7976 | loss: 1.30675 - acc: 0.7306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7977  | total loss: \u001b[1m\u001b[32m1.20373\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7977 | loss: 1.20373 - acc: 0.7576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7978  | total loss: \u001b[1m\u001b[32m1.43725\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7978 | loss: 1.43725 - acc: 0.6961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7979  | total loss: \u001b[1m\u001b[32m1.32203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7979 | loss: 1.32203 - acc: 0.7265 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7980  | total loss: \u001b[1m\u001b[32m1.56181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7980 | loss: 1.56181 - acc: 0.6610 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7981  | total loss: \u001b[1m\u001b[32m1.43568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7981 | loss: 1.43568 - acc: 0.6949 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7982  | total loss: \u001b[1m\u001b[32m1.32292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7982 | loss: 1.32292 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7983  | total loss: \u001b[1m\u001b[32m1.22180\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7983 | loss: 1.22180 - acc: 0.7528 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7984  | total loss: \u001b[1m\u001b[32m1.13084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7984 | loss: 1.13084 - acc: 0.7776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7985  | total loss: \u001b[1m\u001b[32m1.04872\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 7985 | loss: 1.04872 - acc: 0.7998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7986  | total loss: \u001b[1m\u001b[32m0.97428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7986 | loss: 0.97428 - acc: 0.8198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7987  | total loss: \u001b[1m\u001b[32m0.90652\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7987 | loss: 0.90652 - acc: 0.8378 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7988  | total loss: \u001b[1m\u001b[32m1.19667\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7988 | loss: 1.19667 - acc: 0.7612 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7989  | total loss: \u001b[1m\u001b[32m1.10564\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7989 | loss: 1.10564 - acc: 0.7851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7990  | total loss: \u001b[1m\u001b[32m1.02339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7990 | loss: 1.02339 - acc: 0.8066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7991  | total loss: \u001b[1m\u001b[32m0.94881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7991 | loss: 0.94881 - acc: 0.8259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7992  | total loss: \u001b[1m\u001b[32m0.88096\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7992 | loss: 0.88096 - acc: 0.8433 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7993  | total loss: \u001b[1m\u001b[32m0.81901\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7993 | loss: 0.81901 - acc: 0.8590 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7994  | total loss: \u001b[1m\u001b[32m1.13309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7994 | loss: 1.13309 - acc: 0.7802 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7995  | total loss: \u001b[1m\u001b[32m1.04477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7995 | loss: 1.04477 - acc: 0.8022 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7996  | total loss: \u001b[1m\u001b[32m0.96494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7996 | loss: 0.96494 - acc: 0.8220 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 7997  | total loss: \u001b[1m\u001b[32m0.89256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7997 | loss: 0.89256 - acc: 0.8398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7998  | total loss: \u001b[1m\u001b[32m0.82677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7998 | loss: 0.82677 - acc: 0.8558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 7999  | total loss: \u001b[1m\u001b[32m0.76679\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 7999 | loss: 0.76679 - acc: 0.8702 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8000  | total loss: \u001b[1m\u001b[32m1.11184\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8000 | loss: 1.11184 - acc: 0.7904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8001  | total loss: \u001b[1m\u001b[32m1.02245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8001 | loss: 1.02245 - acc: 0.8113 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8002  | total loss: \u001b[1m\u001b[32m0.94179\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8002 | loss: 0.94179 - acc: 0.8302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8003  | total loss: \u001b[1m\u001b[32m0.86885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8003 | loss: 0.86885 - acc: 0.8472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8004  | total loss: \u001b[1m\u001b[32m0.80272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8004 | loss: 0.80272 - acc: 0.8624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8005  | total loss: \u001b[1m\u001b[32m0.74262\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8005 | loss: 0.74262 - acc: 0.8762 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8006  | total loss: \u001b[1m\u001b[32m1.05781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8006 | loss: 1.05781 - acc: 0.8029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8007  | total loss: \u001b[1m\u001b[32m0.97160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8007 | loss: 0.97160 - acc: 0.8226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8008  | total loss: \u001b[1m\u001b[32m1.28761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8008 | loss: 1.28761 - acc: 0.7475 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8009  | total loss: \u001b[1m\u001b[32m1.17895\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8009 | loss: 1.17895 - acc: 0.7727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8010  | total loss: \u001b[1m\u001b[32m1.45420\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8010 | loss: 1.45420 - acc: 0.7097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8011  | total loss: \u001b[1m\u001b[32m1.33028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8011 | loss: 1.33028 - acc: 0.7388 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8012  | total loss: \u001b[1m\u001b[32m1.21950\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8012 | loss: 1.21950 - acc: 0.7649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8013  | total loss: \u001b[1m\u001b[32m1.12032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8013 | loss: 1.12032 - acc: 0.7884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8014  | total loss: \u001b[1m\u001b[32m1.44530\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8014 | loss: 1.44530 - acc: 0.7096 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8015  | total loss: \u001b[1m\u001b[32m1.32485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8015 | loss: 1.32485 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8016  | total loss: \u001b[1m\u001b[32m1.60564\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8016 | loss: 1.60564 - acc: 0.6647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8017  | total loss: \u001b[1m\u001b[32m1.47139\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8017 | loss: 1.47139 - acc: 0.6983 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8018  | total loss: \u001b[1m\u001b[32m1.35171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8018 | loss: 1.35171 - acc: 0.7284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8019  | total loss: \u001b[1m\u001b[32m1.24481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8019 | loss: 1.24481 - acc: 0.7556 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8020  | total loss: \u001b[1m\u001b[32m1.50889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8020 | loss: 1.50889 - acc: 0.6872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8021  | total loss: \u001b[1m\u001b[32m1.38795\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8021 | loss: 1.38795 - acc: 0.7185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8022  | total loss: \u001b[1m\u001b[32m1.27993\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8022 | loss: 1.27993 - acc: 0.7466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8023  | total loss: \u001b[1m\u001b[32m1.18319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8023 | loss: 1.18319 - acc: 0.7720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8024  | total loss: \u001b[1m\u001b[32m1.37459\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8024 | loss: 1.37459 - acc: 0.7162 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8025  | total loss: \u001b[1m\u001b[32m1.26916\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8025 | loss: 1.26916 - acc: 0.7446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8026  | total loss: \u001b[1m\u001b[32m1.52409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8026 | loss: 1.52409 - acc: 0.6773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8027  | total loss: \u001b[1m\u001b[32m1.40499\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8027 | loss: 1.40499 - acc: 0.7095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8028  | total loss: \u001b[1m\u001b[32m1.63588\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8028 | loss: 1.63588 - acc: 0.6386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8029  | total loss: \u001b[1m\u001b[32m1.50749\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8029 | loss: 1.50749 - acc: 0.6747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8030  | total loss: \u001b[1m\u001b[32m1.39279\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8030 | loss: 1.39279 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8031  | total loss: \u001b[1m\u001b[32m1.29002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8031 | loss: 1.29002 - acc: 0.7365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8032  | total loss: \u001b[1m\u001b[32m1.50115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8032 | loss: 1.50115 - acc: 0.6772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8033  | total loss: \u001b[1m\u001b[32m1.38839\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8033 | loss: 1.38839 - acc: 0.7094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8034  | total loss: \u001b[1m\u001b[32m1.64321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8034 | loss: 1.64321 - acc: 0.6385 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8035  | total loss: \u001b[1m\u001b[32m1.51782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8035 | loss: 1.51782 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8036  | total loss: \u001b[1m\u001b[32m1.40571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8036 | loss: 1.40571 - acc: 0.7072 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8037  | total loss: \u001b[1m\u001b[32m1.30511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8037 | loss: 1.30511 - acc: 0.7365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8038  | total loss: \u001b[1m\u001b[32m1.21444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8038 | loss: 1.21444 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8039  | total loss: \u001b[1m\u001b[32m1.13234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8039 | loss: 1.13234 - acc: 0.7865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8040  | total loss: \u001b[1m\u001b[32m1.05764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8040 | loss: 1.05764 - acc: 0.8079 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8041  | total loss: \u001b[1m\u001b[32m0.98932\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8041 | loss: 0.98932 - acc: 0.8271 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8042  | total loss: \u001b[1m\u001b[32m1.28791\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8042 | loss: 1.28791 - acc: 0.7444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8043  | total loss: \u001b[1m\u001b[32m1.19493\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8043 | loss: 1.19493 - acc: 0.7699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8044  | total loss: \u001b[1m\u001b[32m1.11065\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8044 | loss: 1.11065 - acc: 0.7930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8045  | total loss: \u001b[1m\u001b[32m1.03393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8045 | loss: 1.03393 - acc: 0.8137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8046  | total loss: \u001b[1m\u001b[32m0.96380\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8046 | loss: 0.96380 - acc: 0.8323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8047  | total loss: \u001b[1m\u001b[32m0.89945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8047 | loss: 0.89945 - acc: 0.8491 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8048  | total loss: \u001b[1m\u001b[32m1.13477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8048 | loss: 1.13477 - acc: 0.7784 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8049  | total loss: \u001b[1m\u001b[32m1.05137\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8049 | loss: 1.05137 - acc: 0.8006 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8050  | total loss: \u001b[1m\u001b[32m1.32035\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8050 | loss: 1.32035 - acc: 0.7277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8051  | total loss: \u001b[1m\u001b[32m1.21765\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8051 | loss: 1.21765 - acc: 0.7549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8052  | total loss: \u001b[1m\u001b[32m1.12500\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8052 | loss: 1.12500 - acc: 0.7794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8053  | total loss: \u001b[1m\u001b[32m1.04115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8053 | loss: 1.04115 - acc: 0.8015 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8054  | total loss: \u001b[1m\u001b[32m1.21760\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8054 | loss: 1.21760 - acc: 0.7570 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8055  | total loss: \u001b[1m\u001b[32m1.12372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8055 | loss: 1.12372 - acc: 0.7813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8056  | total loss: \u001b[1m\u001b[32m1.34778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8056 | loss: 1.34778 - acc: 0.7246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8057  | total loss: \u001b[1m\u001b[32m1.24078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8057 | loss: 1.24078 - acc: 0.7522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8058  | total loss: \u001b[1m\u001b[32m1.45723\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8058 | loss: 1.45723 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8059  | total loss: \u001b[1m\u001b[32m1.33995\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8059 | loss: 1.33995 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8060  | total loss: \u001b[1m\u001b[32m1.53985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8060 | loss: 1.53985 - acc: 0.6642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8061  | total loss: \u001b[1m\u001b[32m1.41564\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8061 | loss: 1.41564 - acc: 0.6978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8062  | total loss: \u001b[1m\u001b[32m1.30448\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8062 | loss: 1.30448 - acc: 0.7280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8063  | total loss: \u001b[1m\u001b[32m1.20474\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8063 | loss: 1.20474 - acc: 0.7552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8064  | total loss: \u001b[1m\u001b[32m1.48987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8064 | loss: 1.48987 - acc: 0.6797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8065  | total loss: \u001b[1m\u001b[32m1.37244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8065 | loss: 1.37244 - acc: 0.7117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8066  | total loss: \u001b[1m\u001b[32m1.26724\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8066 | loss: 1.26724 - acc: 0.7405 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8067  | total loss: \u001b[1m\u001b[32m1.17270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8067 | loss: 1.17270 - acc: 0.7665 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8068  | total loss: \u001b[1m\u001b[32m1.44495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8068 | loss: 1.44495 - acc: 0.6898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8069  | total loss: \u001b[1m\u001b[32m1.33313\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8069 | loss: 1.33313 - acc: 0.7209 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8070  | total loss: \u001b[1m\u001b[32m1.23279\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8070 | loss: 1.23279 - acc: 0.7488 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8071  | total loss: \u001b[1m\u001b[32m1.14244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8071 | loss: 1.14244 - acc: 0.7739 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8072  | total loss: \u001b[1m\u001b[32m1.38797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8072 | loss: 1.38797 - acc: 0.7036 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8073  | total loss: \u001b[1m\u001b[32m1.28215\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8073 | loss: 1.28215 - acc: 0.7333 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8074  | total loss: \u001b[1m\u001b[32m1.52363\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8074 | loss: 1.52363 - acc: 0.6671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8075  | total loss: \u001b[1m\u001b[32m1.40507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8075 | loss: 1.40507 - acc: 0.7004 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8076  | total loss: \u001b[1m\u001b[32m1.62576\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8076 | loss: 1.62576 - acc: 0.6303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8077  | total loss: \u001b[1m\u001b[32m1.49856\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8077 | loss: 1.49856 - acc: 0.6673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8078  | total loss: \u001b[1m\u001b[32m1.73183\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8078 | loss: 1.73183 - acc: 0.6006 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8079  | total loss: \u001b[1m\u001b[32m1.59623\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8079 | loss: 1.59623 - acc: 0.6405 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8080  | total loss: \u001b[1m\u001b[32m1.70400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8080 | loss: 1.70400 - acc: 0.6050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8081  | total loss: \u001b[1m\u001b[32m1.57354\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8081 | loss: 1.57354 - acc: 0.6445 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8082  | total loss: \u001b[1m\u001b[32m1.76964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8082 | loss: 1.76964 - acc: 0.5872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8083  | total loss: \u001b[1m\u001b[32m1.63500\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8083 | loss: 1.63500 - acc: 0.6285 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8084  | total loss: \u001b[1m\u001b[32m1.84831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8084 | loss: 1.84831 - acc: 0.5657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8085  | total loss: \u001b[1m\u001b[32m1.70847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8085 | loss: 1.70847 - acc: 0.6091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8086  | total loss: \u001b[1m\u001b[32m1.88730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8086 | loss: 1.88730 - acc: 0.5553 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8087  | total loss: \u001b[1m\u001b[32m1.74645\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8087 | loss: 1.74645 - acc: 0.5998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8088  | total loss: \u001b[1m\u001b[32m1.93649\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8088 | loss: 1.93649 - acc: 0.5398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8089  | total loss: \u001b[1m\u001b[32m1.79382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8089 | loss: 1.79382 - acc: 0.5858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8090  | total loss: \u001b[1m\u001b[32m1.66668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8090 | loss: 1.66668 - acc: 0.6272 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8091  | total loss: \u001b[1m\u001b[32m1.55283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8091 | loss: 1.55283 - acc: 0.6645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8092  | total loss: \u001b[1m\u001b[32m1.74802\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8092 | loss: 1.74802 - acc: 0.5981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8093  | total loss: \u001b[1m\u001b[32m1.62685\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8093 | loss: 1.62685 - acc: 0.6383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8094  | total loss: \u001b[1m\u001b[32m1.80475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8094 | loss: 1.80475 - acc: 0.5816 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8095  | total loss: \u001b[1m\u001b[32m1.67901\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8095 | loss: 1.67901 - acc: 0.6234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8096  | total loss: \u001b[1m\u001b[32m1.56607\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8096 | loss: 1.56607 - acc: 0.6611 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8097  | total loss: \u001b[1m\u001b[32m1.46405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8097 | loss: 1.46405 - acc: 0.6950 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8098  | total loss: \u001b[1m\u001b[32m1.37131\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8098 | loss: 1.37131 - acc: 0.7255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8099  | total loss: \u001b[1m\u001b[32m1.28646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8099 | loss: 1.28646 - acc: 0.7529 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8100  | total loss: \u001b[1m\u001b[32m1.49981\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8100 | loss: 1.49981 - acc: 0.6848 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8101  | total loss: \u001b[1m\u001b[32m1.39955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8101 | loss: 1.39955 - acc: 0.7163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8102  | total loss: \u001b[1m\u001b[32m1.57113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8102 | loss: 1.57113 - acc: 0.6590 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8103  | total loss: \u001b[1m\u001b[32m1.46215\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8103 | loss: 1.46215 - acc: 0.6931 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8104  | total loss: \u001b[1m\u001b[32m1.63751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8104 | loss: 1.63751 - acc: 0.6380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8105  | total loss: \u001b[1m\u001b[32m1.52098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8105 | loss: 1.52098 - acc: 0.6742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8106  | total loss: \u001b[1m\u001b[32m1.65696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8106 | loss: 1.65696 - acc: 0.6282 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8107  | total loss: \u001b[1m\u001b[32m1.53800\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8107 | loss: 1.53800 - acc: 0.6654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8108  | total loss: \u001b[1m\u001b[32m1.75041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8108 | loss: 1.75041 - acc: 0.6060 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8109  | total loss: \u001b[1m\u001b[32m1.62217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8109 | loss: 1.62217 - acc: 0.6454 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8110  | total loss: \u001b[1m\u001b[32m1.50671\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8110 | loss: 1.50671 - acc: 0.6809 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8111  | total loss: \u001b[1m\u001b[32m1.40228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8111 | loss: 1.40228 - acc: 0.7128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8112  | total loss: \u001b[1m\u001b[32m1.30733\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8112 | loss: 1.30733 - acc: 0.7415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8113  | total loss: \u001b[1m\u001b[32m1.22057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8113 | loss: 1.22057 - acc: 0.7674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8114  | total loss: \u001b[1m\u001b[32m1.14087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8114 | loss: 1.14087 - acc: 0.7906 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8115  | total loss: \u001b[1m\u001b[32m1.06728\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8115 | loss: 1.06728 - acc: 0.8116 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8116  | total loss: \u001b[1m\u001b[32m1.34961\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8116 | loss: 1.34961 - acc: 0.7304 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8117  | total loss: \u001b[1m\u001b[32m1.25227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8117 | loss: 1.25227 - acc: 0.7574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8118  | total loss: \u001b[1m\u001b[32m1.47778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8118 | loss: 1.47778 - acc: 0.6888 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8119  | total loss: \u001b[1m\u001b[32m1.36631\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8119 | loss: 1.36631 - acc: 0.7199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8120  | total loss: \u001b[1m\u001b[32m1.60516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8120 | loss: 1.60516 - acc: 0.6550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8121  | total loss: \u001b[1m\u001b[32m1.48081\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8121 | loss: 1.48081 - acc: 0.6895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8122  | total loss: \u001b[1m\u001b[32m1.36889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8122 | loss: 1.36889 - acc: 0.7206 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8123  | total loss: \u001b[1m\u001b[32m1.26781\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8123 | loss: 1.26781 - acc: 0.7485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8124  | total loss: \u001b[1m\u001b[32m1.17617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8124 | loss: 1.17617 - acc: 0.7737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8125  | total loss: \u001b[1m\u001b[32m1.09276\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8125 | loss: 1.09276 - acc: 0.7963 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8126  | total loss: \u001b[1m\u001b[32m1.36221\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8126 | loss: 1.36221 - acc: 0.7238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8127  | total loss: \u001b[1m\u001b[32m1.25884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8127 | loss: 1.25884 - acc: 0.7514 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8128  | total loss: \u001b[1m\u001b[32m1.16532\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8128 | loss: 1.16532 - acc: 0.7763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8129  | total loss: \u001b[1m\u001b[32m1.08041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8129 | loss: 1.08041 - acc: 0.7987 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8130  | total loss: \u001b[1m\u001b[32m1.32240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8130 | loss: 1.32240 - acc: 0.7331 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8131  | total loss: \u001b[1m\u001b[32m1.22067\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8131 | loss: 1.22067 - acc: 0.7598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8132  | total loss: \u001b[1m\u001b[32m1.50978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8132 | loss: 1.50978 - acc: 0.6838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8133  | total loss: \u001b[1m\u001b[32m1.38941\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8133 | loss: 1.38941 - acc: 0.7154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8134  | total loss: \u001b[1m\u001b[32m1.65166\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8134 | loss: 1.65166 - acc: 0.6439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8135  | total loss: \u001b[1m\u001b[32m1.51834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8135 | loss: 1.51834 - acc: 0.6795 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8136  | total loss: \u001b[1m\u001b[32m1.76171\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8136 | loss: 1.76171 - acc: 0.6187 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8137  | total loss: \u001b[1m\u001b[32m1.61949\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8137 | loss: 1.61949 - acc: 0.6568 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8138  | total loss: \u001b[1m\u001b[32m1.83186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8138 | loss: 1.83186 - acc: 0.5911 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8139  | total loss: \u001b[1m\u001b[32m1.68551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8139 | loss: 1.68551 - acc: 0.6320 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8140  | total loss: \u001b[1m\u001b[32m1.81013\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8140 | loss: 1.81013 - acc: 0.5902 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8141  | total loss: \u001b[1m\u001b[32m1.66917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8141 | loss: 1.66917 - acc: 0.6312 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8142  | total loss: \u001b[1m\u001b[32m1.89858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8142 | loss: 1.89858 - acc: 0.5681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8143  | total loss: \u001b[1m\u001b[32m1.75222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8143 | loss: 1.75222 - acc: 0.6113 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8144  | total loss: \u001b[1m\u001b[32m1.62203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8144 | loss: 1.62203 - acc: 0.6502 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8145  | total loss: \u001b[1m\u001b[32m1.50575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8145 | loss: 1.50575 - acc: 0.6851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8146  | total loss: \u001b[1m\u001b[32m1.70832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8146 | loss: 1.70832 - acc: 0.6166 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8147  | total loss: \u001b[1m\u001b[32m1.58489\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8147 | loss: 1.58489 - acc: 0.6550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8148  | total loss: \u001b[1m\u001b[32m1.77666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8148 | loss: 1.77666 - acc: 0.5895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8149  | total loss: \u001b[1m\u001b[32m1.64827\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8149 | loss: 1.64827 - acc: 0.6305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8150  | total loss: \u001b[1m\u001b[32m1.81233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8150 | loss: 1.81233 - acc: 0.5818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8151  | total loss: \u001b[1m\u001b[32m1.68235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8151 | loss: 1.68235 - acc: 0.6236 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8152  | total loss: \u001b[1m\u001b[32m1.84462\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8152 | loss: 1.84462 - acc: 0.5684 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8153  | total loss: \u001b[1m\u001b[32m1.71326\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8153 | loss: 1.71326 - acc: 0.6115 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8154  | total loss: \u001b[1m\u001b[32m1.59556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8154 | loss: 1.59556 - acc: 0.6504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8155  | total loss: \u001b[1m\u001b[32m1.48948\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8155 | loss: 1.48948 - acc: 0.6853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8156  | total loss: \u001b[1m\u001b[32m1.39327\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8156 | loss: 1.39327 - acc: 0.7168 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8157  | total loss: \u001b[1m\u001b[32m1.30542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8157 | loss: 1.30542 - acc: 0.7451 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8158  | total loss: \u001b[1m\u001b[32m1.50463\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8158 | loss: 1.50463 - acc: 0.6778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8159  | total loss: \u001b[1m\u001b[32m1.40318\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8159 | loss: 1.40318 - acc: 0.7100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8160  | total loss: \u001b[1m\u001b[32m1.31064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8160 | loss: 1.31064 - acc: 0.7390 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8161  | total loss: \u001b[1m\u001b[32m1.22577\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8161 | loss: 1.22577 - acc: 0.7651 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8162  | total loss: \u001b[1m\u001b[32m1.45135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8162 | loss: 1.45135 - acc: 0.6957 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8163  | total loss: \u001b[1m\u001b[32m1.34966\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8163 | loss: 1.34966 - acc: 0.7261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8164  | total loss: \u001b[1m\u001b[32m1.25692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8164 | loss: 1.25692 - acc: 0.7535 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8165  | total loss: \u001b[1m\u001b[32m1.17196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8165 | loss: 1.17196 - acc: 0.7782 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8166  | total loss: \u001b[1m\u001b[32m1.41737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8166 | loss: 1.41737 - acc: 0.7004 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8167  | total loss: \u001b[1m\u001b[32m1.31396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8167 | loss: 1.31396 - acc: 0.7303 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8168  | total loss: \u001b[1m\u001b[32m1.52563\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8168 | loss: 1.52563 - acc: 0.6644 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8169  | total loss: \u001b[1m\u001b[32m1.41042\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8169 | loss: 1.41042 - acc: 0.6980 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8170  | total loss: \u001b[1m\u001b[32m1.30636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8170 | loss: 1.30636 - acc: 0.7282 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8171  | total loss: \u001b[1m\u001b[32m1.21200\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8171 | loss: 1.21200 - acc: 0.7554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8172  | total loss: \u001b[1m\u001b[32m1.12608\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8172 | loss: 1.12608 - acc: 0.7798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8173  | total loss: \u001b[1m\u001b[32m1.04751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8173 | loss: 1.04751 - acc: 0.8019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8174  | total loss: \u001b[1m\u001b[32m0.97538\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8174 | loss: 0.97538 - acc: 0.8217 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8175  | total loss: \u001b[1m\u001b[32m0.90887\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8175 | loss: 0.90887 - acc: 0.8395 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8176  | total loss: \u001b[1m\u001b[32m1.17762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8176 | loss: 1.17762 - acc: 0.7627 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8177  | total loss: \u001b[1m\u001b[32m1.08848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8177 | loss: 1.08848 - acc: 0.7864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8178  | total loss: \u001b[1m\u001b[32m1.36462\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8178 | loss: 1.36462 - acc: 0.7149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8179  | total loss: \u001b[1m\u001b[32m1.25589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8179 | loss: 1.25589 - acc: 0.7434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8180  | total loss: \u001b[1m\u001b[32m1.55894\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8180 | loss: 1.55894 - acc: 0.6691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8181  | total loss: \u001b[1m\u001b[32m1.43124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8181 | loss: 1.43124 - acc: 0.7022 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8182  | total loss: \u001b[1m\u001b[32m1.31666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8182 | loss: 1.31666 - acc: 0.7320 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8183  | total loss: \u001b[1m\u001b[32m1.21360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8183 | loss: 1.21360 - acc: 0.7588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8184  | total loss: \u001b[1m\u001b[32m1.48077\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8184 | loss: 1.48077 - acc: 0.6829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8185  | total loss: \u001b[1m\u001b[32m1.36172\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8185 | loss: 1.36172 - acc: 0.7146 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8186  | total loss: \u001b[1m\u001b[32m1.62914\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8186 | loss: 1.62914 - acc: 0.6431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8187  | total loss: \u001b[1m\u001b[32m1.49674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8187 | loss: 1.49674 - acc: 0.6788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8188  | total loss: \u001b[1m\u001b[32m1.37839\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8188 | loss: 1.37839 - acc: 0.7109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8189  | total loss: \u001b[1m\u001b[32m1.27227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8189 | loss: 1.27227 - acc: 0.7398 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8190  | total loss: \u001b[1m\u001b[32m1.56786\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8190 | loss: 1.56786 - acc: 0.6659 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8191  | total loss: \u001b[1m\u001b[32m1.44383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8191 | loss: 1.44383 - acc: 0.6993 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8192  | total loss: \u001b[1m\u001b[32m1.64376\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8192 | loss: 1.64376 - acc: 0.6436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8193  | total loss: \u001b[1m\u001b[32m1.51385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8193 | loss: 1.51385 - acc: 0.6793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8194  | total loss: \u001b[1m\u001b[32m1.72014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8194 | loss: 1.72014 - acc: 0.6185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8195  | total loss: \u001b[1m\u001b[32m1.58479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8195 | loss: 1.58479 - acc: 0.6566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8196  | total loss: \u001b[1m\u001b[32m1.77381\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8196 | loss: 1.77381 - acc: 0.5981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8197  | total loss: \u001b[1m\u001b[32m1.63582\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8197 | loss: 1.63582 - acc: 0.6383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8198  | total loss: \u001b[1m\u001b[32m1.51280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8198 | loss: 1.51280 - acc: 0.6745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8199  | total loss: \u001b[1m\u001b[32m1.40270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8199 | loss: 1.40270 - acc: 0.7070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8200  | total loss: \u001b[1m\u001b[32m1.63039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8200 | loss: 1.63039 - acc: 0.6363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8201  | total loss: \u001b[1m\u001b[32m1.50964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8201 | loss: 1.50964 - acc: 0.6727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8202  | total loss: \u001b[1m\u001b[32m1.40140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8202 | loss: 1.40140 - acc: 0.7054 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8203  | total loss: \u001b[1m\u001b[32m1.30389\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8203 | loss: 1.30389 - acc: 0.7349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8204  | total loss: \u001b[1m\u001b[32m1.21558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8204 | loss: 1.21558 - acc: 0.7614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8205  | total loss: \u001b[1m\u001b[32m1.13514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8205 | loss: 1.13514 - acc: 0.7853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8206  | total loss: \u001b[1m\u001b[32m1.06145\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8206 | loss: 1.06145 - acc: 0.8067 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8207  | total loss: \u001b[1m\u001b[32m0.99354\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8207 | loss: 0.99354 - acc: 0.8261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8208  | total loss: \u001b[1m\u001b[32m1.29343\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8208 | loss: 1.29343 - acc: 0.7434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8209  | total loss: \u001b[1m\u001b[32m1.20001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8209 | loss: 1.20001 - acc: 0.7691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8210  | total loss: \u001b[1m\u001b[32m1.47176\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8210 | loss: 1.47176 - acc: 0.6922 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8211  | total loss: \u001b[1m\u001b[32m1.35984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8211 | loss: 1.35984 - acc: 0.7230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8212  | total loss: \u001b[1m\u001b[32m1.61883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8212 | loss: 1.61883 - acc: 0.6507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8213  | total loss: \u001b[1m\u001b[32m1.49274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8213 | loss: 1.49274 - acc: 0.6856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8214  | total loss: \u001b[1m\u001b[32m1.67233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8214 | loss: 1.67233 - acc: 0.6242 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8215  | total loss: \u001b[1m\u001b[32m1.54235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8215 | loss: 1.54235 - acc: 0.6618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8216  | total loss: \u001b[1m\u001b[32m1.77259\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8216 | loss: 1.77259 - acc: 0.5956 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8217  | total loss: \u001b[1m\u001b[32m1.63477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8217 | loss: 1.63477 - acc: 0.6360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8218  | total loss: \u001b[1m\u001b[32m1.51173\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8218 | loss: 1.51173 - acc: 0.6724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8219  | total loss: \u001b[1m\u001b[32m1.40149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8219 | loss: 1.40149 - acc: 0.7052 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8220  | total loss: \u001b[1m\u001b[32m1.63378\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8220 | loss: 1.63378 - acc: 0.6418 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8221  | total loss: \u001b[1m\u001b[32m1.51215\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8221 | loss: 1.51215 - acc: 0.6776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8222  | total loss: \u001b[1m\u001b[32m1.40297\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8222 | loss: 1.40297 - acc: 0.7099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8223  | total loss: \u001b[1m\u001b[32m1.30451\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8223 | loss: 1.30451 - acc: 0.7389 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8224  | total loss: \u001b[1m\u001b[32m1.51333\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8224 | loss: 1.51333 - acc: 0.6721 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8225  | total loss: \u001b[1m\u001b[32m1.40345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8225 | loss: 1.40345 - acc: 0.7049 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8226  | total loss: \u001b[1m\u001b[32m1.60255\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8226 | loss: 1.60255 - acc: 0.6487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8227  | total loss: \u001b[1m\u001b[32m1.48409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8227 | loss: 1.48409 - acc: 0.6838 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8228  | total loss: \u001b[1m\u001b[32m1.71660\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8228 | loss: 1.71660 - acc: 0.6155 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8229  | total loss: \u001b[1m\u001b[32m1.58772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8229 | loss: 1.58772 - acc: 0.6539 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8230  | total loss: \u001b[1m\u001b[32m1.74616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8230 | loss: 1.74616 - acc: 0.6028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8231  | total loss: \u001b[1m\u001b[32m1.61584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8231 | loss: 1.61584 - acc: 0.6425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8232  | total loss: \u001b[1m\u001b[32m1.76694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8232 | loss: 1.76694 - acc: 0.5997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8233  | total loss: \u001b[1m\u001b[32m1.63621\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8233 | loss: 1.63621 - acc: 0.6397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8234  | total loss: \u001b[1m\u001b[32m1.51907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8234 | loss: 1.51907 - acc: 0.6758 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8235  | total loss: \u001b[1m\u001b[32m1.41360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8235 | loss: 1.41360 - acc: 0.7082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8236  | total loss: \u001b[1m\u001b[32m1.31815\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8236 | loss: 1.31815 - acc: 0.7374 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8237  | total loss: \u001b[1m\u001b[32m1.23129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8237 | loss: 1.23129 - acc: 0.7636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8238  | total loss: \u001b[1m\u001b[32m1.47439\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8238 | loss: 1.47439 - acc: 0.6873 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8239  | total loss: \u001b[1m\u001b[32m1.37029\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8239 | loss: 1.37029 - acc: 0.7185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8240  | total loss: \u001b[1m\u001b[32m1.27590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8240 | loss: 1.27590 - acc: 0.7467 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8241  | total loss: \u001b[1m\u001b[32m1.18988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8241 | loss: 1.18988 - acc: 0.7720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8242  | total loss: \u001b[1m\u001b[32m1.11108\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8242 | loss: 1.11108 - acc: 0.7948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8243  | total loss: \u001b[1m\u001b[32m1.03853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8243 | loss: 1.03853 - acc: 0.8153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8244  | total loss: \u001b[1m\u001b[32m0.97143\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8244 | loss: 0.97143 - acc: 0.8338 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8245  | total loss: \u001b[1m\u001b[32m0.90909\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8245 | loss: 0.90909 - acc: 0.8504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8246  | total loss: \u001b[1m\u001b[32m0.85095\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8246 | loss: 0.85095 - acc: 0.8654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8247  | total loss: \u001b[1m\u001b[32m0.79656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8247 | loss: 0.79656 - acc: 0.8788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8248  | total loss: \u001b[1m\u001b[32m0.74555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8248 | loss: 0.74555 - acc: 0.8910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8249  | total loss: \u001b[1m\u001b[32m0.69761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8249 | loss: 0.69761 - acc: 0.9019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8250  | total loss: \u001b[1m\u001b[32m0.65248\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8250 | loss: 0.65248 - acc: 0.9117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8251  | total loss: \u001b[1m\u001b[32m0.60998\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8251 | loss: 0.60998 - acc: 0.9205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8252  | total loss: \u001b[1m\u001b[32m0.56994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8252 | loss: 0.56994 - acc: 0.9285 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8253  | total loss: \u001b[1m\u001b[32m0.53221\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8253 | loss: 0.53221 - acc: 0.9356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8254  | total loss: \u001b[1m\u001b[32m0.90804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8254 | loss: 0.90804 - acc: 0.8492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8255  | total loss: \u001b[1m\u001b[32m0.83426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8255 | loss: 0.83426 - acc: 0.8643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8256  | total loss: \u001b[1m\u001b[32m0.76716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8256 | loss: 0.76716 - acc: 0.8778 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8257  | total loss: \u001b[1m\u001b[32m0.70606\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8257 | loss: 0.70606 - acc: 0.8901 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8258  | total loss: \u001b[1m\u001b[32m0.65033\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8258 | loss: 0.65033 - acc: 0.9011 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8259  | total loss: \u001b[1m\u001b[32m0.59944\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8259 | loss: 0.59944 - acc: 0.9109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8260  | total loss: \u001b[1m\u001b[32m0.55291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8260 | loss: 0.55291 - acc: 0.9199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8261  | total loss: \u001b[1m\u001b[32m0.51032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8261 | loss: 0.51032 - acc: 0.9279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8262  | total loss: \u001b[1m\u001b[32m0.47129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8262 | loss: 0.47129 - acc: 0.9351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8263  | total loss: \u001b[1m\u001b[32m0.43548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8263 | loss: 0.43548 - acc: 0.9416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8264  | total loss: \u001b[1m\u001b[32m0.40261\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8264 | loss: 0.40261 - acc: 0.9474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8265  | total loss: \u001b[1m\u001b[32m0.37240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8265 | loss: 0.37240 - acc: 0.9527 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8266  | total loss: \u001b[1m\u001b[32m0.82934\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8266 | loss: 0.82934 - acc: 0.8646 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8267  | total loss: \u001b[1m\u001b[32m0.75578\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8267 | loss: 0.75578 - acc: 0.8781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8268  | total loss: \u001b[1m\u001b[32m1.19299\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8268 | loss: 1.19299 - acc: 0.7903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8269  | total loss: \u001b[1m\u001b[32m1.08331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8269 | loss: 1.08331 - acc: 0.8113 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8270  | total loss: \u001b[1m\u001b[32m1.40602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8270 | loss: 1.40602 - acc: 0.7444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8271  | total loss: \u001b[1m\u001b[32m1.27603\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8271 | loss: 1.27603 - acc: 0.7700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8272  | total loss: \u001b[1m\u001b[32m1.62370\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8272 | loss: 1.62370 - acc: 0.6930 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8273  | total loss: \u001b[1m\u001b[32m1.47372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8273 | loss: 1.47372 - acc: 0.7237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8274  | total loss: \u001b[1m\u001b[32m1.33978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8274 | loss: 1.33978 - acc: 0.7513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8275  | total loss: \u001b[1m\u001b[32m1.22015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8275 | loss: 1.22015 - acc: 0.7762 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8276  | total loss: \u001b[1m\u001b[32m1.53874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8276 | loss: 1.53874 - acc: 0.6986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8277  | total loss: \u001b[1m\u001b[32m1.40133\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8277 | loss: 1.40133 - acc: 0.7287 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8278  | total loss: \u001b[1m\u001b[32m1.70869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8278 | loss: 1.70869 - acc: 0.6558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8279  | total loss: \u001b[1m\u001b[32m1.55730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8279 | loss: 1.55730 - acc: 0.6903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8280  | total loss: \u001b[1m\u001b[32m1.83069\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8280 | loss: 1.83069 - acc: 0.6284 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8281  | total loss: \u001b[1m\u001b[32m1.67103\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8281 | loss: 1.67103 - acc: 0.6655 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8282  | total loss: \u001b[1m\u001b[32m1.88309\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8282 | loss: 1.88309 - acc: 0.6133 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8283  | total loss: \u001b[1m\u001b[32m1.72286\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8283 | loss: 1.72286 - acc: 0.6519 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8284  | total loss: \u001b[1m\u001b[32m1.58092\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8284 | loss: 1.58092 - acc: 0.6867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8285  | total loss: \u001b[1m\u001b[32m1.45497\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8285 | loss: 1.45497 - acc: 0.7181 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8286  | total loss: \u001b[1m\u001b[32m1.69164\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8286 | loss: 1.69164 - acc: 0.6463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8287  | total loss: \u001b[1m\u001b[32m1.55802\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8287 | loss: 1.55802 - acc: 0.6816 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8288  | total loss: \u001b[1m\u001b[32m1.80950\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8288 | loss: 1.80950 - acc: 0.6135 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8289  | total loss: \u001b[1m\u001b[32m1.66800\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8289 | loss: 1.66800 - acc: 0.6521 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8290  | total loss: \u001b[1m\u001b[32m1.88585\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8290 | loss: 1.88585 - acc: 0.5869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8291  | total loss: \u001b[1m\u001b[32m1.74103\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8291 | loss: 1.74103 - acc: 0.6282 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8292  | total loss: \u001b[1m\u001b[32m1.61255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8292 | loss: 1.61255 - acc: 0.6654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8293  | total loss: \u001b[1m\u001b[32m1.49810\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8293 | loss: 1.49810 - acc: 0.6989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8294  | total loss: \u001b[1m\u001b[32m1.61343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8294 | loss: 1.61343 - acc: 0.6575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8295  | total loss: \u001b[1m\u001b[32m1.50042\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8295 | loss: 1.50042 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8296  | total loss: \u001b[1m\u001b[32m1.70488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8296 | loss: 1.70488 - acc: 0.6226 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8297  | total loss: \u001b[1m\u001b[32m1.58433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8297 | loss: 1.58433 - acc: 0.6604 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8298  | total loss: \u001b[1m\u001b[32m1.47642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8298 | loss: 1.47642 - acc: 0.6943 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8299  | total loss: \u001b[1m\u001b[32m1.37924\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8299 | loss: 1.37924 - acc: 0.7249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8300  | total loss: \u001b[1m\u001b[32m1.29119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8300 | loss: 1.29119 - acc: 0.7524 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8301  | total loss: \u001b[1m\u001b[32m1.21086\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8301 | loss: 1.21086 - acc: 0.7772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8302  | total loss: \u001b[1m\u001b[32m1.43417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8302 | loss: 1.43417 - acc: 0.6994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8303  | total loss: \u001b[1m\u001b[32m1.33756\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8303 | loss: 1.33756 - acc: 0.7295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8304  | total loss: \u001b[1m\u001b[32m1.55890\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8304 | loss: 1.55890 - acc: 0.6565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8305  | total loss: \u001b[1m\u001b[32m1.44891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8305 | loss: 1.44891 - acc: 0.6909 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8306  | total loss: \u001b[1m\u001b[32m1.63841\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8306 | loss: 1.63841 - acc: 0.6289 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8307  | total loss: \u001b[1m\u001b[32m1.52036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8307 | loss: 1.52036 - acc: 0.6661 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8308  | total loss: \u001b[1m\u001b[32m1.70263\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8308 | loss: 1.70263 - acc: 0.6066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8309  | total loss: \u001b[1m\u001b[32m1.57866\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8309 | loss: 1.57866 - acc: 0.6459 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8310  | total loss: \u001b[1m\u001b[32m1.72155\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8310 | loss: 1.72155 - acc: 0.6028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8311  | total loss: \u001b[1m\u001b[32m1.59646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8311 | loss: 1.59646 - acc: 0.6425 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8312  | total loss: \u001b[1m\u001b[32m1.79488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8312 | loss: 1.79488 - acc: 0.5782 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8313  | total loss: \u001b[1m\u001b[32m1.66350\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8313 | loss: 1.66350 - acc: 0.6204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8314  | total loss: \u001b[1m\u001b[32m1.81036\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8314 | loss: 1.81036 - acc: 0.5727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8315  | total loss: \u001b[1m\u001b[32m1.67876\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8315 | loss: 1.67876 - acc: 0.6154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8316  | total loss: \u001b[1m\u001b[32m1.56070\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8316 | loss: 1.56070 - acc: 0.6539 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8317  | total loss: \u001b[1m\u001b[32m1.45425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8317 | loss: 1.45425 - acc: 0.6885 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8318  | total loss: \u001b[1m\u001b[32m1.35777\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8318 | loss: 1.35777 - acc: 0.7196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8319  | total loss: \u001b[1m\u001b[32m1.26982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8319 | loss: 1.26982 - acc: 0.7477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8320  | total loss: \u001b[1m\u001b[32m1.52569\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 8320 | loss: 1.52569 - acc: 0.6729 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8321  | total loss: \u001b[1m\u001b[32m1.41903\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8321 | loss: 1.41903 - acc: 0.7056 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8322  | total loss: \u001b[1m\u001b[32m1.62888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8322 | loss: 1.62888 - acc: 0.6350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8323  | total loss: \u001b[1m\u001b[32m1.51113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8323 | loss: 1.51113 - acc: 0.6715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8324  | total loss: \u001b[1m\u001b[32m1.40476\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8324 | loss: 1.40476 - acc: 0.7044 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8325  | total loss: \u001b[1m\u001b[32m1.30823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8325 | loss: 1.30823 - acc: 0.7339 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8326  | total loss: \u001b[1m\u001b[32m1.50930\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8326 | loss: 1.50930 - acc: 0.6677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8327  | total loss: \u001b[1m\u001b[32m1.40087\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8327 | loss: 1.40087 - acc: 0.7009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8328  | total loss: \u001b[1m\u001b[32m1.61376\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8328 | loss: 1.61376 - acc: 0.6380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8329  | total loss: \u001b[1m\u001b[32m1.49446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8329 | loss: 1.49446 - acc: 0.6742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8330  | total loss: \u001b[1m\u001b[32m1.38687\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8330 | loss: 1.38687 - acc: 0.7068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8331  | total loss: \u001b[1m\u001b[32m1.28945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8331 | loss: 1.28945 - acc: 0.7361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8332  | total loss: \u001b[1m\u001b[32m1.50858\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8332 | loss: 1.50858 - acc: 0.6696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8333  | total loss: \u001b[1m\u001b[32m1.39793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8333 | loss: 1.39793 - acc: 0.7027 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8334  | total loss: \u001b[1m\u001b[32m1.29785\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8334 | loss: 1.29785 - acc: 0.7324 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8335  | total loss: \u001b[1m\u001b[32m1.20694\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8335 | loss: 1.20694 - acc: 0.7592 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8336  | total loss: \u001b[1m\u001b[32m1.12401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8336 | loss: 1.12401 - acc: 0.7832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8337  | total loss: \u001b[1m\u001b[32m1.04801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8337 | loss: 1.04801 - acc: 0.8049 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8338  | total loss: \u001b[1m\u001b[32m1.31210\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8338 | loss: 1.31210 - acc: 0.7244 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8339  | total loss: \u001b[1m\u001b[32m1.21518\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8339 | loss: 1.21518 - acc: 0.7520 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8340  | total loss: \u001b[1m\u001b[32m1.12711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8340 | loss: 1.12711 - acc: 0.7768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8341  | total loss: \u001b[1m\u001b[32m1.04680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8341 | loss: 1.04680 - acc: 0.7991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8342  | total loss: \u001b[1m\u001b[32m1.30749\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8342 | loss: 1.30749 - acc: 0.7263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8343  | total loss: \u001b[1m\u001b[32m1.20760\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8343 | loss: 1.20760 - acc: 0.7537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8344  | total loss: \u001b[1m\u001b[32m1.49852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8344 | loss: 1.49852 - acc: 0.6783 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8345  | total loss: \u001b[1m\u001b[32m1.37937\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8345 | loss: 1.37937 - acc: 0.7105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8346  | total loss: \u001b[1m\u001b[32m1.61325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8346 | loss: 1.61325 - acc: 0.6466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8347  | total loss: \u001b[1m\u001b[32m1.48357\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8347 | loss: 1.48357 - acc: 0.6819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8348  | total loss: \u001b[1m\u001b[32m1.36733\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8348 | loss: 1.36733 - acc: 0.7137 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8349  | total loss: \u001b[1m\u001b[32m1.26285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8349 | loss: 1.26285 - acc: 0.7424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8350  | total loss: \u001b[1m\u001b[32m1.51713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8350 | loss: 1.51713 - acc: 0.6681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8351  | total loss: \u001b[1m\u001b[32m1.39818\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8351 | loss: 1.39818 - acc: 0.7013 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8352  | total loss: \u001b[1m\u001b[32m1.63568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8352 | loss: 1.63568 - acc: 0.6383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8353  | total loss: \u001b[1m\u001b[32m1.50626\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8353 | loss: 1.50626 - acc: 0.6745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8354  | total loss: \u001b[1m\u001b[32m1.39043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8354 | loss: 1.39043 - acc: 0.7070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8355  | total loss: \u001b[1m\u001b[32m1.28642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8355 | loss: 1.28642 - acc: 0.7363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8356  | total loss: \u001b[1m\u001b[32m1.19269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8356 | loss: 1.19269 - acc: 0.7627 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8357  | total loss: \u001b[1m\u001b[32m1.10788\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8357 | loss: 1.10788 - acc: 0.7864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8358  | total loss: \u001b[1m\u001b[32m1.03078\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8358 | loss: 1.03078 - acc: 0.8078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8359  | total loss: \u001b[1m\u001b[32m0.96040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8359 | loss: 0.96040 - acc: 0.8270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8360  | total loss: \u001b[1m\u001b[32m1.23051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8360 | loss: 1.23051 - acc: 0.7515 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8361  | total loss: \u001b[1m\u001b[32m1.13869\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8361 | loss: 1.13869 - acc: 0.7763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8362  | total loss: \u001b[1m\u001b[32m1.05552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8362 | loss: 1.05552 - acc: 0.7987 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8363  | total loss: \u001b[1m\u001b[32m0.97991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8363 | loss: 0.97991 - acc: 0.8188 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8364  | total loss: \u001b[1m\u001b[32m1.27980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8364 | loss: 1.27980 - acc: 0.7441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8365  | total loss: \u001b[1m\u001b[32m1.18071\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8365 | loss: 1.18071 - acc: 0.7697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8366  | total loss: \u001b[1m\u001b[32m1.09117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8366 | loss: 1.09117 - acc: 0.7927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8367  | total loss: \u001b[1m\u001b[32m1.01001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8367 | loss: 1.01001 - acc: 0.8134 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8368  | total loss: \u001b[1m\u001b[32m1.25830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8368 | loss: 1.25830 - acc: 0.7464 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8369  | total loss: \u001b[1m\u001b[32m1.15963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8369 | loss: 1.15963 - acc: 0.7717 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8370  | total loss: \u001b[1m\u001b[32m1.07057\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8370 | loss: 1.07057 - acc: 0.7946 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8371  | total loss: \u001b[1m\u001b[32m0.98993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8371 | loss: 0.98993 - acc: 0.8151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8372  | total loss: \u001b[1m\u001b[32m1.30993\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8372 | loss: 1.30993 - acc: 0.7336 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8373  | total loss: \u001b[1m\u001b[32m1.20495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8373 | loss: 1.20495 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8374  | total loss: \u001b[1m\u001b[32m1.11045\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8374 | loss: 1.11045 - acc: 0.7842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8375  | total loss: \u001b[1m\u001b[32m1.02515\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8375 | loss: 1.02515 - acc: 0.8058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8376  | total loss: \u001b[1m\u001b[32m1.37934\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8376 | loss: 1.37934 - acc: 0.7252 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8377  | total loss: \u001b[1m\u001b[32m1.26716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8377 | loss: 1.26716 - acc: 0.7527 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8378  | total loss: \u001b[1m\u001b[32m1.16638\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8378 | loss: 1.16638 - acc: 0.7774 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8379  | total loss: \u001b[1m\u001b[32m1.07561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8379 | loss: 1.07561 - acc: 0.7997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8380  | total loss: \u001b[1m\u001b[32m1.38511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8380 | loss: 1.38511 - acc: 0.7197 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8381  | total loss: \u001b[1m\u001b[32m1.27273\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8381 | loss: 1.27273 - acc: 0.7477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8382  | total loss: \u001b[1m\u001b[32m1.47083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8382 | loss: 1.47083 - acc: 0.6944 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8383  | total loss: \u001b[1m\u001b[32m1.35097\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8383 | loss: 1.35097 - acc: 0.7250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8384  | total loss: \u001b[1m\u001b[32m1.24362\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8384 | loss: 1.24362 - acc: 0.7525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8385  | total loss: \u001b[1m\u001b[32m1.14724\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8385 | loss: 1.14724 - acc: 0.7772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8386  | total loss: \u001b[1m\u001b[32m1.42013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8386 | loss: 1.42013 - acc: 0.7066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8387  | total loss: \u001b[1m\u001b[32m1.30675\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8387 | loss: 1.30675 - acc: 0.7360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8388  | total loss: \u001b[1m\u001b[32m1.55536\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8388 | loss: 1.55536 - acc: 0.6695 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8389  | total loss: \u001b[1m\u001b[32m1.42994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8389 | loss: 1.42994 - acc: 0.7026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8390  | total loss: \u001b[1m\u001b[32m1.31780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8390 | loss: 1.31780 - acc: 0.7323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8391  | total loss: \u001b[1m\u001b[32m1.21724\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8391 | loss: 1.21724 - acc: 0.7591 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8392  | total loss: \u001b[1m\u001b[32m1.12679\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8392 | loss: 1.12679 - acc: 0.7832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8393  | total loss: \u001b[1m\u001b[32m1.04512\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8393 | loss: 1.04512 - acc: 0.8049 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8394  | total loss: \u001b[1m\u001b[32m1.33824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8394 | loss: 1.33824 - acc: 0.7244 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8395  | total loss: \u001b[1m\u001b[32m1.23525\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8395 | loss: 1.23525 - acc: 0.7519 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8396  | total loss: \u001b[1m\u001b[32m1.14258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8396 | loss: 1.14258 - acc: 0.7767 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8397  | total loss: \u001b[1m\u001b[32m1.05891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8397 | loss: 1.05891 - acc: 0.7991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8398  | total loss: \u001b[1m\u001b[32m0.98308\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8398 | loss: 0.98308 - acc: 0.8192 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8399  | total loss: \u001b[1m\u001b[32m0.91410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8399 | loss: 0.91410 - acc: 0.8372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8400  | total loss: \u001b[1m\u001b[32m0.85108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8400 | loss: 0.85108 - acc: 0.8535 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8401  | total loss: \u001b[1m\u001b[32m0.79329\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8401 | loss: 0.79329 - acc: 0.8682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8402  | total loss: \u001b[1m\u001b[32m0.74009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8402 | loss: 0.74009 - acc: 0.8813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8403  | total loss: \u001b[1m\u001b[32m0.69095\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8403 | loss: 0.69095 - acc: 0.8932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8404  | total loss: \u001b[1m\u001b[32m0.64540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8404 | loss: 0.64540 - acc: 0.9039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8405  | total loss: \u001b[1m\u001b[32m0.60307\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8405 | loss: 0.60307 - acc: 0.9135 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8406  | total loss: \u001b[1m\u001b[32m0.56363\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8406 | loss: 0.56363 - acc: 0.9222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8407  | total loss: \u001b[1m\u001b[32m0.52681\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8407 | loss: 0.52681 - acc: 0.9299 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8408  | total loss: \u001b[1m\u001b[32m0.89972\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8408 | loss: 0.89972 - acc: 0.8369 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8409  | total loss: \u001b[1m\u001b[32m0.82758\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8409 | loss: 0.82758 - acc: 0.8532 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8410  | total loss: \u001b[1m\u001b[32m1.19988\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8410 | loss: 1.19988 - acc: 0.7679 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8411  | total loss: \u001b[1m\u001b[32m1.09744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8411 | loss: 1.09744 - acc: 0.7911 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8412  | total loss: \u001b[1m\u001b[32m1.00531\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8412 | loss: 1.00531 - acc: 0.8120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8413  | total loss: \u001b[1m\u001b[32m0.92233\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8413 | loss: 0.92233 - acc: 0.8308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8414  | total loss: \u001b[1m\u001b[32m1.27142\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8414 | loss: 1.27142 - acc: 0.7477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8415  | total loss: \u001b[1m\u001b[32m1.16216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8415 | loss: 1.16216 - acc: 0.7730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8416  | total loss: \u001b[1m\u001b[32m1.49620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8416 | loss: 1.49620 - acc: 0.6957 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8417  | total loss: \u001b[1m\u001b[32m1.36588\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8417 | loss: 1.36588 - acc: 0.7261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8418  | total loss: \u001b[1m\u001b[32m1.65815\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8418 | loss: 1.65815 - acc: 0.6606 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8419  | total loss: \u001b[1m\u001b[32m1.51400\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8419 | loss: 1.51400 - acc: 0.6946 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8420  | total loss: \u001b[1m\u001b[32m1.74971\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8420 | loss: 1.74971 - acc: 0.6323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8421  | total loss: \u001b[1m\u001b[32m1.59955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8421 | loss: 1.59955 - acc: 0.6690 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8422  | total loss: \u001b[1m\u001b[32m1.46598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8422 | loss: 1.46598 - acc: 0.7021 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8423  | total loss: \u001b[1m\u001b[32m1.34699\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8423 | loss: 1.34699 - acc: 0.7319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8424  | total loss: \u001b[1m\u001b[32m1.56570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8424 | loss: 1.56570 - acc: 0.6730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8425  | total loss: \u001b[1m\u001b[32m1.43907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8425 | loss: 1.43907 - acc: 0.7057 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8426  | total loss: \u001b[1m\u001b[32m1.57102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8426 | loss: 1.57102 - acc: 0.6637 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8427  | total loss: \u001b[1m\u001b[32m1.44633\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8427 | loss: 1.44633 - acc: 0.6973 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8428  | total loss: \u001b[1m\u001b[32m1.33511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8428 | loss: 1.33511 - acc: 0.7276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8429  | total loss: \u001b[1m\u001b[32m1.23558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8429 | loss: 1.23558 - acc: 0.7548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8430  | total loss: \u001b[1m\u001b[32m1.49981\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8430 | loss: 1.49981 - acc: 0.6794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8431  | total loss: \u001b[1m\u001b[32m1.38505\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8431 | loss: 1.38505 - acc: 0.7114 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8432  | total loss: \u001b[1m\u001b[32m1.63073\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8432 | loss: 1.63073 - acc: 0.6474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8433  | total loss: \u001b[1m\u001b[32m1.50488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8433 | loss: 1.50488 - acc: 0.6827 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8434  | total loss: \u001b[1m\u001b[32m1.39252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8434 | loss: 1.39252 - acc: 0.7144 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8435  | total loss: \u001b[1m\u001b[32m1.29183\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8435 | loss: 1.29183 - acc: 0.7430 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8436  | total loss: \u001b[1m\u001b[32m1.20122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8436 | loss: 1.20122 - acc: 0.7687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8437  | total loss: \u001b[1m\u001b[32m1.11928\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8437 | loss: 1.11928 - acc: 0.7918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8438  | total loss: \u001b[1m\u001b[32m1.04481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8438 | loss: 1.04481 - acc: 0.8126 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8439  | total loss: \u001b[1m\u001b[32m0.97677\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8439 | loss: 0.97677 - acc: 0.8314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8440  | total loss: \u001b[1m\u001b[32m1.24354\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8440 | loss: 1.24354 - acc: 0.7554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8441  | total loss: \u001b[1m\u001b[32m1.15407\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8441 | loss: 1.15407 - acc: 0.7798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8442  | total loss: \u001b[1m\u001b[32m1.38175\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8442 | loss: 1.38175 - acc: 0.7161 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8443  | total loss: \u001b[1m\u001b[32m1.27796\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8443 | loss: 1.27796 - acc: 0.7445 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8444  | total loss: \u001b[1m\u001b[32m1.18434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8444 | loss: 1.18434 - acc: 0.7701 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8445  | total loss: \u001b[1m\u001b[32m1.09957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8445 | loss: 1.09957 - acc: 0.7931 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8446  | total loss: \u001b[1m\u001b[32m1.38358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8446 | loss: 1.38358 - acc: 0.7138 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8447  | total loss: \u001b[1m\u001b[32m1.27830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8447 | loss: 1.27830 - acc: 0.7424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8448  | total loss: \u001b[1m\u001b[32m1.52858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8448 | loss: 1.52858 - acc: 0.6753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8449  | total loss: \u001b[1m\u001b[32m1.40931\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8449 | loss: 1.40931 - acc: 0.7078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8450  | total loss: \u001b[1m\u001b[32m1.30224\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8450 | loss: 1.30224 - acc: 0.7370 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8451  | total loss: \u001b[1m\u001b[32m1.20581\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8451 | loss: 1.20581 - acc: 0.7633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8452  | total loss: \u001b[1m\u001b[32m1.47927\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8452 | loss: 1.47927 - acc: 0.6870 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8453  | total loss: \u001b[1m\u001b[32m1.36524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8453 | loss: 1.36524 - acc: 0.7183 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8454  | total loss: \u001b[1m\u001b[32m1.62090\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8454 | loss: 1.62090 - acc: 0.6464 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8455  | total loss: \u001b[1m\u001b[32m1.49384\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8455 | loss: 1.49384 - acc: 0.6818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8456  | total loss: \u001b[1m\u001b[32m1.65179\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8456 | loss: 1.65179 - acc: 0.6350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8457  | total loss: \u001b[1m\u001b[32m1.52332\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8457 | loss: 1.52332 - acc: 0.6715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8458  | total loss: \u001b[1m\u001b[32m1.40835\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8458 | loss: 1.40835 - acc: 0.7044 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8459  | total loss: \u001b[1m\u001b[32m1.30511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8459 | loss: 1.30511 - acc: 0.7339 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8460  | total loss: \u001b[1m\u001b[32m1.51978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8460 | loss: 1.51978 - acc: 0.6677 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8461  | total loss: \u001b[1m\u001b[32m1.40585\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8461 | loss: 1.40585 - acc: 0.7009 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8462  | total loss: \u001b[1m\u001b[32m1.53507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8462 | loss: 1.53507 - acc: 0.6594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8463  | total loss: \u001b[1m\u001b[32m1.42049\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8463 | loss: 1.42049 - acc: 0.6935 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8464  | total loss: \u001b[1m\u001b[32m1.62114\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8464 | loss: 1.62114 - acc: 0.6313 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8465  | total loss: \u001b[1m\u001b[32m1.49917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8465 | loss: 1.49917 - acc: 0.6681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8466  | total loss: \u001b[1m\u001b[32m1.68345\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8466 | loss: 1.68345 - acc: 0.6156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8467  | total loss: \u001b[1m\u001b[32m1.55692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8467 | loss: 1.55692 - acc: 0.6540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8468  | total loss: \u001b[1m\u001b[32m1.74978\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8468 | loss: 1.74978 - acc: 0.5958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8469  | total loss: \u001b[1m\u001b[32m1.61864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8469 | loss: 1.61864 - acc: 0.6362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8470  | total loss: \u001b[1m\u001b[32m1.81007\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8470 | loss: 1.81007 - acc: 0.5797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8471  | total loss: \u001b[1m\u001b[32m1.67516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8471 | loss: 1.67516 - acc: 0.6218 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8472  | total loss: \u001b[1m\u001b[32m1.83117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8472 | loss: 1.83117 - acc: 0.5739 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8473  | total loss: \u001b[1m\u001b[32m1.69648\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8473 | loss: 1.69648 - acc: 0.6165 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8474  | total loss: \u001b[1m\u001b[32m1.87813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8474 | loss: 1.87813 - acc: 0.5620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8475  | total loss: \u001b[1m\u001b[32m1.74111\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8475 | loss: 1.74111 - acc: 0.6058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8476  | total loss: \u001b[1m\u001b[32m1.88767\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8476 | loss: 1.88767 - acc: 0.5523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8477  | total loss: \u001b[1m\u001b[32m1.75196\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8477 | loss: 1.75196 - acc: 0.5971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8478  | total loss: \u001b[1m\u001b[32m1.83783\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8478 | loss: 1.83783 - acc: 0.5660 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8479  | total loss: \u001b[1m\u001b[32m1.70899\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8479 | loss: 1.70899 - acc: 0.6094 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8480  | total loss: \u001b[1m\u001b[32m1.59347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8480 | loss: 1.59347 - acc: 0.6484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8481  | total loss: \u001b[1m\u001b[32m1.48927\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8481 | loss: 1.48927 - acc: 0.6836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8482  | total loss: \u001b[1m\u001b[32m1.39470\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8482 | loss: 1.39470 - acc: 0.7152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8483  | total loss: \u001b[1m\u001b[32m1.30828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8483 | loss: 1.30828 - acc: 0.7437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8484  | total loss: \u001b[1m\u001b[32m1.51888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8484 | loss: 1.51888 - acc: 0.6765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8485  | total loss: \u001b[1m\u001b[32m1.41750\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8485 | loss: 1.41750 - acc: 0.7088 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8486  | total loss: \u001b[1m\u001b[32m1.57054\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8486 | loss: 1.57054 - acc: 0.6522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8487  | total loss: \u001b[1m\u001b[32m1.46223\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8487 | loss: 1.46223 - acc: 0.6870 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8488  | total loss: \u001b[1m\u001b[32m1.36382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8488 | loss: 1.36382 - acc: 0.7183 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8489  | total loss: \u001b[1m\u001b[32m1.27392\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8489 | loss: 1.27392 - acc: 0.7465 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8490  | total loss: \u001b[1m\u001b[32m1.50116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8490 | loss: 1.50116 - acc: 0.6790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8491  | total loss: \u001b[1m\u001b[32m1.39520\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8491 | loss: 1.39520 - acc: 0.7111 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8492  | total loss: \u001b[1m\u001b[32m1.60603\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8492 | loss: 1.60603 - acc: 0.6400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8493  | total loss: \u001b[1m\u001b[32m1.48841\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8493 | loss: 1.48841 - acc: 0.6760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8494  | total loss: \u001b[1m\u001b[32m1.65331\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8494 | loss: 1.65331 - acc: 0.6298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8495  | total loss: \u001b[1m\u001b[32m1.53053\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8495 | loss: 1.53053 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8496  | total loss: \u001b[1m\u001b[32m1.72546\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8496 | loss: 1.72546 - acc: 0.6073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8497  | total loss: \u001b[1m\u001b[32m1.59559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8497 | loss: 1.59559 - acc: 0.6466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8498  | total loss: \u001b[1m\u001b[32m1.75414\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8498 | loss: 1.75414 - acc: 0.5962 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8499  | total loss: \u001b[1m\u001b[32m1.62203\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8499 | loss: 1.62203 - acc: 0.6366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8500  | total loss: \u001b[1m\u001b[32m1.50329\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8500 | loss: 1.50329 - acc: 0.6729 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8501  | total loss: \u001b[1m\u001b[32m1.39615\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8501 | loss: 1.39615 - acc: 0.7056 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8502  | total loss: \u001b[1m\u001b[32m1.29905\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8502 | loss: 1.29905 - acc: 0.7351 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8503  | total loss: \u001b[1m\u001b[32m1.21068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8503 | loss: 1.21068 - acc: 0.7616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8504  | total loss: \u001b[1m\u001b[32m1.12987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8504 | loss: 1.12987 - acc: 0.7854 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8505  | total loss: \u001b[1m\u001b[32m1.05564\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8505 | loss: 1.05564 - acc: 0.8069 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8506  | total loss: \u001b[1m\u001b[32m0.98716\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8506 | loss: 0.98716 - acc: 0.8262 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8507  | total loss: \u001b[1m\u001b[32m0.92372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8507 | loss: 0.92372 - acc: 0.8436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8508  | total loss: \u001b[1m\u001b[32m1.13886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8508 | loss: 1.13886 - acc: 0.7806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8509  | total loss: \u001b[1m\u001b[32m1.05729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8509 | loss: 1.05729 - acc: 0.8026 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8510  | total loss: \u001b[1m\u001b[32m1.32417\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8510 | loss: 1.32417 - acc: 0.7295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8511  | total loss: \u001b[1m\u001b[32m1.22254\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8511 | loss: 1.22254 - acc: 0.7565 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8512  | total loss: \u001b[1m\u001b[32m1.47077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8512 | loss: 1.47077 - acc: 0.6880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8513  | total loss: \u001b[1m\u001b[32m1.35415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8513 | loss: 1.35415 - acc: 0.7192 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8514  | total loss: \u001b[1m\u001b[32m1.60456\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8514 | loss: 1.60456 - acc: 0.6473 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8515  | total loss: \u001b[1m\u001b[32m1.47523\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8515 | loss: 1.47523 - acc: 0.6826 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8516  | total loss: \u001b[1m\u001b[32m1.35924\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8516 | loss: 1.35924 - acc: 0.7143 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8517  | total loss: \u001b[1m\u001b[32m1.25495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8517 | loss: 1.25495 - acc: 0.7429 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8518  | total loss: \u001b[1m\u001b[32m1.51853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8518 | loss: 1.51853 - acc: 0.6686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8519  | total loss: \u001b[1m\u001b[32m1.39875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8519 | loss: 1.39875 - acc: 0.7017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8520  | total loss: \u001b[1m\u001b[32m1.29124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8520 | loss: 1.29124 - acc: 0.7315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8521  | total loss: \u001b[1m\u001b[32m1.19445\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8521 | loss: 1.19445 - acc: 0.7584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8522  | total loss: \u001b[1m\u001b[32m1.10702\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8522 | loss: 1.10702 - acc: 0.7826 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8523  | total loss: \u001b[1m\u001b[32m1.02775\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8523 | loss: 1.02775 - acc: 0.8043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8524  | total loss: \u001b[1m\u001b[32m0.95562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8524 | loss: 0.95562 - acc: 0.8239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8525  | total loss: \u001b[1m\u001b[32m0.88972\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8525 | loss: 0.88972 - acc: 0.8415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8526  | total loss: \u001b[1m\u001b[32m0.82929\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8526 | loss: 0.82929 - acc: 0.8573 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8527  | total loss: \u001b[1m\u001b[32m0.77366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8527 | loss: 0.77366 - acc: 0.8716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8528  | total loss: \u001b[1m\u001b[32m1.13637\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8528 | loss: 1.13637 - acc: 0.7844 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8529  | total loss: \u001b[1m\u001b[32m1.04836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8529 | loss: 1.04836 - acc: 0.8060 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8530  | total loss: \u001b[1m\u001b[32m1.30992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8530 | loss: 1.30992 - acc: 0.7397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8531  | total loss: \u001b[1m\u001b[32m1.20421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8531 | loss: 1.20421 - acc: 0.7657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8532  | total loss: \u001b[1m\u001b[32m1.49108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8532 | loss: 1.49108 - acc: 0.6891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8533  | total loss: \u001b[1m\u001b[32m1.36800\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8533 | loss: 1.36800 - acc: 0.7202 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8534  | total loss: \u001b[1m\u001b[32m1.62647\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8534 | loss: 1.62647 - acc: 0.6553 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8535  | total loss: \u001b[1m\u001b[32m1.49155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8535 | loss: 1.49155 - acc: 0.6898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8536  | total loss: \u001b[1m\u001b[32m1.74418\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8536 | loss: 1.74418 - acc: 0.6208 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8537  | total loss: \u001b[1m\u001b[32m1.60004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8537 | loss: 1.60004 - acc: 0.6587 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8538  | total loss: \u001b[1m\u001b[32m1.80602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8538 | loss: 1.80602 - acc: 0.6000 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8539  | total loss: \u001b[1m\u001b[32m1.65898\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8539 | loss: 1.65898 - acc: 0.6400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8540  | total loss: \u001b[1m\u001b[32m1.85552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8540 | loss: 1.85552 - acc: 0.5832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8541  | total loss: \u001b[1m\u001b[32m1.70733\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8541 | loss: 1.70733 - acc: 0.6248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8542  | total loss: \u001b[1m\u001b[32m1.89985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8542 | loss: 1.89985 - acc: 0.5695 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8543  | total loss: \u001b[1m\u001b[32m1.75126\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8543 | loss: 1.75126 - acc: 0.6125 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8544  | total loss: \u001b[1m\u001b[32m1.61925\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8544 | loss: 1.61925 - acc: 0.6513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8545  | total loss: \u001b[1m\u001b[32m1.50157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8545 | loss: 1.50157 - acc: 0.6862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8546  | total loss: \u001b[1m\u001b[32m1.39623\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8546 | loss: 1.39623 - acc: 0.7175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8547  | total loss: \u001b[1m\u001b[32m1.30147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8547 | loss: 1.30147 - acc: 0.7458 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8548  | total loss: \u001b[1m\u001b[32m1.55359\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8548 | loss: 1.55359 - acc: 0.6712 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8549  | total loss: \u001b[1m\u001b[32m1.44310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8549 | loss: 1.44310 - acc: 0.7041 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8550  | total loss: \u001b[1m\u001b[32m1.63563\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8550 | loss: 1.63563 - acc: 0.6480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8551  | total loss: \u001b[1m\u001b[32m1.51745\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8551 | loss: 1.51745 - acc: 0.6832 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8552  | total loss: \u001b[1m\u001b[32m1.41117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8552 | loss: 1.41117 - acc: 0.7149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8553  | total loss: \u001b[1m\u001b[32m1.31515\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8553 | loss: 1.31515 - acc: 0.7434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8554  | total loss: \u001b[1m\u001b[32m1.51451\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8554 | loss: 1.51451 - acc: 0.6833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8555  | total loss: \u001b[1m\u001b[32m1.40734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8555 | loss: 1.40734 - acc: 0.7150 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8556  | total loss: \u001b[1m\u001b[32m1.59281\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8556 | loss: 1.59281 - acc: 0.6578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8557  | total loss: \u001b[1m\u001b[32m1.47763\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8557 | loss: 1.47763 - acc: 0.6920 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8558  | total loss: \u001b[1m\u001b[32m1.70836\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8558 | loss: 1.70836 - acc: 0.6228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8559  | total loss: \u001b[1m\u001b[32m1.58206\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8559 | loss: 1.58206 - acc: 0.6605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8560  | total loss: \u001b[1m\u001b[32m1.78849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8560 | loss: 1.78849 - acc: 0.5945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8561  | total loss: \u001b[1m\u001b[32m1.65527\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8561 | loss: 1.65527 - acc: 0.6350 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8562  | total loss: \u001b[1m\u001b[32m1.87522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8562 | loss: 1.87522 - acc: 0.5715 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8563  | total loss: \u001b[1m\u001b[32m1.73497\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8563 | loss: 1.73497 - acc: 0.6144 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8564  | total loss: \u001b[1m\u001b[32m1.84837\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8564 | loss: 1.84837 - acc: 0.5744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8565  | total loss: \u001b[1m\u001b[32m1.71258\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8565 | loss: 1.71258 - acc: 0.6169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8566  | total loss: \u001b[1m\u001b[32m1.89093\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8566 | loss: 1.89093 - acc: 0.5552 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8567  | total loss: \u001b[1m\u001b[32m1.75275\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8567 | loss: 1.75275 - acc: 0.5997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8568  | total loss: \u001b[1m\u001b[32m1.87023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8568 | loss: 1.87023 - acc: 0.5612 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8569  | total loss: \u001b[1m\u001b[32m1.73600\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8569 | loss: 1.73600 - acc: 0.6050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8570  | total loss: \u001b[1m\u001b[32m1.87880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8570 | loss: 1.87880 - acc: 0.5588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8571  | total loss: \u001b[1m\u001b[32m1.74536\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8571 | loss: 1.74536 - acc: 0.6029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8572  | total loss: \u001b[1m\u001b[32m1.89315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8572 | loss: 1.89315 - acc: 0.5498 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8573  | total loss: \u001b[1m\u001b[32m1.75985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8573 | loss: 1.75985 - acc: 0.5948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8574  | total loss: \u001b[1m\u001b[32m1.64031\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8574 | loss: 1.64031 - acc: 0.6353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8575  | total loss: \u001b[1m\u001b[32m1.53254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8575 | loss: 1.53254 - acc: 0.6718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8576  | total loss: \u001b[1m\u001b[32m1.73581\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8576 | loss: 1.73581 - acc: 0.6046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8577  | total loss: \u001b[1m\u001b[32m1.61785\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8577 | loss: 1.61785 - acc: 0.6442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8578  | total loss: \u001b[1m\u001b[32m1.51120\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8578 | loss: 1.51120 - acc: 0.6797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8579  | total loss: \u001b[1m\u001b[32m1.41425\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8579 | loss: 1.41425 - acc: 0.7118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8580  | total loss: \u001b[1m\u001b[32m1.63030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8580 | loss: 1.63030 - acc: 0.6406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8581  | total loss: \u001b[1m\u001b[32m1.51956\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8581 | loss: 1.51956 - acc: 0.6765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8582  | total loss: \u001b[1m\u001b[32m1.41896\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8582 | loss: 1.41896 - acc: 0.7089 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8583  | total loss: \u001b[1m\u001b[32m1.32710\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8583 | loss: 1.32710 - acc: 0.7380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8584  | total loss: \u001b[1m\u001b[32m1.24276\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8584 | loss: 1.24276 - acc: 0.7642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8585  | total loss: \u001b[1m\u001b[32m1.16491\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8585 | loss: 1.16491 - acc: 0.7878 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8586  | total loss: \u001b[1m\u001b[32m1.38047\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8586 | loss: 1.38047 - acc: 0.7233 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8587  | total loss: \u001b[1m\u001b[32m1.28545\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8587 | loss: 1.28545 - acc: 0.7510 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8588  | total loss: \u001b[1m\u001b[32m1.48990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8588 | loss: 1.48990 - acc: 0.6901 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8589  | total loss: \u001b[1m\u001b[32m1.38174\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8589 | loss: 1.38174 - acc: 0.7211 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8590  | total loss: \u001b[1m\u001b[32m1.57686\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8590 | loss: 1.57686 - acc: 0.6633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8591  | total loss: \u001b[1m\u001b[32m1.45879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8591 | loss: 1.45879 - acc: 0.6970 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8592  | total loss: \u001b[1m\u001b[32m1.35197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8592 | loss: 1.35197 - acc: 0.7273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8593  | total loss: \u001b[1m\u001b[32m1.25498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8593 | loss: 1.25498 - acc: 0.7545 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8594  | total loss: \u001b[1m\u001b[32m1.49531\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8594 | loss: 1.49531 - acc: 0.6862 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8595  | total loss: \u001b[1m\u001b[32m1.38269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8595 | loss: 1.38269 - acc: 0.7176 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8596  | total loss: \u001b[1m\u001b[32m1.61438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8596 | loss: 1.61438 - acc: 0.6530 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8597  | total loss: \u001b[1m\u001b[32m1.48966\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8597 | loss: 1.48966 - acc: 0.6877 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8598  | total loss: \u001b[1m\u001b[32m1.70133\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8598 | loss: 1.70133 - acc: 0.6261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8599  | total loss: \u001b[1m\u001b[32m1.56854\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8599 | loss: 1.56854 - acc: 0.6635 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8600  | total loss: \u001b[1m\u001b[32m1.71907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8600 | loss: 1.71907 - acc: 0.6185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8601  | total loss: \u001b[1m\u001b[32m1.58558\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8601 | loss: 1.58558 - acc: 0.6567 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8602  | total loss: \u001b[1m\u001b[32m1.78002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8602 | loss: 1.78002 - acc: 0.5910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8603  | total loss: \u001b[1m\u001b[32m1.64199\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8603 | loss: 1.64199 - acc: 0.6319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8604  | total loss: \u001b[1m\u001b[32m1.85634\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8604 | loss: 1.85634 - acc: 0.5687 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8605  | total loss: \u001b[1m\u001b[32m1.71272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8605 | loss: 1.71272 - acc: 0.6119 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8606  | total loss: \u001b[1m\u001b[32m1.58430\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8606 | loss: 1.58430 - acc: 0.6507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8607  | total loss: \u001b[1m\u001b[32m1.46907\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8607 | loss: 1.46907 - acc: 0.6856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8608  | total loss: \u001b[1m\u001b[32m1.68726\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8608 | loss: 1.68726 - acc: 0.6170 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8609  | total loss: \u001b[1m\u001b[32m1.56229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8609 | loss: 1.56229 - acc: 0.6553 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8610  | total loss: \u001b[1m\u001b[32m1.76218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8610 | loss: 1.76218 - acc: 0.5969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8611  | total loss: \u001b[1m\u001b[32m1.63076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8611 | loss: 1.63076 - acc: 0.6373 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8612  | total loss: \u001b[1m\u001b[32m1.51285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8612 | loss: 1.51285 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8613  | total loss: \u001b[1m\u001b[32m1.40661\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8613 | loss: 1.40661 - acc: 0.7062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8614  | total loss: \u001b[1m\u001b[32m1.61241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8614 | loss: 1.61241 - acc: 0.6427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8615  | total loss: \u001b[1m\u001b[32m1.49595\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8615 | loss: 1.49595 - acc: 0.6784 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8616  | total loss: \u001b[1m\u001b[32m1.39094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8616 | loss: 1.39094 - acc: 0.7106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8617  | total loss: \u001b[1m\u001b[32m1.29584\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8617 | loss: 1.29584 - acc: 0.7395 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8618  | total loss: \u001b[1m\u001b[32m1.54701\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8618 | loss: 1.54701 - acc: 0.6656 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8619  | total loss: \u001b[1m\u001b[32m1.43522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8619 | loss: 1.43522 - acc: 0.6990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8620  | total loss: \u001b[1m\u001b[32m1.33410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8620 | loss: 1.33410 - acc: 0.7291 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8621  | total loss: \u001b[1m\u001b[32m1.24222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8621 | loss: 1.24222 - acc: 0.7562 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8622  | total loss: \u001b[1m\u001b[32m1.15839\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8622 | loss: 1.15839 - acc: 0.7806 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8623  | total loss: \u001b[1m\u001b[32m1.08155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8623 | loss: 1.08155 - acc: 0.8025 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8624  | total loss: \u001b[1m\u001b[32m1.27535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8624 | loss: 1.27535 - acc: 0.7437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8625  | total loss: \u001b[1m\u001b[32m1.18440\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8625 | loss: 1.18440 - acc: 0.7693 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8626  | total loss: \u001b[1m\u001b[32m1.10146\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8626 | loss: 1.10146 - acc: 0.7924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8627  | total loss: \u001b[1m\u001b[32m1.02556\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8627 | loss: 1.02556 - acc: 0.8132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8628  | total loss: \u001b[1m\u001b[32m0.95583\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8628 | loss: 0.95583 - acc: 0.8318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8629  | total loss: \u001b[1m\u001b[32m0.89156\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8629 | loss: 0.89156 - acc: 0.8487 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8630  | total loss: \u001b[1m\u001b[32m0.83213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8630 | loss: 0.83213 - acc: 0.8638 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8631  | total loss: \u001b[1m\u001b[32m0.77701\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8631 | loss: 0.77701 - acc: 0.8774 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8632  | total loss: \u001b[1m\u001b[32m1.11018\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8632 | loss: 1.11018 - acc: 0.7897 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8633  | total loss: \u001b[1m\u001b[32m1.02495\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8633 | loss: 1.02495 - acc: 0.8107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8634  | total loss: \u001b[1m\u001b[32m1.33825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8634 | loss: 1.33825 - acc: 0.7296 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8635  | total loss: \u001b[1m\u001b[32m1.22946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8635 | loss: 1.22946 - acc: 0.7567 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8636  | total loss: \u001b[1m\u001b[32m1.50864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8636 | loss: 1.50864 - acc: 0.6881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8637  | total loss: \u001b[1m\u001b[32m1.38321\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8637 | loss: 1.38321 - acc: 0.7193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8638  | total loss: \u001b[1m\u001b[32m1.27063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8638 | loss: 1.27063 - acc: 0.7474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8639  | total loss: \u001b[1m\u001b[32m1.16938\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8639 | loss: 1.16938 - acc: 0.7727 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8640  | total loss: \u001b[1m\u001b[32m1.07811\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8640 | loss: 1.07811 - acc: 0.7954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8641  | total loss: \u001b[1m\u001b[32m0.99564\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8641 | loss: 0.99564 - acc: 0.8159 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8642  | total loss: \u001b[1m\u001b[32m1.23787\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8642 | loss: 1.23787 - acc: 0.7557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8643  | total loss: \u001b[1m\u001b[32m1.13902\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8643 | loss: 1.13902 - acc: 0.7801 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8644  | total loss: \u001b[1m\u001b[32m1.41140\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8644 | loss: 1.41140 - acc: 0.7093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8645  | total loss: \u001b[1m\u001b[32m1.29568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8645 | loss: 1.29568 - acc: 0.7383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8646  | total loss: \u001b[1m\u001b[32m1.57641\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8646 | loss: 1.57641 - acc: 0.6645 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8647  | total loss: \u001b[1m\u001b[32m1.44561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8647 | loss: 1.44561 - acc: 0.6980 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8648  | total loss: \u001b[1m\u001b[32m1.32868\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8648 | loss: 1.32868 - acc: 0.7282 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8649  | total loss: \u001b[1m\u001b[32m1.22394\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8649 | loss: 1.22394 - acc: 0.7554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8650  | total loss: \u001b[1m\u001b[32m1.44753\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8650 | loss: 1.44753 - acc: 0.6942 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8651  | total loss: \u001b[1m\u001b[32m1.33191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8651 | loss: 1.33191 - acc: 0.7247 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8652  | total loss: \u001b[1m\u001b[32m1.22834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8652 | loss: 1.22834 - acc: 0.7523 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8653  | total loss: \u001b[1m\u001b[32m1.13531\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8653 | loss: 1.13531 - acc: 0.7770 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8654  | total loss: \u001b[1m\u001b[32m1.36965\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8654 | loss: 1.36965 - acc: 0.7136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8655  | total loss: \u001b[1m\u001b[32m1.26293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8655 | loss: 1.26293 - acc: 0.7423 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8656  | total loss: \u001b[1m\u001b[32m1.16711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8656 | loss: 1.16711 - acc: 0.7680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8657  | total loss: \u001b[1m\u001b[32m1.08082\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8657 | loss: 1.08082 - acc: 0.7912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8658  | total loss: \u001b[1m\u001b[32m1.36719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8658 | loss: 1.36719 - acc: 0.7121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8659  | total loss: \u001b[1m\u001b[32m1.26104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8659 | loss: 1.26104 - acc: 0.7409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8660  | total loss: \u001b[1m\u001b[32m1.52609\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8660 | loss: 1.52609 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8661  | total loss: \u001b[1m\u001b[32m1.40512\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8661 | loss: 1.40512 - acc: 0.7001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8662  | total loss: \u001b[1m\u001b[32m1.62423\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8662 | loss: 1.62423 - acc: 0.6373 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8663  | total loss: \u001b[1m\u001b[32m1.49525\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8663 | loss: 1.49525 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8664  | total loss: \u001b[1m\u001b[32m1.74534\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8664 | loss: 1.74534 - acc: 0.6062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8665  | total loss: \u001b[1m\u001b[32m1.60666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8665 | loss: 1.60666 - acc: 0.6456 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8666  | total loss: \u001b[1m\u001b[32m1.79778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8666 | loss: 1.79778 - acc: 0.5953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8667  | total loss: \u001b[1m\u001b[32m1.65665\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8667 | loss: 1.65665 - acc: 0.6358 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8668  | total loss: \u001b[1m\u001b[32m1.83826\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8668 | loss: 1.83826 - acc: 0.5793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8669  | total loss: \u001b[1m\u001b[32m1.69610\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8669 | loss: 1.69610 - acc: 0.6214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8670  | total loss: \u001b[1m\u001b[32m1.56943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8670 | loss: 1.56943 - acc: 0.6593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8671  | total loss: \u001b[1m\u001b[32m1.45618\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8671 | loss: 1.45618 - acc: 0.6933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8672  | total loss: \u001b[1m\u001b[32m1.68994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8672 | loss: 1.68994 - acc: 0.6240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8673  | total loss: \u001b[1m\u001b[32m1.56594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8673 | loss: 1.56594 - acc: 0.6616 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8674  | total loss: \u001b[1m\u001b[32m1.45485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8674 | loss: 1.45485 - acc: 0.6954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8675  | total loss: \u001b[1m\u001b[32m1.35488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8675 | loss: 1.35488 - acc: 0.7259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8676  | total loss: \u001b[1m\u001b[32m1.26449\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8676 | loss: 1.26449 - acc: 0.7533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8677  | total loss: \u001b[1m\u001b[32m1.18234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8677 | loss: 1.18234 - acc: 0.7780 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8678  | total loss: \u001b[1m\u001b[32m1.42030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8678 | loss: 1.42030 - acc: 0.7002 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8679  | total loss: \u001b[1m\u001b[32m1.32119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8679 | loss: 1.32119 - acc: 0.7302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8680  | total loss: \u001b[1m\u001b[32m1.23137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8680 | loss: 1.23137 - acc: 0.7571 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8681  | total loss: \u001b[1m\u001b[32m1.14960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8681 | loss: 1.14960 - acc: 0.7814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8682  | total loss: \u001b[1m\u001b[32m1.07479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8682 | loss: 1.07479 - acc: 0.8033 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8683  | total loss: \u001b[1m\u001b[32m1.00603\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8683 | loss: 1.00603 - acc: 0.8230 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8684  | total loss: \u001b[1m\u001b[32m0.94254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8684 | loss: 0.94254 - acc: 0.8407 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8685  | total loss: \u001b[1m\u001b[32m0.88366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8685 | loss: 0.88366 - acc: 0.8566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8686  | total loss: \u001b[1m\u001b[32m1.18147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8686 | loss: 1.18147 - acc: 0.7709 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8687  | total loss: \u001b[1m\u001b[32m1.09602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8687 | loss: 1.09602 - acc: 0.7938 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8688  | total loss: \u001b[1m\u001b[32m1.36717\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8688 | loss: 1.36717 - acc: 0.7216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8689  | total loss: \u001b[1m\u001b[32m1.26191\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8689 | loss: 1.26191 - acc: 0.7494 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8690  | total loss: \u001b[1m\u001b[32m1.16674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8690 | loss: 1.16674 - acc: 0.7745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8691  | total loss: \u001b[1m\u001b[32m1.08043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8691 | loss: 1.08043 - acc: 0.7970 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8692  | total loss: \u001b[1m\u001b[32m1.00191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8692 | loss: 1.00191 - acc: 0.8173 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8693  | total loss: \u001b[1m\u001b[32m0.93028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8693 | loss: 0.93028 - acc: 0.8356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8694  | total loss: \u001b[1m\u001b[32m1.25806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8694 | loss: 1.25806 - acc: 0.7520 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8695  | total loss: \u001b[1m\u001b[32m1.15954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8695 | loss: 1.15954 - acc: 0.7768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8696  | total loss: \u001b[1m\u001b[32m1.07050\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8696 | loss: 1.07050 - acc: 0.7992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8697  | total loss: \u001b[1m\u001b[32m0.98982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8697 | loss: 0.98982 - acc: 0.8192 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8698  | total loss: \u001b[1m\u001b[32m1.31337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8698 | loss: 1.31337 - acc: 0.7373 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8699  | total loss: \u001b[1m\u001b[32m1.20791\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8699 | loss: 1.20791 - acc: 0.7636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8700  | total loss: \u001b[1m\u001b[32m1.51594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8700 | loss: 1.51594 - acc: 0.6872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8701  | total loss: \u001b[1m\u001b[32m1.39093\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8701 | loss: 1.39093 - acc: 0.7185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8702  | total loss: \u001b[1m\u001b[32m1.66007\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8702 | loss: 1.66007 - acc: 0.6467 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8703  | total loss: \u001b[1m\u001b[32m1.52225\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8703 | loss: 1.52225 - acc: 0.6820 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8704  | total loss: \u001b[1m\u001b[32m1.72674\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8704 | loss: 1.72674 - acc: 0.6209 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8705  | total loss: \u001b[1m\u001b[32m1.58454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8705 | loss: 1.58454 - acc: 0.6588 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8706  | total loss: \u001b[1m\u001b[32m1.80172\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8706 | loss: 1.80172 - acc: 0.6001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8707  | total loss: \u001b[1m\u001b[32m1.65485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8707 | loss: 1.65485 - acc: 0.6401 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8708  | total loss: \u001b[1m\u001b[32m1.87057\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8708 | loss: 1.87057 - acc: 0.5761 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8709  | total loss: \u001b[1m\u001b[32m1.72023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8709 | loss: 1.72023 - acc: 0.6185 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8710  | total loss: \u001b[1m\u001b[32m1.58651\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8710 | loss: 1.58651 - acc: 0.6566 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8711  | total loss: \u001b[1m\u001b[32m1.46727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8711 | loss: 1.46727 - acc: 0.6910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8712  | total loss: \u001b[1m\u001b[32m1.68681\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8712 | loss: 1.68681 - acc: 0.6219 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8713  | total loss: \u001b[1m\u001b[32m1.55954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8713 | loss: 1.55954 - acc: 0.6597 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8714  | total loss: \u001b[1m\u001b[32m1.70991\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8714 | loss: 1.70991 - acc: 0.6151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8715  | total loss: \u001b[1m\u001b[32m1.58240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8715 | loss: 1.58240 - acc: 0.6536 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8716  | total loss: \u001b[1m\u001b[32m1.76534\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8716 | loss: 1.76534 - acc: 0.5954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8717  | total loss: \u001b[1m\u001b[32m1.63434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8717 | loss: 1.63434 - acc: 0.6359 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8718  | total loss: \u001b[1m\u001b[32m1.80823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8718 | loss: 1.80823 - acc: 0.5794 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8719  | total loss: \u001b[1m\u001b[32m1.67516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8719 | loss: 1.67516 - acc: 0.6215 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8720  | total loss: \u001b[1m\u001b[32m1.55625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8720 | loss: 1.55625 - acc: 0.6593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8721  | total loss: \u001b[1m\u001b[32m1.44953\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8721 | loss: 1.44953 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8722  | total loss: \u001b[1m\u001b[32m1.35327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8722 | loss: 1.35327 - acc: 0.7241 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8723  | total loss: \u001b[1m\u001b[32m1.26598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8723 | loss: 1.26598 - acc: 0.7517 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8724  | total loss: \u001b[1m\u001b[32m1.18638\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8724 | loss: 1.18638 - acc: 0.7765 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8725  | total loss: \u001b[1m\u001b[32m1.11336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8725 | loss: 1.11336 - acc: 0.7988 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8726  | total loss: \u001b[1m\u001b[32m1.32512\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8726 | loss: 1.32512 - acc: 0.7261 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8727  | total loss: \u001b[1m\u001b[32m1.23579\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8727 | loss: 1.23579 - acc: 0.7535 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8728  | total loss: \u001b[1m\u001b[32m1.15429\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8728 | loss: 1.15429 - acc: 0.7781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8729  | total loss: \u001b[1m\u001b[32m1.07958\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8729 | loss: 1.07958 - acc: 0.8003 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8730  | total loss: \u001b[1m\u001b[32m1.01076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8730 | loss: 1.01076 - acc: 0.8203 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8731  | total loss: \u001b[1m\u001b[32m0.94709\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8731 | loss: 0.94709 - acc: 0.8383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8732  | total loss: \u001b[1m\u001b[32m1.25824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8732 | loss: 1.25824 - acc: 0.7544 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8733  | total loss: \u001b[1m\u001b[32m1.16712\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8733 | loss: 1.16712 - acc: 0.7790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8734  | total loss: \u001b[1m\u001b[32m1.39460\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8734 | loss: 1.39460 - acc: 0.7154 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8735  | total loss: \u001b[1m\u001b[32m1.28851\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8735 | loss: 1.28851 - acc: 0.7438 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8736  | total loss: \u001b[1m\u001b[32m1.54045\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8736 | loss: 1.54045 - acc: 0.6766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8737  | total loss: \u001b[1m\u001b[32m1.41951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8737 | loss: 1.41951 - acc: 0.7089 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8738  | total loss: \u001b[1m\u001b[32m1.67060\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8738 | loss: 1.67060 - acc: 0.6380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8739  | total loss: \u001b[1m\u001b[32m1.53733\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8739 | loss: 1.53733 - acc: 0.6742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8740  | total loss: \u001b[1m\u001b[32m1.77320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8740 | loss: 1.77320 - acc: 0.6068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8741  | total loss: \u001b[1m\u001b[32m1.63116\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8741 | loss: 1.63116 - acc: 0.6461 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8742  | total loss: \u001b[1m\u001b[32m1.79207\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8742 | loss: 1.79207 - acc: 0.5958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8743  | total loss: \u001b[1m\u001b[32m1.65008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8743 | loss: 1.65008 - acc: 0.6362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8744  | total loss: \u001b[1m\u001b[32m1.88976\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8744 | loss: 1.88976 - acc: 0.5726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8745  | total loss: \u001b[1m\u001b[32m1.74037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8745 | loss: 1.74037 - acc: 0.6153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8746  | total loss: \u001b[1m\u001b[32m1.60699\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8746 | loss: 1.60699 - acc: 0.6538 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8747  | total loss: \u001b[1m\u001b[32m1.48756\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8747 | loss: 1.48756 - acc: 0.6884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8748  | total loss: \u001b[1m\u001b[32m1.71507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8748 | loss: 1.71507 - acc: 0.6196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8749  | total loss: \u001b[1m\u001b[32m1.58588\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8749 | loss: 1.58588 - acc: 0.6576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8750  | total loss: \u001b[1m\u001b[32m1.47001\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8750 | loss: 1.47001 - acc: 0.6919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8751  | total loss: \u001b[1m\u001b[32m1.36572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8751 | loss: 1.36572 - acc: 0.7227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8752  | total loss: \u001b[1m\u001b[32m1.60157\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8752 | loss: 1.60157 - acc: 0.6504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8753  | total loss: \u001b[1m\u001b[32m1.48412\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8753 | loss: 1.48412 - acc: 0.6854 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8754  | total loss: \u001b[1m\u001b[32m1.65680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8754 | loss: 1.65680 - acc: 0.6311 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8755  | total loss: \u001b[1m\u001b[32m1.53438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8755 | loss: 1.53438 - acc: 0.6680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8756  | total loss: \u001b[1m\u001b[32m1.75760\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8756 | loss: 1.75760 - acc: 0.6012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8757  | total loss: \u001b[1m\u001b[32m1.62612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8757 | loss: 1.62612 - acc: 0.6411 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8758  | total loss: \u001b[1m\u001b[32m1.79640\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8758 | loss: 1.79640 - acc: 0.5913 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8759  | total loss: \u001b[1m\u001b[32m1.66241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8759 | loss: 1.66241 - acc: 0.6321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8760  | total loss: \u001b[1m\u001b[32m1.85431\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8760 | loss: 1.85431 - acc: 0.5689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8761  | total loss: \u001b[1m\u001b[32m1.71611\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8761 | loss: 1.71611 - acc: 0.6120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8762  | total loss: \u001b[1m\u001b[32m1.84784\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8762 | loss: 1.84784 - acc: 0.5723 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8763  | total loss: \u001b[1m\u001b[32m1.71197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8763 | loss: 1.71197 - acc: 0.6150 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8764  | total loss: \u001b[1m\u001b[32m1.86112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8764 | loss: 1.86112 - acc: 0.5607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8765  | total loss: \u001b[1m\u001b[32m1.72555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8765 | loss: 1.72555 - acc: 0.6046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8766  | total loss: \u001b[1m\u001b[32m1.85530\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8766 | loss: 1.85530 - acc: 0.5584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8767  | total loss: \u001b[1m\u001b[32m1.72188\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8767 | loss: 1.72188 - acc: 0.6026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8768  | total loss: \u001b[1m\u001b[32m1.88232\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8768 | loss: 1.88232 - acc: 0.5495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8769  | total loss: \u001b[1m\u001b[32m1.74773\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8769 | loss: 1.74773 - acc: 0.5945 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8770  | total loss: \u001b[1m\u001b[32m1.90460\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8770 | loss: 1.90460 - acc: 0.5422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8771  | total loss: \u001b[1m\u001b[32m1.76931\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8771 | loss: 1.76931 - acc: 0.5880 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8772  | total loss: \u001b[1m\u001b[32m1.89122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8772 | loss: 1.89122 - acc: 0.5435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8773  | total loss: \u001b[1m\u001b[32m1.75871\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8773 | loss: 1.75871 - acc: 0.5891 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8774  | total loss: \u001b[1m\u001b[32m1.92058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8774 | loss: 1.92058 - acc: 0.5302 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8775  | total loss: \u001b[1m\u001b[32m1.78651\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8775 | loss: 1.78651 - acc: 0.5772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8776  | total loss: \u001b[1m\u001b[32m1.94507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8776 | loss: 1.94507 - acc: 0.5195 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8777  | total loss: \u001b[1m\u001b[32m1.80997\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8777 | loss: 1.80997 - acc: 0.5675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8778  | total loss: \u001b[1m\u001b[32m1.98413\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8778 | loss: 1.98413 - acc: 0.5108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8779  | total loss: \u001b[1m\u001b[32m1.84661\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8779 | loss: 1.84661 - acc: 0.5597 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8780  | total loss: \u001b[1m\u001b[32m1.96283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8780 | loss: 1.96283 - acc: 0.5109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8781  | total loss: \u001b[1m\u001b[32m1.82879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8781 | loss: 1.82879 - acc: 0.5598 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8782  | total loss: \u001b[1m\u001b[32m1.95505\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8782 | loss: 1.95505 - acc: 0.5109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8783  | total loss: \u001b[1m\u001b[32m1.82290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8783 | loss: 1.82290 - acc: 0.5599 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8784  | total loss: \u001b[1m\u001b[32m1.70412\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8784 | loss: 1.70412 - acc: 0.6039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8785  | total loss: \u001b[1m\u001b[32m1.59677\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8785 | loss: 1.59677 - acc: 0.6435 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8786  | total loss: \u001b[1m\u001b[32m1.76306\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8786 | loss: 1.76306 - acc: 0.5863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8787  | total loss: \u001b[1m\u001b[32m1.64851\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8787 | loss: 1.64851 - acc: 0.6276 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8788  | total loss: \u001b[1m\u001b[32m1.84207\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8788 | loss: 1.84207 - acc: 0.5649 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8789  | total loss: \u001b[1m\u001b[32m1.71873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8789 | loss: 1.71873 - acc: 0.6084 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8790  | total loss: \u001b[1m\u001b[32m1.60713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8790 | loss: 1.60713 - acc: 0.6476 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8791  | total loss: \u001b[1m\u001b[32m1.50560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8791 | loss: 1.50560 - acc: 0.6828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8792  | total loss: \u001b[1m\u001b[32m1.41270\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8792 | loss: 1.41270 - acc: 0.7145 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8793  | total loss: \u001b[1m\u001b[32m1.32719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8793 | loss: 1.32719 - acc: 0.7431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8794  | total loss: \u001b[1m\u001b[32m1.24805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8794 | loss: 1.24805 - acc: 0.7688 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8795  | total loss: \u001b[1m\u001b[32m1.17441\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8795 | loss: 1.17441 - acc: 0.7919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8796  | total loss: \u001b[1m\u001b[32m1.38735\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8796 | loss: 1.38735 - acc: 0.7198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8797  | total loss: \u001b[1m\u001b[32m1.29562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8797 | loss: 1.29562 - acc: 0.7479 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8798  | total loss: \u001b[1m\u001b[32m1.54155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8798 | loss: 1.54155 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8799  | total loss: \u001b[1m\u001b[32m1.43176\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8799 | loss: 1.43176 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8800  | total loss: \u001b[1m\u001b[32m1.62309\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8800 | loss: 1.62309 - acc: 0.6423 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8801  | total loss: \u001b[1m\u001b[32m1.50371\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8801 | loss: 1.50371 - acc: 0.6781 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8802  | total loss: \u001b[1m\u001b[32m1.39560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8802 | loss: 1.39560 - acc: 0.7103 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8803  | total loss: \u001b[1m\u001b[32m1.29734\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8803 | loss: 1.29734 - acc: 0.7393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8804  | total loss: \u001b[1m\u001b[32m1.48551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8804 | loss: 1.48551 - acc: 0.6796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8805  | total loss: \u001b[1m\u001b[32m1.37659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8805 | loss: 1.37659 - acc: 0.7117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8806  | total loss: \u001b[1m\u001b[32m1.58668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8806 | loss: 1.58668 - acc: 0.6476 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8807  | total loss: \u001b[1m\u001b[32m1.46691\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8807 | loss: 1.46691 - acc: 0.6829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8808  | total loss: \u001b[1m\u001b[32m1.61553\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8808 | loss: 1.61553 - acc: 0.6360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8809  | total loss: \u001b[1m\u001b[32m1.49276\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8809 | loss: 1.49276 - acc: 0.6724 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8810  | total loss: \u001b[1m\u001b[32m1.38212\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8810 | loss: 1.38212 - acc: 0.7052 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8811  | total loss: \u001b[1m\u001b[32m1.28206\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8811 | loss: 1.28206 - acc: 0.7347 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8812  | total loss: \u001b[1m\u001b[32m1.19125\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8812 | loss: 1.19125 - acc: 0.7612 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8813  | total loss: \u001b[1m\u001b[32m1.10851\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8813 | loss: 1.10851 - acc: 0.7851 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8814  | total loss: \u001b[1m\u001b[32m1.39254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8814 | loss: 1.39254 - acc: 0.7066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8815  | total loss: \u001b[1m\u001b[32m1.28818\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8815 | loss: 1.28818 - acc: 0.7359 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8816  | total loss: \u001b[1m\u001b[32m1.54722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8816 | loss: 1.54722 - acc: 0.6623 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8817  | total loss: \u001b[1m\u001b[32m1.42715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8817 | loss: 1.42715 - acc: 0.6961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8818  | total loss: \u001b[1m\u001b[32m1.64341\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8818 | loss: 1.64341 - acc: 0.6408 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8819  | total loss: \u001b[1m\u001b[32m1.51434\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8819 | loss: 1.51434 - acc: 0.6767 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8820  | total loss: \u001b[1m\u001b[32m1.76289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8820 | loss: 1.76289 - acc: 0.6090 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8821  | total loss: \u001b[1m\u001b[32m1.62319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8821 | loss: 1.62319 - acc: 0.6481 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8822  | total loss: \u001b[1m\u001b[32m1.78911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8822 | loss: 1.78911 - acc: 0.5976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8823  | total loss: \u001b[1m\u001b[32m1.64861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8823 | loss: 1.64861 - acc: 0.6378 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8824  | total loss: \u001b[1m\u001b[32m1.52293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8824 | loss: 1.52293 - acc: 0.6740 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8825  | total loss: \u001b[1m\u001b[32m1.41015\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8825 | loss: 1.41015 - acc: 0.7066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8826  | total loss: \u001b[1m\u001b[32m1.60004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8826 | loss: 1.60004 - acc: 0.6503 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8827  | total loss: \u001b[1m\u001b[32m1.48006\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8827 | loss: 1.48006 - acc: 0.6852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8828  | total loss: \u001b[1m\u001b[32m1.71109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8828 | loss: 1.71109 - acc: 0.6167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8829  | total loss: \u001b[1m\u001b[32m1.58115\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8829 | loss: 1.58115 - acc: 0.6550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8830  | total loss: \u001b[1m\u001b[32m1.80204\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8830 | loss: 1.80204 - acc: 0.5895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8831  | total loss: \u001b[1m\u001b[32m1.66472\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8831 | loss: 1.66472 - acc: 0.6306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8832  | total loss: \u001b[1m\u001b[32m1.81778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8832 | loss: 1.81778 - acc: 0.5818 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8833  | total loss: \u001b[1m\u001b[32m1.68081\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8833 | loss: 1.68081 - acc: 0.6236 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8834  | total loss: \u001b[1m\u001b[32m1.86436\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8834 | loss: 1.86436 - acc: 0.5613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8835  | total loss: \u001b[1m\u001b[32m1.72478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8835 | loss: 1.72478 - acc: 0.6051 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8836  | total loss: \u001b[1m\u001b[32m1.87934\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8836 | loss: 1.87934 - acc: 0.5518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8837  | total loss: \u001b[1m\u001b[32m1.74048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8837 | loss: 1.74048 - acc: 0.5966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8838  | total loss: \u001b[1m\u001b[32m1.88977\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8838 | loss: 1.88977 - acc: 0.5512 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8839  | total loss: \u001b[1m\u001b[32m1.75212\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8839 | loss: 1.75212 - acc: 0.5961 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8840  | total loss: \u001b[1m\u001b[32m1.93274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8840 | loss: 1.93274 - acc: 0.5365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8841  | total loss: \u001b[1m\u001b[32m1.79310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8841 | loss: 1.79310 - acc: 0.5828 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8842  | total loss: \u001b[1m\u001b[32m1.95468\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8842 | loss: 1.95468 - acc: 0.5317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8843  | total loss: \u001b[1m\u001b[32m1.81509\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8843 | loss: 1.81509 - acc: 0.5785 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8844  | total loss: \u001b[1m\u001b[32m1.98043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8844 | loss: 1.98043 - acc: 0.5207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8845  | total loss: \u001b[1m\u001b[32m1.84044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8845 | loss: 1.84044 - acc: 0.5686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8846  | total loss: \u001b[1m\u001b[32m1.71521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8846 | loss: 1.71521 - acc: 0.6117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8847  | total loss: \u001b[1m\u001b[32m1.60266\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8847 | loss: 1.60266 - acc: 0.6506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8848  | total loss: \u001b[1m\u001b[32m1.80671\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8848 | loss: 1.80671 - acc: 0.5855 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8849  | total loss: \u001b[1m\u001b[32m1.68496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8849 | loss: 1.68496 - acc: 0.6270 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8850  | total loss: \u001b[1m\u001b[32m1.57516\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8850 | loss: 1.57516 - acc: 0.6643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8851  | total loss: \u001b[1m\u001b[32m1.47562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8851 | loss: 1.47562 - acc: 0.6978 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8852  | total loss: \u001b[1m\u001b[32m1.65880\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8852 | loss: 1.65880 - acc: 0.6352 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8853  | total loss: \u001b[1m\u001b[32m1.54925\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8853 | loss: 1.54925 - acc: 0.6717 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8854  | total loss: \u001b[1m\u001b[32m1.44974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8854 | loss: 1.44974 - acc: 0.7045 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8855  | total loss: \u001b[1m\u001b[32m1.35885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8855 | loss: 1.35885 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8856  | total loss: \u001b[1m\u001b[32m1.27538\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8856 | loss: 1.27538 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8857  | total loss: \u001b[1m\u001b[32m1.19832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8857 | loss: 1.19832 - acc: 0.7846 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8858  | total loss: \u001b[1m\u001b[32m1.39507\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8858 | loss: 1.39507 - acc: 0.7204 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8859  | total loss: \u001b[1m\u001b[32m1.30254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8859 | loss: 1.30254 - acc: 0.7484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8860  | total loss: \u001b[1m\u001b[32m1.53998\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8860 | loss: 1.53998 - acc: 0.6735 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8861  | total loss: \u001b[1m\u001b[32m1.43074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8861 | loss: 1.43074 - acc: 0.7062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8862  | total loss: \u001b[1m\u001b[32m1.61347\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8862 | loss: 1.61347 - acc: 0.6427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8863  | total loss: \u001b[1m\u001b[32m1.49574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8863 | loss: 1.49574 - acc: 0.6784 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8864  | total loss: \u001b[1m\u001b[32m1.69883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8864 | loss: 1.69883 - acc: 0.6177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8865  | total loss: \u001b[1m\u001b[32m1.57216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8865 | loss: 1.57216 - acc: 0.6560 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8866  | total loss: \u001b[1m\u001b[32m1.45793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8866 | loss: 1.45793 - acc: 0.6904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8867  | total loss: \u001b[1m\u001b[32m1.35454\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8867 | loss: 1.35454 - acc: 0.7213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8868  | total loss: \u001b[1m\u001b[32m1.59589\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8868 | loss: 1.59589 - acc: 0.6492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8869  | total loss: \u001b[1m\u001b[32m1.47775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8869 | loss: 1.47775 - acc: 0.6843 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8870  | total loss: \u001b[1m\u001b[32m1.37101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8870 | loss: 1.37101 - acc: 0.7158 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8871  | total loss: \u001b[1m\u001b[32m1.27420\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8871 | loss: 1.27420 - acc: 0.7443 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8872  | total loss: \u001b[1m\u001b[32m1.52269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8872 | loss: 1.52269 - acc: 0.6698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8873  | total loss: \u001b[1m\u001b[32m1.40954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8873 | loss: 1.40954 - acc: 0.7029 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8874  | total loss: \u001b[1m\u001b[32m1.62954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8874 | loss: 1.62954 - acc: 0.6397 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8875  | total loss: \u001b[1m\u001b[32m1.50537\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8875 | loss: 1.50537 - acc: 0.6757 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8876  | total loss: \u001b[1m\u001b[32m1.69288\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8876 | loss: 1.69288 - acc: 0.6153 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8877  | total loss: \u001b[1m\u001b[32m1.56272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8877 | loss: 1.56272 - acc: 0.6538 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8878  | total loss: \u001b[1m\u001b[32m1.78712\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8878 | loss: 1.78712 - acc: 0.5884 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8879  | total loss: \u001b[1m\u001b[32m1.64858\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8879 | loss: 1.64858 - acc: 0.6296 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8880  | total loss: \u001b[1m\u001b[32m1.85612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8880 | loss: 1.85612 - acc: 0.5666 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8881  | total loss: \u001b[1m\u001b[32m1.71234\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8881 | loss: 1.71234 - acc: 0.6099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8882  | total loss: \u001b[1m\u001b[32m1.92354\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8882 | loss: 1.92354 - acc: 0.5489 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8883  | total loss: \u001b[1m\u001b[32m1.77522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8883 | loss: 1.77522 - acc: 0.5941 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8884  | total loss: \u001b[1m\u001b[32m1.94177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8884 | loss: 1.94177 - acc: 0.5418 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8885  | total loss: \u001b[1m\u001b[32m1.79411\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8885 | loss: 1.79411 - acc: 0.5876 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8886  | total loss: \u001b[1m\u001b[32m1.97848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8886 | loss: 1.97848 - acc: 0.5289 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8887  | total loss: \u001b[1m\u001b[32m1.82974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8887 | loss: 1.82974 - acc: 0.5760 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8888  | total loss: \u001b[1m\u001b[32m1.97379\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8888 | loss: 1.97379 - acc: 0.5255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8889  | total loss: \u001b[1m\u001b[32m1.82814\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8889 | loss: 1.82814 - acc: 0.5730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8890  | total loss: \u001b[1m\u001b[32m2.00252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8890 | loss: 2.00252 - acc: 0.5157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8891  | total loss: \u001b[1m\u001b[32m1.85653\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8891 | loss: 1.85653 - acc: 0.5641 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8892  | total loss: \u001b[1m\u001b[32m2.01059\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8892 | loss: 2.01059 - acc: 0.5148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8893  | total loss: \u001b[1m\u001b[32m1.86618\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8893 | loss: 1.86618 - acc: 0.5633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8894  | total loss: \u001b[1m\u001b[32m1.93819\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8894 | loss: 1.93819 - acc: 0.5356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8895  | total loss: \u001b[1m\u001b[32m1.80292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8895 | loss: 1.80292 - acc: 0.5820 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8896  | total loss: \u001b[1m\u001b[32m1.68163\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8896 | loss: 1.68163 - acc: 0.6238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8897  | total loss: \u001b[1m\u001b[32m1.57232\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8897 | loss: 1.57232 - acc: 0.6614 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8898  | total loss: \u001b[1m\u001b[32m1.69356\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8898 | loss: 1.69356 - acc: 0.6167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8899  | total loss: \u001b[1m\u001b[32m1.58226\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8899 | loss: 1.58226 - acc: 0.6551 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8900  | total loss: \u001b[1m\u001b[32m1.78061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8900 | loss: 1.78061 - acc: 0.5895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8901  | total loss: \u001b[1m\u001b[32m1.66008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8901 | loss: 1.66008 - acc: 0.6306 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8902  | total loss: \u001b[1m\u001b[32m1.55119\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8902 | loss: 1.55119 - acc: 0.6675 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8903  | total loss: \u001b[1m\u001b[32m1.45230\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8903 | loss: 1.45230 - acc: 0.7008 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8904  | total loss: \u001b[1m\u001b[32m1.36199\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8904 | loss: 1.36199 - acc: 0.7307 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8905  | total loss: \u001b[1m\u001b[32m1.27906\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8905 | loss: 1.27906 - acc: 0.7576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8906  | total loss: \u001b[1m\u001b[32m1.20247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8906 | loss: 1.20247 - acc: 0.7819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8907  | total loss: \u001b[1m\u001b[32m1.13137\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8907 | loss: 1.13137 - acc: 0.8037 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8908  | total loss: \u001b[1m\u001b[32m1.34403\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8908 | loss: 1.34403 - acc: 0.7305 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8909  | total loss: \u001b[1m\u001b[32m1.25494\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8909 | loss: 1.25494 - acc: 0.7574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8910  | total loss: \u001b[1m\u001b[32m1.50156\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8910 | loss: 1.50156 - acc: 0.6817 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8911  | total loss: \u001b[1m\u001b[32m1.39426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8911 | loss: 1.39426 - acc: 0.7135 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8912  | total loss: \u001b[1m\u001b[32m1.55280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8912 | loss: 1.55280 - acc: 0.6636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8913  | total loss: \u001b[1m\u001b[32m1.43892\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8913 | loss: 1.43892 - acc: 0.6972 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8914  | total loss: \u001b[1m\u001b[32m1.33569\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8914 | loss: 1.33569 - acc: 0.7275 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8915  | total loss: \u001b[1m\u001b[32m1.24178\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8915 | loss: 1.24178 - acc: 0.7548 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8916  | total loss: \u001b[1m\u001b[32m1.15602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8916 | loss: 1.15602 - acc: 0.7793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8917  | total loss: \u001b[1m\u001b[32m1.07740\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8917 | loss: 1.07740 - acc: 0.8013 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8918  | total loss: \u001b[1m\u001b[32m1.36116\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8918 | loss: 1.36116 - acc: 0.7212 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8919  | total loss: \u001b[1m\u001b[32m1.25982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8919 | loss: 1.25982 - acc: 0.7491 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8920  | total loss: \u001b[1m\u001b[32m1.48189\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8920 | loss: 1.48189 - acc: 0.6813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8921  | total loss: \u001b[1m\u001b[32m1.36755\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8921 | loss: 1.36755 - acc: 0.7132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8922  | total loss: \u001b[1m\u001b[32m1.60954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8922 | loss: 1.60954 - acc: 0.6490 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8923  | total loss: \u001b[1m\u001b[32m1.48248\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8923 | loss: 1.48248 - acc: 0.6841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8924  | total loss: \u001b[1m\u001b[32m1.71149\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8924 | loss: 1.71149 - acc: 0.6157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8925  | total loss: \u001b[1m\u001b[32m1.57518\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8925 | loss: 1.57518 - acc: 0.6541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8926  | total loss: \u001b[1m\u001b[32m1.80571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8926 | loss: 1.80571 - acc: 0.5887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8927  | total loss: \u001b[1m\u001b[32m1.66172\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8927 | loss: 1.66172 - acc: 0.6298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8928  | total loss: \u001b[1m\u001b[32m1.81801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8928 | loss: 1.81801 - acc: 0.5883 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8929  | total loss: \u001b[1m\u001b[32m1.67496\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8929 | loss: 1.67496 - acc: 0.6295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8930  | total loss: \u001b[1m\u001b[32m1.84306\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8930 | loss: 1.84306 - acc: 0.5737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8931  | total loss: \u001b[1m\u001b[32m1.69987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8931 | loss: 1.69987 - acc: 0.6163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8932  | total loss: \u001b[1m\u001b[32m1.86058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8932 | loss: 1.86058 - acc: 0.5689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8933  | total loss: \u001b[1m\u001b[32m1.71819\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8933 | loss: 1.71819 - acc: 0.6121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8934  | total loss: \u001b[1m\u001b[32m1.59105\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8934 | loss: 1.59105 - acc: 0.6508 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8935  | total loss: \u001b[1m\u001b[32m1.47713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8935 | loss: 1.47713 - acc: 0.6858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8936  | total loss: \u001b[1m\u001b[32m1.37461\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8936 | loss: 1.37461 - acc: 0.7172 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8937  | total loss: \u001b[1m\u001b[32m1.28192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8937 | loss: 1.28192 - acc: 0.7455 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8938  | total loss: \u001b[1m\u001b[32m1.47341\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8938 | loss: 1.47341 - acc: 0.6852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8939  | total loss: \u001b[1m\u001b[32m1.36993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8939 | loss: 1.36993 - acc: 0.7167 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8940  | total loss: \u001b[1m\u001b[32m1.58952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8940 | loss: 1.58952 - acc: 0.6522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8941  | total loss: \u001b[1m\u001b[32m1.47421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8941 | loss: 1.47421 - acc: 0.6869 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8942  | total loss: \u001b[1m\u001b[32m1.69366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8942 | loss: 1.69366 - acc: 0.6183 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8943  | total loss: \u001b[1m\u001b[32m1.56841\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8943 | loss: 1.56841 - acc: 0.6564 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8944  | total loss: \u001b[1m\u001b[32m1.75616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8944 | loss: 1.75616 - acc: 0.5908 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8945  | total loss: \u001b[1m\u001b[32m1.62577\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8945 | loss: 1.62577 - acc: 0.6317 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8946  | total loss: \u001b[1m\u001b[32m1.84240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8946 | loss: 1.84240 - acc: 0.5685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8947  | total loss: \u001b[1m\u001b[32m1.70501\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8947 | loss: 1.70501 - acc: 0.6117 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8948  | total loss: \u001b[1m\u001b[32m1.85479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8948 | loss: 1.85479 - acc: 0.5648 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8949  | total loss: \u001b[1m\u001b[32m1.71804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8949 | loss: 1.71804 - acc: 0.6083 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8950  | total loss: \u001b[1m\u001b[32m1.88056\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8950 | loss: 1.88056 - acc: 0.5546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8951  | total loss: \u001b[1m\u001b[32m1.74319\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8951 | loss: 1.74319 - acc: 0.5992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8952  | total loss: \u001b[1m\u001b[32m1.93678\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8952 | loss: 1.93678 - acc: 0.5392 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8953  | total loss: \u001b[1m\u001b[32m1.79588\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8953 | loss: 1.79588 - acc: 0.5853 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8954  | total loss: \u001b[1m\u001b[32m1.66984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8954 | loss: 1.66984 - acc: 0.6268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8955  | total loss: \u001b[1m\u001b[32m1.55656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8955 | loss: 1.55656 - acc: 0.6641 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8956  | total loss: \u001b[1m\u001b[32m1.71513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8956 | loss: 1.71513 - acc: 0.6120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8957  | total loss: \u001b[1m\u001b[32m1.59715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8957 | loss: 1.59715 - acc: 0.6508 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8958  | total loss: \u001b[1m\u001b[32m1.49064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8958 | loss: 1.49064 - acc: 0.6857 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8959  | total loss: \u001b[1m\u001b[32m1.39396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8959 | loss: 1.39396 - acc: 0.7171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8960  | total loss: \u001b[1m\u001b[32m1.30569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8960 | loss: 1.30569 - acc: 0.7454 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8961  | total loss: \u001b[1m\u001b[32m1.22466\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8961 | loss: 1.22466 - acc: 0.7709 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8962  | total loss: \u001b[1m\u001b[32m1.14984\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8962 | loss: 1.14984 - acc: 0.7938 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8963  | total loss: \u001b[1m\u001b[32m1.08038\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8963 | loss: 1.08038 - acc: 0.8144 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8964  | total loss: \u001b[1m\u001b[32m1.01559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8964 | loss: 1.01559 - acc: 0.8330 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8965  | total loss: \u001b[1m\u001b[32m0.95489\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8965 | loss: 0.95489 - acc: 0.8497 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 8966  | total loss: \u001b[1m\u001b[32m1.17150\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8966 | loss: 1.17150 - acc: 0.7861 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8967  | total loss: \u001b[1m\u001b[32m1.09122\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8967 | loss: 1.09122 - acc: 0.8075 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8968  | total loss: \u001b[1m\u001b[32m1.01730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8968 | loss: 1.01730 - acc: 0.8268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8969  | total loss: \u001b[1m\u001b[32m0.94900\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8969 | loss: 0.94900 - acc: 0.8441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8970  | total loss: \u001b[1m\u001b[32m1.23433\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8970 | loss: 1.23433 - acc: 0.7597 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8971  | total loss: \u001b[1m\u001b[32m1.14167\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8971 | loss: 1.14167 - acc: 0.7837 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8972  | total loss: \u001b[1m\u001b[32m1.05729\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8972 | loss: 1.05729 - acc: 0.8053 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8973  | total loss: \u001b[1m\u001b[32m0.98022\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8973 | loss: 0.98022 - acc: 0.8248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8974  | total loss: \u001b[1m\u001b[32m0.90962\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8974 | loss: 0.90962 - acc: 0.8423 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8975  | total loss: \u001b[1m\u001b[32m0.84479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8975 | loss: 0.84479 - acc: 0.8581 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8976  | total loss: \u001b[1m\u001b[32m1.19262\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8976 | loss: 1.19262 - acc: 0.7723 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8977  | total loss: \u001b[1m\u001b[32m1.09775\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8977 | loss: 1.09775 - acc: 0.7951 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8978  | total loss: \u001b[1m\u001b[32m1.01182\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8978 | loss: 1.01182 - acc: 0.8156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8979  | total loss: \u001b[1m\u001b[32m0.93382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8979 | loss: 0.93382 - acc: 0.8340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8980  | total loss: \u001b[1m\u001b[32m0.86283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8980 | loss: 0.86283 - acc: 0.8506 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8981  | total loss: \u001b[1m\u001b[32m0.79808\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8981 | loss: 0.79808 - acc: 0.8655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8982  | total loss: \u001b[1m\u001b[32m1.13278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8982 | loss: 1.13278 - acc: 0.7861 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8983  | total loss: \u001b[1m\u001b[32m1.04002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8983 | loss: 1.04002 - acc: 0.8075 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8984  | total loss: \u001b[1m\u001b[32m1.28374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8984 | loss: 1.28374 - acc: 0.7482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8985  | total loss: \u001b[1m\u001b[32m1.17602\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8985 | loss: 1.17602 - acc: 0.7734 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8986  | total loss: \u001b[1m\u001b[32m1.07925\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8986 | loss: 1.07925 - acc: 0.7960 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8987  | total loss: \u001b[1m\u001b[32m0.99216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8987 | loss: 0.99216 - acc: 0.8164 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8988  | total loss: \u001b[1m\u001b[32m0.91362\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8988 | loss: 0.91362 - acc: 0.8348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8989  | total loss: \u001b[1m\u001b[32m0.84264\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8989 | loss: 0.84264 - acc: 0.8513 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8990  | total loss: \u001b[1m\u001b[32m0.77834\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8990 | loss: 0.77834 - acc: 0.8662 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8991  | total loss: \u001b[1m\u001b[32m0.71994\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8991 | loss: 0.71994 - acc: 0.8796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8992  | total loss: \u001b[1m\u001b[32m1.09293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8992 | loss: 1.09293 - acc: 0.7916 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8993  | total loss: \u001b[1m\u001b[32m1.00261\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 8993 | loss: 1.00261 - acc: 0.8124 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8994  | total loss: \u001b[1m\u001b[32m1.35314\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8994 | loss: 1.35314 - acc: 0.7312 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8995  | total loss: \u001b[1m\u001b[32m1.23744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8995 | loss: 1.23744 - acc: 0.7581 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8996  | total loss: \u001b[1m\u001b[32m1.54021\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8996 | loss: 1.54021 - acc: 0.6894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8997  | total loss: \u001b[1m\u001b[32m1.40737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8997 | loss: 1.40737 - acc: 0.7205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8998  | total loss: \u001b[1m\u001b[32m1.65003\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8998 | loss: 1.65003 - acc: 0.6556 -- iter: 14/14\n",
      "--\n",
      "Training Step: 8999  | total loss: \u001b[1m\u001b[32m1.50850\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 8999 | loss: 1.50850 - acc: 0.6900 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9000  | total loss: \u001b[1m\u001b[32m1.70552\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9000 | loss: 1.70552 - acc: 0.6424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9001  | total loss: \u001b[1m\u001b[32m1.56125\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9001 | loss: 1.56125 - acc: 0.6782 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9002  | total loss: \u001b[1m\u001b[32m1.78311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9002 | loss: 1.78311 - acc: 0.6175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9003  | total loss: \u001b[1m\u001b[32m1.63438\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9003 | loss: 1.63438 - acc: 0.6558 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9004  | total loss: \u001b[1m\u001b[32m1.50211\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9004 | loss: 1.50211 - acc: 0.6902 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9005  | total loss: \u001b[1m\u001b[32m1.38427\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9005 | loss: 1.38427 - acc: 0.7212 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9006  | total loss: \u001b[1m\u001b[32m1.59488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9006 | loss: 1.59488 - acc: 0.6633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9007  | total loss: \u001b[1m\u001b[32m1.46995\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9007 | loss: 1.46995 - acc: 0.6970 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9008  | total loss: \u001b[1m\u001b[32m1.35847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9008 | loss: 1.35847 - acc: 0.7273 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9009  | total loss: \u001b[1m\u001b[32m1.25868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9009 | loss: 1.25868 - acc: 0.7546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9010  | total loss: \u001b[1m\u001b[32m1.51462\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9010 | loss: 1.51462 - acc: 0.6791 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9011  | total loss: \u001b[1m\u001b[32m1.40026\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9011 | loss: 1.40026 - acc: 0.7112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9012  | total loss: \u001b[1m\u001b[32m1.29780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9012 | loss: 1.29780 - acc: 0.7401 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9013  | total loss: \u001b[1m\u001b[32m1.20566\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9013 | loss: 1.20566 - acc: 0.7661 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9014  | total loss: \u001b[1m\u001b[32m1.12244\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9014 | loss: 1.12244 - acc: 0.7895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9015  | total loss: \u001b[1m\u001b[32m1.04695\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9015 | loss: 1.04695 - acc: 0.8105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9016  | total loss: \u001b[1m\u001b[32m0.97813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9016 | loss: 0.97813 - acc: 0.8295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9017  | total loss: \u001b[1m\u001b[32m0.91510\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9017 | loss: 0.91510 - acc: 0.8465 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9018  | total loss: \u001b[1m\u001b[32m1.16382\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9018 | loss: 1.16382 - acc: 0.7690 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9019  | total loss: \u001b[1m\u001b[32m1.08044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9019 | loss: 1.08044 - acc: 0.7921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9020  | total loss: \u001b[1m\u001b[32m1.33668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9020 | loss: 1.33668 - acc: 0.7200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9021  | total loss: \u001b[1m\u001b[32m1.23533\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9021 | loss: 1.23533 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9022  | total loss: \u001b[1m\u001b[32m1.49580\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9022 | loss: 1.49580 - acc: 0.6732 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9023  | total loss: \u001b[1m\u001b[32m1.37891\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9023 | loss: 1.37891 - acc: 0.7059 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9024  | total loss: \u001b[1m\u001b[32m1.63935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9024 | loss: 1.63935 - acc: 0.6353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9025  | total loss: \u001b[1m\u001b[32m1.50940\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9025 | loss: 1.50940 - acc: 0.6718 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9026  | total loss: \u001b[1m\u001b[32m1.39310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9026 | loss: 1.39310 - acc: 0.7046 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9027  | total loss: \u001b[1m\u001b[32m1.28871\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9027 | loss: 1.28871 - acc: 0.7341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9028  | total loss: \u001b[1m\u001b[32m1.19471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9028 | loss: 1.19471 - acc: 0.7607 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9029  | total loss: \u001b[1m\u001b[32m1.10977\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9029 | loss: 1.10977 - acc: 0.7847 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9030  | total loss: \u001b[1m\u001b[32m1.32040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9030 | loss: 1.32040 - acc: 0.7205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9031  | total loss: \u001b[1m\u001b[32m1.22229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9031 | loss: 1.22229 - acc: 0.7484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9032  | total loss: \u001b[1m\u001b[32m1.48911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9032 | loss: 1.48911 - acc: 0.6736 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9033  | total loss: \u001b[1m\u001b[32m1.37443\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9033 | loss: 1.37443 - acc: 0.7062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9034  | total loss: \u001b[1m\u001b[32m1.27144\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9034 | loss: 1.27144 - acc: 0.7356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9035  | total loss: \u001b[1m\u001b[32m1.17865\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9035 | loss: 1.17865 - acc: 0.7620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9036  | total loss: \u001b[1m\u001b[32m1.38526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9036 | loss: 1.38526 - acc: 0.7073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9037  | total loss: \u001b[1m\u001b[32m1.28091\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9037 | loss: 1.28091 - acc: 0.7365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9038  | total loss: \u001b[1m\u001b[32m1.52565\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9038 | loss: 1.52565 - acc: 0.6700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9039  | total loss: \u001b[1m\u001b[32m1.40776\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9039 | loss: 1.40776 - acc: 0.7030 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9040  | total loss: \u001b[1m\u001b[32m1.30192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9040 | loss: 1.30192 - acc: 0.7327 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9041  | total loss: \u001b[1m\u001b[32m1.20658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9041 | loss: 1.20658 - acc: 0.7595 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9042  | total loss: \u001b[1m\u001b[32m1.12039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9042 | loss: 1.12039 - acc: 0.7835 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9043  | total loss: \u001b[1m\u001b[32m1.04218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9043 | loss: 1.04218 - acc: 0.8052 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9044  | total loss: \u001b[1m\u001b[32m0.97093\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9044 | loss: 0.97093 - acc: 0.8246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9045  | total loss: \u001b[1m\u001b[32m0.90575\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9045 | loss: 0.90575 - acc: 0.8422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9046  | total loss: \u001b[1m\u001b[32m1.20324\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9046 | loss: 1.20324 - acc: 0.7651 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9047  | total loss: \u001b[1m\u001b[32m1.11328\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9047 | loss: 1.11328 - acc: 0.7886 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9048  | total loss: \u001b[1m\u001b[32m1.38684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9048 | loss: 1.38684 - acc: 0.7169 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9049  | total loss: \u001b[1m\u001b[32m1.27815\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9049 | loss: 1.27815 - acc: 0.7452 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9050  | total loss: \u001b[1m\u001b[32m1.18027\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9050 | loss: 1.18027 - acc: 0.7707 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9051  | total loss: \u001b[1m\u001b[32m1.09188\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9051 | loss: 1.09188 - acc: 0.7936 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9052  | total loss: \u001b[1m\u001b[32m1.38422\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9052 | loss: 1.38422 - acc: 0.7142 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9053  | total loss: \u001b[1m\u001b[32m1.27522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9053 | loss: 1.27522 - acc: 0.7428 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9054  | total loss: \u001b[1m\u001b[32m1.17715\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9054 | loss: 1.17715 - acc: 0.7685 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9055  | total loss: \u001b[1m\u001b[32m1.08867\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9055 | loss: 1.08867 - acc: 0.7917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9056  | total loss: \u001b[1m\u001b[32m1.32198\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9056 | loss: 1.32198 - acc: 0.7268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9057  | total loss: \u001b[1m\u001b[32m1.21883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9057 | loss: 1.21883 - acc: 0.7541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9058  | total loss: \u001b[1m\u001b[32m1.42872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9058 | loss: 1.42872 - acc: 0.7001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9059  | total loss: \u001b[1m\u001b[32m1.31541\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9059 | loss: 1.31541 - acc: 0.7301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9060  | total loss: \u001b[1m\u001b[32m1.54503\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9060 | loss: 1.54503 - acc: 0.6714 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9061  | total loss: \u001b[1m\u001b[32m1.42123\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9061 | loss: 1.42123 - acc: 0.7043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9062  | total loss: \u001b[1m\u001b[32m1.63079\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9062 | loss: 1.63079 - acc: 0.6481 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9063  | total loss: \u001b[1m\u001b[32m1.50013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9063 | loss: 1.50013 - acc: 0.6833 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9064  | total loss: \u001b[1m\u001b[32m1.72930\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9064 | loss: 1.72930 - acc: 0.6150 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9065  | total loss: \u001b[1m\u001b[32m1.59106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9065 | loss: 1.59106 - acc: 0.6535 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9066  | total loss: \u001b[1m\u001b[32m1.46772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9066 | loss: 1.46772 - acc: 0.6881 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9067  | total loss: \u001b[1m\u001b[32m1.35739\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9067 | loss: 1.35739 - acc: 0.7193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9068  | total loss: \u001b[1m\u001b[32m1.25837\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9068 | loss: 1.25837 - acc: 0.7474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9069  | total loss: \u001b[1m\u001b[32m1.16918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9069 | loss: 1.16918 - acc: 0.7726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9070  | total loss: \u001b[1m\u001b[32m1.08852\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9070 | loss: 1.08852 - acc: 0.7954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9071  | total loss: \u001b[1m\u001b[32m1.01524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9071 | loss: 1.01524 - acc: 0.8158 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9072  | total loss: \u001b[1m\u001b[32m1.27044\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9072 | loss: 1.27044 - acc: 0.7414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9073  | total loss: \u001b[1m\u001b[32m1.17795\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9073 | loss: 1.17795 - acc: 0.7673 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9074  | total loss: \u001b[1m\u001b[32m1.41457\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9074 | loss: 1.41457 - acc: 0.6977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9075  | total loss: \u001b[1m\u001b[32m1.30762\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9075 | loss: 1.30762 - acc: 0.7279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9076  | total loss: \u001b[1m\u001b[32m1.21138\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9076 | loss: 1.21138 - acc: 0.7551 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9077  | total loss: \u001b[1m\u001b[32m1.12447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9077 | loss: 1.12447 - acc: 0.7796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9078  | total loss: \u001b[1m\u001b[32m1.40177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9078 | loss: 1.40177 - acc: 0.7016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9079  | total loss: \u001b[1m\u001b[32m1.29551\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9079 | loss: 1.29551 - acc: 0.7315 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9080  | total loss: \u001b[1m\u001b[32m1.54672\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9080 | loss: 1.54672 - acc: 0.6655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9081  | total loss: \u001b[1m\u001b[32m1.42654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9081 | loss: 1.42654 - acc: 0.6989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9082  | total loss: \u001b[1m\u001b[32m1.63152\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9082 | loss: 1.63152 - acc: 0.6362 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9083  | total loss: \u001b[1m\u001b[32m1.50402\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9083 | loss: 1.50402 - acc: 0.6726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9084  | total loss: \u001b[1m\u001b[32m1.74930\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9084 | loss: 1.74930 - acc: 0.6053 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9085  | total loss: \u001b[1m\u001b[32m1.61181\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9085 | loss: 1.61181 - acc: 0.6448 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9086  | total loss: \u001b[1m\u001b[32m1.82136\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9086 | loss: 1.82136 - acc: 0.5803 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9087  | total loss: \u001b[1m\u001b[32m1.67911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9087 | loss: 1.67911 - acc: 0.6223 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9088  | total loss: \u001b[1m\u001b[32m1.55217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9088 | loss: 1.55217 - acc: 0.6600 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9089  | total loss: \u001b[1m\u001b[32m1.43852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9089 | loss: 1.43852 - acc: 0.6940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9090  | total loss: \u001b[1m\u001b[32m1.64376\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9090 | loss: 1.64376 - acc: 0.6318 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9091  | total loss: \u001b[1m\u001b[32m1.52190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9091 | loss: 1.52190 - acc: 0.6686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9092  | total loss: \u001b[1m\u001b[32m1.74257\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9092 | loss: 1.74257 - acc: 0.6017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9093  | total loss: \u001b[1m\u001b[32m1.61228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9093 | loss: 1.61228 - acc: 0.6416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9094  | total loss: \u001b[1m\u001b[32m1.49562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9094 | loss: 1.49562 - acc: 0.6774 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9095  | total loss: \u001b[1m\u001b[32m1.39072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9095 | loss: 1.39072 - acc: 0.7097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9096  | total loss: \u001b[1m\u001b[32m1.59899\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9096 | loss: 1.59899 - acc: 0.6458 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9097  | total loss: \u001b[1m\u001b[32m1.48385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9097 | loss: 1.48385 - acc: 0.6813 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9098  | total loss: \u001b[1m\u001b[32m1.68719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9098 | loss: 1.68719 - acc: 0.6203 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9099  | total loss: \u001b[1m\u001b[32m1.56383\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9099 | loss: 1.56383 - acc: 0.6582 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9100  | total loss: \u001b[1m\u001b[32m1.76040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9100 | loss: 1.76040 - acc: 0.5924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9101  | total loss: \u001b[1m\u001b[32m1.63084\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9101 | loss: 1.63084 - acc: 0.6332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9102  | total loss: \u001b[1m\u001b[32m1.83960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9102 | loss: 1.83960 - acc: 0.5699 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9103  | total loss: \u001b[1m\u001b[32m1.70380\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9103 | loss: 1.70380 - acc: 0.6129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9104  | total loss: \u001b[1m\u001b[32m1.89927\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9104 | loss: 1.89927 - acc: 0.5516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9105  | total loss: \u001b[1m\u001b[32m1.75957\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9105 | loss: 1.75957 - acc: 0.5964 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9106  | total loss: \u001b[1m\u001b[32m1.91227\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9106 | loss: 1.91227 - acc: 0.5439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9107  | total loss: \u001b[1m\u001b[32m1.77349\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9107 | loss: 1.77349 - acc: 0.5895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9108  | total loss: \u001b[1m\u001b[32m1.93010\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9108 | loss: 1.93010 - acc: 0.5377 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9109  | total loss: \u001b[1m\u001b[32m1.79170\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9109 | loss: 1.79170 - acc: 0.5840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9110  | total loss: \u001b[1m\u001b[32m1.96242\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9110 | loss: 1.96242 - acc: 0.5256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9111  | total loss: \u001b[1m\u001b[32m1.82289\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9111 | loss: 1.82289 - acc: 0.5730 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9112  | total loss: \u001b[1m\u001b[32m1.98175\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9112 | loss: 1.98175 - acc: 0.5157 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9113  | total loss: \u001b[1m\u001b[32m1.84237\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9113 | loss: 1.84237 - acc: 0.5641 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9114  | total loss: \u001b[1m\u001b[32m1.71759\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9114 | loss: 1.71759 - acc: 0.6077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9115  | total loss: \u001b[1m\u001b[32m1.60527\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9115 | loss: 1.60527 - acc: 0.6469 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9116  | total loss: \u001b[1m\u001b[32m1.79236\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9116 | loss: 1.79236 - acc: 0.5823 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9117  | total loss: \u001b[1m\u001b[32m1.67222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9117 | loss: 1.67222 - acc: 0.6240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9118  | total loss: \u001b[1m\u001b[32m1.82022\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9118 | loss: 1.82022 - acc: 0.5688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9119  | total loss: \u001b[1m\u001b[32m1.69730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9119 | loss: 1.69730 - acc: 0.6119 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9120  | total loss: \u001b[1m\u001b[32m1.58637\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9120 | loss: 1.58637 - acc: 0.6507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9121  | total loss: \u001b[1m\u001b[32m1.48569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9121 | loss: 1.48569 - acc: 0.6856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9122  | total loss: \u001b[1m\u001b[32m1.67862\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9122 | loss: 1.67862 - acc: 0.6171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9123  | total loss: \u001b[1m\u001b[32m1.56705\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9123 | loss: 1.56705 - acc: 0.6554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9124  | total loss: \u001b[1m\u001b[32m1.71877\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9124 | loss: 1.71877 - acc: 0.6041 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9125  | total loss: \u001b[1m\u001b[32m1.60219\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9125 | loss: 1.60219 - acc: 0.6437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9126  | total loss: \u001b[1m\u001b[32m1.49658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9126 | loss: 1.49658 - acc: 0.6793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9127  | total loss: \u001b[1m\u001b[32m1.40040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9127 | loss: 1.40040 - acc: 0.7114 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9128  | total loss: \u001b[1m\u001b[32m1.31229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9128 | loss: 1.31229 - acc: 0.7403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9129  | total loss: \u001b[1m\u001b[32m1.23113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9129 | loss: 1.23113 - acc: 0.7662 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9130  | total loss: \u001b[1m\u001b[32m1.48104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9130 | loss: 1.48104 - acc: 0.6896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9131  | total loss: \u001b[1m\u001b[32m1.37983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9131 | loss: 1.37983 - acc: 0.7206 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9132  | total loss: \u001b[1m\u001b[32m1.54117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9132 | loss: 1.54117 - acc: 0.6629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9133  | total loss: \u001b[1m\u001b[32m1.43193\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9133 | loss: 1.43193 - acc: 0.6966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9134  | total loss: \u001b[1m\u001b[32m1.65002\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9134 | loss: 1.65002 - acc: 0.6269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9135  | total loss: \u001b[1m\u001b[32m1.52881\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9135 | loss: 1.52881 - acc: 0.6642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9136  | total loss: \u001b[1m\u001b[32m1.69992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9136 | loss: 1.69992 - acc: 0.6050 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9137  | total loss: \u001b[1m\u001b[32m1.57343\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9137 | loss: 1.57343 - acc: 0.6445 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9138  | total loss: \u001b[1m\u001b[32m1.45940\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9138 | loss: 1.45940 - acc: 0.6800 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9139  | total loss: \u001b[1m\u001b[32m1.35618\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9139 | loss: 1.35618 - acc: 0.7120 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9140  | total loss: \u001b[1m\u001b[32m1.59487\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9140 | loss: 1.59487 - acc: 0.6408 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9141  | total loss: \u001b[1m\u001b[32m1.47718\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9141 | loss: 1.47718 - acc: 0.6767 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9142  | total loss: \u001b[1m\u001b[32m1.37087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9142 | loss: 1.37087 - acc: 0.7091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9143  | total loss: \u001b[1m\u001b[32m1.27446\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9143 | loss: 1.27446 - acc: 0.7381 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9144  | total loss: \u001b[1m\u001b[32m1.18666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9144 | loss: 1.18666 - acc: 0.7643 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9145  | total loss: \u001b[1m\u001b[32m1.10636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9145 | loss: 1.10636 - acc: 0.7879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9146  | total loss: \u001b[1m\u001b[32m1.36356\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9146 | loss: 1.36356 - acc: 0.7163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9147  | total loss: \u001b[1m\u001b[32m1.26348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9147 | loss: 1.26348 - acc: 0.7446 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9148  | total loss: \u001b[1m\u001b[32m1.45937\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9148 | loss: 1.45937 - acc: 0.6845 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9149  | total loss: \u001b[1m\u001b[32m1.34874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9149 | loss: 1.34874 - acc: 0.7160 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9150  | total loss: \u001b[1m\u001b[32m1.24876\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9150 | loss: 1.24876 - acc: 0.7444 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9151  | total loss: \u001b[1m\u001b[32m1.15811\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9151 | loss: 1.15811 - acc: 0.7700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9152  | total loss: \u001b[1m\u001b[32m1.37921\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9152 | loss: 1.37921 - acc: 0.7073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9153  | total loss: \u001b[1m\u001b[32m1.27444\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9153 | loss: 1.27444 - acc: 0.7365 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9154  | total loss: \u001b[1m\u001b[32m1.53113\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9154 | loss: 1.53113 - acc: 0.6700 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9155  | total loss: \u001b[1m\u001b[32m1.41106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9155 | loss: 1.41106 - acc: 0.7030 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9156  | total loss: \u001b[1m\u001b[32m1.30300\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9156 | loss: 1.30300 - acc: 0.7327 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9157  | total loss: \u001b[1m\u001b[32m1.20546\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9157 | loss: 1.20546 - acc: 0.7594 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9158  | total loss: \u001b[1m\u001b[32m1.48830\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9158 | loss: 1.48830 - acc: 0.6835 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9159  | total loss: \u001b[1m\u001b[32m1.37191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9159 | loss: 1.37191 - acc: 0.7151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9160  | total loss: \u001b[1m\u001b[32m1.63627\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9160 | loss: 1.63627 - acc: 0.6436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9161  | total loss: \u001b[1m\u001b[32m1.50570\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9161 | loss: 1.50570 - acc: 0.6793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9162  | total loss: \u001b[1m\u001b[32m1.38854\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9162 | loss: 1.38854 - acc: 0.7113 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9163  | total loss: \u001b[1m\u001b[32m1.28311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9163 | loss: 1.28311 - acc: 0.7402 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9164  | total loss: \u001b[1m\u001b[32m1.18794\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9164 | loss: 1.18794 - acc: 0.7662 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9165  | total loss: \u001b[1m\u001b[32m1.10175\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9165 | loss: 1.10175 - acc: 0.7896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9166  | total loss: \u001b[1m\u001b[32m1.02342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9166 | loss: 1.02342 - acc: 0.8106 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9167  | total loss: \u001b[1m\u001b[32m0.95197\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9167 | loss: 0.95197 - acc: 0.8296 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9168  | total loss: \u001b[1m\u001b[32m1.24195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9168 | loss: 1.24195 - acc: 0.7537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9169  | total loss: \u001b[1m\u001b[32m1.14727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9169 | loss: 1.14727 - acc: 0.7784 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9170  | total loss: \u001b[1m\u001b[32m1.41940\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9170 | loss: 1.41940 - acc: 0.7005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9171  | total loss: \u001b[1m\u001b[32m1.30679\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9171 | loss: 1.30679 - acc: 0.7305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9172  | total loss: \u001b[1m\u001b[32m1.55522\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9172 | loss: 1.55522 - acc: 0.6646 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9173  | total loss: \u001b[1m\u001b[32m1.42982\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9173 | loss: 1.42982 - acc: 0.6981 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9174  | total loss: \u001b[1m\u001b[32m1.68455\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9174 | loss: 1.68455 - acc: 0.6283 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9175  | total loss: \u001b[1m\u001b[32m1.54780\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9175 | loss: 1.54780 - acc: 0.6655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9176  | total loss: \u001b[1m\u001b[32m1.71678\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9176 | loss: 1.71678 - acc: 0.6132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9177  | total loss: \u001b[1m\u001b[32m1.57895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9177 | loss: 1.57895 - acc: 0.6519 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9178  | total loss: \u001b[1m\u001b[32m1.45585\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9178 | loss: 1.45585 - acc: 0.6867 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9179  | total loss: \u001b[1m\u001b[32m1.34562\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9179 | loss: 1.34562 - acc: 0.7180 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9180  | total loss: \u001b[1m\u001b[32m1.24661\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9180 | loss: 1.24661 - acc: 0.7462 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9181  | total loss: \u001b[1m\u001b[32m1.15736\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9181 | loss: 1.15736 - acc: 0.7716 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9182  | total loss: \u001b[1m\u001b[32m1.07660\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9182 | loss: 1.07660 - acc: 0.7944 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9183  | total loss: \u001b[1m\u001b[32m1.00320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9183 | loss: 1.00320 - acc: 0.8150 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9184  | total loss: \u001b[1m\u001b[32m1.28180\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9184 | loss: 1.28180 - acc: 0.7335 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9185  | total loss: \u001b[1m\u001b[32m1.18684\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9185 | loss: 1.18684 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9186  | total loss: \u001b[1m\u001b[32m1.41545\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9186 | loss: 1.41545 - acc: 0.6984 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9187  | total loss: \u001b[1m\u001b[32m1.30703\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9187 | loss: 1.30703 - acc: 0.7286 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9188  | total loss: \u001b[1m\u001b[32m1.54921\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9188 | loss: 1.54921 - acc: 0.6629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9189  | total loss: \u001b[1m\u001b[32m1.42807\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9189 | loss: 1.42807 - acc: 0.6966 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9190  | total loss: \u001b[1m\u001b[32m1.65188\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9190 | loss: 1.65188 - acc: 0.6341 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9191  | total loss: \u001b[1m\u001b[32m1.52186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9191 | loss: 1.52186 - acc: 0.6707 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9192  | total loss: \u001b[1m\u001b[32m1.75272\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9192 | loss: 1.75272 - acc: 0.6036 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9193  | total loss: \u001b[1m\u001b[32m1.61469\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9193 | loss: 1.61469 - acc: 0.6432 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9194  | total loss: \u001b[1m\u001b[32m1.80366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9194 | loss: 1.80366 - acc: 0.5861 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9195  | total loss: \u001b[1m\u001b[32m1.66311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9195 | loss: 1.66311 - acc: 0.6274 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9196  | total loss: \u001b[1m\u001b[32m1.87886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9196 | loss: 1.87886 - acc: 0.5647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9197  | total loss: \u001b[1m\u001b[32m1.73371\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9197 | loss: 1.73371 - acc: 0.6082 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9198  | total loss: \u001b[1m\u001b[32m1.90027\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9198 | loss: 1.90027 - acc: 0.5546 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9199  | total loss: \u001b[1m\u001b[32m1.75613\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9199 | loss: 1.75613 - acc: 0.5991 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9200  | total loss: \u001b[1m\u001b[32m1.92278\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9200 | loss: 1.92278 - acc: 0.5463 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9201  | total loss: \u001b[1m\u001b[32m1.77945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9201 | loss: 1.77945 - acc: 0.5917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9202  | total loss: \u001b[1m\u001b[32m1.94943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9202 | loss: 1.94943 - acc: 0.5325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9203  | total loss: \u001b[1m\u001b[32m1.80643\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9203 | loss: 1.80643 - acc: 0.5793 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9204  | total loss: \u001b[1m\u001b[32m1.67888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9204 | loss: 1.67888 - acc: 0.6213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9205  | total loss: \u001b[1m\u001b[32m1.56462\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9205 | loss: 1.56462 - acc: 0.6592 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9206  | total loss: \u001b[1m\u001b[32m1.78058\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9206 | loss: 1.78058 - acc: 0.5933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9207  | total loss: \u001b[1m\u001b[32m1.65679\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9207 | loss: 1.65679 - acc: 0.6340 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9208  | total loss: \u001b[1m\u001b[32m1.54548\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9208 | loss: 1.54548 - acc: 0.6706 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9209  | total loss: \u001b[1m\u001b[32m1.44486\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9209 | loss: 1.44486 - acc: 0.7035 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9210  | total loss: \u001b[1m\u001b[32m1.62998\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9210 | loss: 1.62998 - acc: 0.6403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9211  | total loss: \u001b[1m\u001b[32m1.51985\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9211 | loss: 1.51985 - acc: 0.6763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9212  | total loss: \u001b[1m\u001b[32m1.42010\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9212 | loss: 1.42010 - acc: 0.7086 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9213  | total loss: \u001b[1m\u001b[32m1.32925\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9213 | loss: 1.32925 - acc: 0.7378 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9214  | total loss: \u001b[1m\u001b[32m1.54493\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9214 | loss: 1.54493 - acc: 0.6640 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9215  | total loss: \u001b[1m\u001b[32m1.43964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9215 | loss: 1.43964 - acc: 0.6976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9216  | total loss: \u001b[1m\u001b[32m1.34395\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9216 | loss: 1.34395 - acc: 0.7278 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9217  | total loss: \u001b[1m\u001b[32m1.25656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9217 | loss: 1.25656 - acc: 0.7551 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9218  | total loss: \u001b[1m\u001b[32m1.17635\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9218 | loss: 1.17635 - acc: 0.7796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9219  | total loss: \u001b[1m\u001b[32m1.10238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9219 | loss: 1.10238 - acc: 0.8016 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9220  | total loss: \u001b[1m\u001b[32m1.03384\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9220 | loss: 1.03384 - acc: 0.8214 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9221  | total loss: \u001b[1m\u001b[32m0.97008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9221 | loss: 0.97008 - acc: 0.8393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9222  | total loss: \u001b[1m\u001b[32m1.22012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9222 | loss: 1.22012 - acc: 0.7696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9223  | total loss: \u001b[1m\u001b[32m1.13432\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9223 | loss: 1.13432 - acc: 0.7927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9224  | total loss: \u001b[1m\u001b[32m1.05572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9224 | loss: 1.05572 - acc: 0.8134 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9225  | total loss: \u001b[1m\u001b[32m0.98346\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9225 | loss: 0.98346 - acc: 0.8321 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9226  | total loss: \u001b[1m\u001b[32m0.91683\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9226 | loss: 0.91683 - acc: 0.8489 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9227  | total loss: \u001b[1m\u001b[32m0.85521\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9227 | loss: 0.85521 - acc: 0.8640 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9228  | total loss: \u001b[1m\u001b[32m0.79808\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9228 | loss: 0.79808 - acc: 0.8776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9229  | total loss: \u001b[1m\u001b[32m0.74499\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9229 | loss: 0.74499 - acc: 0.8898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9230  | total loss: \u001b[1m\u001b[32m1.07987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9230 | loss: 1.07987 - acc: 0.8080 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9231  | total loss: \u001b[1m\u001b[32m0.99625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9231 | loss: 0.99625 - acc: 0.8272 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9232  | total loss: \u001b[1m\u001b[32m1.28779\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9232 | loss: 1.28779 - acc: 0.7516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9233  | total loss: \u001b[1m\u001b[32m1.18251\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9233 | loss: 1.18251 - acc: 0.7764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9234  | total loss: \u001b[1m\u001b[32m1.44782\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9234 | loss: 1.44782 - acc: 0.7131 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9235  | total loss: \u001b[1m\u001b[32m1.32672\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9235 | loss: 1.32672 - acc: 0.7418 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9236  | total loss: \u001b[1m\u001b[32m1.62574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9236 | loss: 1.62574 - acc: 0.6676 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9237  | total loss: \u001b[1m\u001b[32m1.48801\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9237 | loss: 1.48801 - acc: 0.7008 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9238  | total loss: \u001b[1m\u001b[32m1.36475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9238 | loss: 1.36475 - acc: 0.7308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9239  | total loss: \u001b[1m\u001b[32m1.25426\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9239 | loss: 1.25426 - acc: 0.7577 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9240  | total loss: \u001b[1m\u001b[32m1.15502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9240 | loss: 1.15502 - acc: 0.7819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9241  | total loss: \u001b[1m\u001b[32m1.06568\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9241 | loss: 1.06568 - acc: 0.8037 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9242  | total loss: \u001b[1m\u001b[32m1.35072\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9242 | loss: 1.35072 - acc: 0.7305 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9243  | total loss: \u001b[1m\u001b[32m1.24202\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9243 | loss: 1.24202 - acc: 0.7574 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9244  | total loss: \u001b[1m\u001b[32m1.47214\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9244 | loss: 1.47214 - acc: 0.6960 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9245  | total loss: \u001b[1m\u001b[32m1.35228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9245 | loss: 1.35228 - acc: 0.7264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9246  | total loss: \u001b[1m\u001b[32m1.56833\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9246 | loss: 1.56833 - acc: 0.6680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9247  | total loss: \u001b[1m\u001b[32m1.44046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9247 | loss: 1.44046 - acc: 0.7012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9248  | total loss: \u001b[1m\u001b[32m1.66515\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9248 | loss: 1.66515 - acc: 0.6383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9249  | total loss: \u001b[1m\u001b[32m1.52979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9249 | loss: 1.52979 - acc: 0.6744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9250  | total loss: \u001b[1m\u001b[32m1.40901\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9250 | loss: 1.40901 - acc: 0.7070 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9251  | total loss: \u001b[1m\u001b[32m1.30098\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9251 | loss: 1.30098 - acc: 0.7363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9252  | total loss: \u001b[1m\u001b[32m1.52667\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9252 | loss: 1.52667 - acc: 0.6698 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9253  | total loss: \u001b[1m\u001b[32m1.40819\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9253 | loss: 1.40819 - acc: 0.7028 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9254  | total loss: \u001b[1m\u001b[32m1.30217\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9254 | loss: 1.30217 - acc: 0.7325 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9255  | total loss: \u001b[1m\u001b[32m1.20697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9255 | loss: 1.20697 - acc: 0.7593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9256  | total loss: \u001b[1m\u001b[32m1.43580\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9256 | loss: 1.43580 - acc: 0.6976 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9257  | total loss: \u001b[1m\u001b[32m1.32770\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9257 | loss: 1.32770 - acc: 0.7279 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9258  | total loss: \u001b[1m\u001b[32m1.54598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9258 | loss: 1.54598 - acc: 0.6622 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9259  | total loss: \u001b[1m\u001b[32m1.42795\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9259 | loss: 1.42795 - acc: 0.6960 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9260  | total loss: \u001b[1m\u001b[32m1.65821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9260 | loss: 1.65821 - acc: 0.6264 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9261  | total loss: \u001b[1m\u001b[32m1.53068\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9261 | loss: 1.53068 - acc: 0.6638 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9262  | total loss: \u001b[1m\u001b[32m1.41667\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9262 | loss: 1.41667 - acc: 0.6974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9263  | total loss: \u001b[1m\u001b[32m1.31441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9263 | loss: 1.31441 - acc: 0.7277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9264  | total loss: \u001b[1m\u001b[32m1.54327\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9264 | loss: 1.54327 - acc: 0.6620 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9265  | total loss: \u001b[1m\u001b[32m1.42888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9265 | loss: 1.42888 - acc: 0.6958 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9266  | total loss: \u001b[1m\u001b[32m1.66185\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9266 | loss: 1.66185 - acc: 0.6262 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9267  | total loss: \u001b[1m\u001b[32m1.53672\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9267 | loss: 1.53672 - acc: 0.6636 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9268  | total loss: \u001b[1m\u001b[32m1.76109\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9268 | loss: 1.76109 - acc: 0.5973 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9269  | total loss: \u001b[1m\u001b[32m1.62772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9269 | loss: 1.62772 - acc: 0.6375 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9270  | total loss: \u001b[1m\u001b[32m1.79975\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9270 | loss: 1.79975 - acc: 0.5809 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9271  | total loss: \u001b[1m\u001b[32m1.66453\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9271 | loss: 1.66453 - acc: 0.6228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9272  | total loss: \u001b[1m\u001b[32m1.85789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9272 | loss: 1.85789 - acc: 0.5605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9273  | total loss: \u001b[1m\u001b[32m1.71919\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9273 | loss: 1.71919 - acc: 0.6045 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9274  | total loss: \u001b[1m\u001b[32m1.59531\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9274 | loss: 1.59531 - acc: 0.6440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9275  | total loss: \u001b[1m\u001b[32m1.48423\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9275 | loss: 1.48423 - acc: 0.6796 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9276  | total loss: \u001b[1m\u001b[32m1.65855\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9276 | loss: 1.65855 - acc: 0.6188 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9277  | total loss: \u001b[1m\u001b[32m1.54160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9277 | loss: 1.54160 - acc: 0.6569 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9278  | total loss: \u001b[1m\u001b[32m1.43637\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9278 | loss: 1.43637 - acc: 0.6912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9279  | total loss: \u001b[1m\u001b[32m1.34121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9279 | loss: 1.34121 - acc: 0.7221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9280  | total loss: \u001b[1m\u001b[32m1.25470\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9280 | loss: 1.25470 - acc: 0.7499 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9281  | total loss: \u001b[1m\u001b[32m1.17560\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9281 | loss: 1.17560 - acc: 0.7749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9282  | total loss: \u001b[1m\u001b[32m1.10288\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9282 | loss: 1.10288 - acc: 0.7974 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9283  | total loss: \u001b[1m\u001b[32m1.03567\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9283 | loss: 1.03567 - acc: 0.8177 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9284  | total loss: \u001b[1m\u001b[32m1.28010\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9284 | loss: 1.28010 - acc: 0.7431 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9285  | total loss: \u001b[1m\u001b[32m1.19218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9285 | loss: 1.19218 - acc: 0.7688 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9286  | total loss: \u001b[1m\u001b[32m1.44285\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9286 | loss: 1.44285 - acc: 0.6990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9287  | total loss: \u001b[1m\u001b[32m1.33692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9287 | loss: 1.33692 - acc: 0.7291 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9288  | total loss: \u001b[1m\u001b[32m1.55112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9288 | loss: 1.55112 - acc: 0.6633 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9289  | total loss: \u001b[1m\u001b[32m1.43361\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9289 | loss: 1.43361 - acc: 0.6970 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9290  | total loss: \u001b[1m\u001b[32m1.65363\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9290 | loss: 1.65363 - acc: 0.6345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9291  | total loss: \u001b[1m\u001b[32m1.52592\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9291 | loss: 1.52592 - acc: 0.6710 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9292  | total loss: \u001b[1m\u001b[32m1.41100\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9292 | loss: 1.41100 - acc: 0.7039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9293  | total loss: \u001b[1m\u001b[32m1.30727\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9293 | loss: 1.30727 - acc: 0.7335 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9294  | total loss: \u001b[1m\u001b[32m1.21332\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9294 | loss: 1.21332 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9295  | total loss: \u001b[1m\u001b[32m1.12793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9295 | loss: 1.12793 - acc: 0.7841 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9296  | total loss: \u001b[1m\u001b[32m1.37315\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9296 | loss: 1.37315 - acc: 0.7129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9297  | total loss: \u001b[1m\u001b[32m1.27045\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9297 | loss: 1.27045 - acc: 0.7416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9298  | total loss: \u001b[1m\u001b[32m1.50484\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9298 | loss: 1.50484 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9299  | total loss: \u001b[1m\u001b[32m1.38864\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 9299 | loss: 1.38864 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9300  | total loss: \u001b[1m\u001b[32m1.28396\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9300 | loss: 1.28396 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9301  | total loss: \u001b[1m\u001b[32m1.18937\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9301 | loss: 1.18937 - acc: 0.7628 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9302  | total loss: \u001b[1m\u001b[32m1.45585\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9302 | loss: 1.45585 - acc: 0.6865 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9303  | total loss: \u001b[1m\u001b[32m1.34366\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9303 | loss: 1.34366 - acc: 0.7178 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9304  | total loss: \u001b[1m\u001b[32m1.54919\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9304 | loss: 1.54919 - acc: 0.6603 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9305  | total loss: \u001b[1m\u001b[32m1.42804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9305 | loss: 1.42804 - acc: 0.6943 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9306  | total loss: \u001b[1m\u001b[32m1.31917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9306 | loss: 1.31917 - acc: 0.7249 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9307  | total loss: \u001b[1m\u001b[32m1.22104\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9307 | loss: 1.22104 - acc: 0.7524 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9308  | total loss: \u001b[1m\u001b[32m1.41531\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9308 | loss: 1.41531 - acc: 0.6986 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9309  | total loss: \u001b[1m\u001b[32m1.30730\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9309 | loss: 1.30730 - acc: 0.7287 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9310  | total loss: \u001b[1m\u001b[32m1.48898\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9310 | loss: 1.48898 - acc: 0.6773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9311  | total loss: \u001b[1m\u001b[32m1.37386\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9311 | loss: 1.37386 - acc: 0.7095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9312  | total loss: \u001b[1m\u001b[32m1.27034\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9312 | loss: 1.27034 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9313  | total loss: \u001b[1m\u001b[32m1.17696\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9313 | loss: 1.17696 - acc: 0.7647 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9314  | total loss: \u001b[1m\u001b[32m1.46259\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9314 | loss: 1.46259 - acc: 0.6883 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9315  | total loss: \u001b[1m\u001b[32m1.34979\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9315 | loss: 1.34979 - acc: 0.7194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9316  | total loss: \u001b[1m\u001b[32m1.54591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9316 | loss: 1.54591 - acc: 0.6618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9317  | total loss: \u001b[1m\u001b[32m1.42534\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9317 | loss: 1.42534 - acc: 0.6956 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9318  | total loss: \u001b[1m\u001b[32m1.68086\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9318 | loss: 1.68086 - acc: 0.6260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9319  | total loss: \u001b[1m\u001b[32m1.54802\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9319 | loss: 1.54802 - acc: 0.6634 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9320  | total loss: \u001b[1m\u001b[32m1.77040\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9320 | loss: 1.77040 - acc: 0.5971 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9321  | total loss: \u001b[1m\u001b[32m1.63048\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9321 | loss: 1.63048 - acc: 0.6374 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9322  | total loss: \u001b[1m\u001b[32m1.83960\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9322 | loss: 1.83960 - acc: 0.5736 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9323  | total loss: \u001b[1m\u001b[32m1.69511\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9323 | loss: 1.69511 - acc: 0.6163 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9324  | total loss: \u001b[1m\u001b[32m1.91659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9324 | loss: 1.91659 - acc: 0.5547 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9325  | total loss: \u001b[1m\u001b[32m1.76719\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9325 | loss: 1.76719 - acc: 0.5992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9326  | total loss: \u001b[1m\u001b[32m1.63397\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9326 | loss: 1.63397 - acc: 0.6393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9327  | total loss: \u001b[1m\u001b[32m1.51481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9327 | loss: 1.51481 - acc: 0.6753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9328  | total loss: \u001b[1m\u001b[32m1.68439\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9328 | loss: 1.68439 - acc: 0.6221 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9329  | total loss: \u001b[1m\u001b[32m1.56124\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9329 | loss: 1.56124 - acc: 0.6599 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9330  | total loss: \u001b[1m\u001b[32m1.45072\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9330 | loss: 1.45072 - acc: 0.6939 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9331  | total loss: \u001b[1m\u001b[32m1.35112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9331 | loss: 1.35112 - acc: 0.7245 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9332  | total loss: \u001b[1m\u001b[32m1.54591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9332 | loss: 1.54591 - acc: 0.6663 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9333  | total loss: \u001b[1m\u001b[32m1.43634\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9333 | loss: 1.43634 - acc: 0.6997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9334  | total loss: \u001b[1m\u001b[32m1.65746\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9334 | loss: 1.65746 - acc: 0.6297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9335  | total loss: \u001b[1m\u001b[32m1.53689\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9335 | loss: 1.53689 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9336  | total loss: \u001b[1m\u001b[32m1.42840\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9336 | loss: 1.42840 - acc: 0.7001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9337  | total loss: \u001b[1m\u001b[32m1.33037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9337 | loss: 1.33037 - acc: 0.7301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9338  | total loss: \u001b[1m\u001b[32m1.56101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9338 | loss: 1.56101 - acc: 0.6571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9339  | total loss: \u001b[1m\u001b[32m1.44909\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9339 | loss: 1.44909 - acc: 0.6914 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9340  | total loss: \u001b[1m\u001b[32m1.34805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9340 | loss: 1.34805 - acc: 0.7222 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9341  | total loss: \u001b[1m\u001b[32m1.25645\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9341 | loss: 1.25645 - acc: 0.7500 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9342  | total loss: \u001b[1m\u001b[32m1.41324\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9342 | loss: 1.41324 - acc: 0.7036 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9343  | total loss: \u001b[1m\u001b[32m1.31372\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9343 | loss: 1.31372 - acc: 0.7332 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9344  | total loss: \u001b[1m\u001b[32m1.55965\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9344 | loss: 1.55965 - acc: 0.6670 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9345  | total loss: \u001b[1m\u001b[32m1.44480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9345 | loss: 1.44480 - acc: 0.7003 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9346  | total loss: \u001b[1m\u001b[32m1.34111\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9346 | loss: 1.34111 - acc: 0.7303 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9347  | total loss: \u001b[1m\u001b[32m1.24715\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9347 | loss: 1.24715 - acc: 0.7573 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9348  | total loss: \u001b[1m\u001b[32m1.47282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9348 | loss: 1.47282 - acc: 0.6887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9349  | total loss: \u001b[1m\u001b[32m1.36459\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9349 | loss: 1.36459 - acc: 0.7198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9350  | total loss: \u001b[1m\u001b[32m1.57369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9350 | loss: 1.57369 - acc: 0.6550 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9351  | total loss: \u001b[1m\u001b[32m1.45509\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9351 | loss: 1.45509 - acc: 0.6895 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9352  | total loss: \u001b[1m\u001b[32m1.34821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9352 | loss: 1.34821 - acc: 0.7205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9353  | total loss: \u001b[1m\u001b[32m1.25155\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9353 | loss: 1.25155 - acc: 0.7485 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9354  | total loss: \u001b[1m\u001b[32m1.45439\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9354 | loss: 1.45439 - acc: 0.6879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9355  | total loss: \u001b[1m\u001b[32m1.34625\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9355 | loss: 1.34625 - acc: 0.7191 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9356  | total loss: \u001b[1m\u001b[32m1.24852\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9356 | loss: 1.24852 - acc: 0.7472 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9357  | total loss: \u001b[1m\u001b[32m1.15987\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9357 | loss: 1.15987 - acc: 0.7725 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9358  | total loss: \u001b[1m\u001b[32m1.43561\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9358 | loss: 1.43561 - acc: 0.6952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9359  | total loss: \u001b[1m\u001b[32m1.32724\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9359 | loss: 1.32724 - acc: 0.7257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9360  | total loss: \u001b[1m\u001b[32m1.51610\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9360 | loss: 1.51610 - acc: 0.6674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9361  | total loss: \u001b[1m\u001b[32m1.39953\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9361 | loss: 1.39953 - acc: 0.7007 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9362  | total loss: \u001b[1m\u001b[32m1.53971\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9362 | loss: 1.53971 - acc: 0.6592 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9363  | total loss: \u001b[1m\u001b[32m1.42111\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9363 | loss: 1.42111 - acc: 0.6933 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9364  | total loss: \u001b[1m\u001b[32m1.65247\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9364 | loss: 1.65247 - acc: 0.6311 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9365  | total loss: \u001b[1m\u001b[32m1.52337\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9365 | loss: 1.52337 - acc: 0.6680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9366  | total loss: \u001b[1m\u001b[32m1.40751\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9366 | loss: 1.40751 - acc: 0.7012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9367  | total loss: \u001b[1m\u001b[32m1.30324\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9367 | loss: 1.30324 - acc: 0.7311 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9368  | total loss: \u001b[1m\u001b[32m1.56654\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9368 | loss: 1.56654 - acc: 0.6580 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9369  | total loss: \u001b[1m\u001b[32m1.44655\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9369 | loss: 1.44655 - acc: 0.6922 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9370  | total loss: \u001b[1m\u001b[32m1.64959\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9370 | loss: 1.64959 - acc: 0.6301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9371  | total loss: \u001b[1m\u001b[32m1.52214\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9371 | loss: 1.52214 - acc: 0.6671 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9372  | total loss: \u001b[1m\u001b[32m1.74339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9372 | loss: 1.74339 - acc: 0.6004 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9373  | total loss: \u001b[1m\u001b[32m1.60791\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9373 | loss: 1.60791 - acc: 0.6403 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9374  | total loss: \u001b[1m\u001b[32m1.48659\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9374 | loss: 1.48659 - acc: 0.6763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9375  | total loss: \u001b[1m\u001b[32m1.37761\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9375 | loss: 1.37761 - acc: 0.7087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9376  | total loss: \u001b[1m\u001b[32m1.58075\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9376 | loss: 1.58075 - acc: 0.6449 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9377  | total loss: \u001b[1m\u001b[32m1.46274\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9377 | loss: 1.46274 - acc: 0.6805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9378  | total loss: \u001b[1m\u001b[32m1.68087\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9378 | loss: 1.68087 - acc: 0.6195 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9379  | total loss: \u001b[1m\u001b[32m1.55377\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9379 | loss: 1.55377 - acc: 0.6576 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9380  | total loss: \u001b[1m\u001b[32m1.43976\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9380 | loss: 1.43976 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9381  | total loss: \u001b[1m\u001b[32m1.33712\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9381 | loss: 1.33712 - acc: 0.7227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9382  | total loss: \u001b[1m\u001b[32m1.24436\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9382 | loss: 1.24436 - acc: 0.7504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9383  | total loss: \u001b[1m\u001b[32m1.16019\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9383 | loss: 1.16019 - acc: 0.7753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9384  | total loss: \u001b[1m\u001b[32m1.40862\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9384 | loss: 1.40862 - acc: 0.6978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9385  | total loss: \u001b[1m\u001b[32m1.30692\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9385 | loss: 1.30692 - acc: 0.7280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9386  | total loss: \u001b[1m\u001b[32m1.51849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9386 | loss: 1.51849 - acc: 0.6695 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9387  | total loss: \u001b[1m\u001b[32m1.40560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9387 | loss: 1.40560 - acc: 0.7026 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9388  | total loss: \u001b[1m\u001b[32m1.30388\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9388 | loss: 1.30388 - acc: 0.7323 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9389  | total loss: \u001b[1m\u001b[32m1.21190\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9389 | loss: 1.21190 - acc: 0.7591 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9390  | total loss: \u001b[1m\u001b[32m1.45110\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9390 | loss: 1.45110 - acc: 0.6903 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9391  | total loss: \u001b[1m\u001b[32m1.34372\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9391 | loss: 1.34372 - acc: 0.7213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9392  | total loss: \u001b[1m\u001b[32m1.58488\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9392 | loss: 1.58488 - acc: 0.6492 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9393  | total loss: \u001b[1m\u001b[32m1.46424\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9393 | loss: 1.46424 - acc: 0.6842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9394  | total loss: \u001b[1m\u001b[32m1.35571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9394 | loss: 1.35571 - acc: 0.7158 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9395  | total loss: \u001b[1m\u001b[32m1.25774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9395 | loss: 1.25774 - acc: 0.7442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9396  | total loss: \u001b[1m\u001b[32m1.49663\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9396 | loss: 1.49663 - acc: 0.6770 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9397  | total loss: \u001b[1m\u001b[32m1.38411\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9397 | loss: 1.38411 - acc: 0.7093 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9398  | total loss: \u001b[1m\u001b[32m1.60168\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9398 | loss: 1.60168 - acc: 0.6383 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9399  | total loss: \u001b[1m\u001b[32m1.47899\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9399 | loss: 1.47899 - acc: 0.6745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9400  | total loss: \u001b[1m\u001b[32m1.36874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9400 | loss: 1.36874 - acc: 0.7070 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9401  | total loss: \u001b[1m\u001b[32m1.26935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9401 | loss: 1.26935 - acc: 0.7363 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9402  | total loss: \u001b[1m\u001b[32m1.17942\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9402 | loss: 1.17942 - acc: 0.7627 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9403  | total loss: \u001b[1m\u001b[32m1.09775\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9403 | loss: 1.09775 - acc: 0.7864 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9404  | total loss: \u001b[1m\u001b[32m1.35077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9404 | loss: 1.35077 - acc: 0.7149 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9405  | total loss: \u001b[1m\u001b[32m1.25085\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9405 | loss: 1.25085 - acc: 0.7434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9406  | total loss: \u001b[1m\u001b[32m1.51806\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9406 | loss: 1.51806 - acc: 0.6691 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9407  | total loss: \u001b[1m\u001b[32m1.40136\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9407 | loss: 1.40136 - acc: 0.7022 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9408  | total loss: \u001b[1m\u001b[32m1.60624\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9408 | loss: 1.60624 - acc: 0.6391 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9409  | total loss: \u001b[1m\u001b[32m1.48148\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9409 | loss: 1.48148 - acc: 0.6752 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9410  | total loss: \u001b[1m\u001b[32m1.36954\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9410 | loss: 1.36954 - acc: 0.7077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9411  | total loss: \u001b[1m\u001b[32m1.26879\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9411 | loss: 1.26879 - acc: 0.7369 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9412  | total loss: \u001b[1m\u001b[32m1.53535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9412 | loss: 1.53535 - acc: 0.6632 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9413  | total loss: \u001b[1m\u001b[32m1.41820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9413 | loss: 1.41820 - acc: 0.6969 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9414  | total loss: \u001b[1m\u001b[32m1.31290\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9414 | loss: 1.31290 - acc: 0.7272 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9415  | total loss: \u001b[1m\u001b[32m1.21792\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9415 | loss: 1.21792 - acc: 0.7545 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9416  | total loss: \u001b[1m\u001b[32m1.13195\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9416 | loss: 1.13195 - acc: 0.7790 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9417  | total loss: \u001b[1m\u001b[32m1.05381\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9417 | loss: 1.05381 - acc: 0.8011 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9418  | total loss: \u001b[1m\u001b[32m1.29235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9418 | loss: 1.29235 - acc: 0.7353 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9419  | total loss: \u001b[1m\u001b[32m1.19693\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9419 | loss: 1.19693 - acc: 0.7618 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9420  | total loss: \u001b[1m\u001b[32m1.11051\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9420 | loss: 1.11051 - acc: 0.7856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9421  | total loss: \u001b[1m\u001b[32m1.03198\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9421 | loss: 1.03198 - acc: 0.8070 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9422  | total loss: \u001b[1m\u001b[32m1.32822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9422 | loss: 1.32822 - acc: 0.7263 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9423  | total loss: \u001b[1m\u001b[32m1.22689\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9423 | loss: 1.22689 - acc: 0.7537 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9424  | total loss: \u001b[1m\u001b[32m1.49294\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9424 | loss: 1.49294 - acc: 0.6783 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9425  | total loss: \u001b[1m\u001b[32m1.37524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9425 | loss: 1.37524 - acc: 0.7105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9426  | total loss: \u001b[1m\u001b[32m1.61831\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9426 | loss: 1.61831 - acc: 0.6466 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9427  | total loss: \u001b[1m\u001b[32m1.48911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9427 | loss: 1.48911 - acc: 0.6819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9428  | total loss: \u001b[1m\u001b[32m1.66120\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9428 | loss: 1.66120 - acc: 0.6280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9429  | total loss: \u001b[1m\u001b[32m1.52931\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9429 | loss: 1.52931 - acc: 0.6652 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9430  | total loss: \u001b[1m\u001b[32m1.77295\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9430 | loss: 1.77295 - acc: 0.5987 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9431  | total loss: \u001b[1m\u001b[32m1.63198\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9431 | loss: 1.63198 - acc: 0.6388 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9432  | total loss: \u001b[1m\u001b[32m1.86020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9432 | loss: 1.86020 - acc: 0.5749 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9433  | total loss: \u001b[1m\u001b[32m1.71320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9433 | loss: 1.71320 - acc: 0.6175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9434  | total loss: \u001b[1m\u001b[32m1.91271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9434 | loss: 1.91271 - acc: 0.5557 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9435  | total loss: \u001b[1m\u001b[32m1.76358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9435 | loss: 1.76358 - acc: 0.6001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9436  | total loss: \u001b[1m\u001b[32m1.63074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9436 | loss: 1.63074 - acc: 0.6401 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9437  | total loss: \u001b[1m\u001b[32m1.51202\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9437 | loss: 1.51202 - acc: 0.6761 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9438  | total loss: \u001b[1m\u001b[32m1.61373\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9438 | loss: 1.61373 - acc: 0.6442 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9439  | total loss: \u001b[1m\u001b[32m1.49772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9439 | loss: 1.49772 - acc: 0.6798 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9440  | total loss: \u001b[1m\u001b[32m1.39349\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9440 | loss: 1.39349 - acc: 0.7118 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9441  | total loss: \u001b[1m\u001b[32m1.29942\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9441 | loss: 1.29942 - acc: 0.7406 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9442  | total loss: \u001b[1m\u001b[32m1.49652\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9442 | loss: 1.49652 - acc: 0.6737 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9443  | total loss: \u001b[1m\u001b[32m1.39159\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9443 | loss: 1.39159 - acc: 0.7063 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9444  | total loss: \u001b[1m\u001b[32m1.62028\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9444 | loss: 1.62028 - acc: 0.6357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9445  | total loss: \u001b[1m\u001b[32m1.50310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9445 | loss: 1.50310 - acc: 0.6721 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9446  | total loss: \u001b[1m\u001b[32m1.68888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9446 | loss: 1.68888 - acc: 0.6121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9447  | total loss: \u001b[1m\u001b[32m1.56557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9447 | loss: 1.56557 - acc: 0.6509 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9448  | total loss: \u001b[1m\u001b[32m1.74594\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9448 | loss: 1.74594 - acc: 0.5929 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9449  | total loss: \u001b[1m\u001b[32m1.61811\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9449 | loss: 1.61811 - acc: 0.6336 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9450  | total loss: \u001b[1m\u001b[32m1.50348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9450 | loss: 1.50348 - acc: 0.6703 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9451  | total loss: \u001b[1m\u001b[32m1.40023\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9451 | loss: 1.40023 - acc: 0.7032 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9452  | total loss: \u001b[1m\u001b[32m1.61763\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9452 | loss: 1.61763 - acc: 0.6329 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9453  | total loss: \u001b[1m\u001b[32m1.50271\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9453 | loss: 1.50271 - acc: 0.6696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9454  | total loss: \u001b[1m\u001b[32m1.68989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9454 | loss: 1.68989 - acc: 0.6098 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9455  | total loss: \u001b[1m\u001b[32m1.56797\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9455 | loss: 1.56797 - acc: 0.6488 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9456  | total loss: \u001b[1m\u001b[32m1.78038\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9456 | loss: 1.78038 - acc: 0.5839 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9457  | total loss: \u001b[1m\u001b[32m1.65011\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9457 | loss: 1.65011 - acc: 0.6255 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9458  | total loss: \u001b[1m\u001b[32m1.83253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9458 | loss: 1.83253 - acc: 0.5701 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9459  | total loss: \u001b[1m\u001b[32m1.69812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9459 | loss: 1.69812 - acc: 0.6131 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9460  | total loss: \u001b[1m\u001b[32m1.57746\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9460 | loss: 1.57746 - acc: 0.6518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9461  | total loss: \u001b[1m\u001b[32m1.46868\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9461 | loss: 1.46868 - acc: 0.6866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9462  | total loss: \u001b[1m\u001b[32m1.66980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9462 | loss: 1.66980 - acc: 0.6251 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9463  | total loss: \u001b[1m\u001b[32m1.55127\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9463 | loss: 1.55127 - acc: 0.6626 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9464  | total loss: \u001b[1m\u001b[32m1.44423\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9464 | loss: 1.44423 - acc: 0.6963 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9465  | total loss: \u001b[1m\u001b[32m1.34713\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9465 | loss: 1.34713 - acc: 0.7267 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9466  | total loss: \u001b[1m\u001b[32m1.25862\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9466 | loss: 1.25862 - acc: 0.7540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9467  | total loss: \u001b[1m\u001b[32m1.17755\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9467 | loss: 1.17755 - acc: 0.7786 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9468  | total loss: \u001b[1m\u001b[32m1.10292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9468 | loss: 1.10292 - acc: 0.8008 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9469  | total loss: \u001b[1m\u001b[32m1.03390\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9469 | loss: 1.03390 - acc: 0.8207 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9470  | total loss: \u001b[1m\u001b[32m1.29509\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9470 | loss: 1.29509 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9471  | total loss: \u001b[1m\u001b[32m1.20385\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9471 | loss: 1.20385 - acc: 0.7648 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9472  | total loss: \u001b[1m\u001b[32m1.44362\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9472 | loss: 1.44362 - acc: 0.6954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9473  | total loss: \u001b[1m\u001b[32m1.33590\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9473 | loss: 1.33590 - acc: 0.7259 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9474  | total loss: \u001b[1m\u001b[32m1.23829\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9474 | loss: 1.23829 - acc: 0.7533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9475  | total loss: \u001b[1m\u001b[32m1.14955\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9475 | loss: 1.14955 - acc: 0.7780 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9476  | total loss: \u001b[1m\u001b[32m1.38849\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9476 | loss: 1.38849 - acc: 0.7073 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9477  | total loss: \u001b[1m\u001b[32m1.28329\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9477 | loss: 1.28329 - acc: 0.7366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9478  | total loss: \u001b[1m\u001b[32m1.18802\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9478 | loss: 1.18802 - acc: 0.7629 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9479  | total loss: \u001b[1m\u001b[32m1.10147\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9479 | loss: 1.10147 - acc: 0.7866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9480  | total loss: \u001b[1m\u001b[32m1.36874\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9480 | loss: 1.36874 - acc: 0.7151 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9481  | total loss: \u001b[1m\u001b[32m1.26294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9481 | loss: 1.26294 - acc: 0.7436 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9482  | total loss: \u001b[1m\u001b[32m1.50237\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9482 | loss: 1.50237 - acc: 0.6764 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9483  | total loss: \u001b[1m\u001b[32m1.38307\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9483 | loss: 1.38307 - acc: 0.7087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9484  | total loss: \u001b[1m\u001b[32m1.55555\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9484 | loss: 1.55555 - acc: 0.6593 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9485  | total loss: \u001b[1m\u001b[32m1.43148\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9485 | loss: 1.43148 - acc: 0.6934 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9486  | total loss: \u001b[1m\u001b[32m1.32004\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9486 | loss: 1.32004 - acc: 0.7240 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9487  | total loss: \u001b[1m\u001b[32m1.21969\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9487 | loss: 1.21969 - acc: 0.7516 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9488  | total loss: \u001b[1m\u001b[32m1.46658\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9488 | loss: 1.46658 - acc: 0.6836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9489  | total loss: \u001b[1m\u001b[32m1.35167\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9489 | loss: 1.35167 - acc: 0.7152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9490  | total loss: \u001b[1m\u001b[32m1.24838\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9490 | loss: 1.24838 - acc: 0.7437 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9491  | total loss: \u001b[1m\u001b[32m1.15526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9491 | loss: 1.15526 - acc: 0.7694 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9492  | total loss: \u001b[1m\u001b[32m1.46974\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9492 | loss: 1.46974 - acc: 0.6924 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9493  | total loss: \u001b[1m\u001b[32m1.35456\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9493 | loss: 1.35456 - acc: 0.7232 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9494  | total loss: \u001b[1m\u001b[32m1.63737\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9494 | loss: 1.63737 - acc: 0.6509 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9495  | total loss: \u001b[1m\u001b[32m1.50656\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9495 | loss: 1.50656 - acc: 0.6858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9496  | total loss: \u001b[1m\u001b[32m1.72107\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9496 | loss: 1.72107 - acc: 0.6243 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9497  | total loss: \u001b[1m\u001b[32m1.58370\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9497 | loss: 1.58370 - acc: 0.6619 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9498  | total loss: \u001b[1m\u001b[32m1.80642\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9498 | loss: 1.80642 - acc: 0.5957 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9499  | total loss: \u001b[1m\u001b[32m1.66287\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9499 | loss: 1.66287 - acc: 0.6361 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9500  | total loss: \u001b[1m\u001b[32m1.53477\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9500 | loss: 1.53477 - acc: 0.6725 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9501  | total loss: \u001b[1m\u001b[32m1.42013\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9501 | loss: 1.42013 - acc: 0.7053 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9502  | total loss: \u001b[1m\u001b[32m1.62113\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9502 | loss: 1.62113 - acc: 0.6419 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9503  | total loss: \u001b[1m\u001b[32m1.49898\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9503 | loss: 1.49898 - acc: 0.6777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9504  | total loss: \u001b[1m\u001b[32m1.38946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9504 | loss: 1.38946 - acc: 0.7099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9505  | total loss: \u001b[1m\u001b[32m1.29092\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9505 | loss: 1.29092 - acc: 0.7389 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9506  | total loss: \u001b[1m\u001b[32m1.51935\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9506 | loss: 1.51935 - acc: 0.6722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9507  | total loss: \u001b[1m\u001b[32m1.40785\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9507 | loss: 1.40785 - acc: 0.7050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9508  | total loss: \u001b[1m\u001b[32m1.56257\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9508 | loss: 1.56257 - acc: 0.6488 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9509  | total loss: \u001b[1m\u001b[32m1.44733\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9509 | loss: 1.44733 - acc: 0.6839 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9510  | total loss: \u001b[1m\u001b[32m1.34379\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9510 | loss: 1.34379 - acc: 0.7155 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9511  | total loss: \u001b[1m\u001b[32m1.25039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9511 | loss: 1.25039 - acc: 0.7439 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9512  | total loss: \u001b[1m\u001b[32m1.16574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9512 | loss: 1.16574 - acc: 0.7695 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9513  | total loss: \u001b[1m\u001b[32m1.08867\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9513 | loss: 1.08867 - acc: 0.7926 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9514  | total loss: \u001b[1m\u001b[32m1.33820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9514 | loss: 1.33820 - acc: 0.7205 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9515  | total loss: \u001b[1m\u001b[32m1.24240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9515 | loss: 1.24240 - acc: 0.7484 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9516  | total loss: \u001b[1m\u001b[32m1.48723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9516 | loss: 1.48723 - acc: 0.6807 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9517  | total loss: \u001b[1m\u001b[32m1.37606\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9517 | loss: 1.37606 - acc: 0.7127 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9518  | total loss: \u001b[1m\u001b[32m1.60680\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9518 | loss: 1.60680 - acc: 0.6414 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9519  | total loss: \u001b[1m\u001b[32m1.48416\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9519 | loss: 1.48416 - acc: 0.6773 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9520  | total loss: \u001b[1m\u001b[32m1.37405\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9520 | loss: 1.37405 - acc: 0.7095 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9521  | total loss: \u001b[1m\u001b[32m1.27485\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9521 | loss: 1.27485 - acc: 0.7386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9522  | total loss: \u001b[1m\u001b[32m1.50255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9522 | loss: 1.50255 - acc: 0.6719 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9523  | total loss: \u001b[1m\u001b[32m1.39041\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9523 | loss: 1.39041 - acc: 0.7047 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9524  | total loss: \u001b[1m\u001b[32m1.28945\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9524 | loss: 1.28945 - acc: 0.7342 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9525  | total loss: \u001b[1m\u001b[32m1.19821\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9525 | loss: 1.19821 - acc: 0.7608 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9526  | total loss: \u001b[1m\u001b[32m1.43810\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9526 | loss: 1.43810 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9527  | total loss: \u001b[1m\u001b[32m1.33140\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 9527 | loss: 1.33140 - acc: 0.7227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9528  | total loss: \u001b[1m\u001b[32m1.23513\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9528 | loss: 1.23513 - acc: 0.7504 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9529  | total loss: \u001b[1m\u001b[32m1.14793\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9529 | loss: 1.14793 - acc: 0.7754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9530  | total loss: \u001b[1m\u001b[32m1.39206\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9530 | loss: 1.39206 - acc: 0.7050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9531  | total loss: \u001b[1m\u001b[32m1.28832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9531 | loss: 1.28832 - acc: 0.7345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9532  | total loss: \u001b[1m\u001b[32m1.48966\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9532 | loss: 1.48966 - acc: 0.6753 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9533  | total loss: \u001b[1m\u001b[32m1.37612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9533 | loss: 1.37612 - acc: 0.7078 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9534  | total loss: \u001b[1m\u001b[32m1.61823\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9534 | loss: 1.61823 - acc: 0.6441 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9535  | total loss: \u001b[1m\u001b[32m1.49241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9535 | loss: 1.49241 - acc: 0.6797 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9536  | total loss: \u001b[1m\u001b[32m1.70102\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9536 | loss: 1.70102 - acc: 0.6189 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9537  | total loss: \u001b[1m\u001b[32m1.56804\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9537 | loss: 1.56804 - acc: 0.6570 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9538  | total loss: \u001b[1m\u001b[32m1.77816\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9538 | loss: 1.77816 - acc: 0.5985 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9539  | total loss: \u001b[1m\u001b[32m1.63895\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9539 | loss: 1.63895 - acc: 0.6386 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9540  | total loss: \u001b[1m\u001b[32m1.82755\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9540 | loss: 1.82755 - acc: 0.5819 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9541  | total loss: \u001b[1m\u001b[32m1.68524\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9541 | loss: 1.68524 - acc: 0.6237 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9542  | total loss: \u001b[1m\u001b[32m1.55792\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9542 | loss: 1.55792 - acc: 0.6613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9543  | total loss: \u001b[1m\u001b[32m1.44363\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9543 | loss: 1.44363 - acc: 0.6952 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9544  | total loss: \u001b[1m\u001b[32m1.66008\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9544 | loss: 1.66008 - acc: 0.6257 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9545  | total loss: \u001b[1m\u001b[32m1.53617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9545 | loss: 1.53617 - acc: 0.6631 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9546  | total loss: \u001b[1m\u001b[32m1.73827\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9546 | loss: 1.73827 - acc: 0.5968 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9547  | total loss: \u001b[1m\u001b[32m1.60777\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9547 | loss: 1.60777 - acc: 0.6371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9548  | total loss: \u001b[1m\u001b[32m1.79314\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9548 | loss: 1.79314 - acc: 0.5805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9549  | total loss: \u001b[1m\u001b[32m1.65886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9549 | loss: 1.65886 - acc: 0.6225 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9550  | total loss: \u001b[1m\u001b[32m1.81235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9550 | loss: 1.81235 - acc: 0.5745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9551  | total loss: \u001b[1m\u001b[32m1.67805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9551 | loss: 1.67805 - acc: 0.6171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9552  | total loss: \u001b[1m\u001b[32m1.55789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9552 | loss: 1.55789 - acc: 0.6554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9553  | total loss: \u001b[1m\u001b[32m1.44990\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9553 | loss: 1.44990 - acc: 0.6898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9554  | total loss: \u001b[1m\u001b[32m1.35241\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9554 | loss: 1.35241 - acc: 0.7208 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9555  | total loss: \u001b[1m\u001b[32m1.26393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9555 | loss: 1.26393 - acc: 0.7488 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9556  | total loss: \u001b[1m\u001b[32m1.48311\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9556 | loss: 1.48311 - acc: 0.6810 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9557  | total loss: \u001b[1m\u001b[32m1.38021\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9557 | loss: 1.38021 - acc: 0.7129 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9558  | total loss: \u001b[1m\u001b[32m1.59825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9558 | loss: 1.59825 - acc: 0.6416 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9559  | total loss: \u001b[1m\u001b[32m1.48336\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9559 | loss: 1.48336 - acc: 0.6775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9560  | total loss: \u001b[1m\u001b[32m1.37970\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9560 | loss: 1.37970 - acc: 0.7097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9561  | total loss: \u001b[1m\u001b[32m1.28574\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9561 | loss: 1.28574 - acc: 0.7388 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9562  | total loss: \u001b[1m\u001b[32m1.51785\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9562 | loss: 1.51785 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9563  | total loss: \u001b[1m\u001b[32m1.40885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9563 | loss: 1.40885 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9564  | total loss: \u001b[1m\u001b[32m1.31014\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9564 | loss: 1.31014 - acc: 0.7343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9565  | total loss: \u001b[1m\u001b[32m1.22037\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9565 | loss: 1.22037 - acc: 0.7609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9566  | total loss: \u001b[1m\u001b[32m1.42123\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9566 | loss: 1.42123 - acc: 0.7062 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9567  | total loss: \u001b[1m\u001b[32m1.31861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9567 | loss: 1.31861 - acc: 0.7356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9568  | total loss: \u001b[1m\u001b[32m1.54128\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9568 | loss: 1.54128 - acc: 0.6763 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9569  | total loss: \u001b[1m\u001b[32m1.42573\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9569 | loss: 1.42573 - acc: 0.7087 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9570  | total loss: \u001b[1m\u001b[32m1.62526\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9570 | loss: 1.62526 - acc: 0.6450 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9571  | total loss: \u001b[1m\u001b[32m1.50121\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9571 | loss: 1.50121 - acc: 0.6805 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9572  | total loss: \u001b[1m\u001b[32m1.38951\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9572 | loss: 1.38951 - acc: 0.7124 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9573  | total loss: \u001b[1m\u001b[32m1.28859\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9573 | loss: 1.28859 - acc: 0.7412 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9574  | total loss: \u001b[1m\u001b[32m1.48340\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9574 | loss: 1.48340 - acc: 0.6814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9575  | total loss: \u001b[1m\u001b[32m1.37239\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9575 | loss: 1.37239 - acc: 0.7132 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9576  | total loss: \u001b[1m\u001b[32m1.59110\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9576 | loss: 1.59110 - acc: 0.6419 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9577  | total loss: \u001b[1m\u001b[32m1.46941\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9577 | loss: 1.46941 - acc: 0.6777 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9578  | total loss: \u001b[1m\u001b[32m1.67764\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9578 | loss: 1.67764 - acc: 0.6171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9579  | total loss: \u001b[1m\u001b[32m1.54809\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9579 | loss: 1.54809 - acc: 0.6554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9580  | total loss: \u001b[1m\u001b[32m1.43182\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9580 | loss: 1.43182 - acc: 0.6898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9581  | total loss: \u001b[1m\u001b[32m1.32711\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9581 | loss: 1.32711 - acc: 0.7209 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9582  | total loss: \u001b[1m\u001b[32m1.23245\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9582 | loss: 1.23245 - acc: 0.7488 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9583  | total loss: \u001b[1m\u001b[32m1.14654\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9583 | loss: 1.14654 - acc: 0.7739 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9584  | total loss: \u001b[1m\u001b[32m1.37963\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9584 | loss: 1.37963 - acc: 0.7036 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9585  | total loss: \u001b[1m\u001b[32m1.27778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9585 | loss: 1.27778 - acc: 0.7333 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9586  | total loss: \u001b[1m\u001b[32m1.53229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9586 | loss: 1.53229 - acc: 0.6600 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9587  | total loss: \u001b[1m\u001b[32m1.41492\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9587 | loss: 1.41492 - acc: 0.6940 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9588  | total loss: \u001b[1m\u001b[32m1.30921\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9588 | loss: 1.30921 - acc: 0.7246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9589  | total loss: \u001b[1m\u001b[32m1.21369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9589 | loss: 1.21369 - acc: 0.7521 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9590  | total loss: \u001b[1m\u001b[32m1.46549\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9590 | loss: 1.46549 - acc: 0.6840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9591  | total loss: \u001b[1m\u001b[32m1.35390\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9591 | loss: 1.35390 - acc: 0.7156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9592  | total loss: \u001b[1m\u001b[32m1.25335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9592 | loss: 1.25335 - acc: 0.7441 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9593  | total loss: \u001b[1m\u001b[32m1.16244\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9593 | loss: 1.16244 - acc: 0.7697 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9594  | total loss: \u001b[1m\u001b[32m1.07993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9594 | loss: 1.07993 - acc: 0.7927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9595  | total loss: \u001b[1m\u001b[32m1.00475\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9595 | loss: 1.00475 - acc: 0.8134 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9596  | total loss: \u001b[1m\u001b[32m1.26788\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9596 | loss: 1.26788 - acc: 0.7392 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9597  | total loss: \u001b[1m\u001b[32m1.17252\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9597 | loss: 1.17252 - acc: 0.7653 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9598  | total loss: \u001b[1m\u001b[32m1.08617\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9598 | loss: 1.08617 - acc: 0.7888 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9599  | total loss: \u001b[1m\u001b[32m1.00772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9599 | loss: 1.00772 - acc: 0.8099 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9600  | total loss: \u001b[1m\u001b[32m0.93620\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9600 | loss: 0.93620 - acc: 0.8289 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9601  | total loss: \u001b[1m\u001b[32m0.87077\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9601 | loss: 0.87077 - acc: 0.8460 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9602  | total loss: \u001b[1m\u001b[32m1.15802\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9602 | loss: 1.15802 - acc: 0.7686 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9603  | total loss: \u001b[1m\u001b[32m1.06889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9603 | loss: 1.06889 - acc: 0.7917 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9604  | total loss: \u001b[1m\u001b[32m1.35238\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9604 | loss: 1.35238 - acc: 0.7197 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9605  | total loss: \u001b[1m\u001b[32m1.24357\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9605 | loss: 1.24357 - acc: 0.7477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9606  | total loss: \u001b[1m\u001b[32m1.50135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9606 | loss: 1.50135 - acc: 0.6801 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9607  | total loss: \u001b[1m\u001b[32m1.37837\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9607 | loss: 1.37837 - acc: 0.7121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9608  | total loss: \u001b[1m\u001b[32m1.65625\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9608 | loss: 1.65625 - acc: 0.6409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9609  | total loss: \u001b[1m\u001b[32m1.51938\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9609 | loss: 1.51938 - acc: 0.6768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9610  | total loss: \u001b[1m\u001b[32m1.39704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9610 | loss: 1.39704 - acc: 0.7091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9611  | total loss: \u001b[1m\u001b[32m1.28744\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9611 | loss: 1.28744 - acc: 0.7382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9612  | total loss: \u001b[1m\u001b[32m1.54918\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9612 | loss: 1.54918 - acc: 0.6644 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9613  | total loss: \u001b[1m\u001b[32m1.42557\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9613 | loss: 1.42557 - acc: 0.6979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9614  | total loss: \u001b[1m\u001b[32m1.62421\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9614 | loss: 1.62421 - acc: 0.6424 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9615  | total loss: \u001b[1m\u001b[32m1.49502\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9615 | loss: 1.49502 - acc: 0.6782 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9616  | total loss: \u001b[1m\u001b[32m1.37964\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9616 | loss: 1.37964 - acc: 0.7104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9617  | total loss: \u001b[1m\u001b[32m1.27628\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9617 | loss: 1.27628 - acc: 0.7393 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9618  | total loss: \u001b[1m\u001b[32m1.18338\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9618 | loss: 1.18338 - acc: 0.7654 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9619  | total loss: \u001b[1m\u001b[32m1.09955\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9619 | loss: 1.09955 - acc: 0.7889 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9620  | total loss: \u001b[1m\u001b[32m1.37587\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9620 | loss: 1.37587 - acc: 0.7100 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9621  | total loss: \u001b[1m\u001b[32m1.27265\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9621 | loss: 1.27265 - acc: 0.7390 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9622  | total loss: \u001b[1m\u001b[32m1.17979\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9622 | loss: 1.17979 - acc: 0.7651 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9623  | total loss: \u001b[1m\u001b[32m1.09592\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9623 | loss: 1.09592 - acc: 0.7886 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9624  | total loss: \u001b[1m\u001b[32m1.38031\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9624 | loss: 1.38031 - acc: 0.7097 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9625  | total loss: \u001b[1m\u001b[32m1.27616\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9625 | loss: 1.27616 - acc: 0.7387 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9626  | total loss: \u001b[1m\u001b[32m1.52256\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9626 | loss: 1.52256 - acc: 0.6720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9627  | total loss: \u001b[1m\u001b[32m1.40493\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9627 | loss: 1.40493 - acc: 0.7048 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9628  | total loss: \u001b[1m\u001b[32m1.29940\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9628 | loss: 1.29940 - acc: 0.7343 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9629  | total loss: \u001b[1m\u001b[32m1.20441\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9629 | loss: 1.20441 - acc: 0.7609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9630  | total loss: \u001b[1m\u001b[32m1.45697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9630 | loss: 1.45697 - acc: 0.6919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9631  | total loss: \u001b[1m\u001b[32m1.34637\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9631 | loss: 1.34637 - acc: 0.7228 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9632  | total loss: \u001b[1m\u001b[32m1.24694\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9632 | loss: 1.24694 - acc: 0.7505 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9633  | total loss: \u001b[1m\u001b[32m1.15723\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9633 | loss: 1.15723 - acc: 0.7754 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9634  | total loss: \u001b[1m\u001b[32m1.40216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9634 | loss: 1.40216 - acc: 0.7050 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9635  | total loss: \u001b[1m\u001b[32m1.29666\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9635 | loss: 1.29666 - acc: 0.7345 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9636  | total loss: \u001b[1m\u001b[32m1.20164\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9636 | loss: 1.20164 - acc: 0.7611 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9637  | total loss: \u001b[1m\u001b[32m1.11572\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9637 | loss: 1.11572 - acc: 0.7850 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9638  | total loss: \u001b[1m\u001b[32m1.36458\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9638 | loss: 1.36458 - acc: 0.7136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9639  | total loss: \u001b[1m\u001b[32m1.26186\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9639 | loss: 1.26186 - acc: 0.7423 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9640  | total loss: \u001b[1m\u001b[32m1.16923\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9640 | loss: 1.16923 - acc: 0.7680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9641  | total loss: \u001b[1m\u001b[32m1.08542\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9641 | loss: 1.08542 - acc: 0.7912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9642  | total loss: \u001b[1m\u001b[32m1.37399\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9642 | loss: 1.37399 - acc: 0.7121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9643  | total loss: \u001b[1m\u001b[32m1.26918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9643 | loss: 1.26918 - acc: 0.7409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9644  | total loss: \u001b[1m\u001b[32m1.54177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9644 | loss: 1.54177 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9645  | total loss: \u001b[1m\u001b[32m1.42080\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9645 | loss: 1.42080 - acc: 0.7001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9646  | total loss: \u001b[1m\u001b[32m1.31230\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9646 | loss: 1.31230 - acc: 0.7301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9647  | total loss: \u001b[1m\u001b[32m1.21468\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9647 | loss: 1.21468 - acc: 0.7571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9648  | total loss: \u001b[1m\u001b[32m1.49154\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9648 | loss: 1.49154 - acc: 0.6814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9649  | total loss: \u001b[1m\u001b[32m1.37629\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9649 | loss: 1.37629 - acc: 0.7133 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9650  | total loss: \u001b[1m\u001b[32m1.62076\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9650 | loss: 1.62076 - acc: 0.6491 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9651  | total loss: \u001b[1m\u001b[32m1.49369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9651 | loss: 1.49369 - acc: 0.6842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9652  | total loss: \u001b[1m\u001b[32m1.71228\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9652 | loss: 1.71228 - acc: 0.6229 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9653  | total loss: \u001b[1m\u001b[32m1.57778\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9653 | loss: 1.57778 - acc: 0.6606 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9654  | total loss: \u001b[1m\u001b[32m1.76897\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9654 | loss: 1.76897 - acc: 0.6017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9655  | total loss: \u001b[1m\u001b[32m1.63101\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9655 | loss: 1.63101 - acc: 0.6415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9656  | total loss: \u001b[1m\u001b[32m1.85611\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9656 | loss: 1.85611 - acc: 0.5774 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9657  | total loss: \u001b[1m\u001b[32m1.71213\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9657 | loss: 1.71213 - acc: 0.6196 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9658  | total loss: \u001b[1m\u001b[32m1.58374\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9658 | loss: 1.58374 - acc: 0.6577 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9659  | total loss: \u001b[1m\u001b[32m1.46884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9659 | loss: 1.46884 - acc: 0.6919 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9660  | total loss: \u001b[1m\u001b[32m1.70179\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9660 | loss: 1.70179 - acc: 0.6227 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9661  | total loss: \u001b[1m\u001b[32m1.57620\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9661 | loss: 1.57620 - acc: 0.6604 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9662  | total loss: \u001b[1m\u001b[32m1.46360\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9662 | loss: 1.46360 - acc: 0.6944 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9663  | total loss: \u001b[1m\u001b[32m1.36218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9663 | loss: 1.36218 - acc: 0.7250 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9664  | total loss: \u001b[1m\u001b[32m1.27039\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9664 | loss: 1.27039 - acc: 0.7525 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9665  | total loss: \u001b[1m\u001b[32m1.18687\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9665 | loss: 1.18687 - acc: 0.7772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9666  | total loss: \u001b[1m\u001b[32m1.42461\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9666 | loss: 1.42461 - acc: 0.7066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9667  | total loss: \u001b[1m\u001b[32m1.32406\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9667 | loss: 1.32406 - acc: 0.7360 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9668  | total loss: \u001b[1m\u001b[32m1.23283\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9668 | loss: 1.23283 - acc: 0.7624 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9669  | total loss: \u001b[1m\u001b[32m1.14968\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9669 | loss: 1.14968 - acc: 0.7861 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9670  | total loss: \u001b[1m\u001b[32m1.41784\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9670 | loss: 1.41784 - acc: 0.7075 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9671  | total loss: \u001b[1m\u001b[32m1.31452\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9671 | loss: 1.31452 - acc: 0.7368 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9672  | total loss: \u001b[1m\u001b[32m1.53408\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9672 | loss: 1.53408 - acc: 0.6702 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9673  | total loss: \u001b[1m\u001b[32m1.41860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9673 | loss: 1.41860 - acc: 0.7032 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9674  | total loss: \u001b[1m\u001b[32m1.31447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9674 | loss: 1.31447 - acc: 0.7329 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9675  | total loss: \u001b[1m\u001b[32m1.22024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9675 | loss: 1.22024 - acc: 0.7596 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9676  | total loss: \u001b[1m\u001b[32m1.45923\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9676 | loss: 1.45923 - acc: 0.6979 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9677  | total loss: \u001b[1m\u001b[32m1.34966\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9677 | loss: 1.34966 - acc: 0.7281 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9678  | total loss: \u001b[1m\u001b[32m1.51489\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9678 | loss: 1.51489 - acc: 0.6768 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9679  | total loss: \u001b[1m\u001b[32m1.39956\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9679 | loss: 1.39956 - acc: 0.7091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9680  | total loss: \u001b[1m\u001b[32m1.29564\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9680 | loss: 1.29564 - acc: 0.7382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9681  | total loss: \u001b[1m\u001b[32m1.20165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9681 | loss: 1.20165 - acc: 0.7644 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9682  | total loss: \u001b[1m\u001b[32m1.11634\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9682 | loss: 1.11634 - acc: 0.7879 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9683  | total loss: \u001b[1m\u001b[32m1.03861\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9683 | loss: 1.03861 - acc: 0.8091 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9684  | total loss: \u001b[1m\u001b[32m1.23786\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9684 | loss: 1.23786 - acc: 0.7496 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9685  | total loss: \u001b[1m\u001b[32m1.14636\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9685 | loss: 1.14636 - acc: 0.7747 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9686  | total loss: \u001b[1m\u001b[32m1.06333\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9686 | loss: 1.06333 - acc: 0.7972 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9687  | total loss: \u001b[1m\u001b[32m0.98772\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9687 | loss: 0.98772 - acc: 0.8175 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9688  | total loss: \u001b[1m\u001b[32m0.91860\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9688 | loss: 0.91860 - acc: 0.8357 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9689  | total loss: \u001b[1m\u001b[32m0.85520\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9689 | loss: 0.85520 - acc: 0.8522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9690  | total loss: \u001b[1m\u001b[32m0.79684\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9690 | loss: 0.79684 - acc: 0.8669 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9691  | total loss: \u001b[1m\u001b[32m0.74295\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9691 | loss: 0.74295 - acc: 0.8803 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9692  | total loss: \u001b[1m\u001b[32m1.07043\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9692 | loss: 1.07043 - acc: 0.7994 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9693  | total loss: \u001b[1m\u001b[32m0.98722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9693 | loss: 0.98722 - acc: 0.8194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9694  | total loss: \u001b[1m\u001b[32m1.27294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9694 | loss: 1.27294 - acc: 0.7518 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9695  | total loss: \u001b[1m\u001b[32m1.16886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9695 | loss: 1.16886 - acc: 0.7766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9696  | total loss: \u001b[1m\u001b[32m1.07505\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9696 | loss: 1.07505 - acc: 0.7989 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9697  | total loss: \u001b[1m\u001b[32m0.99032\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9697 | loss: 0.99032 - acc: 0.8190 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9698  | total loss: \u001b[1m\u001b[32m0.91361\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9698 | loss: 0.91361 - acc: 0.8371 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9699  | total loss: \u001b[1m\u001b[32m0.84401\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9699 | loss: 0.84401 - acc: 0.8534 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9700  | total loss: \u001b[1m\u001b[32m1.22293\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9700 | loss: 1.22293 - acc: 0.7681 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9701  | total loss: \u001b[1m\u001b[32m1.12191\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9701 | loss: 1.12191 - acc: 0.7913 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9702  | total loss: \u001b[1m\u001b[32m1.41943\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9702 | loss: 1.41943 - acc: 0.7193 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9703  | total loss: \u001b[1m\u001b[32m1.29945\u001b[0m\u001b[0m\n",
      "| Adam | epoch: 9703 | loss: 1.29945 - acc: 0.7474 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9704  | total loss: \u001b[1m\u001b[32m1.19192\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9704 | loss: 1.19192 - acc: 0.7726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9705  | total loss: \u001b[1m\u001b[32m1.09539\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9705 | loss: 1.09539 - acc: 0.7954 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9706  | total loss: \u001b[1m\u001b[32m1.00855\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9706 | loss: 1.00855 - acc: 0.8158 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9707  | total loss: \u001b[1m\u001b[32m0.93024\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9707 | loss: 0.93024 - acc: 0.8342 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9708  | total loss: \u001b[1m\u001b[32m0.85946\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9708 | loss: 0.85946 - acc: 0.8508 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9709  | total loss: \u001b[1m\u001b[32m0.79530\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9709 | loss: 0.79530 - acc: 0.8657 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9710  | total loss: \u001b[1m\u001b[32m1.12447\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9710 | loss: 1.12447 - acc: 0.7863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9711  | total loss: \u001b[1m\u001b[32m1.03341\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9711 | loss: 1.03341 - acc: 0.8077 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9712  | total loss: \u001b[1m\u001b[32m1.35325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9712 | loss: 1.35325 - acc: 0.7269 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9713  | total loss: \u001b[1m\u001b[32m1.24005\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9713 | loss: 1.24005 - acc: 0.7542 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9714  | total loss: \u001b[1m\u001b[32m1.53835\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9714 | loss: 1.53835 - acc: 0.6788 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9715  | total loss: \u001b[1m\u001b[32m1.40844\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9715 | loss: 1.40844 - acc: 0.7109 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9716  | total loss: \u001b[1m\u001b[32m1.64231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9716 | loss: 1.64231 - acc: 0.6541 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9717  | total loss: \u001b[1m\u001b[32m1.50461\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9717 | loss: 1.50461 - acc: 0.6887 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9718  | total loss: \u001b[1m\u001b[32m1.76514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9718 | loss: 1.76514 - acc: 0.6198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9719  | total loss: \u001b[1m\u001b[32m1.61843\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9719 | loss: 1.61843 - acc: 0.6578 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9720  | total loss: \u001b[1m\u001b[32m1.86110\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9720 | loss: 1.86110 - acc: 0.5921 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9721  | total loss: \u001b[1m\u001b[32m1.70866\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9721 | loss: 1.70866 - acc: 0.6329 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9722  | total loss: \u001b[1m\u001b[32m1.83940\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9722 | loss: 1.83940 - acc: 0.5910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9723  | total loss: \u001b[1m\u001b[32m1.69320\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9723 | loss: 1.69320 - acc: 0.6319 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9724  | total loss: \u001b[1m\u001b[32m1.82064\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9724 | loss: 1.82064 - acc: 0.5901 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9725  | total loss: \u001b[1m\u001b[32m1.68016\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9725 | loss: 1.68016 - acc: 0.6311 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9726  | total loss: \u001b[1m\u001b[32m1.55528\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9726 | loss: 1.55528 - acc: 0.6680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9727  | total loss: \u001b[1m\u001b[32m1.44384\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9727 | loss: 1.44384 - acc: 0.7012 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9728  | total loss: \u001b[1m\u001b[32m1.62393\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9728 | loss: 1.62393 - acc: 0.6382 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9729  | total loss: \u001b[1m\u001b[32m1.50718\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9729 | loss: 1.50718 - acc: 0.6744 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9730  | total loss: \u001b[1m\u001b[32m1.65961\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9730 | loss: 1.65961 - acc: 0.6213 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9731  | total loss: \u001b[1m\u001b[32m1.54100\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9731 | loss: 1.54100 - acc: 0.6591 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9732  | total loss: \u001b[1m\u001b[32m1.43478\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9732 | loss: 1.43478 - acc: 0.6932 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9733  | total loss: \u001b[1m\u001b[32m1.33917\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9733 | loss: 1.33917 - acc: 0.7239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9734  | total loss: \u001b[1m\u001b[32m1.51989\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9734 | loss: 1.51989 - acc: 0.6658 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9735  | total loss: \u001b[1m\u001b[32m1.41548\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9735 | loss: 1.41548 - acc: 0.6992 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9736  | total loss: \u001b[1m\u001b[32m1.63026\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9736 | loss: 1.63026 - acc: 0.6293 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9737  | total loss: \u001b[1m\u001b[32m1.51504\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9737 | loss: 1.51504 - acc: 0.6664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9738  | total loss: \u001b[1m\u001b[32m1.41131\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9738 | loss: 1.41131 - acc: 0.6997 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9739  | total loss: \u001b[1m\u001b[32m1.31742\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9739 | loss: 1.31742 - acc: 0.7298 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9740  | total loss: \u001b[1m\u001b[32m1.53611\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9740 | loss: 1.53611 - acc: 0.6639 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9741  | total loss: \u001b[1m\u001b[32m1.42873\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9741 | loss: 1.42873 - acc: 0.6975 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9742  | total loss: \u001b[1m\u001b[32m1.62566\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9742 | loss: 1.62566 - acc: 0.6349 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9743  | total loss: \u001b[1m\u001b[32m1.50903\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9743 | loss: 1.50903 - acc: 0.6714 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9744  | total loss: \u001b[1m\u001b[32m1.40380\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9744 | loss: 1.40380 - acc: 0.7043 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9745  | total loss: \u001b[1m\u001b[32m1.30841\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9745 | loss: 1.30841 - acc: 0.7339 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9746  | total loss: \u001b[1m\u001b[32m1.22150\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9746 | loss: 1.22150 - acc: 0.7605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9747  | total loss: \u001b[1m\u001b[32m1.14193\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9747 | loss: 1.14193 - acc: 0.7844 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9748  | total loss: \u001b[1m\u001b[32m1.36170\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9748 | loss: 1.36170 - acc: 0.7203 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9749  | total loss: \u001b[1m\u001b[32m1.26571\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9749 | loss: 1.26571 - acc: 0.7482 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9750  | total loss: \u001b[1m\u001b[32m1.44083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9750 | loss: 1.44083 - acc: 0.6948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9751  | total loss: \u001b[1m\u001b[32m1.33537\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9751 | loss: 1.33537 - acc: 0.7254 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9752  | total loss: \u001b[1m\u001b[32m1.23968\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9752 | loss: 1.23968 - acc: 0.7528 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9753  | total loss: \u001b[1m\u001b[32m1.15255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9753 | loss: 1.15255 - acc: 0.7775 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9754  | total loss: \u001b[1m\u001b[32m1.07291\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9754 | loss: 1.07291 - acc: 0.7998 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9755  | total loss: \u001b[1m\u001b[32m0.99983\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9755 | loss: 0.99983 - acc: 0.8198 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9756  | total loss: \u001b[1m\u001b[32m1.20596\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9756 | loss: 1.20596 - acc: 0.7664 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9757  | total loss: \u001b[1m\u001b[32m1.11725\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9757 | loss: 1.11725 - acc: 0.7898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9758  | total loss: \u001b[1m\u001b[32m1.03641\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9758 | loss: 1.03641 - acc: 0.8108 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9759  | total loss: \u001b[1m\u001b[32m0.96253\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9759 | loss: 0.96253 - acc: 0.8297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9760  | total loss: \u001b[1m\u001b[32m0.89481\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9760 | loss: 0.89481 - acc: 0.8467 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9761  | total loss: \u001b[1m\u001b[32m0.83254\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9761 | loss: 0.83254 - acc: 0.8621 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9762  | total loss: \u001b[1m\u001b[32m1.15300\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9762 | loss: 1.15300 - acc: 0.7759 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9763  | total loss: \u001b[1m\u001b[32m1.06310\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9763 | loss: 1.06310 - acc: 0.7983 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9764  | total loss: \u001b[1m\u001b[32m0.98160\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9764 | loss: 0.98160 - acc: 0.8184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9765  | total loss: \u001b[1m\u001b[32m0.90753\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9765 | loss: 0.90753 - acc: 0.8366 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9766  | total loss: \u001b[1m\u001b[32m1.23325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9766 | loss: 1.23325 - acc: 0.7529 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9767  | total loss: \u001b[1m\u001b[32m1.13317\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9767 | loss: 1.13317 - acc: 0.7776 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9768  | total loss: \u001b[1m\u001b[32m1.04291\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9768 | loss: 1.04291 - acc: 0.7999 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9769  | total loss: \u001b[1m\u001b[32m0.96132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9769 | loss: 0.96132 - acc: 0.8199 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9770  | total loss: \u001b[1m\u001b[32m1.23397\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9770 | loss: 1.23397 - acc: 0.7522 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9771  | total loss: \u001b[1m\u001b[32m1.13292\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9771 | loss: 1.13292 - acc: 0.7770 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9772  | total loss: \u001b[1m\u001b[32m1.39560\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9772 | loss: 1.39560 - acc: 0.7136 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9773  | total loss: \u001b[1m\u001b[32m1.27889\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9773 | loss: 1.27889 - acc: 0.7422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9774  | total loss: \u001b[1m\u001b[32m1.17419\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9774 | loss: 1.17419 - acc: 0.7680 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9775  | total loss: \u001b[1m\u001b[32m1.08009\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9775 | loss: 1.08009 - acc: 0.7912 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9776  | total loss: \u001b[1m\u001b[32m1.39046\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9776 | loss: 1.39046 - acc: 0.7121 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9777  | total loss: \u001b[1m\u001b[32m1.27541\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9777 | loss: 1.27541 - acc: 0.7409 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9778  | total loss: \u001b[1m\u001b[32m1.17235\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9778 | loss: 1.17235 - acc: 0.7668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9779  | total loss: \u001b[1m\u001b[32m1.07983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9779 | loss: 1.07983 - acc: 0.7901 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9780  | total loss: \u001b[1m\u001b[32m1.39189\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9780 | loss: 1.39189 - acc: 0.7111 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9781  | total loss: \u001b[1m\u001b[32m1.27822\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9781 | loss: 1.27822 - acc: 0.7400 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9782  | total loss: \u001b[1m\u001b[32m1.54225\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9782 | loss: 1.54225 - acc: 0.6731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9783  | total loss: \u001b[1m\u001b[32m1.41523\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9783 | loss: 1.41523 - acc: 0.7058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9784  | total loss: \u001b[1m\u001b[32m1.30177\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9784 | loss: 1.30177 - acc: 0.7352 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9785  | total loss: \u001b[1m\u001b[32m1.20020\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9785 | loss: 1.20020 - acc: 0.7617 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9786  | total loss: \u001b[1m\u001b[32m1.46428\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9786 | loss: 1.46428 - acc: 0.6927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9787  | total loss: \u001b[1m\u001b[32m1.34766\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9787 | loss: 1.34766 - acc: 0.7234 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9788  | total loss: \u001b[1m\u001b[32m1.60423\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9788 | loss: 1.60423 - acc: 0.6511 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9789  | total loss: \u001b[1m\u001b[32m1.47553\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9789 | loss: 1.47553 - acc: 0.6860 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9790  | total loss: \u001b[1m\u001b[32m1.36061\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9790 | loss: 1.36061 - acc: 0.7174 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9791  | total loss: \u001b[1m\u001b[32m1.25773\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9791 | loss: 1.25773 - acc: 0.7456 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9792  | total loss: \u001b[1m\u001b[32m1.52450\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9792 | loss: 1.52450 - acc: 0.6711 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9793  | total loss: \u001b[1m\u001b[32m1.40635\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9793 | loss: 1.40635 - acc: 0.7040 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9794  | total loss: \u001b[1m\u001b[32m1.59009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9794 | loss: 1.59009 - acc: 0.6478 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9795  | total loss: \u001b[1m\u001b[32m1.46704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9795 | loss: 1.46704 - acc: 0.6831 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9796  | total loss: \u001b[1m\u001b[32m1.71852\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9796 | loss: 1.71852 - acc: 0.6148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9797  | total loss: \u001b[1m\u001b[32m1.58479\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9797 | loss: 1.58479 - acc: 0.6533 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9798  | total loss: \u001b[1m\u001b[32m1.78668\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9798 | loss: 1.78668 - acc: 0.5951 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9799  | total loss: \u001b[1m\u001b[32m1.64872\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9799 | loss: 1.64872 - acc: 0.6356 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9800  | total loss: \u001b[1m\u001b[32m1.85451\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9800 | loss: 1.85451 - acc: 0.5720 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9801  | total loss: \u001b[1m\u001b[32m1.71269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9801 | loss: 1.71269 - acc: 0.6148 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9802  | total loss: \u001b[1m\u001b[32m1.87418\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9802 | loss: 1.87418 - acc: 0.5605 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9803  | total loss: \u001b[1m\u001b[32m1.73348\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9803 | loss: 1.73348 - acc: 0.6044 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9804  | total loss: \u001b[1m\u001b[32m1.91853\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9804 | loss: 1.91853 - acc: 0.5440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9805  | total loss: \u001b[1m\u001b[32m1.77657\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9805 | loss: 1.77657 - acc: 0.5896 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9806  | total loss: \u001b[1m\u001b[32m1.90911\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9806 | loss: 1.90911 - acc: 0.5378 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9807  | total loss: \u001b[1m\u001b[32m1.77117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9807 | loss: 1.77117 - acc: 0.5840 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9808  | total loss: \u001b[1m\u001b[32m1.64812\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9808 | loss: 1.64812 - acc: 0.6256 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9809  | total loss: \u001b[1m\u001b[32m1.53779\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9809 | loss: 1.53779 - acc: 0.6630 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9810  | total loss: \u001b[1m\u001b[32m1.43828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9810 | loss: 1.43828 - acc: 0.6967 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9811  | total loss: \u001b[1m\u001b[32m1.34792\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9811 | loss: 1.34792 - acc: 0.7271 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9812  | total loss: \u001b[1m\u001b[32m1.47132\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9812 | loss: 1.47132 - acc: 0.6829 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9813  | total loss: \u001b[1m\u001b[32m1.37564\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9813 | loss: 1.37564 - acc: 0.7146 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9814  | total loss: \u001b[1m\u001b[32m1.28832\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9814 | loss: 1.28832 - acc: 0.7432 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9815  | total loss: \u001b[1m\u001b[32m1.20816\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9815 | loss: 1.20816 - acc: 0.7689 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9816  | total loss: \u001b[1m\u001b[32m1.13415\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9816 | loss: 1.13415 - acc: 0.7920 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9817  | total loss: \u001b[1m\u001b[32m1.06545\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9817 | loss: 1.06545 - acc: 0.8128 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9818  | total loss: \u001b[1m\u001b[32m1.00135\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9818 | loss: 1.00135 - acc: 0.8315 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9819  | total loss: \u001b[1m\u001b[32m0.94129\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9819 | loss: 0.94129 - acc: 0.8483 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9820  | total loss: \u001b[1m\u001b[32m0.88480\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9820 | loss: 0.88480 - acc: 0.8635 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9821  | total loss: \u001b[1m\u001b[32m0.83151\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9821 | loss: 0.83151 - acc: 0.8772 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9822  | total loss: \u001b[1m\u001b[32m0.78112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9822 | loss: 0.78112 - acc: 0.8894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9823  | total loss: \u001b[1m\u001b[32m0.73339\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9823 | loss: 0.73339 - acc: 0.9005 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9824  | total loss: \u001b[1m\u001b[32m0.68813\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9824 | loss: 0.68813 - acc: 0.9104 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9825  | total loss: \u001b[1m\u001b[32m0.64519\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9825 | loss: 0.64519 - acc: 0.9194 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9826  | total loss: \u001b[1m\u001b[32m0.98993\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9826 | loss: 0.98993 - acc: 0.8275 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9827  | total loss: \u001b[1m\u001b[32m0.91369\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9827 | loss: 0.91369 - acc: 0.8447 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9828  | total loss: \u001b[1m\u001b[32m1.24875\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9828 | loss: 1.24875 - acc: 0.7602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9829  | total loss: \u001b[1m\u001b[32m1.14550\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9829 | loss: 1.14550 - acc: 0.7842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9830  | total loss: \u001b[1m\u001b[32m1.05237\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9830 | loss: 1.05237 - acc: 0.8058 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9831  | total loss: \u001b[1m\u001b[32m0.96820\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9831 | loss: 0.96820 - acc: 0.8252 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9832  | total loss: \u001b[1m\u001b[32m0.89198\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9832 | loss: 0.89198 - acc: 0.8427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9833  | total loss: \u001b[1m\u001b[32m0.82280\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9833 | loss: 0.82280 - acc: 0.8584 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9834  | total loss: \u001b[1m\u001b[32m1.20164\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9834 | loss: 1.20164 - acc: 0.7726 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9835  | total loss: \u001b[1m\u001b[32m1.10095\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9835 | loss: 1.10095 - acc: 0.7953 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9836  | total loss: \u001b[1m\u001b[32m1.32341\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9836 | loss: 1.32341 - acc: 0.7372 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9837  | total loss: \u001b[1m\u001b[32m1.21117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9837 | loss: 1.21117 - acc: 0.7635 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9838  | total loss: \u001b[1m\u001b[32m1.49970\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9838 | loss: 1.49970 - acc: 0.6872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9839  | total loss: \u001b[1m\u001b[32m1.37151\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9839 | loss: 1.37151 - acc: 0.7184 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9840  | total loss: \u001b[1m\u001b[32m1.61803\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9840 | loss: 1.61803 - acc: 0.6609 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9841  | total loss: \u001b[1m\u001b[32m1.48063\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9841 | loss: 1.48063 - acc: 0.6948 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9842  | total loss: \u001b[1m\u001b[32m1.68569\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9842 | loss: 1.68569 - acc: 0.6396 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9843  | total loss: \u001b[1m\u001b[32m1.54490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9843 | loss: 1.54490 - acc: 0.6756 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9844  | total loss: \u001b[1m\u001b[32m1.41983\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9844 | loss: 1.41983 - acc: 0.7081 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9845  | total loss: \u001b[1m\u001b[32m1.30848\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9845 | loss: 1.30848 - acc: 0.7373 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9846  | total loss: \u001b[1m\u001b[32m1.20903\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9846 | loss: 1.20903 - acc: 0.7635 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9847  | total loss: \u001b[1m\u001b[32m1.11988\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9847 | loss: 1.11988 - acc: 0.7872 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9848  | total loss: \u001b[1m\u001b[32m1.38455\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9848 | loss: 1.38455 - acc: 0.7156 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9849  | total loss: \u001b[1m\u001b[32m1.27847\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9849 | loss: 1.27847 - acc: 0.7440 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9850  | total loss: \u001b[1m\u001b[32m1.18326\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9850 | loss: 1.18326 - acc: 0.7696 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9851  | total loss: \u001b[1m\u001b[32m1.09745\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9851 | loss: 1.09745 - acc: 0.7927 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9852  | total loss: \u001b[1m\u001b[32m1.33410\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9852 | loss: 1.33410 - acc: 0.7277 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9853  | total loss: \u001b[1m\u001b[32m1.23302\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9853 | loss: 1.23302 - acc: 0.7549 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9854  | total loss: \u001b[1m\u001b[32m1.47108\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9854 | loss: 1.47108 - acc: 0.6866 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9855  | total loss: \u001b[1m\u001b[32m1.35697\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9855 | loss: 1.35697 - acc: 0.7179 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9856  | total loss: \u001b[1m\u001b[32m1.62106\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9856 | loss: 1.62106 - acc: 0.6461 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9857  | total loss: \u001b[1m\u001b[32m1.49358\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9857 | loss: 1.49358 - acc: 0.6815 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9858  | total loss: \u001b[1m\u001b[32m1.37965\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9858 | loss: 1.37965 - acc: 0.7134 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9859  | total loss: \u001b[1m\u001b[32m1.27746\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9859 | loss: 1.27746 - acc: 0.7420 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9860  | total loss: \u001b[1m\u001b[32m1.18540\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9860 | loss: 1.18540 - acc: 0.7678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9861  | total loss: \u001b[1m\u001b[32m1.10209\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9861 | loss: 1.10209 - acc: 0.7910 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9862  | total loss: \u001b[1m\u001b[32m1.02631\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9862 | loss: 1.02631 - acc: 0.8119 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9863  | total loss: \u001b[1m\u001b[32m0.95704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9863 | loss: 0.95704 - acc: 0.8307 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9864  | total loss: \u001b[1m\u001b[32m0.89342\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9864 | loss: 0.89342 - acc: 0.8477 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9865  | total loss: \u001b[1m\u001b[32m0.83471\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9865 | loss: 0.83471 - acc: 0.8629 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9866  | total loss: \u001b[1m\u001b[32m1.15216\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9866 | loss: 1.15216 - acc: 0.7766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9867  | total loss: \u001b[1m\u001b[32m1.06559\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9867 | loss: 1.06559 - acc: 0.7990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9868  | total loss: \u001b[1m\u001b[32m1.32591\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9868 | loss: 1.32591 - acc: 0.7262 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9869  | total loss: \u001b[1m\u001b[32m1.22153\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9869 | loss: 1.22153 - acc: 0.7536 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9870  | total loss: \u001b[1m\u001b[32m1.42480\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9870 | loss: 1.42480 - acc: 0.6996 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9871  | total loss: \u001b[1m\u001b[32m1.31113\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9871 | loss: 1.31113 - acc: 0.7297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9872  | total loss: \u001b[1m\u001b[32m1.53195\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9872 | loss: 1.53195 - acc: 0.6710 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9873  | total loss: \u001b[1m\u001b[32m1.40885\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9873 | loss: 1.40885 - acc: 0.7039 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9874  | total loss: \u001b[1m\u001b[32m1.65349\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9874 | loss: 1.65349 - acc: 0.6407 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9875  | total loss: \u001b[1m\u001b[32m1.52021\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 9875 | loss: 1.52021 - acc: 0.6766 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9876  | total loss: \u001b[1m\u001b[32m1.76872\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9876 | loss: 1.76872 - acc: 0.6089 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9877  | total loss: \u001b[1m\u001b[32m1.62667\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9877 | loss: 1.62667 - acc: 0.6480 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9878  | total loss: \u001b[1m\u001b[32m1.83753\u001b[0m\u001b[0m | time: 0.012s\n",
      "| Adam | epoch: 9878 | loss: 1.83753 - acc: 0.5904 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9879  | total loss: \u001b[1m\u001b[32m1.69187\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9879 | loss: 1.69187 - acc: 0.6313 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9880  | total loss: \u001b[1m\u001b[32m1.56218\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9880 | loss: 1.56218 - acc: 0.6682 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9881  | total loss: \u001b[1m\u001b[32m1.44628\u001b[0m\u001b[0m | time: 0.028s\n",
      "| Adam | epoch: 9881 | loss: 1.44628 - acc: 0.7014 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9882  | total loss: \u001b[1m\u001b[32m1.65222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9882 | loss: 1.65222 - acc: 0.6384 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9883  | total loss: \u001b[1m\u001b[32m1.52864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9883 | loss: 1.52864 - acc: 0.6745 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9884  | total loss: \u001b[1m\u001b[32m1.41789\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9884 | loss: 1.41789 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9885  | total loss: \u001b[1m\u001b[32m1.31817\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9885 | loss: 1.31817 - acc: 0.7364 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9886  | total loss: \u001b[1m\u001b[32m1.46718\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9886 | loss: 1.46718 - acc: 0.6842 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9887  | total loss: \u001b[1m\u001b[32m1.36222\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9887 | loss: 1.36222 - acc: 0.7158 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9888  | total loss: \u001b[1m\u001b[32m1.51917\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9888 | loss: 1.51917 - acc: 0.6656 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9889  | total loss: \u001b[1m\u001b[32m1.40914\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9889 | loss: 1.40914 - acc: 0.6990 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9890  | total loss: \u001b[1m\u001b[32m1.59282\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9890 | loss: 1.59282 - acc: 0.6434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9891  | total loss: \u001b[1m\u001b[32m1.47598\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9891 | loss: 1.47598 - acc: 0.6791 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9892  | total loss: \u001b[1m\u001b[32m1.37094\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9892 | loss: 1.37094 - acc: 0.7112 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9893  | total loss: \u001b[1m\u001b[32m1.27606\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9893 | loss: 1.27606 - acc: 0.7401 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9894  | total loss: \u001b[1m\u001b[32m1.18992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9894 | loss: 1.18992 - acc: 0.7661 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9895  | total loss: \u001b[1m\u001b[32m1.11130\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9895 | loss: 1.11130 - acc: 0.7894 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9896  | total loss: \u001b[1m\u001b[32m1.03918\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9896 | loss: 1.03918 - acc: 0.8105 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9897  | total loss: \u001b[1m\u001b[32m0.97269\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9897 | loss: 0.97269 - acc: 0.8295 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9898  | total loss: \u001b[1m\u001b[32m1.27470\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9898 | loss: 1.27470 - acc: 0.7465 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9899  | total loss: \u001b[1m\u001b[32m1.18219\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9899 | loss: 1.18219 - acc: 0.7719 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9900  | total loss: \u001b[1m\u001b[32m1.09798\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9900 | loss: 1.09798 - acc: 0.7947 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9901  | total loss: \u001b[1m\u001b[32m1.02105\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9901 | loss: 1.02105 - acc: 0.8152 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9902  | total loss: \u001b[1m\u001b[32m1.32030\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9902 | loss: 1.32030 - acc: 0.7337 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9903  | total loss: \u001b[1m\u001b[32m1.21952\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9903 | loss: 1.21952 - acc: 0.7603 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9904  | total loss: \u001b[1m\u001b[32m1.12825\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9904 | loss: 1.12825 - acc: 0.7843 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9905  | total loss: \u001b[1m\u001b[32m1.04535\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9905 | loss: 1.04535 - acc: 0.8059 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9906  | total loss: \u001b[1m\u001b[32m0.96980\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9906 | loss: 0.96980 - acc: 0.8253 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9907  | total loss: \u001b[1m\u001b[32m0.90074\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9907 | loss: 0.90074 - acc: 0.8427 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9908  | total loss: \u001b[1m\u001b[32m1.12926\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9908 | loss: 1.12926 - acc: 0.7799 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9909  | total loss: \u001b[1m\u001b[32m1.04255\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9909 | loss: 1.04255 - acc: 0.8019 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9910  | total loss: \u001b[1m\u001b[32m1.35295\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9910 | loss: 1.35295 - acc: 0.7217 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9911  | total loss: \u001b[1m\u001b[32m1.24334\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9911 | loss: 1.24334 - acc: 0.7495 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9912  | total loss: \u001b[1m\u001b[32m1.53721\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9912 | loss: 1.53721 - acc: 0.6746 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9913  | total loss: \u001b[1m\u001b[32m1.40987\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9913 | loss: 1.40987 - acc: 0.7071 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9914  | total loss: \u001b[1m\u001b[32m1.61508\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9914 | loss: 1.61508 - acc: 0.6507 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9915  | total loss: \u001b[1m\u001b[32m1.48145\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9915 | loss: 1.48145 - acc: 0.6856 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9916  | total loss: \u001b[1m\u001b[32m1.74081\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9916 | loss: 1.74081 - acc: 0.6171 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9917  | total loss: \u001b[1m\u001b[32m1.59675\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9917 | loss: 1.59675 - acc: 0.6554 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9918  | total loss: \u001b[1m\u001b[32m1.82356\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9918 | loss: 1.82356 - acc: 0.5898 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9919  | total loss: \u001b[1m\u001b[32m1.67402\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9919 | loss: 1.67402 - acc: 0.6308 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9920  | total loss: \u001b[1m\u001b[32m1.54074\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9920 | loss: 1.54074 - acc: 0.6678 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9921  | total loss: \u001b[1m\u001b[32m1.42168\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9921 | loss: 1.42168 - acc: 0.7010 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9922  | total loss: \u001b[1m\u001b[32m1.65325\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9922 | loss: 1.65325 - acc: 0.6380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9923  | total loss: \u001b[1m\u001b[32m1.52458\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9923 | loss: 1.52458 - acc: 0.6742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9924  | total loss: \u001b[1m\u001b[32m1.70165\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9924 | loss: 1.70165 - acc: 0.6211 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9925  | total loss: \u001b[1m\u001b[32m1.57009\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9925 | loss: 1.57009 - acc: 0.6590 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9926  | total loss: \u001b[1m\u001b[32m1.45249\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9926 | loss: 1.45249 - acc: 0.6931 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9927  | total loss: \u001b[1m\u001b[32m1.34700\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9927 | loss: 1.34700 - acc: 0.7238 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9928  | total loss: \u001b[1m\u001b[32m1.57843\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9928 | loss: 1.57843 - acc: 0.6514 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9929  | total loss: \u001b[1m\u001b[32m1.46100\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9929 | loss: 1.46100 - acc: 0.6863 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9930  | total loss: \u001b[1m\u001b[32m1.66779\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9930 | loss: 1.66779 - acc: 0.6248 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9931  | total loss: \u001b[1m\u001b[32m1.54265\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9931 | loss: 1.54265 - acc: 0.6623 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9932  | total loss: \u001b[1m\u001b[32m1.73864\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9932 | loss: 1.73864 - acc: 0.6032 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9933  | total loss: \u001b[1m\u001b[32m1.60805\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9933 | loss: 1.60805 - acc: 0.6429 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9934  | total loss: \u001b[1m\u001b[32m1.49117\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9934 | loss: 1.49117 - acc: 0.6786 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9935  | total loss: \u001b[1m\u001b[32m1.38614\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9935 | loss: 1.38614 - acc: 0.7107 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9936  | total loss: \u001b[1m\u001b[32m1.57756\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9936 | loss: 1.57756 - acc: 0.6540 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9937  | total loss: \u001b[1m\u001b[32m1.46404\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9937 | loss: 1.46404 - acc: 0.6886 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9938  | total loss: \u001b[1m\u001b[32m1.65390\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9938 | loss: 1.65390 - acc: 0.6268 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9939  | total loss: \u001b[1m\u001b[32m1.53335\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9939 | loss: 1.53335 - acc: 0.6642 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9940  | total loss: \u001b[1m\u001b[32m1.75704\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9940 | loss: 1.75704 - acc: 0.5977 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9941  | total loss: \u001b[1m\u001b[32m1.62722\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9941 | loss: 1.62722 - acc: 0.6380 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9942  | total loss: \u001b[1m\u001b[32m1.51076\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9942 | loss: 1.51076 - acc: 0.6742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9943  | total loss: \u001b[1m\u001b[32m1.40583\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9943 | loss: 1.40583 - acc: 0.7068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9944  | total loss: \u001b[1m\u001b[32m1.56611\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9944 | loss: 1.56611 - acc: 0.6575 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9945  | total loss: \u001b[1m\u001b[32m1.45519\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9945 | loss: 1.45519 - acc: 0.6918 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9946  | total loss: \u001b[1m\u001b[32m1.63758\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9946 | loss: 1.63758 - acc: 0.6297 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9947  | total loss: \u001b[1m\u001b[32m1.51945\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9947 | loss: 1.51945 - acc: 0.6668 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9948  | total loss: \u001b[1m\u001b[32m1.41300\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9948 | loss: 1.41300 - acc: 0.7001 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9949  | total loss: \u001b[1m\u001b[32m1.31663\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9949 | loss: 1.31663 - acc: 0.7301 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9950  | total loss: \u001b[1m\u001b[32m1.22898\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9950 | loss: 1.22898 - acc: 0.7571 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9951  | total loss: \u001b[1m\u001b[32m1.14886\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9951 | loss: 1.14886 - acc: 0.7814 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9952  | total loss: \u001b[1m\u001b[32m1.41113\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9952 | loss: 1.41113 - acc: 0.7032 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9953  | total loss: \u001b[1m\u001b[32m1.31080\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9953 | loss: 1.31080 - acc: 0.7329 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9954  | total loss: \u001b[1m\u001b[32m1.21968\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9954 | loss: 1.21968 - acc: 0.7596 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9955  | total loss: \u001b[1m\u001b[32m1.13658\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9955 | loss: 1.13658 - acc: 0.7836 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9956  | total loss: \u001b[1m\u001b[32m1.40127\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9956 | loss: 1.40127 - acc: 0.7053 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9957  | total loss: \u001b[1m\u001b[32m1.29828\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9957 | loss: 1.29828 - acc: 0.7348 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9958  | total loss: \u001b[1m\u001b[32m1.20490\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9958 | loss: 1.20490 - acc: 0.7613 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9959  | total loss: \u001b[1m\u001b[32m1.11992\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9959 | loss: 1.11992 - acc: 0.7852 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9960  | total loss: \u001b[1m\u001b[32m1.04231\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9960 | loss: 1.04231 - acc: 0.8066 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9961  | total loss: \u001b[1m\u001b[32m0.97119\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9961 | loss: 0.97119 - acc: 0.8260 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9962  | total loss: \u001b[1m\u001b[32m0.90578\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9962 | loss: 0.90578 - acc: 0.8434 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9963  | total loss: \u001b[1m\u001b[32m0.84543\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9963 | loss: 0.84543 - acc: 0.8590 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9964  | total loss: \u001b[1m\u001b[32m0.78957\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9964 | loss: 0.78957 - acc: 0.8731 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9965  | total loss: \u001b[1m\u001b[32m0.73774\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9965 | loss: 0.73774 - acc: 0.8858 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9966  | total loss: \u001b[1m\u001b[32m1.04612\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9966 | loss: 1.04612 - acc: 0.8044 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9967  | total loss: \u001b[1m\u001b[32m0.96633\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9967 | loss: 0.96633 - acc: 0.8239 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9968  | total loss: \u001b[1m\u001b[32m1.28747\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9968 | loss: 1.28747 - acc: 0.7415 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9969  | total loss: \u001b[1m\u001b[32m1.18264\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9969 | loss: 1.18264 - acc: 0.7674 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9970  | total loss: \u001b[1m\u001b[32m1.47888\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9970 | loss: 1.47888 - acc: 0.6978 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9971  | total loss: \u001b[1m\u001b[32m1.35514\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9971 | loss: 1.35514 - acc: 0.7280 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9972  | total loss: \u001b[1m\u001b[32m1.24404\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9972 | loss: 1.24404 - acc: 0.7552 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9973  | total loss: \u001b[1m\u001b[32m1.14409\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9973 | loss: 1.14409 - acc: 0.7797 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9974  | total loss: \u001b[1m\u001b[32m1.05400\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9974 | loss: 1.05400 - acc: 0.8017 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9975  | total loss: \u001b[1m\u001b[32m0.97260\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9975 | loss: 0.97260 - acc: 0.8216 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9976  | total loss: \u001b[1m\u001b[32m1.31229\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9976 | loss: 1.31229 - acc: 0.7394 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9977  | total loss: \u001b[1m\u001b[32m1.20498\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9977 | loss: 1.20498 - acc: 0.7655 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9978  | total loss: \u001b[1m\u001b[32m1.51933\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9978 | loss: 1.51933 - acc: 0.6889 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9979  | total loss: \u001b[1m\u001b[32m1.39240\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9979 | loss: 1.39240 - acc: 0.7200 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9980  | total loss: \u001b[1m\u001b[32m1.27883\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9980 | loss: 1.27883 - acc: 0.7480 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9981  | total loss: \u001b[1m\u001b[32m1.17702\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9981 | loss: 1.17702 - acc: 0.7732 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9982  | total loss: \u001b[1m\u001b[32m1.43442\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9982 | loss: 1.43442 - acc: 0.7030 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9983  | total loss: \u001b[1m\u001b[32m1.31800\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9983 | loss: 1.31800 - acc: 0.7327 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9984  | total loss: \u001b[1m\u001b[32m1.21373\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9984 | loss: 1.21373 - acc: 0.7595 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9985  | total loss: \u001b[1m\u001b[32m1.12012\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9985 | loss: 1.12012 - acc: 0.7835 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9986  | total loss: \u001b[1m\u001b[32m1.03585\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9986 | loss: 1.03585 - acc: 0.8052 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9987  | total loss: \u001b[1m\u001b[32m0.95977\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9987 | loss: 0.95977 - acc: 0.8246 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9988  | total loss: \u001b[1m\u001b[32m0.89086\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9988 | loss: 0.89086 - acc: 0.8422 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9989  | total loss: \u001b[1m\u001b[32m0.82824\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9989 | loss: 0.82824 - acc: 0.8580 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9990  | total loss: \u001b[1m\u001b[32m0.77112\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9990 | loss: 0.77112 - acc: 0.8722 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9991  | total loss: \u001b[1m\u001b[32m0.71884\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9991 | loss: 0.71884 - acc: 0.8850 -- iter: 14/14\n",
      "--\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 9992  | total loss: \u001b[1m\u001b[32m0.67083\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9992 | loss: 0.67083 - acc: 0.8965 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9993  | total loss: \u001b[1m\u001b[32m0.62660\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9993 | loss: 0.62660 - acc: 0.9068 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9994  | total loss: \u001b[1m\u001b[32m0.87294\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9994 | loss: 0.87294 - acc: 0.8447 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9995  | total loss: \u001b[1m\u001b[32m0.80694\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9995 | loss: 0.80694 - acc: 0.8602 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9996  | total loss: \u001b[1m\u001b[32m1.17646\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9996 | loss: 1.17646 - acc: 0.7742 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9997  | total loss: \u001b[1m\u001b[32m1.07977\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9997 | loss: 1.07977 - acc: 0.7968 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9998  | total loss: \u001b[1m\u001b[32m1.34467\u001b[0m\u001b[0m | time: 0.008s\n",
      "| Adam | epoch: 9998 | loss: 1.34467 - acc: 0.7314 -- iter: 14/14\n",
      "--\n",
      "Training Step: 9999  | total loss: \u001b[1m\u001b[32m1.23184\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 9999 | loss: 1.23184 - acc: 0.7583 -- iter: 14/14\n",
      "--\n",
      "Training Step: 10000  | total loss: \u001b[1m\u001b[32m1.46120\u001b[0m\u001b[0m | time: 0.004s\n",
      "| Adam | epoch: 10000 | loss: 1.46120 - acc: 0.7039 -- iter: 14/14\n",
      "--\n",
      "INFO:tensorflow:C:\\Users\\Steven\\Documents\\HTN v. 4\\model.tflearn is not in all_model_checkpoint_paths. Manually adding it.\n"
     ]
    }
   ],
   "source": [
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 200)\n",
    "net = tflearn.fully_connected(net, 100)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')\n",
    "# Start training (apply gradient descent algorithm)\n",
    "model.fit(train_x, train_y, n_epoch=10000, batch_size=16, show_metric=True)\n",
    "model.save('model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all of our data structures\n",
    "import pickle\n",
    "pickle.dump( {'words':words, 'classes':classes, 'train_x':train_x, 'train_y':train_y, 'classes_details':classes_details}, open( \"training_data\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coreml_model = coremltools.converters.keras.convert(model)\n",
    "coreml_model.save('my_model.mlmodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
